\documentclass{report}
\usepackage[utf8]{inputenc}


\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{braket}

%\usepackage{stix}

%\usepackage[toc, page]{appendix}
%\usepackage[nottoc, numbib]{tocbibind}
\usepackage[nottoc]{tocbibind}
\usepackage[bookmarks=true]{hyperref}
\usepackage[numbered]{bookmark}

%%%\usepackage{hyperref}     
%%%\usepackage{amsthm}     
%%\usepackage{cleveref}
%\usepackage{silence}
%\WarningFilter{pdftex}{destination with the same}

\hypersetup{
	colorlinks	= true,
	urlcolor	= blue,
	linkcolor	= black,
	citecolor	= black
}

\usepackage{comment}

\usepackage{lipsum}


\title{
	Note collection (2023--20xx)
	\author{Mads J.\ Damgaard%
		%\footnote{
		%	See https://www.github.com/mjdamgaard/notes for potential updates, additional points, and other work.
		%}
		%\footnote{
		%	B.Sc.\ at the Niels Bohr Institute, University of Copenhagen.
		%	B.Sc.\ at the Department of Computer Science, University of Copenhagen.
		%	E-mail: fxn318@alumni.ku.dk.
		%	GitHub folder: https://www.github.com/mjdamgaard/notes.
		%}
	}
}

\usepackage[margin=1.5in]{geometry}

\begin{document}
\maketitle

\section*{Foreword}
{\centering\noindent
	\vspace{-\baselineskip}
	\hspace{-0.7em}
	{\hspace{-4.em}$|$\hspace{\linewidth}\hspace{8em}$|$}
}
Note collection from 10.01.23--???. 

%Kopieret nedenfra:
	%"(10.01.23) Okay, jeg har lige påbegyndt dette notesæt. Jeg er pt. i gang med at skrive version 2 (en meget mere simpel udgave) af min SRC-artikel, og så har jeg ikke kunne lade være med at bruge en del af tiden (som jeg "burde" have brugt på at skrive om SRC) på at tænke mere over, hvordan jeg ville starte mine hjemmesider, jeg har i tankerne, hvis jeg selv skulle gå i gang (hvad jeg faktisk stærkt overvejer). Særligt har jeg tænkt nogle tanker om en alternativ opsætning end den med fanerne, når det kommer til hele den applikation der. De tanker vil jeg skrive ned, når jeg vender tilbage her, sikkert senere i dag/aften. (For inden da vil jeg lige fortsætte lidt mere med SRC-arbejdet.) (17:17)"
%

\ 

%\lipsum[1]


\chapter{Web ideas}

%(10.01.23) Okay, jeg har lige påbegyndt dette notesæt. Jeg er pt. i gang med at skrive version 2 (en meget mere simpel udgave) af min SRC-artikel, og så har jeg ikke kunne lade være med at bruge en del af tiden (som jeg "burde" have brugt på at skrive om SRC) på at tænke mere over, hvordan jeg ville starte mine hjemmesider, jeg har i tankerne, hvis jeg selv skulle gå i gang (hvad jeg faktisk stærkt overvejer). Særligt har jeg tænkt nogle tanker om en alternativ opsætning end den med fanerne, når det kommer til hele den applikation der. De tanker vil jeg skrive ned, når jeg vender tilbage her, sikkert senere i dag/aften. (For inden da vil jeg lige fortsætte lidt mere med SRC-arbejdet.) (17:17)

\section{Nye tanker om, hvordan Web 2.0--3.0-siden kunne være til at starte med (10.01.23)}

(17:58, 10.01.23) Jeg har nogle nye tanker om, hvad jeg gør mht.\ mine hjemmeside-idéer. Sidst jeg skrev om det var for ret kort tid siden i mine 22--23-huskenoter, og inden da har jeg skrevet nogle tanker ned i det, der endte med at blive udkommenterede noter under SRC-artiklen (version 1). Men jeg har nu skiftet mening siden de noter. Jeg tænker således ikke længere på at starte med det der fane-værk. Nu har jeg en anden indledende opsætning i tankerne.

Men inden jeg går i gang med at beskrive den opsætning, så lad mig også lige sige, at jeg nu faktisk tænker at fokusere mest på web-applikationen, der har med semantiske strukturer, tag-ratings, opdelte kommentarer, ``automatiske point'' (og ``brugergrupper'') osv.\ at gøre, og derudover så også min debatside-applikation. Og jeg tænker så altså lidt at starte med førstnævnte emne, og så også tænke på at tilføje en debatside-applikation til den hjemmeside også inden for en nær fremtid efter, at jeg har fået den første applikation i gang. Desuden tænker jeg nu at gøre det open source. Jeg tænker altså ikke længere på at fokusere på at starte en SRC omkring det. I forhold til det monetære, så synes jeg nemlig, det er bedre at gøre dette i et separat lag oven over det applikationsmæssige lag. Så jeg tænker dermed altså, at den monetære del bare skal implementeres via donationer, og muligvis særligt via en donationsforening, ligesom.\,.

Ok. Nej, vent. Og fordi jeg vil gøre det helt open source, så tænker jeg altså også bare at tage med arme og ben fra andre open source-hjemmesider. Særligt kunne det være smart at tage fra en YouTube-agtig open source applikation og en Reddit/Twitter-agtig (måske Mastodon) applikation.\,. Og så altså derfra påsætte min.\,. hm, lad mig bare kalde det min `semantik-applikation' for nu; det er nemmere end, hvad jeg ellers har haft gang i (så som min ``Web 2.0--3.0-hjemmeside''). Jeg vil altså prøve at påsætte den applikation oven på de andre --- og efterfølgende påsætte en debatside-applikation oveni, så det bliver altså lidt af en Schweizerkniv-hjemmeside, men hvorfor ikke?\,. (sagde han helt naivt.\,. ej, jeg håber, det kommer til at give god mening sådan, 7, 9, 13).\,. 

Nå, og nu til at forklare, hvordan jeg tænker min semantiske applikation nu --- og det er ved at blive småsent, så jeg ser bare, hvor langt jeg når (og hvor sammenhængende det bliver), og så må jeg samle tråden op igen en af de kommende dage.

Som jeg forestiller mig min semantiske applikation nu (altså hvordan den kunne starte med at se ud rettere, for i fremtiden kan den så få alle mulige former, det er jo en del af det (altså at brugerne selv skal have frihed til at ændre udseendet)), så forestiller jeg mig altså bare en enkelt HTML-side, hvor at når man ser på lister over ressourcer, hvilket bliver en rigtig central del af applikationens brug, så er dette altså bare en liste midt på HTML-siden. Dog skal der så være en menu i siden, som gerne skal kunne være fold-ud. Denne menu bliver så til, hvad vi kan betragte som brugerens ``workspace.'' (Lad mig kalde det `arbejdsbord' på dansk.) .\,.\,Hm, lad mig lige holde en pause, og så ser jeg lige på, om jeg vender tilbage, eller om jeg bare holder for i dag.\,. (18:22)

(12.01.23, 16:58) I forgårs aften fik jeg tænkt lidt flere gode idéer omkring opbygningen, særligt af fold-ud-menuen. Men lad mig lige starte med at gie en helt grundlæggende beskrivelse, og så kan jeg føje flere detaljer til bagefter.

Lad os forestille os at en bruger kigger på kategorien `film,' og har valgt, ikke at se på en liste over film, men valgt at se en liste over underkategorier til kategorien `film.' Bemærk altså at `film' er implementeret, ikke som et er\_film-prædikat, men som et term simpelthen. Lad os så sige, at brugeren vælger `komediefilm.' Brugeren føjer hermed dette term til sit arbejdsbord, ved siden af `film.' Dette term ligger altså nu i fold-ud-menuen. Brugeren kan så nu i princippet gå til fold-ud-menuen og vælge en knap, der skifter visningen fra underkategorier\_af(term) til termer\_af\_kategorien(term). Og ved så at vælge `komediefilm' fra menuen (der også indeholder brugeren arbejdsbord nemlig), så får brugeren altså nu en liste over alle de termer, som passer på termer\_af\_kategorien(komediefilm). Dette er altså en mulig vej for brugeren i princippet, men allerede i prototypen af hjemmesiden skal det altså gerne være indbygget som en standard ting, at når brugeren har en liste over kategorier, så er der også en knap der gør disse ting på én gang, nemlig tilføjer kategorien til arbejdsbordet og går direkte hen til visningen af termer\_af\_kategorien(term), hvor inputtet så er den valgte kategori. 

Nu ser brugeren så en liste af ressourcer (komediefilm i dette tilfælde). Nu vil brugeren så måske gerne lægge et specifikt filter over denne liste, så kun visse ting bliver vist og i en vis rækkefølge. Nu kan brugeren så i fold-ud-menuen vælge en knap til at se, hvad vi kunne kalde filter-prædikater. Lad os sige, at brugeren allerede har browset film mange gange før og derfor har alle de almindelige filter-prædikater klar såsom `populær,' `godt bedømt' osv., men af en eller anden grund mangler prædikatet `sjov' i listen. Nu vil brugeren så gerne finde et sådant prædikat frem. Dette kan så gøres af to primære vejen, foruden at brugeren selvfølgelig kan lave en normal, ikke-semantisk søgning på prædikatet, hvilket man i praksis ofte vil gøre med tiden, men jeg har dog ikke i sinde at fokusere særligt på den mulighed med min prototype. I stedet kan brugeren enten gå til en grundlæggende visning over prædikat-kategorier, og så navigere frem til det ønskede prædikat, nemlig på samme måde som da brugeren navigerede til `komediefilm,' bare hvor brugeren altså nu søger i prædikat-kategorier (og til sidst -termer) og ikke i ressource-kategorier (og til sidst -termer). Når brugeren så har fundet prædikatet `sjov,' kan denne så tilføje det til arbejdsbordet, hvorved det så bliver vist i filter-prædikat-delmenuen. Ellers kan brugeren også forsøge at vælge en liste over prædikater\_relaterede\_til(term), hvor brugeren så kan vælge et term fra arbejdsbordet at putte ind her som input. Og her vil det jo så være oplagt, at brugeren inputter `komediefilm.' Den resulterende liste over prædikater kan så forestilles at indeholde det søgte prædikat (rimeligt tidligt i listen), og brugen kan så vælge det fra denne liste direkte. 

Når brugeren nu har tilføjet `sjov' til sine filter-prædikater, så kan brugeren nu gå tilbage og se termer\_af\_kategorien(komediefilm). Her kunne brugeren med fordel have valgt at navigere væk fra denne visning i første omgang med et midterklik, eller med ctrl + klik, således at den midlertidige søgning på prædikatet foregik i en ny fane. Pointen er nemlig, at arbejdsbordet skal ændres på tværs af faner (hvis brugeren altså bliver i det samme workspace, men det kommer vi til). I så fald kan brugeren bare klikke tilbage til browserfanen, hvor han/hun kom fra, og får herved nu vist `sjov' i filter-prædikat-menuen. 

Nu kan brugeren så tilpasse filteret mht.\ dette prædikat, hvilket indebærer at basalt set indstille en kurve over en akse for, hvor `sjov' filmen er. Jeg forstiller mig således en todelt gaussisk kurve, som altså næsten er en gaussfunktion, bortset fra at den kan have to forskellige spredninger til hver side (så altså en asymmetrisk version af en gausskurve). I dette tilfælde vil brugeren så sandsynligvis ønske at sætte toppunktet for kurven i enden, hvor `sjov' er mest gældende. Herefter kan brugeren så bestemme spredningen til den eneste af de to sider, der her er relevante. Og sidst men ikke mindst skal brugeren også kunne indstille en min- og en maks-værdi til filteret, således at for eksempel ingen film bliver vist, der har under en vis `sjov'-score. 

Jeg forestiller mig mere specifikt dermed at brugeren får vist tre barer, når brugeren folder indstillingerne ud for et filter-prædikat: Den første har én knap, der kan bevæges over hele baren, og som bestemmer kurvens toppunkt. Den næste bar kunne så være til at indstille de to spredninger og kunne så være en todelt bar, hvor knappen i hver siden kan sættes tæt på midten eller tæt på den respektive ende af baren, alt efter om spredningen til den side skal være lille eller stor (helt flad kurve, hvis man sætter dem i endepunkterne). Den sidste bar kan så være to knapper, der også kan sættes hvor som helst, og som så angiver min- og maks-værdierne for filteret. Imens brugeres finindstiller filter-prædikatet således, forestiller jeg mig, at brugeren også for vist den pågældende kurve i en lille graf over barerne. 

Nu kunne man så tro, at brugeren bare vil tage en virkelig lille spredning for kun at vise de film, der er har fået de allerhøjeste `sjov'-scorer, men i så fald ville de andre filter-prædikater, såsom f.eks.\ `godt bedømt' *(`god,' rettere) blive ubetydende, og derfor kan det altså ofte give god mening ikke at gøre kurverne alt for smalle. 

Cool, lad mig lige tænke over, om der er mere jeg skal sige til denne første lille del-rundgang, og ellers vil jeg gå over til at opsummere detaljerne, som jeg har tænkt mig nu her omkring denne nye opsætning (efter en lille pause.\,.). (17:55)

(18:09) Jo, jeg skal selvfølgelig også lige omkring det her med at rate ressourcer. Lad os sige, at brugeren undrer sig over, at en vis komediefilm kommer enten tidligt eller sent i listen, og så kigger på `sjov'-ratingen og ser, at den ikke ser ud, som brugeren ville forvente/synes. Så bør brugeren så kunne klikke sig ind på en rating-visning, nu hvor.\,. hm, jeg skulle til at skrive, at det er hvor alle andre spredninger er sat til uendeligt og at alle andre kurver end det relevante prædikat dermed bliver til firkantede trinkurver mellem deres valgte min- og maks-værdier i stedet, men er det nu også virkelig ideelt.\,.\,? 

\ldots Ah, man skal selvfølgelig bare have nogle separate filter-indstillinger for at vise rating-lister, og i starten vil de fleste så sikkert kunne nøjes med at bruge et enkelt prædikat udover det pågældende man rater i forhold til, og det er så popularitetsprædikatet. Senere kan man så prøve at implementere nogle indstillinger, hvor brugerne også får prioriteret at vise termer, der er bekendte for brugeren i listen, men det vil så være mere kompliceret at få dette op at køre. Så ja, når brugeren trykker, at denne vil ind og rate termerne, f.eks.\ ift.\ sjovhed i dette tilfælde, så får brugeren altså bare en ny rating-visning, hvor der også er særlige filter-indstillinger til, og hvor brugeren så kan rate ressourcerne/termerne. Og som jeg har forklaret i tidligere noter, så forestiller jeg mig altså her, at brugeren så særligt skal kunne rate termer/ressourcer (ift.\ pågældende prædikat) ved at trække termen op eller ned i listen --- og hvor brugeren kan zoome ind og ud i, hvor mange termer, der vises i listen, hvilket så altså meget vel ofte kunne indebære at indstille på, hvor mange termer vises i listen efter popularitet (altså mere præcist stille på, hvad min-værdien er for popularitet i listen). (Og jeg forestiller mig altså, at brugeren endda kan ``zoome ind og ud'' imens denne trækker en ressource/et term også.) 

Når brugeren så har rykket lidt rundt på termer i denne liste og derved givet dem rating i henhold til pågældende prædikat, kan brugeren jo så gå tilbage til, hvad brugeren egentligt var interesseret i, nemlig at se på en liste over sjove komediefilm. Slut på denne lille overordnede rundgang. Og så kan jeg skrive nogle flere detaljer om disse seneste idéer en anden dag (måske i morgen). (18:58) 

.\,.\,Hm, lad mig lige nævne, at når brugeren skifter type af visning, altså hvis denne f.eks. skifter fra ressource- til prædikat-visninger.\,. hm.\,. .\,.\,Hm, jeg skulle til at skrive noget med, at det ofte gerne må være standarden, at når brugeren går til en anden visning, at der åbnes en ny fane i browseren, men på den anden side er dette svært at sige præcis, hvad der er smartest her. Og måske er det fint, hvis brugeren bare husker at trykke ctrl (eller midterklik) på de rette tidspunkter og, nå ja, så kan brugeren jo altid gå tilbage i browseren --- især idet listerne som regel er simpel HTML, hvilket sikkert vil sige, at browseren endda tit vil kunne huske, hvor i listen brugeren var og dermed kan vende tilbage til samme sted.\,.\,:) 


(13.01.23, 16:40) Nu vil jeg så prøve at tilføje lidt flere detaljer om den opsætning, jeg nu tænker, at prototypen på den semantiske hjemmeside kunne have. Ja, og jeg kan jo starte med at sige, at jeg jo tænker at hjemmesiden kunne have flere applikationer i sig, bl.a.\ en YouTube-agtig applikation og en Reddit-/Twitter-/9gag-agtig applikation, hvor brugere så kan uploade ressourcer i forbindelse med de applikationer, som så derefter også kan findes i den semantiske applikation.

Og hvis vi så ser på den semantiske applikation, så forestiller jeg mig altså en ret central fold-ud-menu, hvor brugerne kan skifte visningen som beskrevet lige her ovenfor. Og når brugeren skifter visningen skal det så bare i prototypen føre til en ændret URL, hvilket så gør at brugerne kan gå frem og tilbage i deres seneste visninger, og åbne flere faner for visninger, ved simpelthen bare at bruge deres browsers velkendte funktionalitet hertil.

Fold-ud-menuen kan så have en liste af faneblade i toppen, der afgør, hvilket workspace brugeren arbejder i. Som sagt, så skal det være sådan, at hvis brugeren føjer en ting til et givent workspace i én fane, så skal ændringen ske i alle faner (som opdateres, når brugeren klikker ind på den igen (eller når brugeren går frem og tilbage i sin sessions browserhistorik)). Men ændringen skal dog kun ske i pågældende workspace.

Nedenunder denne liste kan så være endnu en liste over overordnede undermenuer i fold-ud-menuen. Den mest centrale undermenu er så den, hvor alle de tilføjede termer i workspace'et findes. Jeg forestiller mig, at en mulig løsning her for prototypen kunne være en træ-struktureret menu a la den jeg har her ude i venstre side af min TeXstudio-editor over sektioner og undersektioner (og hvor man så kan folde oversektionerne ind og ud). Sådanne oversigter har sikkert et teknisk navn, men det kender jeg ikke lige på stående fod. Og en endnu simplere løsning, måske til en tidlig version af prototypen, kunne bare være at have en enkelt liste ordnet kronologisk ift.\ hvornår termerne sidst blev brugt/tilføjet. I øvrigt kunne man også tænke sig en blanding af disse muligheder, sådan at man tilføjer endnu en fane af muligheder, hvor den ene så er omtalte træ-struktur-oversigt, og hvor den/de andre bare er lister over seneste brugte og/eller seneste valgte og/eller seneste tilføjet.\,. Ok.

Men udover at se lister over termer (som altså også inkluderer prædikater og relationer --- og også relationer og input-termer sat sammen til prædikater), som så kan bruges til at vælge nye visninger med, så skal der også være en (overordnet) undermenu med filter-prædikater, som nævnt i overordnede tekst. Og der skal være en menu specifikt beregnet til rating-visningerne (altså når brugeren iagttager en liste med udgangspunkt i et specifikt prædikat, som termerne i listen så kan rates i forhold til (gerne ved at brugeren kan flytte op og ned på termer)). 

En anden undermenu, der faktisk bliver ret væsentlig selv på nogenlunde kort sigt, er en hvor brugerne kan vælge indstillinger for, hvordan de gerne vil have diverse ressourcer og lister vist. Her bør man så faktisk ret hurtigt gøre det til en del af applikationen, at brugere kan aktivere CSS styles for diverse ressource-typer. (Og ja, det er en god idé, at man fra start af indfører diverse typer for de forskellige, ja, typer af ressourcer. Så applikation skal altså have et helt typesystem, hvor brugere kan tilføje nye typer, og hvor man så også har indbyggede list-constructor're til at danne list-typer. Her kan der så endda være forskellige typer alt efter om vi f.eks.\ snakker en standard oversigtsliste, eller om vi snakker om en liste beregnet til en rating-visning. Når en bruger opretter en ny ressource-type, så sker dette ved at definere et HTML-template for typen.\,. Tja nej, faktisk to HTML-templates: Et der udgør selve ressourcen, og et der udgør den data, der skal vises, når ressourcen indgår i en listeoversigt over flere ressourcer (f.eks.\ thumbnail og kort beskrivelse og sådan). Indholds-HTML-skabelonen bør så også have datafelter i sig med f.eks.\ titel, tilhørende tekst, og hvad man ellers kan finde på, og hvis ressourcen indeholder et billede eller en video af en art (måske i et eller andet fast format), så skal skabelonen selvfølgelig også indeholde de datafelter. Når så en type er oprettet, og brugere skal uploade andre instanser af typen, så skal de så bare uploade data af passende formater, der passer til felterne i HTML-skabelonen. Og når brugere så får vist ressourcen, så sættes alle disse datafelter altså ind i HTML-skabelonen. Og når brugerne for vist en liste over ressourcer af den pågældende type, så vil elementerne i listen vises i form af den anden HTML-skabelon, hvor det passende data (så som f.eks. thumbnail og kort beskrivelse) er loadet ind. Og for så at vende tilbage til den undermenu, som vi startede med at snakke om, så skal brugere altså gerne kunne indstille, hvordan diverse typer helt præcist skal vises, bl.a. ved at vælge CSS-indstillinger. Og på sigt (gerne kort sigt) skal brugerne endda og også få mulighed for at ændre i og lave tilføjelser til selve HTML'en (ligesom browserudvidelser fungerer), sådan at de kan få vist det lige som de vil have det. 

I øvrigt, og det gælder både, når brugere opretter HTML-skabelonerne, og når brugere opretter udvidelser til eksisterende HTML-skabeloner, så vil det være godt på sigt at få det sådan, at brugere kan lave (div-)felter i skabelonerne, som faktisk får mulighed for at query'e selve hjemmesidens database, og altså vise ting fra denne database. Dette kommer til at gøre, at man kan få levende ressourcer, hvis udseende og struktur kan afhænge af databasens tilstand. For eksempel kunne man lave HTML-skabeloner, der automatisk henter lister over mest relevante ressourcer til pågældende ressource, eller henter kommentarer, ratings, annotationer osv.\ osv.


Det skal så dog nævnes, at den semantiske applikation allerede indeholder en måde, hvorpå brugere kan kommentere ressourcer, nemlig ved at tage termen, der udgør ressourcens reference, og så vælge en relation i den forbindelse, således at man danner et prædikat: er\_kommentarer\_tilhørende\_ressourcen(term), hvor `term' så her er en placeholder for på-gældende ressource. Herved kan man altså gøre kommentarer til ressourcer til en del af den samlede (semantisk strukturerede).\,. database, eller rettere: selve den underlæggende database bør jo (nok) bare være en relationel database, men udefra set får man altså en semantisk struktureret database, og det er altså det jeg mener, når jeg siger en semantisk struktureret database; det er sådan, den ser ud fr brugerne. 


Nå, tilbage til fold-ud-menuen: Derudover kunne det nok også være smart (på sigt) med menuer, mest for de avancerede brugere, til at vælge opsætningsindstillingerne for selve fold-ud-menuen, sådan at selv denne bliver en del af alt det, som brugerne i sidste ende selv kan bestemme opsætningen for.

Ok, så det var altså den overordnede struktur.\,. Nå ja, på nær at jeg også lige kan nævne, at man på sigt også kan åbne op for, at selve applikationen får sin egen måde at have gang i flere visninger på én gang, sådan at dette ikke bare kun opnås via browserens funktionalitet (og ved hele tiden at skifte URL for hver visning). Så på længere sigt skal man måske også gøre, så at brugere kan implementere sådan navigation, og også gerne mulighed for f.eks.\ split-screen-visning, i applikation selv. 

Okay. Det var den gennemgang. Så havde jeg vist lige en eller flere ekstra punkter, som jeg også gerne ville nævne (men som jeg dog har talt om i tidligere noter), hvis jeg ellers kan huske, hvad de var.\,. (Og hvis det altså ikke bare var dem, jeg allerede har nævnt nu her.\,.) .\,.\,Nå, hvis der ar noget mere, så er det lige glippet, så jeg vil bare gå og summe lidt over det, og så ellers bare vende tilbage, når jeg finder nogen tilføjelser, jeg også bør nævne. (17:44)

(14.01.23, 11:48) Okay, der er nogle tilføjelser, jeg mangler, og jeg har også tænkt på lidt nye ting. Jeg mangler at nævne, at al data gerne skal gemmes via, hvad der svarer lidt til tripletter, men hvor de dog ikke behøver at være begrænset til 2-nære relationer; de kan også være 1-ære (altså prædikater) og 3-nære. Der må så vidt jeg kan se også være relationer med endnu flere input en tre, hvis brugerne får behov for dette. Og foruden relation-ID og ID på alle input objekterne (hvilke også kan være placeholders, for man skal f.eks.\ gerne kunne danne prædikater ud fra (f.eks.) en 2-ær relation og en inputterm, so vi har set ovenfor), så skal der også i alle disse udvidede tripletter være bruger-ID for hvem, der siger/har uploadet udsagnet, samt også et tal, der bestemmer hvor meget brugeren mener at udsagnet er sandt, og som i øvrigt også kan være negativt, således at brugeren kan negere udsagnet uden at skulle skifte relation. Dette med at alle udvidede tripletter, som jeg fra nu af vil kalde udsagn, har sådan en floating point rating med sig, er faktisk en super vigtig ting for hele idéen. Uden dette ville applikationen ikke blive nær den samme. .\,.\,Og endda selv for mange relationer, hvor man umiddelbart tror, at man kun er interesseret i at høre en sandt-eller-falsk vurdering fra brugere, kan det alligevel være gavnligt med et floating point-tal --- ikke for alle tilfælde (og så må man bare omfortolke tallet til en binær størrelse), men for mange. For eksempel hvis vi tænker på et udsagn: ``hører denne term til en vis kategori eller ej?'' (som underkategori eller som genstand, der hører til kategorien). Her skulle man tro, at man bare var interesseret i et ja-nej-svar fra brugerne, men faktisk kan det her være rigtigt gavnligt, hvis udsagnene alligevel kan gradbøjes, for nogle underkategorier (eller ressourcer) bare mere relevante end andre, og hermed kunne man altså få en nem måde at gøre, så at når en bruger ser på underkategorier til en kategori, så er det de mest relevante underkategorier, der popper frem øverst på listen. 

Jeg fik heller ikke nævnt noget, jeg ville sige om mine ``brugergrupper,'' som jeg har skrevet en del om i tidligere noter (se disse). Angående dette emne, så tror jeg bare man skal starte med den type ``brugergrupper,'' hvor en vis gruppe af brugere (muligvis bare én) starter med en lige mængde af nogle delelige tokens, der giver dem stemmevægt ift.\ at bedømme udsagn. .\,.\,Hov vent, jamen \emph{skal} vurderingerne så komme med udsagnene, eller skal udsagnene gemmes for sig, og så kan brugeres vurderinger af dem gemmes for sig også.\,.\,? Hm.\,.\,. (12:12) .\,.\,Hm, og brugeren, der uploadede udsagnet, bør i så fald også bare gemmes som et separat udsagn, oprettet automatisk af serveren.\,. hm, så man også kan slette det igen uden at slette brugeren, men hvordan ser man så.\,. Nå jo, i princippet kan serveren så oprette to udsagn for at gemme, at brugeren var ophavsmanden; udsagnet selv og så et udsagn om, at denne server siger, at det var den bruger (med 100\,\% sikkerhed, hvorfor ikke?\,.), der uploadede det originalt (eller rettere set med pågældendes servers øjne (men den siger så ikke noget om, hvorvidt andre brugere var først på andre servere)). Ja, sådan kunne det sagtens være.\,. Hm.\,. \ldots Ja, så nu går jeg faktisk ind for tripletter igen (har jeg ellers ikke gjort i lang tid, mener jeg).\,. .\,.\,Hm, og man kan så faktisk bare droppe de der server-vurderinger,
hvis man bare i stedet gør sådanne, at visse relationer er off-limits ift. hvad brugerne selv kan uploade, nemlig de relationer som er beregnet til at blive ``uploadet''af serveren(erne). 

Nå, men tilbage til ``brugergrupper.'' Omtalte tokens kan så deles i flere, og de kan så efterfølgende gives (delvist) ud til andre brugere. En giver af tokens i en brugergruppe må i reglen godt altid annullere en overførsel af tokens, medmindre.\,. Ja, lad mig sige det sådan her: Tokens kan lånes ud til andre brugere, som kan låne dem videre ad libitum, og hvis så en udlåner af tokens skifter mening, kan denne hive sine tokens tilbage med det samme (uanset hvor mange gange, de er lånt videre). Brugere kan også \emph{give} tokens til andre brugere, nemlig hvis de gerne vil pensioneres som ansvarshaver i brugergruppen. Hver token har så en et floating point number, der bestemmer stemmevægten, som gives af denne. Den samlede stemmevægt summer så op til 1. Og bum, så har man allerede et ret effektivt system til at danne diverse grupper.

Pointen med ``brugergrupper'' er så, at brugere skal have mulighed for, når de indstiller et filter-prædikat, at vælge hvilken/hvilke brugergrupper, som vurderingen skal beregnes ud fra. Så i pågældende menu skal der altså gerne for hver filter-prædikat være en knap til at folde en liste af brugergrupper ud (inkl.\ den basale, hvor alle brugere bare har én stemme), og hvor man så, muligvis ved at indstille vertikale barer tilhørende hver brugergruppe, kan indstille sin vægt til hver brugergruppe i filteret. 

Ok, det var allerede rimeligt dækkende, men jeg har stadig en del flere ting, der skal nævnes, og faktisk også som skal overvejes. Men lad mig starte med en positiv ting, og det er, at brugerne via de ovenfor omtalte HTML-skabelon-udvidelser kan implementere diverse knapper og fold-ud-menuer, når ressourcer af en vis type vises i en liste. For eksempel skal der som en standard være en ``udvidelse'' (som dog altså er standard) til visningen af kategorier i lister.\,. lad mig sige `visning af kategori-\emph{referencer}' fra nu af, som giver mindst to knapper: én hvor brugeren bliver ledt hen til underkategorier (og får kategorien tilføjet til workspacet, om ikke andet så i menuen af `seneste termer' (af typen `kategori')), og én hvor de brugeren bliver ledt hen til en visning over ressourcer/termer i kategorien. .\,.\,Nå ja, og der skal så også gerne være en knap, der leder brugeren hen til en visning over prædikater, der relaterer sig specifikt til den kategori. Denne ``udvidelse'' skal så gerne oprettes, inden applikationen åbnes op for almindelige brugere. 

Og lad mig lige indskyde, at filter-menuen gerne skal have nyligt tilføjede prædikater vist i toppen, da man må regne med, at brugere ikke nær så ofte vil behøve at stille på de typiske prædikater. Men hvis brugere alligevel har nogle typiske prædikater, de gerne tit vil stille på, så skal de så bare have lov til at ``pinne'' dem til toppen af menuen, som man siger. 

\ldots Hm, nu overvejer jeg, om der overhovedet er så mange flere ting, der skal siges i denne omgang, for jeg synes egentligt, at løsningen med hurtigt at arbejde i HTML-udvidelser til referencevisningerne faktisk løser meget af det problem, jeg havde, med at det virkede for indviklet at bruge applikationen i udgangspunket. Jeg tænker lige lidt mere over det, men nu vil jeg ellers bare lige tilføje den idé, at der også skal være en (overordnet) undermenu i fold-ud-menuen (som mange brugere i øvrigt sikkert vil have konstant foldet ud, hvis de arbejder på en computer (ikke en telefon)), som simpelthen er en konsol, hvor brugere kan skrive de udsagn (med placeholders), de gerne vil søge på, og også dem de gerne vil uploade, og hvor der så bør være automatiske forslag til udfyldning af ordene, hvor applikationen altså så (primært) søger i termerne i brugerens workspace, når den skal give forslag til udfyldning af ordene (altså `word completion'). (13:39)  

\ldots\ Der vil også være behov for tokens, der ikke kan videregives af modtager (og som modtager i øvrigt ikke skal acceptere eller afslå, men bare får tildelt sig af en anden). Dette kan f.eks.\ bruges til at flagge spammere; så kan de styrede brugere uddele tokens, enten til alle spammere, eller alle ikke-spammere (som man ikke har mistanke til). Brugere kan så bruge disse bruger-grupper i et er\_spammer- eller et kommer\_fra\_en\_spammer-filterprædikat. (18:03)

(16.01.23, 16:30) Der skal også være en slags automatiske brugergruppe tokens, men nærmere bestemt kan man også kalde dette for `automatiske point.' Vi snakker altså point, som kan gives til brugere --- eller til alle mulige andre termer i databasen, nemlig (og bruger-ID'er indgår nemlig også i databasen som termer) --- ud fra data i databasen om dem. Dette kan så specifikt bruges til at implementere, hvad jeg også i mine tidligere noter har kaldt `brugerdrevet machine learning (ML).' Hvis vi så tager en vis korrelationsegenvektor, når man har lavet ML-statistik over brugerne af applikationen, så kan man altså nu, via disse `automatiske point,' tildele brugere point alt efter, hvor stor projektionen af deres brugerdata ind på på gældende egenvektor er. Og dette kan man jo så bruge videre i diverse filter-indstillinger. For eksempel kunne man forestille sig, at man kunne sige: `sorter disse film ud fra `sjovhed,' med særlig vægt på folks vurderinger, som følger den og den korrelationsvektor. Og ja, man kan i øvrigt også gøre mere simple ting, så som bare at sige: `sorter disse film ud fra `sjovhed,' med særlig vægt på folks vurderinger, der også synes at det og det var sjovt --- altså en mere simpel form for statistisk brug a brugerdata i brugerlavede filteralgoritmer. Mulighederne er virkeligt åbne.

Og måden man så kan query'e databasen om sådanne point kan så bare være ud fra en syntaks, der følger det logiske programmeringsparadigme, nemlig således at pointen både gemmes som tripletter i databasen for hver bruger, og hvor man så kan query'e disse point via den relation, der nu hører til pointene. (16:45) .\,.\,Og lige for at præcisere, så er det altså brugerne selv, der kan uploade forslag til nye automatiske point, nemlig ved at de så uploader den relevante metadata, samt den formel, som det hele handler om, nemlig den formel ud fra hvilken de automatiske point bliver givet til termerne (som i øvrigt i reglen vil være af en bestemt type, som så også defineres som en del af omtalte metadata (eller `header-data' er nok mere rigtigt at kalde det.\,.)). 

(17:13) Jeg havde også i sinde at skrive lidt om, hvordan jeg så forestiller mig, at man også kunne implementere en ``debatside-applikation'' i dette system, hvor brugerne kan bruge dette brugergruppesystem, og jeg kunne måske også finde på nogle små nye tilføjelser i denne forbindelse, men jeg tror nu, jeg bare vil lade emnet være for nu. Jeg har skrevet fint om det, i mine tidligere noter, og selvom jeg sikkert kunne finde på nogle små ting at tilføje, så tror jeg ikke, det vil ændre så meget på idéen overordnet set. Så lad mig lade det emne være for nu. Det ville alligevel også skulle implementeres \emph{efter}, at man får den semantiske applikation op og køre.

Jeg bør også på et tidspunkt vende tilbage her og overveje nærmere, hvad jeg skal begrænse en prototype til, for lige nu har jeg nævnt væsentligt flere features, end man bør prøve at få med fra start af. Hm, jeg mener dog, det vil være en god idé, hvis man så hurtigt som muligt gør, så at brugerne selv kan lave omtalte HTML-udvidelser. Men ellers er det nu godt bare at starte simpelt, og så bygge på derfra. (17:20)

\ 

(24.01.23, 11:39) Man kan sagtens bruge triplet-konstruktioner, man kan også sagtens tillade +2-ære relationer, hvis man vil, det betyder ikke så meget, for man kan altid omstrukturere, hvis man finder ud af, at der er en bedre standard. Så længe brugerne har frihed til at skabe de konstruktioner, de vil, og at grammatikken i disse konstruktioner er veldefineret, så går det fint. To gode muligheder er derfor, 1, kun at tillade 3-term-konstruktioner (tripletter), eller at gøre det helt frit ligesom i en logisk database.

Nu kommer det mere vigtige, dog: I første omgang handler det hele om at konstruere `udsagn' (som brugerne så efterfølgende kan rate (bedømme)). Men disse udsagn skal så \emph{ikke} tolkes som i standard formel logik, hvor har en binær (boolsk) værdi, så at sige. I stedet skal de ses som termer, der beholder informationen om hele deres indre konstruktion, når de indgår i en kontekst som sammensat formular. Hermed for man nemlig særligt mulighed/lov til at sige ting som: ``Jeg synes udsagnet er\_sjov(film) er sand til en grad af 9/10 rating score.'' Man åbner altså herved op for en meget mere intuitiv måde at kontruere sætninger på, en hvis man skulle beskrive den samme sætninger ud fra mere formel logik, hvor er\_sjov(film) altså bare ville være en binær værdi over alt, hvor den indgår, og hvor denne sætning så ikke ville give nogen mening. Man kan så også konstruere mange volapyksætninger med denne semantisk, og kan altså lave ugyldige og eller paradoksale sætninger, men det er kun et sundt tegn, ift.\ hvad sproget skal bruges til. 

De helt centrale udsang, som nemlig er de eneste udsagn, der repræsenterer direkte \emph{sandheder} i systemet, det er så rating-udsagnene. Disse består af et bruger(-ID)-subjekt, et udsang-term (så som `er\_sjov(film)') og så en rating score. Tja, eller dvs., der mangler én mere information her, og det er informationen om, hvad konteksten er for ratingscorens talværdi. Her kan man så eksempelvis, hvis man tillader +2-ære relationer, som jeg så forresten i virkeligheden er funktioner, fordi alle udsagn er termer (og disse funktioner vil så i øvrigt også som regel være bijektive, i henhold til hvad jeg lige nævnte om, at information ikke bør gå tabt i udsagnene (indmaden forsvinder ikke, med andre ord; hvert udsagn ``kender'' sit eget udsende på papiret)).\,. hvis man tillader 2-ære relationer, så kan man så tilføje en funktion, der sender et udsagn så som `er\_sjov(film)' til et nyt udsagn, der siger ``er\_sjov(film) ud fra ratingscoren $x$,'' hvor $x$ så også er input til omtalte funktion. Nå ja, så lige med dette eksempel er der så ikke behov for +2-ære relationer, eller funktioner rettere, men hvis man skal kunne sådanne ting, så bør man dog kunne have funktioner af alle mulige typer (og ordner). *(Hm, så never mind, at tripletter er fine for systemet. Jeg synes faktisk, at databasen bare mere bør være som en logisk database.)

*Hov, jeg skal forresten lige nævne, at de eneste restriktioner i databasen, udover på hvor meget data og hvor mange termer hver bruger må uploade hver dag/uge/måned, hvilket i øvrigt vil være en god idé at have, nok ellers bare skal være, at det kun er brugeren selv, der må uploade rating-udsagn, hvor brugerens bruger-ID indgår. Så hvis en bruger-udsagn-rating-instans forekommer i databasen, så er det fordi pågældende bruger har givet den rating. Hver bruger skal også have mulighed for at slette sine egne ratings igen fra databasen (hvorfor det faktisk ikke dur med et decentralt system, synes jeg). I den forbindelse kan jeg så også nævne, at man godt kan få det sådan på sigt, at ressourcer faktisk automatisk sender rating-information til databasen på brugerens vegne (hvis brugeren har valgt de ``HTML-udvidelser,'' der gør dette), hvilket f.eks.\ så kan bruges til at sende, om brugeren har set en vis ressource eller ej (hvilket kan bruges til at fjerne gengangere i et feed, f.eks.), men så kan brugeren altid bare selv fjerne sådant data igen efter eget behov. Nå ja, og herved er det jo så også vigtigt lige at nævne, at brugerne sagtens skal kunne uploade data til deres egen private del af databasen, sådan at f.eks.\ ikke alle kan se den data om, hvad brugereb har set og ikke set, eller kan se alt hvad brugeren har ratet for den sags skyld. Brugerne kan sagtens rate rent anonymt, og så bare kun bruge den data til at forbedre egen oplevelse, hvis de vil. Men de kan så selvfølgelig også vælge at offentliggøre noget af denne data (dog med mulighed for at slette det igen fra den offentlige del af databasen), hvis de gerne vil bidrage til, hvad andre brugere ser af brugerratings (hvad de fleste brugere gerne vil; det er typisk en vigtig del af, hvorfor vi normalt afgiver ratings rundtomkring på internettet). (12:42)

Men kommer brugerne ikke bare til at bruge den samme type rating hele tiden? Nej, jeg har nemlig tænkt på, at det vil være rigtigt gavnligt, hvis brugerne selv kan vælge, hver gang de rater, om de bare vil rate ud fra en treværdi-score, nemlig negativ, neutral, positiv, eller om de vil bruge flere muligheder, f.eks. fem stjerner eller ti stjerner, eller hvad det kunne være. Og her snakker vi så ikke den rating, jeg har beskrevet, hvor brugerne rater ud fra en liste med en masse andre relevante ressourcer i. Her snakker jeg, hvis brugerne bare skal rate ressourcen alene i dens egen kontekst, enten på ressourcens egen side, eller måske når den vises i en liste. 
\ldots(12:42) Her er det jo så vigtigt, at brugerne så kan sætte dette i system, så de alle kan kende forskel på, hvad den pågældende ratingscore repræsenterer. 

Jeg har skrevet ovenfor et sted, at man kun skal have termerne ordnet ud fra det (filter-)prædikat, man rater med hensyn til, når man rater ressourcer ud fra en liste, og at alle andre filter-prædikater så kun skal være et spørgsmål om at sortere ressourcer fra i listen. Men dette behøver ikke nødvendigvis at være sandt. Man kunne således godt tænke sig, at.\,. Tja, eller rettere, det skal nok være det samme prædikat, så som eksempelvis `er\_sjov()', men det behøver ikke nødvendigvis kun at være én type ratingscore, man så bruger til ordningen. Men kunne således godt forestille sig en ordning, hvor både folks negativ-neutral-positiv-ratings er med, hvor femstjernede og tistjernede (etc.) ratings tæller med, og hvor selvfølgelig folks rating-ud-fra-en-liste-ratings også tæller med. Så kan de forskellige typer scorer indgå på forskellige måder ud fra den endelige sortering efter brugerens eget behov, men når brugeren så afgiver sine egne svar, jamen så er det så bare rating-ud-fra-en-liste-scoretypen, der bliver valgt for den rating, der uploades til databasen herved. .\,.\,Hvordan man så blander de forskellige ratingtyper sammen til en enkelt sortering på en fornuftig måde, det er så en noget mere kompliceret sag, men det er også lige meget her, for det er nemt at overbevise sig selv om, at det må kunne lade sig gøre på en fornuftig måde (især hvis man finder en god måde at implementere ``usikkerheder (statistiske) / spredninger'' på i forbindelse med diverse ratings). 

.\,.\,Lad mig lige tænke over, hvad jeg ellers gerne vil sige noget om.\,. (13:07) .\,.\,Hm, jeg kunne sige, at hvis man så bruger, hvad der svarer til en logisk database (i hvert fald i interfacet med brugerne), så vil man så skulle lave en query-API, som brugerne kan bruge i ``HTML-udvidelserne,'' der svarer til logiske query-sprog, men det giver jo næsten sig selv.\,. .\,.\,Hm, det var faktisk muligvis alle de tekniske ting, jeg ville nævne for denne omgang. Så har jeg også nogle mere overordnede ting, som jeg tror, jeg vil skrive på engelsk under en ny sektion. Så kan jeg jo derfor også bare vende tilbage hertil, hvis jeg har nogle tilføjelser til nogen af disse tekniske ting. (13:18)

*Jo, der er faktisk lige den tilføjelse, at min SRC-idé jo også kunne virke godt til denne idé, nemlig især hvis man gerne vil have et fastansat hold af programmører til siden --- og i det hele taget når det kommer til, at man jo gerne, efter min mening, skal have nogle centraliserede databaser, som så kan underskrive kontrakter om ikke at offentliggøre eller videresælge privat data fra brugerne, samt at brugerne skal kunne bede om at få deres data slettet.

*(17:05) Dette er ikke en teknisk tilføjelse, men en bare en kort tilføjelse omkring min ``debatside-applikation.'' Jeg nævner det nok igen i Sektion \ref{Some_hopes_in_terms_of_my_ideas}, men angående min debatsideidé, så kan det godt være, at den ikke rigtigt vil.\,. take off.\,. få god ind i sejlene, før at den videnskabelige verden virkeligt kommer med og deltager i hele projektet med at strukturere, i dette tilfælde viden og videnskabelige diskussioner, i semantiske grafer. Så jeg håber altså på, at den videnskabelige verden vil benytte denne semantiske teknologi mere og mere, og herved vil det jo så selvsagt være relevant at afholde sådanne diskussioner, som jeg tænker dem i forbindelse med, hvad jeg kalder min debatside-idé. Et alternativ ville være, hvis mine tanker omkring e-demokrati fik god vind i sejlene forinden, så tror jeg også, at dette kunne blive en vej til, at få godt gang i sådanne graf-diskussioner, som jeg tænker dem.\,.

*(26.01.23) Vil lige for det første kort nævne, at jeg synes, det giver rigtig god mening, hvis man i bruger-udsagn-rating-entiteterne også har et flag / en reference til, hvordan ratingværdien skal tolkes. For det synes jeg nemlig giver bedst mening rent fortolkningsmæssigt: Så kan man nemlig se udsagnet for sig som sin egen ting, og se ratingen samt dennes fortolkning som sin egen ting også. (12:52)

*(12:52) Nå, den næste, mere vigtige ting, jeg vil tilføje, er, at jeg nu er kommet på, at brugerne måske også skal kunne tilføje URL-RegEx'er til at scrape indhold fra andre sider. Og når man så har disse scrape-formler, så kan brugere så tilføje specifikke inputs til disse RegEx'er, der giver en gyldig URL til en eksisterende Web-ressource. Og så kan databasen i princippet bare gemme selve inputtet, og når brugerne så iagttager pågældende ressource, så kan hjemmesiden bare hente de relevante URI'er fra sættet af de fuldendte URL-RegEx'er og indsætte dem på hjemmesiden. Så dette kunne altså være en hurtig måde at få en hel masse indhold på siden.

*(12:59) Samtidigt åbner dette så også op for, at man ret nemt kan lave et ``overlay,'' som jeg før har kaldt det i mine noter, nemlig en slags annotationsudvidelse til browseren, således at en bruger kan folde en menu ud og se relevant data, særligt ``rating-tags'', som jeg har kaldt det, for en ressource de browser på en anden hjemmeside. Så når brugerne browser andre hjemmesider, kan de altså få adgang til den ``rating folksonomy,'' der tilhører semantik-hjemmesiden. De kan også få adgang til anden data, så som relevante links, inklusiv den/de oprindelige kilde(r) til ressourcen, og også diverse advarsler, f.eks.\ om NSFW/NSFL, og ikke mindst også om `misinformation.' Disse muligheder kunne muligvis være med til at gøre semantik-applikationen/hjemmesiden populær lynhurtig i sammenligning med, hvis brugerne kun kunne få alle disse muligheder, når de browser semantik-hjemmesiden selv. Man kunne i øvrigt også sælge hele denne idé denne vej rundt, altså hvor man starter med at sælge idéen om et tværgående system, hvor brugere kan få adgang til en ``rating folksonomy,'' der fungerer på tværs af alle mulige hjemmesider, og hvor brugerne også kan få andre links og advarsler herved, og så derfra pointere, at denne applikation så også bør have sin egen hjemmeside, hvor brugere kan se alle tingene samlet, endda på en semantisk struktureret måde, der giver et meget effektivt overblik over alting. 
*(RegEx'erne skal jo også gerne hente al mulig gavnlig metadata såsom titler osv., hvis de kan, og dermed bliver det også relativt nemt at finde en ny passede URL (og måske med nye RegEx'er) til ressourcen, hvis nu hjemmesiden, hvor den er hentet fra i første omgang, skulle ændre sig.)

*(13:11) Nå, og den tredje/fjerde ting, jeg også lige ville nævne her, er omkring trust-fordeling. Når det kommer til brugere, der tilføjer nye ting i applikationen, jamen så vil det være rimeligt nemt at sortere skidt fra kanel, for så kan brugere bare stige i tillid, jo mere de tilføjer, der bliver godkendt af andre brugere, men ellers vil det altid også bare være sådan, at sensitive og/eller utålmodige brugere bare kan have et ret skrapt filter for nye tilføjelser, der altså kræver mange up-votes, før de selv får tilføjelsen at se, og mere engagerede brugere kan så have mindre skrappe filtre og dermed blive mere aktivt med til at godkende og afvise nye tilføjelser. Og angående tillid ift.\ bruger-ratings, så kan man sikkert komme rigtig langt i starten ved bare at antage, at alle konti repræsenterer en unik bruger, og så snart siden vokser bare lit, så kan man begynde at implementere et friend-of-a-friend-system, således at man kan begynde at skille bots fra. Så jeg tror dermed faktisk ikke, at dette bliver så svært, og jeg tror således heller ikke, at mine simple, token-baserede ``brugergrupper'' beskrevet ovenfor bliver særligt nødvendige.\,. .\,.\,Og det er rart at man applikationen ikke er tvunget til at vante på, at brugerne for oprettede sådanne halvavancerede systemer (som kræver noget brugerengagement) til at uddele trust, før at applikationen kan blive god og gavnlig. 



\section{Overall selling points for my Web 2.0--3.0 ideas}

(13:19, 24.01.23) This section is best understood if one has read my previous notes on the subject, including the ones above in the previous section (in Danish). But the notes might make some sense still, even without having read my previous notes.

%(13:22) Jeg tager lige en hurtig pause og tænker lidt over, hvad jeg vil sige i denne sektion... ...(13:52) Okay, lad mig prøve at fortsætte.

One little idea, which can be implemented on any conventional Web 2.0 site as well, is my idea for ``rating folksonomies.'' The idea is basically to attach a rating bar to all tags. Even if the site does nothing further about this technology, it will still be nice for users to be able to see a rating score along all the tags that they observe on the site. On from there it is a very short step to start using this extra data to make searching better on the site, and to make feed algorithms better. Thus, it is a very simple, and I believe very useful, idea that is easy to get going with.

The next idea is to have user-driven search filter / feed algorithms. This idea is more complicated, but I have described how it could work in the notes of the previous section. The big selling points here, are that users will then be able to not just get a single feed algorithm (as well as some very simple search filters) that depends on the user's data, but can always choose from an array of algorithms. This gives the users much more freedom of customization on the site, and in a way such that they can shift between different customizations depending on what they are interested at in the moment. Now, if we think about YouTube in its current state, this is a very good example of a quite terrible user experience with the feed algorithm (in my opinion as well as some other's). I am actually afraid to click on anything that I don't recognize, since I am afraid that that will then trigger a whole bunch of stupid recommendation in the future, where I have to repeatedly click `not interested' in order to get that ``contamination'' out of my feed again. Such ridiculous situations will all be past with a more user-driven system such as the one that I imagine. Here users will instead be able to control their own algorithms quite effectively, and will be able to use a wide array of different sittings depending on what the are interested in at the moment.

User-driven algorithms also means that the users don't even have to feed the machine a lot of their personal data in order to get the feed/search result that they desire. They can instead stand on the back of other users' commitment and simply use their preferences. A
Or they can keep their own data completely private and still use it to find out about, where they lie in the general space of user preferences. They can also at anytime open up completely anonymous accounts and import preferences from other accounts (without having to reveal this data to the public). The users will thus be able to get much more freedom in how the use their data, and will have much more control and ownership over it.

And continuing on the topic of feed/search algorithms, I certainly believe that these will get a lot better for the individual user when there is a large open source community behind them (and when the user has so much ability to use a wide range of settings). This is finally a point where the open source part of the idea starts to get important. Once suc a site takes off, the sheer number of users who want to contribute to better making better search/feed algorithms will make the possibilities far exceed what any private team of web developers can muster for their users. This is just my belief, but yeah, I believe it quite strongly (perhaps with the only exception if AI is going to come in and help provide super good and varied feed algorithms somehow.\,.). .\,.\,But yeah, most likely, a big open source community around such an open source site as what I have in mind will be able to achieve much better things than what we know currently.

Another idea where the open source part is really important, is about having the users be able to change the appearance of the site themselves. Again, we are then talking about a case where the site has already taken off and has gained a very big user network around it. One it has this, this open source community will be able to achieve much more in terms of the usability and nt least the ability for customization than what a limited team of web developers can achieve. And here I should mention that part of my ideas related to this subject is that users are able to choose different settings for different types of resources. Each users can thus customize the appearance of the various interfaces on the site in a modular way. (See my previous notes for more details.)

Moving on, another big selling point about my ideas has to do with having a semantic (I guess) structure of all the resources contained (and referenced) on the site such that all resources can be found in a tree (or graph, rather) structure of categories and subcategories and so on. Hm, well perhaps `semantic' is actually not the right term to use here.\,. %(14:35)
.\,.\,Hm well, yes, I guess it is, cause that is essentially what I achieve with having users being able to also choose more and more filter predicates at the same time as they browse the category tree, such that the end up choosing both a subcategory for the resource they are interested in as well as a bunch of predicates which can specify the resource they are interested in further. %(14:39) ..Går lige en lille tur, før jeg fortsætter. (14:46)

%(16:06)
If keyword searches was never invented, such semantic catalogs would probably have been how we would have ordered resources on the web. Such a resource graph might then have been centralized to begin with, but at one point, an open and user-driven implementation would have become popular. I am glad we keyword searches was invested, but I really think we have been missing out on something big all this time. I really think that such user-driven resource graphs over the contents of the web would have been such a useful thin to have. Whenever a website has content added to it, the author of that content would have wanted it to add a reference to this content in whatever semantic ressource graph would be popular at the time, such that more people would see that content. And since the Web of Trust ideas are quite similar to my ``(user-driven) user groups'' in a lot of ways, I am pretty sure that we would have also quickly implemented ways for users to choose different ways of applying trust when it comes to rating useful contributions to said semantic resource graph. 

Anyway, I think that having such (user-driven) structured graphs over all the content on the web will be such a useful thing to get in the future, and I see (as I have described in the previous section) how I site such as the one I have in mind could be one way to get there. So to add a selling point to the list: Having such a semantic structure of content like the one I have described in the previous section could become a massive thing in the future. 

And the last point I want to mention, which is related to the last point, is that I think it will also be very useful to have content and data related to any specific resource ordered with a similar semantic structure. Having ordered comment sections would thus potentially be quite a nice thing to have, and on top of this, there is also related data/content such as related links, annotations, source material, etc., which could benefit from a similar user-driven, semantic structure. (See my previous notes for more details.)

So that concludes the list of selling points that I have in mind. The first ones are something that a regular Web 2.0 site might also be able to implement to some degree. This is kinda unfortunate for someone like me who thinks that the open source way is the ultimate way to go, for if these selling points could also only be realized on a much more user-driven site, it would sell the idea of such user-driven sites all the more. However, my hope is that other people will see the big potential in starting up an open source site which sets out to realize more and more of all these mentioned ideas, and that we can thus get a big community going around starting up such a site. This community will then consist of mainly open source programmers initially, and there will be a time where the site has yet to attract users from the general public, but once some of the first points mentioned in this list of ideas starts to become realized, users will slowly migrate from other Web 2.0 sites and start using this open source version more and more. The following network effect will then mean (as I foresee it) that some of the last points on this list of ideas will start to become realized, and from there, the sky is the limit. %(16:32) 

(13:22, 26.01.23) Let me also quickly mention the point that I think my system where users rate things by moving them around in a list will be good at encouraging users to give a lot of (valuable) rating data to the system. 

(13:38) In accordance with what I have just added in the previous section, there is now also the selling point, that the application will be able to be used on all kinds of other websites as well, namely such that users can see semantic data about resources they are viewing while browsing other sites. 

(15:10) And just to make clear, there is also another great point, which might not be so easy to ``sell'' since it is hard to argue that things will go according to how I imagine them, but which is really the big underlying reason why I'm so interested in all this. The point is that I believe that this technology can get us to a point where all of science can also be structured in a great semantically linked graph such that is becomes easy to look at all point and counterpoints to a given question, and to look at all existing solutions to a problem (and see arguments for their benefits and drawbacks). The same can also be said for open source programming: I believe we can get to a point where all programming solutions (modular) can be ordered in a great semantically linked graph. I believe that my ``Web 2.1'' ideas here, as we can call them, potentially might be able to bring about such a future, and I really think that this will mean so much for our scientific (and societal) advancement.\,.\,! %(Let me by the way mention here in the comments that I have thought about this today and reconsidered if I still really believe that my Web 2.1 ideas can lead to this, and luckily I have sort of arrived at the point where I think I will double down on that belief. For the way I see it, having a semantic graph over web content can very well become very popular, and this might very well further lead to the scientific --- and open source programming --- community/ties also making use of this technology to structure all scientific knowledge and discussion (each individual scientist (or programmer or amateur) taking part partly of selfish reasons to make their work reach a larger audience). And once such a well-structured graph becomes a reality, I believe this will... Hm, let me actually write this in the rendered text instead.. )
Let me by the way mention that I have thought about this today and reconsidered if I still really believe that my Web 2.1 ideas can lead to this, and luckily I have sort of arrived at the point where I think I will double down on that belief. For the way I see it, having a semantic graph over web content can very well become very popular, and this might very well further lead to the scientific --- and open source programming --- community/ties also making use of this technology to structure all scientific knowledge and discussion (each individual scientist (or programmer or amateur) taking part partly of selfish reasons to make their work reach a larger audience). And once such a well-structured graph becomes a reality, I believe this will greatly increase people's --- scientists/programmers as well as all other people --- ability to look up specific knowledge and to engage in discussions and innovation/solution-finding processes. I thus see that this technology can maybe sort of create a giant online collective intelligence --- not an artificial intelligence, but metaphorically speaking still a big collective brain. These are large words, but I really do think that such technology will give us intellectual powers as a civilization that is many times greater than what we have now. Anyway, I hope so. Hm, I guess that this paragraph belongs more in section \ref{Some_hopes_in_terms_of_my_ideas} below than here, but let me keep it here and simply copy (not cut) and paste it below there as well.\,.




\section{Flere tanker om min semantik-applikation}

(30.01.23, 9:51) Jeg var lidt begyndt at second guess'e, hvor stor en gennemslagskraft min hjemmeside/applikation vil kunne have, men nu føler jeg faktisk virkeligt, at jeg har fundet den røde tråd igen, som gør, at jeg igen virkeligt tror, at det vil kunne bliv kæmpe stort, og på ikke så lang tid endda. 

En stor pointe er, at nu har jeg godt nok snakket med om et prædikat såsom `er\_sjov,' og sådanne prædikater er også vigtige, nemlig prædikater der bruges mere til bedømmelse af en ressource frem for en kategorisering af den. Et relateret prædikat til er\_sjov, der i stedet bruges til bedømmelse, kunne være er\_komedie, når vi snakker film, og ellers kunne det være noget såsom har\_humor\_som\_et\_vigtigt\_fokus. Der vil så generelt være meget mere tværgående enighed omkring sidstnævnte typer af prædikater, hvor bedømmelserne af førstnævnte vil afhænge meget mere af personlige holdninger --- og dermed altså også hvilken `brugergruppe,' man ``spørger'' i forbindelse med diverse filterindstillinger. 

Nå, den store pointe er så, at kategoriseringsprædikater vil være mindst ligeså vigtige for brugerne, og jeg tror på, at disse i høj grad også vil være villige til at bedømme kategorier, som vi kan kalde det, frem for bare at bedømme, hvor godt ressourcen lever op til sine kategorier, osv. Og på den måde, så bliver applikationens brugbarhed altså set ikke så todelt, som jeg egentligt lidt har gået og tænkt på det sidste, for det vil i stedet være sådan, at hele den del af applikationen, der handler om at kategorisere ressourcer, i høj grad også vil hænge sammen med tag-rating-delen. Og dermed tror jeg altså lynhurtigt, man vil få brugerne godt i gang med at tilføje og bedømme kategorier. 

For når man som bruger af gængse hjemmesider afgiver bedømmelser, så er det ofte i høj grad for at støtte skaberen og ikke mindst hjælpe til at andre med samme interesser kan finde frem til det samme. Og dette vil kategori-rating tags jo lige netop kunne hjælpe gevaldigt med. Jeg er altså ret overbevist om, at brugerne i høj grad vil benytte sig af disse.

Og oveni, hvis vi går tilbage og ser på, hvad der generelt vil få applikationen til at blive en stor succes efter min mening, så vil applikationen jo hurtigt kunne bruges vildt bredt. Vi snakker jo således slet ikke bare film og videoer, men også tekster (bl.a.\ fra Wikipedia, men også fra alle mulige andre steder), varer af alverdens afskygninger, bøger, spil og alverdens andre ting omkring fritidsinteresser. Og ja, jeg tror altså nu, at der ikke vil gå særligt lang tid, før at brugerne får udbygget en omfattende kategoriserings-semantik-graf over alle sådanne ting. .\,.\,Nå ja, og i øvrigt forestiller jeg mig også, at politiske holdninger og andre meninger også kunne blive en vigtig type ressource. Altså tekster, der opsummerer en eller anden form for mening om noget, og som folk så kan bedømme efter enighed. Dette kan blive en rigtig god måde for folk at udtrykke sig på (politisk og i andre sammenhænge), f.eks.\ hvis nu de hører i fjernsynet eller i radioen om, at ``der har været en stor bevægelse/underskriftindsamling/shitstorm / et stort backlash/.\,.\,you name it.\,. hvor de selv føler, at de ikke selv er repræsenteret i disse reaktioner. Så kan det være rart at kunne gå ind at give sin mening til kende ved at stemme på de relaterede `meninger' på hjemmesiden/applikationen, og også så at kunne se et mere klart billede af, hvor mange mener det ene og hvor mange mener det andet. Og ja, det kan det selvfølgelig også i mange, mange andre sammenhænge (og også i tilfælde, hvor `meningen' ikke er vildt aktuel i nyhederne, men det er den måske for brugeren selv). Men ja, og hvis vi går et skridt tilbage til at kategorisere (og bedømme!) varer *(og servicer forresten) af alverdens typer, så vil det også blive en kæmpe stor ting. Hvis man f.eks.\ ser på Trust Pilot, så vil den hjemmeside/applikations muligheder være vand ift., hvad man kan på min semantik-hjemmeside. For det første vil man kunne kategorisere alle varer i en semantisk grafstruktur, så det er let at finde frem til, hvad man leder efter, og let at sammenligne, og for det andet vil man så også have mange flere parametre, man kan bedømme varerne (og servicerne) ift.\ (og se bedømmelserne for). 

Og ja, angående vidensressourcer, så tror jeg nu også, at applikation lynhurtigt vil blive super gavnlig, og at brugere således vil kunne bruge den til meget nemmere at finde frem til tekster omkring ligepræcis det, de er interesserede i. 

En lille teknisk tilføjelse omkring videns-ressourcerne, hvilket jo bare er tekster, eventuelt hypertekster, plus kilde-URL'en, jamen så ville jeg vælge bare at gemme (hyper)teksterne direkte i databasen fra start af (i modsætning til tungere ting såsom videoer og billeder). Hvis så kildesiden ændrer struktur en anelse, eller hvis selve teksten bliver skrevet en anelse om, så må man alligevel kunne finde tilbage til det eksakte sted, hvor teksten stammer fra, nemlig ved bare at lave en automatisk søgning og finde det bedste match til teksten på kildesiden. *(Jeg glemte lige at nævne her, at man dog nok ikke bør lade brugerne se disse tekster direkte, da de jo let kan være copyright'ede. .\,.\,Hm, men vent, for vil det så egentligt være særligt smart sådan? Måske på sigt, men det vil jo kræve ret meget programmering, måske man kan finde på noget smartere.\,.\,? .\,.\,Ah, mon ikke hvis man bare gemmer de første par sætninger i teksten i stedet (foruden overskriften, hvis der er en), så kan man vel nok ikke komme i klemme. .\,.\,Nej, det skulle undre mig meget, hvis man kan det.)

Men ja, så det korte af det lange er altså, at jeg virkeligt tror, at hjemmesiden/applikati-onen ift.\ hver enkelt type ressource vil gå fra 0 til `nu er siden brugbar' til 100 på virkeligt kort tid, for når først den semantiske struktur er brugbar for en del brugere, så tror jeg udviklingen vil accelerere helt vildt derfra, nemlig fordi flere og flere brugere vil komme til, og disse vil føje flere og flere ressourcer og bedømmelser (inklusiv kategori-bedømmelser) til. (10:43)


(10:54) Jeg har også tænkt på noget andet, som jeg passende lige kan nævne her, inden jeg går videre, og det er, at følgende donationsidé nok virkeligt også vil være gavnlig, nemlig at brugerne i fællesskab (og hver for sig og, ikke mindst, i grupper) kan udarbejde donationsfordelingsopskrifter, som så altså er opskrifter/planer, der bestemmer, hvordan penge doneret til opskriften/planen skal fordeles mellem skabere/bidragsydere (og altså ikke bare skabere, der har uploadet ressourcer specifikt til webapplikationen; det kan også være skabere, som ikke selv har tilføjet deres indhold specifikt til webapplikationen (men til en anden hjemmeside/applikation), men som dog har registreret sig selv og tilføjet en konto man kan donere til). Hver doner kan så selv vælge, hvilken plan/opskrift, de vil bruge. I princippet kan de så vælge en opskrift, der bare giver pengene tilbage til den selv (ved også at registrere sig selv som en skaber), men hele pointen er så, at andre brugere så også kan se, at du ikke er donor til en af de mest populære planer/opskrifter, men i stedet er donor til en måske meget obskur opskrift. Dermed vil andre brugere altså ikke have nær så stor tendens til at bruge dig særligt meget i diverse filteralgoritmer, mere end hvordan de bruger ikke-donerende brugere. (Og det er nemlig en rigtig gavnlig ting, at brugere kan vægte filteralgoritmer ud fra, hvor meget brugere har givet til visse populære og fornuftige donationsopskrifter. 

En lille anden tanke omkring bruger--skaber-økonomien, som jeg lige kom på nu her (de fleste andre idéer jeg nedskriver nu her stammer ellers fra weekenden, hvor jeg var på Fyn), er at man i stedet for at tænke på at starte en SRC over webapplikationsvirksomheden kunne starte den over en IP-fællespulje i stedet. Her har jeg jo før tænkt, at en sådan IP-organisation kunne indgå som et modul i den samlede SRC omkring en sådan hjemmeside/webapplikation, men nu tænker jeg altså: Hvorfor ikke bare nøjes med at foreslå, at skaberne kan gå sammen (efterfølgende) og oprette en SRC til at forene sig omkring deres samlede IP-rettigheder? Så det tror jeg faktisk er min plan nu: Jeg vil oprette en virksomhed omkring denne semantik-webapplikation, som altså skal stå for de grundlæggende ting, ikke mindst at passe databasen (og som tiltrækker penge ved at vise reklamer (muligvis hvor brugerne selv kan slå dem fra (altså uden at bruge en add blocker)) og så ikke mindst via donationer, og som i øvrigt ikke prøver på at ekspandere særligt meget), og så er tanken, at diverse skabere (indholdsskabere og ``ramme-skabere,'' som jeg har kaldt det) selv kan oprette en SRC omkring en sammensat IP-pulje, hvis de vil. 

Ok, og har jeg andet, jeg vil nævne, inden jeg går videre til mine nye idéer omkring webapplikationens interface og alt det.\,.\,? (11:22)


(13:25) Okay, jeg tillod lige mig selv at tænke noget mere over det hele. Lad mig starte med det vigtigste først. Nu tænker jeg ikke længere at fokusere på den der fold-ud-menu, jeg har snakket om ovenfor, ikke i starten i hvert fald. %Lad mig prøve at opsummere, hvad jeg tænker, man bør prøve at konstruere i starten i stedet for.
I stedet forestiller jeg mig, at det bare er helt standard, at hver ressource i en liste får en lille liste af muligheder, ja, som essentielt set så vil være list-prædikater, der hver er dannet af en relation (2 inputs), hvor pågældende ressource automatisk er sat ind som det ene input. Denne lille liste af muligheder må så gerne kunne afhænge af ressource-typen, men er ellers rimeligt konstant. Det vil sige, at brugeren derfor i princippet vælger en liste for hver ressourcetype (f.eks.\ `kategori,' ress.\,.).\,. Nå nej, lad mig kalde det et term i stedet for en ressource, og så kan jeg bruge ressource som en over-termtype, der indeholder (ressource-)termer såsom `videoressourcer,' tekstressourcer,' `meninger' (som jeg har skrevet om ovenfor), `varer' osv. Okay, og for at fortsætte, så vælger brugeren altså derfor i princippet en liste for hver termtype, nemlig i form af en lille liste af relationer. Disse relationer kan så f.eks.\ være `er\_overkategori\_til\_x' (hvor x så er den automatisk indsatte term), `er\_underkategori\_til\_x,' `hører\_under\_kategorien\_x,' `er\_et\_relateret\_link\_til\_x,' `er\_en\_relateret\_ressource\_til\_x,' osv.\ (hvor disse nævnte relationer så ikke alle vil være relevante for alle termtyper (de to første vil nemlig nok bare være relevante kategorier, hvorimod de tre sidste vil være relevante for diverse ressource-termtyper)). 

Selvfølgelig vil de fleste brugere i starten bare bruge de lister her, som webudviklerne (som jeg så forestiller mig at være en del af) vælger (og justerer løbende), men med tiden vil brugerne selv tage over og gøre det for hinanden, som de vil have det (men her snakker vi altså på langt længere sigt). 

.\,.\,Nå ja, men brugerne kan dog fra starten altså vælge imellem nogle forskellige muligheder for hver termtype, og selv oprette nye liste for hver af disse, hvor de selv tilføjer eller fjerne relationer herfra (ift.\ til standardmulighederne). *(Og de skal selvfølgelig også gerne selv kunne vælge brugervægtningen ift.\ ratingen af relationerne i listen.)

Når brugerne så iagttager en given liste over termer, der er blevet bedømt positivt i forhold til et givent prædikat, så kan de så ved at klikke på en term folde denne lidt ud for at få nogle valgmuligheder med den, og her skal den nævnte lille liste altså så også findes. Her kan brugerne så skifte imellem de forskellige valgmuligheder i listen, hvilket så bestemmer, hvilken liste af termer, som vises hvis brugeren vælger at folde en ny liste ud for det givne term. Jeg forestiller mig så, at brugeren kan folde en ny liste ud på to forskellige måder, via to forskellige tilhørende knapper: èn knap med en pil nedad og én knap med en pil til højre. Hvis brugeren trykker på knappen med pilen pegende nedad, vil en liste foldes ud under termet selv (muligvis med et lille indryk), imellem dette og så den næste term i listen. I øvrigt foldes listen kun lidt ud med de øverste fem-ti valgmuligheder til at starte med, og ved endnu et klik på en nedadpil i bunden kan brugeren så få endnu flere valgmuligheder i listen. Alternativt kan brugeren klikke på pilen pegende mod højre, hvorved samme liste så bliver udfoldet i større format i en kolonne ved siden af den forrige kolonne, hvor det givne term fandtes i. Brugeren kan så også skifte frit imellem valgmulighederne over relationer i den lille liste, jeg har snakket om her, hvorved indholdet i listen, hvad end den er foldet ud under termen eller i en kolonne til højre for den forrige, skifter til den nye relation.

Når brugeren trykker på et hvilket som helst givent term, skal der også enten foldes en rating bar (eller to.\,.) ud til at starte med, eller også skal der være en knap til at folde ratingen/erne ud. For alle termer i en liste skal der så i første omgang være en rating bar, som lige præcis handler om prædikatet om, hvor godt pågældende term passer til den liste, den vises i. Eller med andre ord, for enhver liste afhænger jo af et specifikt prædikat, så skal man altså kunne rate termen i forhold til lige netop dette prædikat. .\,.\,Hm, for prædikat-termer skal man så kunne gøre noget mere, men lad mig lige tænke lidt mere, inden jeg fortsætter omkring dette.\,. (14:09)

(14:32) Okay, når det kommer til prædikater, så skal der også være endnu en rating bar, nemlig hvor brugeren kan rate andre termer ud fra pågældende prædikatet (altså i stedet for at rate pågældende prædikat-term ud fra det prædikat, der danner den liste, som pågældende prædikat-term vises i). Og her skal brugeren så kunne skifte subjekttermen til denne rating bar. Titlen (og måske et tilhørende billede/ikon på længere sigt) kan så vises over eller ved siden af denne rating bar, og ved at klikke på en knap nær ved denne titel, skal brugen så kunne cykle imellem alle de aktuelle\,.\,. hm, de aktuelle termer, men det vil jo i høj grad være ressource-termer, vi taler om her, ikke.\,.\,? Jo.\,. .\,.\,Ja, ok, så i første omgang (som noget der vises allerførst i listen over termer, som brugeren kan rate på denne måde --- hvis altså ikke det bare \emph{kun} er ressource-termer, som brugeren skal kunne rate på denne måde, det kan faktisk godt være.\,.) skal alle de aktuelle ressource-termer altså stå i listen over, hvad brugeren kan rate her. Og disse ressource-termer er så altså nærmere bestemt alle de ressourcer, som brugeren har klikket på for nylig. 

For hver eneste rating bar, der vises, hvad så vi snakker den ene eller den anden af de to nævne ratingbarer (hvor den anden kun giver mening, når pågældende term selv er et prædikat), så skal der kunne udfoldes en lille beskrivelse af, hvordan det relevante prædikat (som rates ift.) er defineret mere eksakt (end bare ved at læse dens titel), og når brugeren peger forskellige steder på ratingbaren, så skal der også gerne vises en lille tekst til det specifikke interval, som brugeren holder over, hvor der given en forklaring på, hvordan en rating i dette interval generelt bør fortolkes (ifølge forfatteren). Det kan godt være, at disse tekster vises, når brugeren indstiller knappen på ratingbaren, måske særligt hvis vi snakker et mobile device, men der skal så selvfølgelig altid være en bekræftelse af hver afgivne rating (og hver ændring af en tidligere afgiven rating), hvor brugeren skal trykke bekræft eller annuller. (14:47)

Okay, jeg har det som om, jeg mangler at nævne noget, men lad mig bare lige gå lidt videre for nu. Hvis vi tænker på de filter-indstillinger, jeg har snakket om ovenfor, så kan dette fungere ret meget ligesom, jeg har beskrevet før, måske endda med en fold-ud-menu fra venstre. Jeg forestiller mig dog, at brugeren skal gå til hjemmesiden for applikationen selv for at lave nye filterindstillinger, og at brugeren defor bare eventuelt har en række yndlingsfiltre, som denne kan vælge fra, hvis brugeren tilgår applikationen via et overlay på en anden hjemmeside.\,.

.\,.\,For jeg har jo allerede nævnt ovenfor, at jeg nu forestiller mig, at applikationen ikke bare skal fungere på sin egen hjemmeside, men at brugerne også kan tilgå den, når de browser ressourcer på andre hjemmesider. Her forestiller jeg mig så, at dette overlay (eller hvad man kalder det) skal kunne rulles ind fra højre, hvis brugeren trykker på en knap, og i øvrigt at denne knap skifter udseende, hvis den ressource, som brugeren betragter på den anden hjemmeside allerede er tilføjet til databasen (altså den semantiske), og hvis der så findes relevant data (så som ratings og relevante links m.m.) til ressourcen i databasen. Men jeg forestiller mig dog lidt, at overlay-applikationen kan være en tand mere simpel, end hvad man kan tilgå på webapplikationens egen hjemmeside. Brugeren skal dog selvfølgelig stadig være logget ind i overlay-applikationen og hermed have adgang til de relation-liste-indstillinger m.m., som jeg har nævnt nu her i dag, og jeg synes også nok gerne, at brugeren må kunne folde underlister ud til højre for forrige kolonne i en ny kolonne ved at trykke på pilen til højre, som beskrevet her ovenfor, men ud over disse ting, så kan det dog godt være, at overlayet bare skal være en tand mere begrænset. Men til gengæld bliver brugeren så bare simpelthen dirigeret om til applikationens egen hjemmeside, hvis denne trykker på en valgmulighed, som ikke er implementeret i overlayet, og så skal brugerens nuværende position i hele semantik-grafen, samt de ressourcer brugeren har valgt, bare overføres, så brugeren starter med helt det samme sted, som denne kom fra i overlayet (nu bare med nogle flere valgmuligheder). Og i øvrigt skal denne omdirigering altså ske via åbning af et nyt vindue, så brugeren ikke forlader den side, han/hun var på. 

Så lad os forestille os, at brugeren betragter en ressource på en vis hjemmeside, og nu ser ude i siden, at der findes data til denne ressource i semantik-databasen. Brugeren kan så folde overlayet som en menu fra højre. Her skal brugeren så.\,. Nå ja, det har jeg ikke nævnt! Jeg vil gerne have.\,. Hm.\,. .\,.\,Jo okay, jeg vil også gerne have en standardvisning for en given ressource, hvor alle relationsmulighederne vises som overskrifter i en sammensat liste, hvor der så kun lige vises de allermest populære termer i hver liste, men hvor man så også får mulighed for at folde disse lister mere ud, både ved at trykke pil nedad eller ved at trykke pil til højre (som beskrevet ovenfor). Hm, vi kan så se denne mulighed som en standardmulighed for hver relationsliste (vi snakker altså denne ``lille liste af muligheder,'' som jeg startede med at forklare om i dag), hvilket altså for lige at gentage det giver en liste, som er sammensat (i rækkefølge) over alle de egentlige relationer, som er i denne liste. Så brugeren kan altså se denne standardliste, hvor alle relation-mulighederne kommer efter hinanden, eller brugeren kan også trykke på en specifik mulighed (ikke i den nye søjle med omtalte standardliste men i den forrige søjle med objekttermen selv), således at hele den nye liste så bare \emph{kun} kommer til at indeholde en specifik mulighed i form af en af de pågældende relationer i relation-listen. (Håber dette giver mening, hvis man læser det et par gange.)

Ok. Brugeren kan herved så trykke overlayet frem fra højre og med det samme se en lille oversigt over de mest relevante ratings og links m.m.\ til pågældende ressource. Og ved bare ét klik mere, nemlig på en nedad-pil, kan brugeren så folde en af disse dellister længere ud og for så at se nogle flere muligheder (i.e.\ en række af de næstmest relevante prædikater/links m.m.). (15:20) .\,.\,Og herfra kan brugeren så endda navigere endnu videre i grafen, navnligt måske hvis denne hurtigt lige vil finde en passende kategori og/eller et passende prædikat som ikke indgår i listen (.\,.\,eller f.eks.\ hvis brugeren lige hurtigt vil tilføje et relevant link). Og hvis brugeren så gerne vil bruge webapplikationen endnu mere end dette, såsom f.eks.\ at betragte ressourcen og/eller andre ressourcer i en liste sorteret ud fra visse filterindstillinger (og alt det jazz), så kan brugeren altid bare klikke på en knap, så applikationens hjemmeside åbner i en ny fane, og hvor brugeren så starter i helt samme tilstand (stort set), som denne var i i overlayet (nemlig de samme sted i grafen og med de samme midlertidigt valgte termer). (15:26)


(02.02.23, 9:32) Jeg har nogle få ændringer. På en måde tror jeg nu, at interfacet skal være lidt en blanding af, hvad jeg skrev om, dengang jeg introducerede og forklarede om fold-ud-menuen (fra venstre) ovenfor, nemlig hvor man har arbejdsbord, og hvor man så føjer flere og flere termer til et arbejdsbord, når man navigerer rundt i grafen, og ja, også så en blanding af det jeg lige har forklaret om, brugeren vælger en lille liste af muligheder for hver term type over, hvad man kan folde ud fra (ved at klikke nedad-pil eller højre-pil) en given term. 

Lige nogle lidt selvstændige tilføjelser, der er rare at få sagt med det samme, inden jeg fortsætter med det mere generelle: Nu forestiller jeg mig, at navigation i den semantiske graf primært kommer til (i det interface, jeg vil sigte mod at bygge) at foregå ved, at man folder flere og flere lister ud, ikke kun af over- og underkategorier, men sådan set af (kategori-)prædikater generelt. Og her skal brugeren så faktisk kunne aktivere flere kategori-prædikater på én gang, nemlig ved at klikke på dem (under navigationen/browsingen) og føje dem til sine aktive (kategori-)(filter-)prædikater. Sådanne prædikater behøver altså slet ikke at være disjunkte, og brugeren kan derfor altså sagtens få brug for at vælge flere på én gang i sin søgning. Jeg forestiller mig, at når brugeren klikker et kategori-prædikat aktivt i sin søgning, så skal den (skifte farve og) highlightes i den pågældende liste, samtidigt med at den også føjes til en speciel mappe i arbejdsbordet. 

Og den anden selvstændige tilføjelse er, at man også skal kunne have filter-prædikater, der har antecedenter foran sig, f.eks.\ til at gøre filtreringen afhængig af termtypen, men antecedenter bør også kunne bestå af eller indeholde andre filter-/kategori-prædikater. Hver bruger kan så endda have en hel lille preamble af faste filter-prædikater (sammensat med diverse antecedenter foran sig), som altid er aktive, når brugeren har gang i en søgning.

Nå, en anden ting er så, at jeg nu tror, at brugerne rigtigt gerne bare vil kunne søge efter nøgleord, når det kommer til bedømmelses-prædikater, som det eksempelvis gerne vil bedømme for en ressource de iagttager (måske på en anden hjemmeside og altså dermed via overlayet (som jeg stadig bare kalder det indtil videre)). Her kunne man sikkert komme langt med gængse søgemaskine-funktionaliteter, men derfor kan man stadig også godt gøre sådan, at brugerne kan tilføje nøgleord til prædikaterne. Så nu forestiller jeg mig altså, at forfatteren i første omgang får lov at tilføje nogle nøgleord, og at andre brugere så ellers også selv kan tilføje flere, samt rate tilføjede nøgleord op og ned. 

Så angående overlayet, så tror jeg bare man i staten kan nøjes med den standardvisning, jeg snakkede om her lige ovenfor i denne sektion, nemlig hvor lidt af alt bliver vist, og hvor brugerne så kan folde listerne mere ud (måske bare via nedad-pil i starten), og så ellers et søgefelt, så brugerne kan søge på prædikater.\,. eller andre termer såsom ressourcer.\,. de ikke finder i denne standardvisning. Hvis det så findes i databasen, kan de så rate det som relevant for pågældende ressource, og ellers kan de gå til hjemmesiden for at tilføje et nyt prædikat eller en ny ressource(-reference) selv. 

\ldots Nå ja, og jeg forestiller mig også nu, at når brugeren folder nye søjler ud via højre-pil, så ryger søjler, der allerede står til højre, ikke væk, men i stedet bliver den nye søjle bare indsat imellem de eksisterende søjler (lige til højre for dens forældersøjle), således at de gamle søjler til højre for bare rykker en tak længere til højre allesammen. Brugere skal så bare selv manuelt lukke de søjler, de ikke længere har behov for. 

Hvis jeg finder på nogle flere tilføjelser, der er relateret til de andre ting i denne sektion, i løbet af de næste par dage, så vender jeg nok tilbage og tilføjer dem her. Og ellers vil jeg nu gå i gang med at planlægge, hvad jeg vil begynde at prøve at programmere for min første prototype af applikationen.

*Hm, man kunne gøre sådan, at hvis brugeren holder shift inde, så vil en ny søjle erstatte den, der tidligere stod til højre, i stedet for bare at blive sat imellem dem.\,.

*Kopieret nedenfra: ``Der skal også gerne være en liste over ressourcer, der konstant ændrer sig, når man vægler flere og flere kategoriseringer til, hvilket vil sige, at vi måske faktisk nærmest skal tilbage til det der med at have navigationen i en fold-ud-menu, eller noget der svarer lidt til.\,. .\,.Hm, lad os sige, at (graf-)søjle-prædikatsøgningen og ressourceliste visningen kan foregå i to faner.\,. som dog godt også kan vises side om side i en tredje fanemulighed.''

*Kopieret nedenfra: ``Okay, jeg tror faktisk, at jeg vil gøre det sådan, at forfatteren til et prædikat faktisk kan tilføje et vilkårligt antal intervalbeskrivelser, endda med vilkårlige og muligvis overlappende intervaller. Disse skal så vises i en liste under ratingbaren, hvor teksten for kun de intervaller, hvor bar-knappen er indenfor, vises. På sigt vil jeg så faktisk også gerne have, at brugeren bare kan trykke på en tekst og se intervallet, og så endda vælge, om ratingen så skal gives ud fra bar-knappens position, eller i stedet bare ud fra den highlightede teksts interval, hvorved ratingen så bare forståes som, at brugerens rating ligger inden for dette interval! Så dette kan altså således også blive den måde, hvorpå brugerne basalt set giver hinanden mulighed for at lave mere diskrete ratings! Virker fornuftigt nok.\,:) Men ja, i første omgang til prototypen skal teksten bare vises, og ratingen skal bare gives ud fra bar-knappens position altid. :) ''


*(03.02.23, 10:34) Jeg skal også på sigt have implementeret et lille aritmetisk sprog (også med sammenligninger, og gerne inklusiv en if-then-(m.m.-)syntaks) til mine ``automatiske point,'' hvilket så må blive en slags ``automatiske prædikater og ($n$-ære) relationer.'' I dette sprog skal brugerne også kunne oprette deres egne funktioner, og ikke mindst skal de kunne tilgå rating distributioner via funktioner, hvor de altså kalder en funktion, der så har værdier ud fra den nuværende rating-distribution af et prædikat eller en relation.\,. ja, nej, eller af et udsagn rettere. Desuden skal brugerne også kunne kalde diverse almindelige descriptors (er det ikke det, det hedder?) (altså parametre så som gennemsnit, skewness osv. *(samt også hvor mange afgivne stemmer ratingen har)) fra nogle andre faste funktioner (hvor udsagnet er et input). ``Returværdien'' af et automatisk prædikat eller en automatisk relation bliver så typisk findes i form af en automatisk rating af pågældende.\,. ja, vi kan jo så passende kalde det et `automatisk udsagn' (altså et automatisk prædikat eller en automatisk relation taget på nogle inputs).\,. hm, hvis vi snakker $n$-ære relationer, så kan jeg jo bare sige at $n$ godt kan være 1, og dermed undgå at sige `prædikat' hele tiden.\,. Nå, men ``returværdien'' er så typisk en beregnet rating for den automatiske relation taget på givent input. Men på sigt kunne man også tillade, at automatiske relationer ligeledes kan give ``returværdier'' i form af input-placeholders, således at den automatiske relation altså ikke behøver at få visse dele af dets input men i stedet selv genererer, hvad dette input skal have af værdi i det endelige (automatiske) udsagn. (Det svarer altså lidt til at give en pointer med til en funktion i C, hvortil en returværdi så i sidste ende overskriver den oprindelige værdi på adressen, rent konceptuelt.) Og ja, så kan man så overveje, om man ligefrem så vil implementere et logisk sprog på baggrund af dette, men fordi brugerne jo allerede har mulighed for at implementere funktioner, så er dette nok ikke nødvendigt, og brugerne kan altså således bare nøjes med at have de automatiske relationer som noget, hvor det endelige returværdier findes, og altså ikke som noget, der kan indgå i selve sproget, der koder for returværdierne. (10:54)

*(10:59) Noget andet ret vigtigt er, at ressourcer i grunden bare skal være et begræsnet antal felter, der definerer ressourcen, nærmere bestemt ikke mht.\ \emph{hvor} den kan findes, men i forhold til hvad der definerer, den ting ressourc(e-referec)en refererer til.\,. Og hvis så duplianter findes på siden, så skal hjemmesiden og brugernetværket altså i reglen sigte efter at slå duplianterne sammen! Så brugerne kan altså hjælpe med at flagge, når der er duplianter (inklusiv når en ressourcetype er duplikeret), og hjemmeside-crewet skal så tjekke dette, og hvis flaggingen er korrekt, så skal duplianterne slås sammen i databasen. Det vil sige, at man ser på den hemmelige info om, hvilke bruger-ID'er ingår i diverse ratings for udsagn, hvor dublianterne indgår (i hver deres udsagn), og så merger databasen disse udsagn, sådan at alle brugere har stemt én gang. Brugere der har stemt på begge ressourcer til samme udsagn (hvilket nok ikke er så mange), de får så en notifikation om, at to af deres tidligere afstemninger er blevet merget til én (måske med gennemsnittet som det endelige svar, hvis det kan lade sig gøre), og kan så eventuelt rette denne rating, hvis de vil. Sådan noget som URL'er til en ressource, jamen det skal så gerne indgå som et 0-til-mange-felt for ressourcen, sådan at brugere altså selv kan føje flere URL'er til. Dette kan så foregå ved, at databasen opretter en ny relation til den pågældende ressourcetype, som så får et passende navn, der indeholder ressourcetypens navn som et slags efternavn, og hvor forfatteren til ressourcetypen så bestemmer fornavnet. Foreksempel kunne relationen komme til at hedde `Movie.hasLocation(),' og inputsne kan så være en URL og en dato for, hvornår URL'en virkede, samt selvfølgelig den pågældende ``Movie.'' Og ja, brugerne kan så efterfølgende rate diverse URL-forslag. Desuden skal der også være et Obsolete-prædikat, som brugerne bør bruge, hvis f.eks.\ en tidligere URL var gyldig (og derfor har en høj gyldighedsrating i udgangspunktet), men at den pludselig er blevet ugyldig. Således kan brugerne altså hurtigt signalere, at en URL er blevet ugyldig, uden at de skal ``kæmpe mod'' den oprindelige gyldighedsrating (som så i stedet bare bør fortolkes som `var URL'en gyldig ved den pågældende dato'), og samtidigt gør dette så også, at man efterfølgende vil kunne se, om en given URL var gyldig (og populær) dengang den blev oprettet (hvilket man ikke kan, hvis brugernetværket skulle ændre den oprindelige gyldighedsrating, nemlig hvis de ikke havde Obsolete-prædikatet). (11:23) .\,.\,Nå ja, og det at flagge dublianter kan (og bør) selvfølgelig også bare ske via en dertil indrettet relation i databasen. 


\section{My first prototype}

(10:30, 02.02.23) Jeg tror jeg vil kalde projektet (og applikationen/hjemmesiden) for SemDB, indtil videre.\,. Hm, lad mig lige hurtigt se, om det er taget.\,. .\,.\,Hm, kunne ikke finde nogen hits, der var særligt relaterede, så lad mig rigtignok bare bruge dette (SemDB) som det midlertidige navn.

For det første kan jeg nævne, at jeg vente med overlayet, så dette bliver altså ikke en del af den allerførste prototype. 

.\,.\,Lad mig også udskyde RegEx-halløjet og i stedet bare selv prøve at populere databasen med nogle eksempelressourcer.\,.

Jeg skal implementere, at man kan oprette sig og logge ind som bruger.\,. .\,.\,Brugere skal kunne tilføje nye prædikater.\,. .\,.\,Brugere skal kunne samle sig et ikke-struktureret (for jeg vil udskude, at de selv kan oprette mapper osv.) arbejdsbord over.\,. Hm, eller skal jeg prøve at føje struktur til.\,.\,? .\,.\,Nej, ikke med det allerførste.\,. De skal så bare have en enkelt liste over prædikater, og én over ressourcer (never mind relationer for nu), hvor de så bare kan fjerne elementer fra listen som den eneste struktur-ændrende handling her. 

Hm, lad mig nøjes med forfatter-tilføjede nøglefraser til prædikaterne.\,. .\,.\,Lad mig også nøjes med en enkelt type rating, nemlig bare den kontinuere type (fra et negativt tal til et positivt), og lad mig vente med at gøre sådan, at forfatterne kan tilføje intervalfortolkningsbeskrivelser. Så prædikaterne har altså bare en titel, nogle nøgleord/-fraser, en beskrivelse, og det er det for nu. .\,.\,(Så eventuelle intervalfortolkningsbeskrivelser føjes altså bare til beskrivelsen her for prototypen.)

I starten kan brugerne bare vælge imellem et lille antal af prædefinerede filterindstillinger for hvert prædikat (og med en knap til at flippe kurven horisontalt, så man ordner fra negativ til positiv i stedet).\,. 

.\,.\,Hm, lad mig lige tænke over, hvor meget jeg vil gøre ud af flersøjle-prædikatsøgningen i starten, før jeg begynder på oerlayet.\,.

I øvrigt skal filterindstillingerne kun foregå i en menu i højre side i starten, så når brugeren ser et prædikat i en liste, skal de altså kun kunne læse om det, og så vælge og tilføje det til arbejdsbordet --- og sikkert også kunne folde en ny søjle (eller underliste) ud fra den, men det vil jeg lige tænke over.\,. 

.\,.\,Jeg vil forresten bare bruge en PHP-server (og med den type SQL-database, der lige hører til den, jeg finder (.\,.\,hm, som sikkert bliver en Apache-server.\,.)). 

Okay, jeg går en tur i solskinnet og tænker videre over, hvor meget af flersøjle-navigati-onen, jeg skal tilføje her i starten, samt også hvordan brugeren skal finde frem til ressourcetermer og bedømmelsesprædikater.\,. (11:24)

(12:33) Okay, jeg tror vist bare, at jeg for prædikater skal have to muligheder i starten, når det kommer til at udfolde børnelister/-søjler, nemlig `relevante kategoriseringsprædikater' og `relevante bedømmelsesprædikater.' .\,.\,Hm, eller rettere `kategoriseringsprædikater som er relevante til brug for at lave en underinddeling, når givne prædikat er valgt.' .\,. .\,.\,Kortere sagt kunne man bare sige `relevante underkategoriseringsprædikater,' eller endnu kortere: `underkategoriseringer.' 

Der skal også gerne være en liste over ressourcer, der konstant ændrer sig, når man vægler flere og flere kategoriseringer til, hvilket vil sige, at vi måske faktisk nærmest skal tilbage til det der med at have navigationen i en fold-ud-menu, eller noget der svarer lidt til.\,. .\,.Hm, lad os sige, at (graf-)søjle-prædikatsøgningen og ressourceliste visningen kan foregå i to faner.\,. som dog godt også kan vises side om side i en tredje fanemulighed. 

Hm, udover at brugere skal kunne føje prædikater til listen over aktive prædikater, skal brugere så også kunne rate relevans for den pågældende søjle, direkte når brugeren har klikket på et prædikat i en søjle.

Lad mig forresten bare holde mig til søjler og dermed altså udskyde omtalte nedad-pils funktionalitet til et senere tidspunkt (og altså kun have højre-pilen). 

\ldots Ressourcer skal kunne rates efter hver enkelt af de valgte prædikater (som inkluderer de aktive prædikater), og barnesøjle-/fold-ud-mulighederne for ressourcer kan bare være `relevante bedømmelsesprædikater,' `relevante kategorier'.\,. Nå nej, never mind. Begge disse to ting er ikke nødvndige (af hver dere grund).\,. .\,.\,Men `relevante ressourcer' er selvfølgelig en god ting.\,. .\,.\,Nå jo forresten `relevante bedømmelsesprædikater' skal faktisk med.\,. Hm.\,. \ldots Der skal rigtignok være `relevante bedømmelsesprædikater' som en fast relation til ressourcetermer, men det er så bare vigtigt, at man sørger for at brugerne også kan få bedømmelsesprædikat-forslag fra ressourcens kategorier i stedet (altså fra når et prædikat er et `relevante bedømmelsesprædikat' til et kategoriprædikat, og hvor ressourcen så er dømt som inden for den kategori).\,. 


\ldots\ Okay, jeg tror faktisk, at jeg vil gøre det sådan, at forfatteren til et prædikat faktisk kan tilføje et vilkårligt antal intervalbeskrivelser, endda med vilkårlige og muligvis overlappende intervaller. Disse skal så vises i en liste under ratingbaren, hvor teksten for kun de intervaller, hvor bar-knappen er indenfor, vises. På sigt vil jeg så faktisk også gerne have, at brugeren bare kan trykke på en tekst og se intervallet, og så endda vælge, om ratingen så skal gives ud fra bar-knappens position, eller i stedet bare ud fra den highlightede teksts interval, hvorved ratingen så bare forståes som, at brugerens rating ligger inden for dette interval! Så dette kan altså således også blive den måde, hvorpå brugerne basalt set giver hinanden mulighed for at lave mere diskrete ratings! Virker fornuftigt nok.\,:) Men ja, i første omgang til prototypen skal teksten bare vises, og ratingen skal bare gives ud fra bar-knappens position altid. :) (16:14)

Hm, når brugeren tilføjer et prædikat til arbejdsbordet, kan denne tilføje det som aktivt eller ikke aktivt. Jeg tror ikke jeg vil lave to lister til aktive og ikke-aktive prædikater i prototypen (bare have én liste) i arbejdsbordet. I stedet skal de aktive prædikater bare highlightes, og brugeren kan så slå prædikater til og fra her, samt ændre på filterindstillingskurverne, og selvfølgelig også fjerne prædikater fra listen igen som nævnt. 






\section{Flere tanker om semantik-applikationen imens jeg arbejder på prototype}

(04.02.23, 9:54) Jeg føler virkeligt, at jeg har ramt noget rigtigt godt med mine seneste tanker. Førhen tænkte jeg jo mere på at starte med tag-ratings og et kategori(serings)træ (eller rettere en graf) som noget, der var hver for sig. Men nu bliver kategoriseringen meget mere bottom-up, også direkte ud fra rating-tags'ne, og det tror jeg altså bare kommer til at gøre så meget for, at applikationen kan komme hurtigt i gang (og at folk nemlig kommer godt i gang med at kategorisere ting på en rigtig god og naturlig måde). 

(9:59) Nå, men jeg har også nogle tekniske tilføjelser, jeg vil nævne. For det første skal URL'er ophæves til en ret vigtig termtype/datatype for systemet. Når hjemmesiden har godkendt en vis URL-RegEx, som kan hentes data fra, så skal brugerne være rimeligt frie til bare at sende URL'er til databasen, der matcher, gerne endda som en hel strøm af forslag, hvor databasen så bare kan time strømmen ud, hvis der er gået lang tid siden den sidst fik en ny URL --- og afbryde strømmen, hvis der er flere ikke-gyldige URL'er i den. 

Jeg vil også.\,. %Hm, jeg skal lige have nget at spise, før jeg kan fortsætte.. (10:04) 
%(10:16):
\ldots gerne have, at datafelter bliver en anden fast type, hvilket nærmere bestemt er relationsentiteter hver især mellem en ressource(-reference), et navn på datafeltet (f.eks.\ `medvirkende skuespiller'), en datatype (tekst, tal eller binær) og så et (andet) %(for datatypen kan også bestemmes af et byte-flag) 
byte-flag, der bestemmer, om det er en 1-, 0--1-, 0--mange- eller 1--mange-relation (f.eks.\ 0--mange hvis vi ser på `medvirkende skuespiller' i en film). Brugerne kan så rate, om et givent datafelt er relevant for en ressourcereference. Bemærk at disse felter så ikke er en del af, hvad der allerede er brugt til at karakterisere ressourcereference; alle felterne i en ressourcereference er nøglefelter, og alle datafelter er ikke nøglefelter, og er sågar nullable. .\,.\,(Så når jeg har skrevet f.eks.\ 1--mange, så er dette bare et signal om, at man ved at ressourcen har mindst én i virkeligheden, men der kan alligevel stadig godt stå null i den semantiske database.\,.) Nå, og brugerne kan så tilføje data til et givent datafelt, og her kan det bemærkes, at al sådan data kan implementeres i en relationel database som en binær relation, nemlig over et givent datafelts hash-nøgle (for sådan en mener jeg også, at hvert datafelt bør have) samt det givne data.\,. ja, og så skal der jo så også lige være en ny hash-nøgle her også.\,. .\,.\,Ja, jo.\,. Brugere kan herefter så rate disse datafeltinstanser, som vi kan kalde dem, op og ned, og herved kan brugerne altså føje data til eksisterende ressourcereferencer på semantisk vis. %(10:38)

URL'er er så et slags specielt datafelt, som en ressourcereference altid har 0--mange af.\,. Hm, og hvad med datareferencer.\,.\,? .\,.\,Nå ja, det var da egentligt lidt meningen, at der skulle have været en URL i stedet for den faktiske data.\,. Hm, men skal man ikke så bare inddele det i to typer datafelter, hvor den ene gemmer data i selve databasen, og hvor den anden i stedet bare ``derefererer'' dataen fra en URL i stedet.\,.\,? .\,.\,Jo, fint. .\,.\,Her skal det så nævnes, at applikationen dog kun rent faktisk vil hente data fra en URL, hvis det kommer fra en URL-RegEx, der allerede er tillid til (så brugere skal først have deres URL'er godkendt). (10:49)


\section{Nye tanker og idéer! (Attributter! Exisd! Idéer om query-sproget m.m.!)}

(09.02.23, 11:09) Jeg har en hel del gode nye idéer, som jeg har tænkt mig at skrive om (og tænke færdig om, når det kommer til visse dele af det). Men nu vil jeg lige starte med at sige, at jeg lige har fundet på et muligt (umiddelbart rimeligt awesome (men jeg skal selvfølgelig have lidt tid til at summe over det / tygge på det)) navn til web-applikationen! Jeg er lige kommet på, at jeg måske kunne kalde det Exisd. Extendable Interface for a Semantic Database. Umiddelbart ret nice, og sikkert ikke brugt til noget andet ellers. Lige inden jeg kom på det, tænkte jeg også på Exodus, nemlig ift.\ noget a la: Extentable.\,. interface for an Open Database of User Semantics. Umiddelbart ligger der bestemt også noget potentiale i denne idé, hvis man arbejder videre på den --- jeg kan især virkeligt godt lide slutningen (dus) --- men på den anden side synes jeg også, at to stavelser klart slår tre.\,. *(Og betydningen af `exodus' rammer også ret meget ved siden af, og i modsætning til Exisd, så synes jeg, at man tænker mere over betydningen af `Exodus,' når man hører/læser ordet.) .\,.\,Anyway, jeg vil tænke videre over det, men fedt endeligt at have nogle mere mundrette (og i det hele taget ret gode) bud på banen! .\,.\,(Og ja, så exisd.com kunne altså være et muligt domænenavn til hjemmesiden.\,.)

*(Nu tror jeg måske, at hjemmesiden skal hedde sema (.net og/eller .com) i stedet.\,. (14:17, 01.03.23))

(11:50) Nå, lad mig skrive om nogle flere af mine nye tanker, navnlig omkring de grundlæggende typer og den grundlæggende semantik. 

De grundlæggende typer, hvis vi ser på en abstraktion over, hvad databasen skal implementere, skal være diverse konstante grundlæggende datatyper såsom `int,' `float,' `date,' `time,' `date-time,' `binary' og `string.' Som jeg forestiller mig database-implementationen, så skal `int' og `float' altid stå på en plads i en databaserelation (i.e.\ en databasetabel), hvor der alligevel skal være plads til en reference også, så for simpelheden skyld (også fordi `floats' gerne må kunne være double precision minimum) så skal `int' og `float' samt alle reference-adresser bare være 8 bytes lange (altså long, double og long hhv.). Hvis brugerne vil snakke om andre datatyper såsom longint, og hvad har vi, så må de altså selv implementere dem via `object'-typere, som jeg kommer til lige om lidt. Angående `string,' så skal der bare være én type, men databasen kan dog selvfølgelig godt implementere mindst to typer, sådan at der både er en datatype 8 byte lange strings, og også en (eller flere) string-reference-type, hvor databasen slår op i en eller flere andre tabeller. Men som sagt: i abstraktionslaget lige over databasen skal der altså kun være én string-type. Denne skal i øvrigt have en fast encoding. Så igen, hvis brugere vil implementere andre encodings, så skal de selv gøre det via object-typerne. Denne faste encoding skal gerne være UTF-8, eller måske en HTML-escaped ændret udgave af UTF-8. .\,.\,Ja, det kommer lidt an på, hvorhenne saniteringsansvaret skal ligge (altså i hvilket lag), det skal jeg lige tænke over på et tidspunkt (når det passer sig). 

Der skal så som nævnt også være en `object'-type, som bliver den mest centrale type, kan man sige, på nær måske `string,' som også bliver ret central. Disse objekttyper bliver faktisk også defineret af (UTF-8-)strings, men forskellen er, at hvor en string-type (og vi er altså stadig i abstraktionen lige over databasen (.\,.\,tja, som man i princippet også kan kalde en database, for `database' er jo selv en abstraktion (og fås i mange udgaver, ikke bare relationel))) altid bør fortolkes som refererende til strengen selv, så skal en objekttype fortolkes som referere til den entitet som strengen taler om. I princippet kan formatet af, hvad vi kan kalde objektstregen, være alt muligt, men der skal dog gerne være en standard allerede til at begynde med for hvordan man formulerer et objekt via objektstrengen. Og her tænker jeg så simpelthen bare Javascripts syntaks for at definere Javascript-objekter, dog måske faktisk uden tuborgparenteserne, det ved jeg ikke. Men det skal altså gerne bare være en kommasepareret liste af attributdefinitioner, alle på formen ``$<$attribute name$>$=$<$attribute value$>$, hm, hvor attribute name så skal backslash-escape'e alle instanser af `=' samt af `\textbackslash,' og hvor attribute value skal backslash-escape alle instanser af `,' samt af `\textbackslash.'

Så alle objekter bliver altså defineret ud fra en række attributter, men dette er slet ikke alt, jeg hr at sige om attributter! For en anden ny idé går nemlig ud på, at brugerne stærkt skal anbefales generelt altid at prøve at (om-)formulere deres relationer, som de har tænkt sig at føje til databasen, som attributter! Så f.eks.: I stedet for at oprette en relation, der siger ``hasSubcategory,'' så bør de bare kalde relationen for ``Subcategory'' i stedet. Og et andet godt eksempel er, at ``hasRelatedArticle(WhichIsTheSecondInput)'' i stedet bare bliver til ``RelatedArticle.'' Jeg forudsiger, at det kommer til at forsimple tingene en hel del, både udseendesmæssigt, men faktisk også rent forståelses mæssigt, for så er det altid let at forstå, at subjektet i relationen er den der har noget, og at navneordende og tillægsordene, der forekommer i relationsnavnet altid har det med at beskrive objektet --- uden at dette behøver at specificeret via alle mulige andre små ord i en sætning, hvilket nemlig ofte kan være rigtigt kompliceret, især hvis sætningen er tvunget til at starte med ``has,'' og at man derfor i reglen vil være tvunget til at udskifte subjektet i sætningen, hvis man vil begynde at kvalificere objektet! Så ja, at holde sig til at prøve at formulere relationerne som attributter i stedet gør det bare SÅ meget nemmere (vil jeg forudsige)! Herved kan langt de fleste relationer kunne formuleres på formen: ``[Tillægsord, Sammensat tillægsord]$<$Navneord $|$ Sammensat navneord $>$.'' (12:49)

Prædikater må på den anden side gerne have formen ``is$<$Tillægsord$>$'' eller andet lignende, altså formen af lowerCamelCase sætninger, hvor subjektet implicit er det første (og eneste) input, og hvor første ord er et verbum. (Dette er i modsætning til attribut-formen, som altså efter min mening bør være UpperCamelCase og med et implicit verbum samt også implicit subjekt og objekt (og hvor attributnavnet så beskriver objektet).) 

Med disse standarder på plads for vi så et udgangspunkt, hvorfra vi kan definere alverdens semantik. Et passende spørgsmål er så: Hvilken type skal relationerne (som altså også kan (og bør!) fortolkes som attributter) og prædikaterne så have? De skal enten have string-typen eller objekt-typen! .\,.\,Hm, tja, vent lige, for jeg har ikke tænkt på, at det faktisk \emph{kan} lade sig gøre, kun at bruge objekttyper til dem, hvilket hænger sammen med, at attributterne i objektstrengene ikke behøver at følge de samme regler som relationsattributterne (for disse to ting skal faktisk bruges helt forskelligt, hvilket jeg vil vende tilbage til).\,. Hm.\,. (13:05) \ldots Hm, på den anden side var jeg jo egentligt alligevel nået frem til, at alle datatyper bliver til, hvad vi måske kunne kalde dynamiske objekter, så at sige.\,. så måske betyder denne overvejelse egentligt ikke så meget.\,.\,?\,.\,. .\,.\,Jo, så never mind.\,. Så alle datatyper kan fortolkes som objekter, nemlig ved altså at lade dem indgå i relationer, hvor relationen er formuleret som en attribut. I princippet kan relationer og prædikater dermed også bare have alle typer, men i praksis giver det selvfølgelig kun mening.\,. tja, hvis de er strenge eller konstante objekter, skulle jeg til at sige, men i princippet kunne man også vælge binær.\,. Tja, men det ville dog være meget mærkeligt at gøre, medmindre at en gruppe brugere på en eller anden måde kan finde gavn af dette på et tidspunkt. Men ja, i reglen bør relationer og prædikater altså enten være strings, og mere specifikt altså som følger den ovennævnte standard (på nær at brugerne også godt \emph{må} formulere relationer på mere konventionel vis, selvom de dog stærkt er opfordret til at formulere dem som attributter i stedet), og eller kan de være konstante objekter.\,. Hm, jeg skal forresten finde på en bedre måde at skelne mellem objektstreng-objekter og streng-objekter.\,. .\,.\,Hm.\,. .\,.\,Hm, jeg kunne måske bare kalde objektstrengene for `objektdefinitioner' i stedet.\,. .\,.\,Ja, det kommer vist til at give rigtig god mening.\,.(!) .\,.\,Klart. Ok, så alle datatyper bør fortolkes som objekter i princippet, og så kan man så dele alle objekter ind i to overordnede kategorier, nemlig i, hvad vi kunne kalde `datamonader' (hvilke så fås i flere underkategorier alt efter den pågældende datatype --- så vi har f.eks.\ `string-monader' og `int-monader' osv.), og så i, hvad vi kunne kalde.\,. .\,.\,hm, man kunne bl.a.\ kalde dem `attributdefinerede objekter.' (13:42) .\,.\,Yes! .\,.\,Hm, eller i stedet for `datamonader,' kan vi også bare kalde dem data\emph{instanser} i stedet, det virker simplere og bedre.\,:) 
.\,.\,Hm, ja, og faktisk burde man næsten kalde det for `attributdefinerede instanser' i stedet.\,. tja, eller det er så spørgsmålet, om vi skal sige ``objekter'' eller ``instanser''.\,. måske er det bedre at sige ``objekter'' i stedet faktisk.\,. .\,.\,Ja, yes, lad os gøre det!\,. 

Så langt, så godt! Lad mig se, hvad skal jeg så fortsætte med at forklare om.\,.\,? (13:50) .\,.\,Nå jo, jeg skal jo først og fremmest lige pointere, at en objektdefinition så typisk ikke er beregnet til at blive brugt i den semantiske databases QL. I stedet forventes det, at brugerne selv tilføjer faktiske attributter (som i princippet altså er omfortolkede relationer) til objekterne, bl.a.\ så at attributterne fra objektdefinitionen også kommer med og bliver til ``faktiske attributter.'' Bemærk, at dette faktisk gør, at man endda kan rette i objekters definerende attributter, nemlig hvis der ikke er nogen tvivl om, hvad objektet repræsenterer, men at der alligevel er sneget sig en fejl ind i definitionen. Et godt eksempel på dette (som dog slet ikke er det eneste eksempel) kunne være, hvis nu man skraber sig til an masse objekter andre steder fra på webbet, men at der så er en lille fejl på en af de lokationer, %...(14:09):
typisk vil man så alligevel kunne regne ud, hvilket objekt der er tale om. Brugernetværket behøver derfor ikke nødvendigvis så at lave et nyt objekt og gentage deres ratings omkring det, men kan så i stedet bare rette i de ``faktiske attributter,'' der indeholder pågældende information. Et andet tilfælde kunne være, hvis nu en af de definerende attributter ændrer sig. Lad os sige at man har en objektklasse af vindere af en eller anden pris, men at én prisvinder pludselig får deres pris annulleret. For ikke at miste ratingdata kan brugernetværket så sagtens bare omformulere de faktiske attributter, så de igen bliver tidssvarende, uden at det altså gør noget, at den oprindelige, ikke-tidssvarende objektdefinition beholdes (for denne bruges altså alligevel bare til at sætte objektet i gang, så at sige). Objektdefinitioner skal altså bare være rimeligt entydige, når de formuleres, hvis man gerne vil have objektet til at bestå, men behøver altså ikke at være fuldt ud korrekt og til alle tider. Endvidere kan objektdefinitioner også godt indeholde en formel tvetydighed, uden at dette gør, at brugernetværket bliver nød til at kassere objektet, for så længe brugernetværket ikke er i tvivl om, hvad var refereret til originalt med objektdefinitionen, så gør det ikke noget, at man senere finder frem til, at der også kunne være en anden fortolkning. Endvidere kan det også være, at brugernetværket får lyst til at dele tidligere objektklasser op i flere versioner. .\,.\,Hm, jeg kan faktisk ikke lige komme på noget godt eksempel, men anyway, lad os sige at netværket gerne vil dele en tidligere klasse op i to udgaver.\,. Tja, never mind, jeg behøver ikke at gå så meget i dybden med det her --- pointen er alligevel bare, at det er ret smart at objekters definitioner ikke behøver at være korrekte (og til alle tider) og hamret ind i sten fra starten af, men at man godt i praksis kan rette på objektdefinitionerne løbende (også selvom den faktiske `objektdefinition'(sstreng) forbliver den samme) uden at miste værdifuld ratingdata omkring objektet. (14:24)

.\,.\,Hm, lad mig lige hurtigt præcisere, at den semantiske database altså kender forskel på et attributdefineret objekt defineret ud fra en given string og så et string object defineret ud fra samme givne string. Så selvom disse to objekter er defineret ud fra samme data, så har de alligevel en typeforskel i den semantiske database, der gør dem forskellige fra hinanden. 

.\,.\,Nu kommer vi vel så til `udsagnene' i den semantiske database (som altså er en abstraktion i et lag over den relationelle database, jeg tænker skal implementere den semantiske database). Et udsagn består, foruden et unikt id (som altså også er med i abstraktionen), af et subjekt-objekt, et relations-/prædikat-objekt, og muligvis et objekt-objekt, alt efter om relations-/prædikat-objektet skal tolkes som en relation eller et prædikat. Her synes jeg så, det er værd at bemærke, at jeg faktisk også forestiller mig, at dette skal implementeres som en enkelt relation i den underliggende relationelle database, som altså både indeholder relations- såvel som prædikat-udsagn, og hvor der så bare lige er et bool-flag, der siger, om det er det ene eller det andet (og hvis flaget er sat til IS\_PREDICATE så skal objekt-objektet selvfølgelig bare altid være null). Herved er det altså udsagnet selv, der ved, om det er et relations- eller et prædikat-udsagn, og hermed skal man altså slet ikke tænke på typer i abstraktionen (a.k.a.\ den semantiske database), når det kommer til at danne udsagn. Så rent typemæssigt består `udsagn'- (eller `statement'-)typen i den semantiske database altså bare af: RelationStatement of Object $\times$ Object $\times$ Object $|$ PredicateStatement of Object $\times$ Object, og hvor objekt så har de førnævnte undertyper af `attributdefinerede objekter,' `string-objekter,' `int-objekter,' osv. Og det er så op til brugerne af den semantiske database selv ikke f.eks.\ at sætte et talobjekt in på en relations plads, eller ikke at sætte f.eks.\ AttDefObj(`Type=predicate, Title=isFunny, Description=[...]') eller StrObj(`isFunny') ind som andet objekt i et prædikat-udsagn. .\,.\,Hm, nu bliver jeg lidt i tvivl om ikke, man bare skal lægge op til en standard om at bruge lowerCamelCase overalt i stedet for attribut- prædikat- og relationsnavne, det synes jeg faktisk.\,. .\,.\,Jo, lad mig sige det for nu. Så kunne jeg altså derfor have skrevet AttDefObj(`type=predicate, title=isFunny, description=[...]') og StrObj(`isFunny') i stedet. Bemærk forresten at man i modsætning til i Javascript og XML m.m.\ ikke behøver at putte gåseøjne omkring værdierne, for det er kun mennesker, der skal læse det alligevel, aldrig maskiner. Maskiner skal nemlig kun læse de ``faktiske attributter'' m.m., som forklaret ovenfor. .\,.\,Hm, men jeg tænker godt nok også at bruge en lidt tilsvarende syntaks for query-sproget, så det kan jo godt være, at man så for objektdefinitionerne vil vælge at holde sig til en tilsvarende syntaks også, nemlig for konsistensens skyld. Men ja, heldigvis er dette i sidste ende bare op til brugerne, for igen: Det er kun mennesker, der skal læse objektdefinitionerne, ikke maskiner (på nær hvis man vil udplukke det strengobjekt som er defineret ud fra samme streng for så at lave streng-operationer på det, hvilket jeg nemlig vil have, at man skal kunne, men det kommer jeg til på et tidspunkt). (Men i forhold til at fortolke værdierne i et attributdefineret objekt, så er det altså kun i reglen mennesker, der skal gøre dette.) 

Nå ja, og i tråd med, at jeg altså gerne vil implementere relations- og prædikatudsagnene i samme tabel i den underliggende (relationelle) database, så skal StatementID'erne også bare løbe fra ulong 0 til ulong $0 - 1$, hvor prædikat- og relationsudsagn altså bare er helt blandet sammen, og hvor ID-nummeret altså bare afhænger af, hvornår udsagnet blev oprettet (igen uagtet undertypen). 

Nu når vi jo så til Rating-typen i den semantiske database, hvilket så består af et udsagnsID, et brugerID, et flag der angiver rating-typen og så ellers to dataobjekter, hvoraf det første meget gerne skal være en double float, der beskriver gennemsnitspunktet for brugerens rating. En af de halt basale ratingtyper kan så være, hvor det andet dataobjekt også er en double float, der beskriver interval radiussen, således at sådanne ratings altså gives som en slags step-funktioner, der så altså er defineret ud fra et midtpunkt og en (halv) intervalbredde. Desuden må ratings også meget gerne indeholde et timestamp (date--time) for, hvornår de blev givet. I modsætning til de andre ting i den semantiske database, så skal brugere ikke generelt have adgang til andre brugeres ratings, altså medmindre at brugerne har givet tilladelse til andet (og ikke har trukket denne tilladelse tilbage, hvad brugere nemlig også skal kunne når som helst). .\,.\,Det kan dog godt være, at man i betaversionen af applikationen bare undlade at implementere denne del, og i stedet bare advare alle brugere i betaversionen om, at alle deres ratings vises offentligt indtil betaversionen slutter. .\,.\,Man ja, lad mig vende tilbage til emnet omkring, hvem kan se hvad, og om hvordan brugere har ret til altid at null'e deres egne bidrag og/eller data, der forbinder dem med objekter m.m.\ i databasen, for det er ikke et vildt centralt eller presserende emne. (15:33)

.\,.\,Sikke tiden er fløjet, men det er jo også en omfattende ny omgang idéer, jeg har skulle skrive om. Jeg mangler nemlig også endda at skrive mere om QL'et, og så skal jeg også skrive om nogle nye idéer ift.\ det med at brugere skal kunne oprette HTML-, CSS- og Javascript-biblioteker/-udvidelser i databasen, som andre brugere så skal kunne loade og bruge (hvis de kan se, at mange har gennemgået koden og godkendt den). Mine ben summer helt vildt efter at blive rørt lidt (som i: helt vildt meget, faktisk), men når jeg kommer tilbage, så kan jeg måske bare lige skrive noget kort om QL'et, skrive om brugerudvidelserne, og så sikkert vende tilbage til QL'et, for jeg regner med, at jeg skal bruge nogle af de kommende dage på at få det på plads.\,. Men ja, gåtur nu! (15:45)

(16:44) Okay, jeg er kommet i tanke om, at man jo selvfølgelig ikke bør bruge strengobjekter som prædikater eller relationer, for det strider jo klart imod den semantik, jeg har lagt op til (nemlig hvor alle dataobjekter kun skal fortolkes som den værdi, de repræsenterer). Og dermed giver det faktisk også mening at kræve, at prædikater og relationer i udsagnene faktisk skal være attributdefinerede objekter, hvilket jo så også sagtens kan lade sig gøre, for den semantiske database kender jo som nævnt allerede forskel på objekt-undertyperne. 

På denne måde kan man forresten også, indså jeg så i samme forbindelse, nok gøre så at.\,. ja, det kan man.\,. gøre så at attribut-(/relations-/prædikat-)nøgleordene kan ændre stil efter brugerens behov.\,. .\,.\,Jeg vender tilbage til dette emne, når jeg når til QL'et, men jeg forestiller mig nemlig så, at brugere kan hive passende nøgleord ud af objekterne (fra deres ``faktiske attributter'' --- hvilket vi forresten også kunne kalde `levende attributter'.\,.), og identificere dem med objektets objektID, nemlig som hvad der svarer til variabeldefinitioner i QL'et. .\,. 

(17:04) På den anden side! Hvad med at jeg bare siger, at der også skal være endnu en objekttype, nemlig en `attribute'-type, som så lige præcis er defineret af strenge, der repræsenterer prædikater eller relationer, og som så følger den standard jeg talte om her tidligere på dagen (altså hvor relationer er formuleret som attributter i stedet, og hvor predikater omvendt gerne starter med et verbum (og gerne med lowerCamelCase-konventionen))?\,!\,. .\,. .\,.\,Hm, tjo tja, lad mig lige tænke lidt over det.\,. .\,.\,Tjo, måske har jeg faktisk fat i noget ret godt her, for i bund og grund handler det så om, at man så kan bruge attributnavnene direkte i QL'et, hvilket jo så netop giver mening, fordi hver attributnavn kun kan referere til ét attributobjekt, og i øvrigt også fordi navnet har en programmeringsvenlig form.\,. nå ja, måske skulle man endda kræve, at attributnavne ligefrem er ASCII, således at alle kan være med på trods af forskellige keyboard layouts. Det virker som en meget god idé.\,. Hm, og skal man så fjerne UTF-8-typen, eller skal have to typer, eller skal man som tredje mulighed bare.\,. tja, ikke have en ASCII type alligvel, men bare tjekke for hvert nyt attributobjekt, at strengen ikke indeholder ikke-ASCII.\,.\,? .\,.\,Det sidste er nok faktisk det nemmeste og det bedste.\,. (17:27) 

.\,.\,Hm, måske kunne man faktisk godt gå tilbage til den standard jeg beskrev, med UpperCC for attributter og lowerCC for prædikater (og eventuelle relationer), hvor sidstnævnte så starter med et verbum. For der er nemlig ingen, der siger, at man behøver at bruge samme konvention for objektdefinitionerne.\,. Hov vent, nej, for navnene skal jo gerne være programmeringsvenlige til QL'et, så derfor skal det faktisk være lowerCC det hele. 

Hm, jeg skal nu lige tænke lidt mere over, om det giver mening.\,. eller rettere, hvor godt det giver mening at have det på den måde med de her ``attributobjekter''.\,. .\,.\,Hm, kan det ske, at det kunne være sådan, at disse ``attributobjekter'' så bare bør være beregnet til meget fundamentale attributter, som altså indtager meget centrale pladser i hele semantikken, og at man, ligeså snart man bevæger sig væk fra de helt fundamentale --- meta!\,.\,. --- ting, så i stedet bør begynde at bruge de ``attributdefinerede objekter'' i stedet.\,.\,? (17:39) 
.\,.\,Hm, alternativt kunne man forresten også bare ændre navnet og fortolkningen af `attributdefineret objekt'-typen, så den også inkluderer objekter, der alene er defineret ud fra lowerCC-navne (nemlig med den attribut-/prædikat-/relations-fortolkning, jeg har snakket meget om).\,. Hm.\,. .\,.\,Tja, og dog: hvorfor ikke dele det op i to typer?\,. .\,. 

Hm, nu tænker jeg så at gøre, så at man enten kan bruge strenge inkapslet i gåseøje eller bruge variable --- eller objektID'er, hvis man virkeligt vil det.\,. nå nej, vent. Lad mig sige det sådan her: Man kan enten bruge strenge inkapslet i gåseøje eller objektID'er, når man referere til en attribut i QL'et, og desuden kan man også altid bruge variable, som så enten kan indeholde en streng eller et objektID. Men ja, jeg vil jo snakke videre om QL'ets opbygning på et senere tidspunkt.\,. .\,.\,Men jo, jeg synes umiddelbart, at dette giver.\,. hm.\,. .\,.\,Jo, det giver mening, for så bør programmører bare i reglen starte med at omdanne alle attributstrengene af de mest almindelige attributter til variable i stedet, sådan at man herefter kan undlade alle gåseøjnene.\,. Hm, men vent, hvad er idéen så med attributobjekter, for så kan man da ligeså godt bare bruge attributdefinerede objekter i stedet?\,.\,. Hm.\,. .\,.\,Ja.\,. (18:04) .\,.\,Ja, jo, men er det så ikke bare det; tilbage til at dele ting op i dataobjekter (af diverse undertyper) og attributdefinerede objekter og til så at kræve at alle prædikater/relationer/attributter skal være af sidstnævnte type?\,.\,. .\,.\,Virker fornuftigt nok, og så er det forventet, at alle bruger et helt grundlæggende bibliotek i første omgang til at definere variable, der repræsenterer de helt grundlæggende attributter. (18:08) .\,.\,Jo, fedt! 

.\,.\,Hm, lad mig egentligt begynde at kalde det `semantiske objekter' i stedet for `attributdefinerede objekter'.\,.\,!\,:) (18:13)

.\,.\,Hm, det eneste er, at objekter nok rammer lidt ved siden af, når vi jo f.eks.\ snakker prædikater og relationer, så hvad med at kalde det `semantiske entiteter' i stedet! Og ligeledes kan jeg så kalde det `dataentiteter' i stedet, hvilket så videre inkluderer `string entities,' `int entities,' osv. Fedt! Især den ændring med at erstatte `attributdefineret' med `semantisk,' det er virkeligt bare en dejlig ændring.\,.\,!\,:) 

(10.02.23, 9:51) Bemærk, at det nu jo heldigvis i princippet bliver ligemeget, det med at opfordre til at bruge en særlig standard for prædikatnavne og relations-/attributnavne. Men fordi jeg har tænkt mig at designe QL'et, som jeg har tænkt mig, så vil det stadig blive ret naturligt, og en god idé(!), det med generelt at gå efter at formulere relationsvariabelnavne som attributnavne. 

I går aftes fik jeg tænkt en del mere over QL'et, og jeg fik også tænkt over, hvad der lidt er det store emne/problem ligenu for mig, hvilket er implementationen af ``brugergrupperne.'' Angående det sidste er jeg så faktisk kommet lidt frem til, at databasen nok kan komme rigtig langt med den helt åbne del af den, altså den del af den som alle har adgang til at se.(.\,!) For brugere får så bare et buger-ID, når de opretter sig, og har i udgangspunktet ikke noget brugernavn i den offentlige database. Det kan de så tilegne sig ved at gå ind på sit eget brugerobjekt, eller rettere sin brugerentitet ifølge min nye terminologi, og up-rate en given brugernavnsattribut. Hjemmesiden kan så have en bot, der parser for grimme ord, og hvis ikke sådanne findes, hvis brugernavnet ikke allerede er tilknyttet en anden bruger, og hvis botten kan se, at brugernavnet er up-ratet af brugeren selv (med det givne bruger-ID), så kan den give et up-rate på navnet også. Ved så at bruge en `brugergruppe' kun bestående af den bot, kan brugernetværket altså herved nemt get'e brugeres selvvalgte brugernavne, hvis de har nogen, og få det vist passende steder i applikationen. 

Lad os så forestille os, at hjemmesiden har en privat database over brugere. For hver bruger kan den private database så.\,. ja, ikke engang gemme hvilke bruger-ID'er er tilknyttet hvilke privat-database-brugere, men bare for hver bruger gemme antallet af oprettede offentlig-database-brugere (hver med et offentligt bruger-ID i den offentlige database). I den offentlige database kan hver bruger så også bare få en offentlig krypteringsnøgle, som kan bruges til at indsende uploads, inklusiv ratings, med. Men den private database gemmer altså ikke den offentlige nøgle selv, den videresender den bare til den offentlige database, når den får den, og sletter den så selv. Og når det er sket, så kan den private database bare forhøje en counter med én, nemlig som så repræsenterer den private brugers antal af offentlige brugere. Hermed kan den private database så begrænse, hvor mange offentlige brugere, den vil tillade hver private bruger at have, men dette antal må gerne være så stort som 10 eller tæt på. På denne måde er hver bruger nemlig sikret, at de har nok forskellige identiteter på den offentlige side, således at de kan undgå at hver enkel (på nær måske én) offentlige profil kan tilknyttes vedkomnes virkelige identitet --- eller tilknyttes en af vedkommendes online identiteter for den sags skyld --- hvis brugeren ikke ønsker dette. Ok! Og med dette, så kan man sikkert bare gøre brugerentiteterne samt deres ratings til noget, som alle i princippet har adgang til, og komme rigtig langt med dette! Det tror jeg på! .\,.\,Og det forsimpler jo virkeligt nogle ting, samtidigt med at det også åbner op for rigtig mange muligheder for brugernetværket med et enkelt slag! Virkeligt nice!\,:) 

Det gør også, at den offentlige database nu også potentielt set kan implementeres som en spredt, decentral database. For hver del af den spredte (distributed) database kan så bare have sin egen private database, som de stoler på i forhold til at være en kilde til offentlige brugernøgler (og som ikke tillader for mange per private bruger). Hm, dette leder jo så med det samme til at tænke på, om ikke man så skulle indføre et præfiks til alle bruger-ID'er i princippet, sådan at man åbner op for, at den offentlige database på et tidspunkt kan blive spredt, hvorved hver afdeling af den spredte database så kan sætte sig på sit eget præfiks og så eller nummerere alle sine brugere i rækkefølge fra 0 til ulong $0-1$.(?) .\,.\,Hm, men så skal man vel også have en præfiks på alle adresser i det hele taget.\,. det kan jeg mærke, at jeg ikke har nok forstand på (altså spredte databaser) til at kunne forudsige. .\,.\,Ja, så lad mig selv undlade at tænke på sådanne præfikser, og hvad har vi, for heldigvis kan man jo altid bare tilføje sådanne med tilbagevirkende.\,. Nej, vent.\,. Hm.\,. .\,.\,Ah: Jo, man kan tilføje præfikser på alle adresser med ``tilbagevirkende kraft,'' men man kan dog ikke tilføje det til de semantiske objekter med tilbagevirkende kraft, så hvis vi ser på det semantiske.\,. den semantiske entitet, der skal repræsentere en offentlig brugerprofil, så skal det altså gerne lige præciseres, at hvad bruger-ID'et refererer til (nemlig en bruger i den originale af de semantiske databaser/databaseafdelinger), det er klart. Hm, men jeg skal så lige tænke over, om brugerentiteter udelukkende skal være semantiske entiteter, eller om der også skal være en hvis bruger-ID-dataentitetstype.\,.\,? (10:41)

.\,.\,Forresten, angående det med præfikser, så vil den første database aldrig nå op på de høje nok long adresser, så efterfølgende databaser/databaseafdelinger kan i princippet bare starte fra en passende stor long-adresse, og så nummerere alle sine adresser derfra. For hvis de nederste bytes er 0 i den valgte startadresse, så vil dette jo bare svare til at vælge et præfiks. (Jeg ville bare lige nævne det, men jeg har ikke tænkt mig at tænke mere over det emne (omkring en spredt database)).

Angående brugerentiteterne, så skal dette jo nok bare være semantiske entiteter med en fast skema for entitetsdefinitionerne, hvor databasen, eller rettere databasecontrolleren, uploader en sådan entitet, hver gang en ny brugerprofil oprettes. Her skal brugerprofilens (unikke) offentlige krypteringsnøgle så indsættes. Og når en bruger uploader en rating til databasen, så krypteres dette upload bare med den tilhørende private krypteringsnøgle, hvorved databasen så kan tjekke, at ratingen stammer fra den givne bruger, og hvis dette stemmer, så opretter databasen en rating i databasen, hvor brugerreferencen så simpelthen bare bliver den semantiske brugerentitets adresse i databasen, og altså ikke selve bruger-ID'et. Det lyder altså ret fornuftigt.\,;)\,\textasciicircum\textasciicircum\ 

\ldots (11:18) Inden jeg går videre, skal jeg også lige nævne, at det så er meningen, at brugere kan bruge vilkårlige tredjeparter til at hjælpe brugeren med at fordele tillid fra én offentlig profil til en anden (mere anonym) profil. Dette kan ske ved at brugeren krypterer en meddelelse med flere af af sine offentlige krypteringsnøgler og sender den i hemmelighed til en tredjepartsinstans, som vekomne stoler på ikke vil røbe hemmeligheden og vil slette hemmeligheden fra hukommelsen, efter at proceduren er fuldført. Instansen kan så tjekke, at de givne profiler er tilknyttede, og kan så beregne en vis samlet tillid, samt muligvis en vektor der approksimativt beskriver brugerens samlede interesser og/eller holdninger (muligvis krydret med en lille tilfældig vektor som plusses på). Og herefter kan instansen så per brugerens forespørgsler så oprette ratings i den offentlige semantiske database omkring de profiler, som brugeren ønsker.\,. nå nej, omkring \emph{den} profil, for i reglen vil man kun gøre det for en profil ad gangen (som modtager tillids-, interesse- og/eller holdningsbekræftende data om sig) for ikke at afsløre tilknytningen offentligt. *(Tja, eller også kan man bare bede instansen om at holde på hemmeligheden i et forlænget tidsrum sådan at den kan rate flere profiler i det tidsrum, nemlig ved så at tilføje tilfældige delays mellem hver profils ratings (og hvor vektorernes tilfældige krydderi så også ændres for hver gang).) Instansen har således en offentlig profil (hvor omverdenen altså kender profilens tilknytningen til instansen) i den offentlige database, hvor den så efterfølgende kan oprette ratings, for den givne brugerprofil som ønsket. .\,. Og når den har oprettet de ønskede ratings, sletter den altså så alle hemmelighederne igen fra brugeren af. Efter hele denne procedure kan andre brugere i brugernetværket nu (eventuelt; hvis de altså har tillid til instansen) bruge instansens ratings til at hjælpe dem med at fordele tillid m.m.\ til diverse brugerprofiler. (11:36)

Ok! Inden jeg fortsætter omkring QL'et, så bør jeg lige snakke lidt om web applikationens interface, og om hvordan brugerne selv kan udvide det. Lad mig starte med at tegne et billede af, hvordan jeg forestiller mig at en tidlig implementation af interfacet kunne se ud. Jeg forestiller mig nu for det første, at der skal være en QL-kolonne/søjle / -fold-ud-menu til venstre, hvor avancerede brugere (hvilket jeg så lidt regner med at alle de helt tidlige brugere vil være (eller rettere blive; relativt til de efterfølgende brugere)) kan skrive og gemme QL-scripts. Når et QL-script (query language, btw) har kørt, så kan scriptet enten vælge, at outputtet skal være en ny kolonne helt til venstre, en kolonne helt til højre, en kolonne lige til højre (eller venstre) for QL-kolonnen (da denne også muligvis kan forekomme som en søjle inde imellem andre søjler/kolonner), eller om outputtet skal åbnes i en ny fane i browseren, eller bare i et nyt vindue i samme browserfane, hvor brugeren så kan skifte mellem disse applikationsvinduer. Det typiske output vil så være en liste af semantiske entiteter, som regel af en vis samme ``type.'' Her er det så vigtigt at pointere, at ``typen'' her bare er defineret ud fra en semantisk (``levende'') attribut ligesom alt andet omkring entiteten (lige på nær dens entitetsdefinition). Men ``type'' skal nu alligevel gerne være en ret fundamental attribut, som hjemmesiden selv i høj grad i starten hjælper med at sætte for hver entitet (og helst i forbindelsen med oprettelsen af entiteten). .\,.\,Hm, ja, man kunne faktisk benytte sig af en vis konvention starten om, at brugere (såvel som hjemmesidens selv ift.\ dennes bidrag/``uploads'') \emph{skal} definere typen i starten af enhver ny semantisk entitet. Hvis en bruger så definerer en typen mærkeligt/forkert ift.\ de efterfølgende definerende (semantiske) attributter i definitionen, jamen så kan brugernetværket bare let kassere entiteten (for det vil nemlig være så godt som umuligt at overse ``typen,'' ift.\ hvordan jeg tænker, at det kommer til at blive, nemlig fordi jeg tror, at ``typen'' vil blive et helt centralt element i alle (gængse, fornuftige) QL-scripts). Jeg forestiller mig så, at hver (tidlig, avanceret) bruger i princippet så vælger en HTML-skabelon for hver type, eller rettere to: En til brug når entiteten vises i en liste og én til brug, når entiteten vises på dens egen ``side,'' så at sige (som jeg også har været inde på før). %(12:00) 
%(12:08):
.\,.\,Noget der så måske er nyt, er at jeg nu forestiller mig, at mulighederne som brugerne har ift.\ at gå til entitetens egen ``side'' eller at folde flere søjler ud på baggrund af entiteten --- eller at tilføje nye variabeldefinitioner til ens QL-script til venstre! --- det skal alt sammen bare implementeres i omtalte HTML-skabeloner (som også godt må indeholde Javascript!) fra starten af. Så man åbner altså det hele op for brugerne fra starten af (og hvor de tidlige brugere altså herved er programmører). Og nu er jeg godt nok bevæget mig lidt væk fra, hvordan jeg forstiller mig et tidligt interface, men lad mig bare fortsætte med dette mere generelle omkring interfacet, og hvordan det kan udvides af brugerne, og så kan jeg senere fortsætte omkring, hvordan jeg forestiller mig en tidlig implementation. (Hm, lad mig lige skifte paragraf og fortsætte omkring det generelle.\,.)

Den gode pointe er så, at det rent sikkerhedsmæssigt ikke kommer til at være anderledes, end hvis brugeren selv programmerede noget i javascript og så åbnede det i en browser. Her kan man jo også søge online på kodeudsnit, hvilket man så delvist kan gennemgå selv og delvist kan vurdere tillid til ud fra, hvordan andre online brugere har ratet kodeudsnittet på siden, hvor man tager det fra. For det skal nemlig ikke være sådan, umiddelbart, at de tidlige brugere kommer til at loade deres HTML--JS-biblioteker/preamble-QL-scripts via queries, som så kan ændre sig i princippet fra gang til gang! I stedet er det meningen, at brugerne refererer til bibliotekerne/scriptsne direkte via deres entitets-ID'er(/-adresser) i databasen, hvilket nemlig ikke ændrer sig fra gang til gang. Så ja, og fordi alle biblioteks-/preamble-script-referencer er konstante, så er det altså helt ligesom at kode javascript i almindelighed. Når vi så ser på en specifik HTML--JS-skabelon, som brugeren vælger til en vis entitetstype (altså den semantiske type), så skal der selvfølgelig være en klar konvention om, at al Javascript i disse skabeloner kun ændrer på ting inde i skabelonen, og altså ikke ændrer på nogen globale variable osv. Og hvis en bruger uploader en skabelon, der gør dette, så vil den jo bare aldrig blive stemt op af nogen troværdig bruger. Hjemmesiden bør forresten også selv hjælpe til med at verificere at skabeloner ikke gør nogle uhensigtsmæssige og/eller skadelige ting, men i sidste ende er det vigtigt ikke at stole på noget, medmindre man kan se at nogle af de troværdige avancerede (måske tidlige) brugere har up-ratet det (og ingen af dem har down-ratet det). 

Hjemmeside-interfacet skal så fordre brugerne med indbyggede JS-funktioner, som de kan gøre brug af i deres HTML(--CSS)--JS-skabeloner, som så bl.a.\ kan bruges til de nævnte ting såsom at åbne nye kolonner ved siden af den relevante kolonne eller i en af enderne, og såsom at tilføje nye variable til brugerens script til højre. Disse funktioner skal også selv inkludere muligheden for at bygge diverse QL-scripts. Bl.a.\ kunne man have en funktion, der parser en string skrevet i pågældende QL-sprog og returnerer et slags query objekt, som brugeren/programmøren så videre kan bruge til at åbne nye kolonner. Jeg har ikke nævt det endnu, men selve listerne i hver kolonne skal også have en HTML--osv.-skabelon, som brugerne så i princippet selv kan vælge. .\,.\,Ah, man kunne eventuelt gøre det sådan, at man laver en funktion, der tager en reference til en liste-HTML--osv.-skabelon samt en QL-string, og så åbner en ny kolonne (ud fra noget ekstra input som også specificerer valget om, hvor og hvordan denne skal åbnes) og videregiver QL-strengen, eller en umiddelbar oversættelse af den i form af et query-objekt, til den nyåbnede kolonne, hvorefter den refererede liste-HTML--osv.-skabelon så kan gå i gang med at bruge query-strengen/-objektet til at ufylde listen med entiteter. Så kan det så videre være denne liste-blabla-skabelons ansvar at vælge den blabla-skabelon, som bestemmer, hvordan entiteterne skal vises i listerne. Bemærk, at der bliver en cirkularitet i dette (fordi den åbnede kolonne så igen kan indeholde entiteter, der skal tildeles den skabelon, som man åbnede listen med i første omgang), men dt kan man sikkert sagtens løse på en god måde. (12:49)

Og ja, når det så kommer til alle disse skabeloner, så er det altså alle sammen nogen som brugeren selv skal gå ind og vælge til (altså når vi er i hjemmesidens tidlige stadie, hvor brugerne er programmører). Så på den måde bliver der altså ikke fare for (og dette kan man let sikre), at interfacet åbner henter flere skabeloner under brugerens normale brug af interfacet. Alle skabeloner skal nemlig bare åbnes som en del af QL-sproget (som altså derved næsten kan siges at blive lidt mere end bare et QL) preamble/header. Og preamblen/headeren bliver altså en ting, der er helt adskilt fra brugerens, lad os kalde det et `arbejdsscript.' Headeren, lad mig kalde den det, kommer til at indeholde skabelon-includes, og den kommer faktisk også til at indeholde noget andet ret vigtigt, nemlig nogle indledende indstillinger for hver ``type,'' lad mig forresten kalde det den `semantiske type' fra nu af, som så nemlig automatisk bliver sat på som et indledende filter for alle efterfølgende queries af pågældende type, medmindre altså at man escaper disse indledende indstillinger igen. Dette gør at brugeren selv kan sætte et personligt filter for, hvilke entiteter brugeren generelt gerne vil se optrædende i diverse kolonne-lister, som brugeren åbner i interfacet. Dette filter kommer så nedenunder alt, hvad en bruger, der har valgt et bart header-filter, ville se, hvis denne bruger brugte de samme skabeloner i interfacet. Så for at opsummere, så kommer headeren altså til at bestå (indtil jeg kommer i tanke om andre ting også) af skabelonsvalg for hver semantiske type samt grundfilter-valg for hver semantiske type. 

Og nu kunne man så spørge: Jamen, vil det så sige, at brugerne kun kommer til at kunne se entiteter af de semantiske typer, de allerede har godkendt i deres header? Ja! Eller faktisk nej, ikke nødvendigvis, for brugeren kan nemlig også helt selv vælge et filter for, hvad der skal ske med resten. Så hvis vi forstiller os en række header definitioner, så kan man altså starte med en grundlæggende indstilling for alle semantiske typer, som så efterfølgende kan overskrives af alle brugeren følgende skabelons- og grundfilter-indstillinger. Men et oplagt valg ville faktisk være simpelthen at udelukke alle entiteter, der ikke har en type som brugeren kender (og så må man bare holde øje med på anden vis, om der skulle tilføjes nogle andre semantiske typer (med tilhørende skabeloner), som brugeren kunne være interesseret i at begynde at gøre brug af også). Men! Til gengæld så er det så i høj grad værd at opfordre til / lægge op til, at brugerne også i høj grad benytter sig af undertyper! .\,.\,Hm, sådanne undertyper kan forresten benævnes i den semantiske definition ved, at man skriver ``$<$super type$>$.$<$subtype$>$=.\,. Nej, vent.\,. Nej, man skriver selvfølgelig bare ``subtype=$<$super type name (including dots if super type is itself a subtype)$>$.$<$subtype name$>$''. Og så er det altså mening, at brugere så også kan bruge disse semantiske undertyper i deres header, nemlig til så at overskrive valg for supertypen.\,:) (13:19)

.\,.\,Måske skal en kolonne også kende sine egne børne kolonner (og altså holde en liste over deres ID'er), således at en kolonne også herved kan få mulighed for at opdatere/overskrive en eksisterende barnekolonne. Ja, det lyder ret fornuftigt.\,:) 

Det er faktisk lige før, at jeg ikke behøver at sige så meget mere om, hvad jeg forestiller mig for en tidlig (brugerdrevet) implementation af interfacet (hvad jeg ellers skrev for lidt siden, at jeg ville vende tilbage til), for jeg har jo faktisk gennemgået det ret meget før, så det ville lidt bare blive en gentagelse af de pointer. Ja, så jeg tror altså, at jeg bare går videre til at snakke om ``QL'et'' nu her.\,. (13:24)

(13:49) Hm, jeg tænkte lige på, at jeg nok kan finde et bedre navn end Exisd med tiden, når jeg også har navngivet ``QL'et,'' og så kom jeg så til at tænke på, at der jo bliver to sprog i det, jeg har refereret til nu her som ``QL'et'' i de seneste paragrafer. Der bliver det faktiske QL for det første, og så bliver der interface-indstillings-sproget, som jo så nok nærmest kan siges at blive et JS-framework til at bygge interfaces, der så snakker direkte (tilsyneladende) med en semantisk database.\,. .\,.\,Og ja, i forhold til navnet på hjemmesiden, så kan det så bare.\,. ja, ligesom have navn efter dette framework.\,. Nå nej, vent, for der er så både et interface-indstillings-sprog, og så et ``sprog'' til at skriveskabelonerne i, som så bare er et JS-bibliotek. .\,.\,Ja, så tre sprog i virkeligheden, hvoraf det sidste så bare er et JS-bibliotek, og altså ikke er et egentligt selvstændigt sprog. Interface-indstillings-sproget kommer så til at kunne include JS-filer skrevet med omtalte bibliotek, og det kommer også til at have QL-sproget som et indre sprog i sig (eller hvad man nu teknisk kalder sådanne ``indre sprog,'' hvis ikke man bare kalder det det, det kan jeg ikke huske.\,.). (14:00)

%Jeg, og mine ben ikke mindst, bliver lige nødt til at gå en tur. Og når jeg vender tilbage, så kan jeg så lige skrive om, hvad jeg tænker omkring den helt grundlæggende syntaks i QL'et (altså det faktiske QL).. (14:07)

(15:18) Okay, jeg er lige kommet hjem fra en gåtur og har lige her sidst på gåturen fået nogle nye vigtige tanker! Jeg har desværre ikke så meget mere tid i dag, før jeg skal noget, og jeg kunne virkeligt godt tænke mig at nå at færdiggøre denne omgang noter i dag, så jeg må bare prøve ad at skynde mig og hamre derudaf.

Først en lille hurtig indskydning: Angående HTML--osv.-skabelonerne, bl.a.\ til at vise selve entiteterne i listerne, så skal disse altså selvfølgelig også selv kunne query'e databasen med QL'et (med AJAX) for at få de ressourcer, som skabelonen gerne vil indsætte i sig selv (inklusiv også eventuelt til diverse knapper og andre interface-funktionaliteter). Ville bare lige sikre mig, at dette var på plads.

Og en meget lille indskudt ting: Alle gemte strenge i den semantiske databasen skal være html-escaped, i hvert fald når de serveres af databasen, således at at hvis en bruger skal hente noget kode fra databasen, så skal brugeren/programmøren selv encode det tilbage til gyldig HTML(--CSS--JS), hvis han/hun vil dette. Det omvendte tilfælde ville være, hvis brugere altid skulle sanitere strenge fra databasen som en aktiv handling. Nej, i stedet skal det være de-saniteringen, der skal være den aktive handling fra programmørens side af. 

Nå, og nu videre til brugergrupper og ratingtyper. Det er jo her faktisk rigtigt fedt, at jeg er tilbage til et system, hvor alle brugere har adgang til al data i databasen (altså den offentlige (semantiske) af de to som hjemmesiden bruger (ikke den førnævnte private database)). For det gør også, at brugergrupper nu kan implementeres via bots, og altså implementeres i applikationslaget (så at sige)! Jeg skal lige tænke lidt mere over, hvordan dette kommer til at bruges i QL'et, så lad mig lige gå videre og nævne noget kort om ratingtyper først.

Det helt korte af det, jeg vil nævne om ratingtyper er, at disse også nu kan implementeres i ``applikationslaget!'' Brugerne kan altså også her i princippet selv implementere bots (eller menneskebrugere for den sags skyld, hvis de har tiden --- og hvis brugergruppen måske ikke er så stor (ift.\ hvor mange menneskebrugere har ansvaret for den).\,. Hov, vent!\,x) Nu snakker jeg jo om ratingtyper, ikke om ``brugergrupper,'' så never mind: for ratingtyper vil det selvfølgelig altid bare være bots, der udfører opgaven), der læser ratingdata fra databasen og så beregner nogle parametre for hvert relevant udsagn ud fra disse grundlæggende rating, hvorefter botten så kan tilføje sin egen type rating, ikke af det samme udsagn, men af et udsagn, der relaterer sig til udsagnet (og altså som har udsagnet som objekt (.\,.\,hov, det har jeg forresten også glemt at snakke om!\,.\.)), og som så indeholder information i sin ratingværdi om, en given descriptor-parameter omkring brugernes rating-fordeling. 

Okay, lad mig så lige tænke lidt videre over disse to ting, samt hvordan det kommer til at indgå i QL'et --- og lad mig prøve at tænke lidt hurtigt.\,.\,!\,;) (15:40)

.\,.\,Nå ja, jeg skal jo lige i hvert fald nævne nogle nye ting omkring QL-headeren, nemlig for det første, at de semantiske typer og undertyper i første omgang i headeren lige selv skal defineres, nærmere bestemt ved at man altså definerer, hvordan man get'er dem fra databasen i første omgang. Selvfølgelig kan man så ikke bruge denne information i de query-statements (eller konstante definitioner), der skal definere dette, så jeg skal lige sikre mig, at det ikke kommer til at blive cyklisk, men at type-gettingen kan defineres på en fornuftig måde til at starte med (muligvis med sit eget indledende sprog, hvem ved.\,.). Ok, og så tror jeg så også, at det bliver vigtigt at brugeren i headeren også får defineret en særlig `brugerentitets'-type, som brugeren nok kommer til at gøre meget brug af (fordi den type så skal bruges i alle efterfølgende queries, når `brugergruppen' (man spørger i query'en) skal defineres for query'en). Hm, det kan da forresten være, hvis nu jeg ikke kan finde på en god måde at fjerne det cykliske i det, at man så i stedet bare bør sige, at typer og undertyper defineres på en helt fast måde i entitetsdefinitionerne (som altid kan parses eksakt af databasen/serveren), og at alle brugere så \emph{skal} holde sig til den konvention (medmindre de vil risikere at blive totalt ned-ratet af alle de gamle brugere). Ja, så den udvej er der også altid (og i så fald kan det så også være, at man vil vælge at separere type- og undertype-definitionerne for sig, og så ændre den gamle `semantiske entitetsdefinition' til ikke at behøve at inkludere typen og eventuelle undertyper af entiteten). Så det er altså altid en mulighed.\,. Ok. .\,.\,Nå ja, angående typen `brugerentitet' (og her snakker vi altså den ``semantiske type'').\,. Hm.\,. %(15:54)

.\,.\,Hm, jeg har desværre ikke så meget tid tilbage.\,. (15:55)

.\,.\,Hm, men det er ikke bare sådan, at man nu, fordi alt det med ``brugergrupper'' og rating-descriptorer bliver implementeret i applikationslaget, så bare kan nøjes med et helt simpelt QL, altså et hvor man for hver query statement (som så også kan bruges til at definere variable, som man kan bruge i efterfølgende query statements) bare basalt set behøver at pege på et prædikat-udsang.\,. som altså rettere er et udsagn på formen this.$<$Predicate$>$, this.$<$Relation$>$.$<$Entity$>$ eller $<$Entity$>$.$<$Relation$>$.this, hvor `this'-keyword'et altså står i stedet for de entiteter, man gerne vil query'e.\,? Hm.\,. .\,.\,Nå, jeg har ikke rigtigt mere tid, så det må jeg lige tænke videre over på vejen (og måske tage nogle noter på min telefon, eventuelt). Der var vist dog også lige en anden ting, som jeg eget gerne lige ville nå at nævne.\,.(?) (16:04)

.\,.\,Nå nej, det skal jo rettere være noget i retning af: ``this . $<$Predicate$>$ ?, this . $<$Relation$>$ . $<$Entity$>$ ?'', ``$<$Entity$>$ . $<$Relation$>$ . this ?'', this . $<$Attribute$>$ == $<$Entity$>$ ?'', ``$<$Entity$>$ . $<$Attribute$>$ == this ?'' (hvor whitespaces er ligemeget).\,. 

.\,.\,Nå jo, der var en ting om, hvordan man eventuelt kan benytte de der intervalbredder for de almindelige ratings, men det må jeg skrive om i morgen (og måske på telefonen på vejen).\,. (16:15) .\,.\,Men helt kort sagt handler det om, at man starter fra de mindste intervalbredder af og så ligger hver rating oven i alle dens eventuelle indre ratings, hvis der er nogen, fordelt ligeligt, hvis vi altså snakker stepfunktioner, og så forstætter man så bare denne proces for alle rating én ad gangen med større og større intervalbredder. Til sidst ligger man så det hele over i et histogram, og så har man en god, sigende rating-fordeling, som man så videre kan bruge til at udtrække descriptors fra. (16:18)

%Fra toget på vej til byen (teater): 
	%"(10.02.23, 17:15) Nu hvor hele den semantiske database er åben for læsning, så kunne et simpelt QL bare være en undermængde af SQL.. ...Tja, nej, lad mig lave et lille QL-sprog, det er beregnet til det. I øvrigt så skal man jo uanset hvad have mindst én bruger med i syntaksen. Så hvis vi tager det, jeg skrev hjemme for lidt tid siden, så kan der være en brugervægtning-expression lige efter spørgsmålstegnet. Og dette kan så bare være et lineært aritmetisk udtryk i form af en parentes med konstanter ganget med variable, som repræsenterer enkelte brugere hver især. Men "en enkelt bruger" kan så til gengæld nu repræsentere en hel brugergruppe (nemlig ved at brugeren så er en bot, der varetager brugergruppen --- ved at summe ratings sammen).
	%
	%Og i forhold til at sammensætte ratings til et samlet filter, så kan QL'et også bare bruge simple aritmetisk udtryk til at opnå dette."
%

(11.02.23, 9:03) Jeg tænkte i går i toget, at man jo nu i princippet også bare kunne gøre QL'et til en undermængde af SQL, nu hvor databasen alligevel er helt open, men nej. Implementationen af den semantiske database skal være skjult, så derfor skal den semantiske database også have sin egen form for QL. Nu her i sengen i tidligere i morges kom jeg i øvrigt til at tænke på navne, og kom på at SEARQL måske kunne være et muligt navn til QL'et. (Jeg tænkte så, at det bliver lidt problematisk, hvis man skal finde på et filefternavn til det, men nej, her kan man bare skrive .srql eller .srq.\,.) .\,.\,Nå ja, og SEAR står altså her for `semantic entity and ratings'.\,. 

Nu har jeg så også tænkt lidt videre over, hvad jeg skulle gøre med de der ``brugergrupper,'' og her er jeg så kommet frem til to ting. Det ene er, at man jo nemt kan gette, om en entitet er en brugerentitet, for man kan jo i databasen kan jo bare slå op om der findes ratings fra den bruger.\,. ja, og databasen skal selvfølgelig også selv kende alle brugere, så det kan forresten godt være, at alle brugere bare \emph{skal} have sådan et unikt (long) bruger-ID. Ja. Nå, og den anden, virkeligt gode ting (som jeg også havde lidt i tankerne i går, men jeg kom lidt fra det igen, fordi der var så meget), er, at man skal kunne lave brugergrupper ud fra prædikat-expression kald (med tilhørende indledende bruger / brugergruppe, som enten er ansvarlig, eller som man bare bruger til, at definere den nye brugergruppe). Lad mig forresten nævne, at jeg tænker at et brugergruppe-udtryk altid skal komme efter spørgsmålstegnet, i den cirka-syntaks, jeg skrev i går. Dette kan så være en brugerentitet --- og altså gerne entitets-ID'et frem for bruger-ID'et (sidstnævnte kan bare være synligt i den semantiske definition af entiteten), men det kan også være et andet prædikat--brugergruppe-expression (gerne holdt i en variabel, dog). Der skal i øvrigt også gerne være et all keyword, som repræsenterer brugergruppen af alle brugere, ikke at man kommer til at bruge det så meget, og ikke fordi man ikke kan implementere det på anden vis, men jeg synes på en eller anden måde (måske), at det er passende alligevel at have.\,. %(9:30)
Og ja, jeg skal også juske at sige, at brugergruppe-udtryk i øvrigt også kan være en linearkombination af tidligere definerede brugergrupper. Så sammenlagt kan man altså definere nye brugergrupper aritmetisk ud fra gamle, og man kan også danne nye brugergrupper ud fra gamle ved at udspørge de gamle om en vis semantisk rating (med et vilkårligt prædikat) af alle brugere (og hvor ikke-ratede brugere i den forbindelse så bare får vægten 0 i brugergruppen). .\,.\,Og lad mig nævne, at det forresten ikke gør noget, hvis brugerne bruger et prædikat--brugergruppe-udtryk, der også giver ratings til ikke brugere, for der skal altid bare være et (grund-)grundfilter, der gør at alle ikke-brugerentiteter altid bliver sorteret fra automatisk for prædikat--brugergruppe-udtryk, der indgår i et brugergruppe-udtryk. (9:37)


(13.01.23, 10:01) Okay, jeg har en hel masse flere tilføjelser nu. Jeg føler virkeligt, at jeg er ved at have godt overordnet styr på det/de grundlæggende lag i systemet nu. .\,.\,Hm, hvor skal jeg starte.\,. .\,.\,Hm, godt spørgsmål, lad mig lige prøve at gå igennem det hele i tankerne en gang og så vende tilbage.\,. 

\ldots Hm, nu kom jeg forresten lige på et nyt navn: UDA (udtales you-dee-ay) for User-Driven Application, og så kan jeg mere specifikt kalde min en SUDA (es-you-dee-ay or suda (perhaps with `oo' sound)), nemlig en Semantic User-Driven Application. (10:48) %..Hm, jeg næsten mærke, at det bliver det..:D..

.\,.\,Hm, hvis det ligger godt i munden, kunne man så næsten kalde min applikation for Asuda.\,. (A for a (som i: ``a semantic user-driven application).\,.) (10:55) .\,.\,Nej, for det navn clasher med, hvis man skal sige ``a SUDA'' i en sætning.\,. hm, \emph{hvis} man altså ikke siger es-you-dee-ay da i stedet.\,. *(hvad man nok vil.\,.) .\,.\,Hm, jeg har også for nylig tænkt på SemNet *(som i: Semantic Network) som et navn til min web applikation, og det kunne jo egentligt også være en mulighed. (Og SemNet kan så bare siges at være en SUDA.\,.)

.\,.\,Nå, men jeg skal videre i teksten.\,. 

Okay, lad mig starte med, at brugerrating-entiteter i databasen også skal være `udsagn,' nemlig hvor man så specifikt tager et andet `udsagn' og bruger som relations-entitet i tripletten. Eller rettere, for nu vil jeg så også have, at man også skal kunne fortolke entiteter som funktioner/constuctors, så faktisk kan man så i første omgang tage en funktion på udsagnet, der går det til en relation, og specifikt altså rate-bar relation, nemlig fordi serveren så kan gemme brugerratings ved at denne udsagn ud fra den relation (med bruger-ID'et som første input og ratingværdien som det andet input). 
Det at brugerratings nu også er udsagns-entiteter gør, at brugerne også kan bruge semantisk logik omkring dem. For eksempel kan de således query'e databasen for, hvilke brugere har ratet et vist udsagn over eller under en vis værdi, hvilket er meget brugbart --- og rart at denne mulighed kommer automatisk nu, fordi man jo alligevel skulle kunne lave tilsvarende queries for vilkårlige udsagn. .\,.\,Tja, eller der bliver faktisk en lille forskel, for ``brugergruppen'' man spørger for at udtrække en hvis brugerrating vil jo altid bare være underforstået (nemlig en underforstået grundlæggende bruger/bot i databasen.\,.).\,. .\,.\,Hm.\,. 
.\,.\,Ja, det kommer til at svare til, at der bare er en automatisk grundlæggende bruger, der forbindes med queries til entiteter af typen ratingentiteter (og mere om sådanne typer senere i dag), og at denne bruger bare automatisk siger 1 (fuld rating) til alle disse udsagn, således at gyldigheden af dem bare afhænger af, om de eksisterer i databasen.\,. Hm, hvilket vil sige, at man egentligt også bare kunne sørge for, at det er omtalte bruger/bot, der bare bestemmer typen `rating(entitet)'.\,. .\,.\,Ja, og dette kan så bare implementeres ved at man gør `rating' til en fundamental type, der bestemmes automatisk af database(servere)n selv. For jeg vil nemlig alligevel gerne have det sådan alligevel, og jeg vil i øvrigt også gerne have at typen `bruger' på tilsvarende vis også skal være sådan en fundamental type. (11:38) 

\ldots Hm, men skal alle uploads ikke have en bruger på sig, så kunne man ikke også bare gøre det.\,. ja, på en lidt anden måde, lad mig lige se.\,. 

\ldots (12:25) Hm, det er ligefør, at alle rating-aggregater bare skal implementeres via ``bot-brugere'' i princippet (og databaseserveren har så bare nogle grundlæggende ``bots'' og kan også oprette flere, hvis der er nok efterspørgsel efter det).\,.(?\,.\,.) 
.\,.\,Og `brugergrupper' kan nemlig så også i princippet implementeres via bots, nemlig som databaseserveren/serversystemet/hjemmesiden så også bare eventuelt kan påtage sig at administrere (ud fra en fast protokol, ligesom), hvis der er nok stemning (som i: nok stemmer) for det.\,. 

For ja, noget af det seneste, jeg kom frem til, før jeg satte mig for at skrive i dag, var nemlig, at brugergrupper altid skal oprettes som entiteter i databasen, og godkendes, før de kan tages i brug. Og derfor kan dette jo også sagtens implementeres ved, at databasen så godkender en brugergruppe ved at oprette en bot til at oprette og vedligeholde stemmer samlet fra denne brugergruppe.\,. (12:37) .\,.\,(Brugere skal dog stadig kunne lave linearkombinationer af brugergrupper i queries, men de kan så ikke nødvendigvis --- ikke i første version af QL'et --- indsætte nye, custom-made brugergrupper her i disse udtryk (ved at indsætte et prædikat-udtryk med this-typen `bruger').)

.\,.\,Jeg har også en masse andet, jeg skal have skrevet om, særligt også tilføjelser omkring ADA-delen af det (og om hvordan bruger loader scripts og XML ved applikationens opstart, og ikke mindst hvordan XML-datastrukturer kan opdateres for hver bruger --- og om at bruge difs/deltas!), men lad mig lige gå en tur (i det her ultrafine vejr, som det er for tiden) og lige prøve at summe det her grundlæggende omkring databasen mere på plads.\,. (12:55)


(16:20) Okay, efter gåtur og efter at have tænkt videre efterfølgende så tror jeg endelig, at jeg er ved at have typesystemet (et lidt nyt et) og implementationen nogenlunde på plads. Lad os se. Vi har for det førte nogle datatyper. Jeg mener nu, at der skal gælde, at alle datatyper af en fast længde mindre eller lig long (8 byte) skal forekomme direkte i tabellen. Så når man vil referere til en dataentitet, så gør man det altså ved simpelthen at angive typen først, og hvis det er an datatype mindre eller lig en long, så skriver man den så direkte i den efterfølgende kolonne (hvis man skulle opstille det i en fornuftig tabel). Og for datatyper/typer såsom `string,' `blob' og `semantic term,' så giver man så en reference i stedet, som så også (indtil man på et eventuelt tidspunkt i fremtiden bliver nødt til at tilføje flere bytes) er en long. Men ift.\ implementationen i den relationelle database, så kan man altså stadig se på datatypen, i hvilken relation/tabel, man skal slå referencen/ID'et op i. Så entiteter med forskellige typer kan altså godt have kolliderende ID'er (men self.\ ikke, når de har samme type). Nå, udover datatyperne er der også.\,. Hm, nu kaldte jeg det lige `semantic term,' men i virkeligheden bør det hellere hede `atomic (semantic) term' og `compound (semantic) term'.\,. .\,.\,Hm nej, lad mig kalde det et `semantic atomic term' og bare et `compound term,' hvilket så er en overtype, hvorimod `semantic atomic term' er en helt specifik type. .\,.\,Hm, nej, det dur faktisk ikke; lad mig finde et andet navn for `semantic atomic term'.\,. .\,.\,Hm, hvad med `interpreted term,' hvor man måske så kan sige `iterm'.\,. nej, det ser mærkeligt ud.\,. .\,.\,Hm, lad mig egentligt også hellere kalde det et `described term' i stedet.\,. .\,.\,Og jeg behøver ikke forkortelse som sådan (DescribedTerm virker fint). Ok. Og så har vi CompoundTerm's, som har undertyperne MonadicTerm of Term $\times$ DescribedTerm og DyadicTerm of  Term $\times$ DescribedTerm $\times$ Term. Disse compound terms vil typisk repræsentere udsagn, men de kan dog også repræsentere funktionelle udtryk. Nå ja, og vi har i øvrigt også typen User, hvilket bare holdet et bruger-ID (long) --- ligesom at DescribedTerm i øvrigt holder en string (hvilket ses direkte som en string i den semantiske database, men som så dog er implementeret som en string-reference, nemlig til et string-ID i en String-relation/-tabel i den undeliggende relationelle database, hvor anden kolonne i den tabel så rent faktisk er en VARCHAR(n) (og grunden til at det skal være sådan, er i øvrigt altså for, at jeg kan have 8-byte data stående overalt i de overordnede relationer/tabeller)). Og sidst (mener jeg nok) men ikke mindst har vi så typen, SemanticInput, hvilket altså er rating-typen (bare hvor jeg har generaliseret navnet an anelse), som har formen, User $\times$ CompoundTerm $\times$ Term. Her er det sidste Term selvfølgelig rating-værdien/-dataen, og bemærk, at fordi alle typer, hvor det kan lade sig gøre at putte dataet direkte ind (nemlig hvis de er mindre eller lig en long), får gjort dette, så vil talværdierne altså stå direkte i den relationel-database-tabel/-relation, der implementerer `semantic inputs.' Fordi vi sammenlagt har så få typer, som vi har (nemlig en håndfuld datatyper og så en fåtal af ikke-datatyper), så kan flaget i databasetabellerne (som både forekommer i den semantiske og i implementationen i den relationelle database), der bestemmer datatypen (når dette er nødvendigt, hvad det eksempelvis ikke er for User i SemanticInput; her kan man bare have en long uden at have noget flag foran), bare være en char. (17:16)

Det næste man så egentligt bør snakke om, efter at man har snakket om den semantiske database, det er jo oplagt QL'et. Men fordi jeg har så mange andre små ting, jeg også skal sige, så lad mig lige prøve at få klaret en del af de ting først.\,. 

.\,.\,Nå ja, jeg kan jo passende starte med at snakke om difs/deltas, for dette skal jo også indgå som en type i den semantiske database!\,.\,. (17:19) .\,.\,Hm, dette bliver så en rekursiv type.\,. Hvad skal vi kalde den.\,.\,? .\,.\,Hm, man skal jo næsten også gerne kunne tage udsnit fra flere eksisterende strenge/tekster på én gang, så hvad skal vi sige der.\,.\,? .\,.\,Oh well, det kan jeg vende tilbage til. Pointen er bare, at der også skal være en DeltaString- eller CompoundString- eller EditedString-, eller hvad-vi-nu-skal-kalde-den-type, som altså danner en ny string ud fra nogle gamle strenge samt eventuelt nogle nye tilføjelser/indsættelser. 

(17:27) Lad mig så snakke om nogle ting mere oppe lige under applikationslaget.\,. For det første skal jeg have nævnt, at der gerne skal være en privat/lukket database også, som gør mere end bare det der med at tælle brugerprofiler pr.\ brugerkonto. Men det skal dog være valgfrit, om man vil gøre brug af denne private database, eller om man vil gøre noget andet, hvilket eventuelt godt kan være bare at sende alle inputs direkte til den offentlige database, hvis man vil det. I øvrigt skal man stadig bare ``logge på'' den offentlige database ved.\,. ja, eller rettere, man logger ikke på, men man sender bare sine inputs krypteret med den offentlige nøgle. Det jeg vist på et tidspunkt sagde med, at den offentlige krypteringsnøgle bare \emph{bliver} bruger-ID'et gælder dog ikke; databasen giver hver brugerprofil en long, der udgør bruger-ID'et, hvilket så bliver omdrejningspunkt for semantikken. 

Men brugerne skal altså også have mulighed for at uploade inputs til en privat database. Her kan de så bl.a.\ uploade og redigere data omkring indstillinger i deres eget personlige interface (altså den jeg kalder en UDA, fordi brugerne i princippet kan ændre den stort set vilkårligt). Om brugeren gemmer til denne private database, til den offentlige eller en blanding, så vil brugeren uanset hvad skulle fortælle databasen (selvom de jo godt kan starte et populært sted og så bare blive der), hvilke nogle scripts og HTML m.m., de gerne vil have loadet i deres applikation under opstarten. Alle scripts kan så få eventuelt inputdata via XML, der også hentes fra databasen under opstart. Her skal brugerne så sørge for, at alle scripts, der skal/kan bruge ekstern XML-data, sørger for at erklære og tjekke et navn på en fast måde (som jeg skal have fundet på), hvor det sikres, at der altså vil returneres en fejl, hvis to loadede scripts bruger det samme navn. Hvis scriptsne så loader uden fejl, så ``ved'' hvert script så, at det er frit til at tilgå og muligvis ændre i (hvis brugeren, der loader scriptet har tilladt dette) et specifikt XML-element (som så har en attribut a la dataIdentifier=$<$unique name$>$). Og scriptet, hvis det har fået lov, må så gerne ``flushe'' sit XML-objekt tilbage til databasen (som regel den private, men det bestemmer brugeren, der loader scriptet), således at brugeren kan loade sine ændringer siden sidst på ny, når denne starter webapplikationen op en anden gang i fremtiden. (17:45)

Angående det jeg på et tidspunkt skrev ovenfor omkring at undgå de cykliske i at loade lister, som så loader samme type elementer, så er svaret her selvfølgelig bare, at man først definerer sit listekolonne-script/-HTML, og kan så bagefter tilføje ressourcetyper til dette script, samt tilhørende visnings-script/-HTML til hver af disse typer. 

(17:48) I øvrigt, nu hvor vi er næsten helt ude i applikationslaget, så tænker jeg at UDA'en kan starte med at have disse ting: listevisningskolonner, som altså bruges til at vise en liste over ressourcer (med tilhørende filtre), som brugeren har spurgt efter (på den ene eller den anden måde); ratingkolonner til når man har selekteret en ressource og bare lige vil have en hurtig oversigt over gode mulige ratings/``rating-tags,'' man så kan benytte; ressourcevisningskolonner, som er ligesom ressourcesider, bare i miniformat; ressourcesider, hvilket så er, når man virkeligt har klikket helt ind på en ressource (vist i stort format for sig selv; ikke klemt inde mellem andre kolonner); terminalkolonner, hvor den avancerede bruger kan lege med at udforme queries i QL'et (og med variable, som er defineret i et tilhørende XML-dataobjekt); samt også; sidst men ikke mindst, kontrolkolonner, som er ligesom terminal kolonner men bare sat op så brugeren skal trykke på knapper og gøre ved som de fleste brugere er vant til for at opnå de samme ting, som de avancerede brugere kan opnå i terminalen (men måske altså bare lidt mindre end dette (men på sigt dog ikke foruden noget, som den almindelige bruger vil savne)). (18:00) .\,.\,Nå ja, og så skal der også være en kolonne eller side, der handler om at indstille start-op-indstillingerne for applikationen (og loade scripts/HTML/CSS og XML-data, samt definere typer og grundfiltre, hvilket jeg kommer til senere). 

(18:59) Jeg tror faktisk, jeg vil inkludere listetyper! Så skal der være 12 forskellige listetyper, nemlig med fra 0 til 11 elementer i sig (så den første er altså den tomme mængde/liste). Og så vil jeg kalde det MonadicStatement og DyadicStatement i stedet, og så ellers bare have et FunctionalTerm of DescribedTerm $\times$ Term, hvor.\,. Nå nej, og jeg vil så heller ikke kun have DescribedTerm som mulige prædikater, relationer eller funktioner, men disse kan også alle være af FunctionalTerm-typen i stedet. Så FunctionalTerm of (DescripedTerm  $|$ FunctionalTerm) $\times$ Term (så typen er altså rekursiv). Og Term her kan så særligt også være en listetype, hvilket netop gør at alle funktioner bare kan være umiddelbart unære. Hvis man gerne vil lave en funktion, som skal kunne gives lister længere end elleve elementer, så kan man sagtens det. Man kan selvfølgelig for det første give den lister af lister i stedet (eller af funktioner taget på lister), men man kan også bare give den.\,. Ja, eller det er jo så også at give den lister af lister i princippet, men hvis man altså meget gerne vil have, at alle elementer opfattes som ligestående, side om side med hinanden, så kan benytte en konvention om at implementere dette ved specifikt at lade det 11.\ input have typen af en ny liste, inklusiv den tomme liste, hvis det samlede antal elementer er rundt, og man er ved den sidste af alle tier-grupperne. .\,.\,Ok, og en sidegevindst er i øvrigt, at nu kan man lade databasen tjekke, at der enten er tale om et MonadicStatement eller et DyadicStatement, hvilket nok vil være godt til at guide brugere til aldrig at rate andet end termer, der semantisk set bør fortolkes som et udsagn (og altså til ikke at begynde at rate ikke-statement-termer direkte med et implicit prædikat; det vil vi helst undgå). (19:17)

.\,.\,Hm, på den anden side vil dette jo netop friste brugerne til at bruge direkte get-funktioner, i stedet for at bruge mere abstrakte get-funktioner, der kan tage højde (i princippet) for efterfølgende rettelser.\,. Så ja, lad mig lige tænke over, hvad der er bedst, for på den ene side gør man det jo nemmere for de første brugere, ved at indføre lister (med automatiske getElement()-funktioner), men på den anden side, så kan brugerne så også blive forvente med disse simple og automatiske funktioner.\,. (Så ja, det må jeg lige tænke over.\,.) 

.\,.\,Ah, men på den anden side, så vil det jo også være ret smart, hvis applikationen kan hente de uredigerede ting først og bare tjekke for de værste faresignaler, og når der så bliver tid, eller når brugeren klikker sig videre ind på ressourcen, så kan applikationen så lave mere grundige gets. Nice!\,:) Fedt nok, så indfører jeg nok de lister der. (19:27)


(14.02.23, 8:54) Hm, jeg kunne også indføre lister uden at indføre funktioner.\,. .\,.\,Hm, det ville måske ikke være en dum idé.\,. Og man kan endda så sige, at jamen funktioner kan jo også bare udelades i første version af systemet (men hvor man bare holder dem klar til at blive indført, så snart der bliver behov for dem, hvis der gør det).\,. .\,.\,Yes, og måske bliver der faktisk aldrig behov for at indføre funktioner. Og det giver mig så det bedste af begge verdner, for nu bliver de tidlige programmører (hvilket jo nok i høj grad bliver mig selv) tvunget til at get'e (gette) attributter omkring et objekt via semantiske queries, hvilket gør implementationen meget mere åben overfor efterfølgende rettelser og ikke mindst også for, at brugere kan få mulighed for at indstille metoderne til deres egne behov. Men samtidigt kan man så bare bede om en enkelt liste som programmør, hvilket.\,. ja, det gør tingene en anelse nemmere, men ikke mindst gør det det også nemmere, hvis brugeren skal indstille get-metoden/erne for et objekt, for så skal de kun ændre indstillingerne for én metode pr.\ objekt (altså fordi der så kun behøver at være én get-metode, som get'er hele listen af relevant data for et objekt). .\,.\,Ja, det er altså virkeligt nice på den måde. Så jeg indfører listetyperne som beskrevet i går aftes, men jeg fjerner så funktionstypen igen (og beholder typenavnene MonadicStatement og DyadicStatement), om ikke andet så bare indtil der alligevel viser sig (hypotetisk) at blive efterspørgsel efter den af en eller anden grund. :) (9:09)

(11:45) Okay, jeg tror, jeg ved, hvordan det grundlæggende QL skal implementeres. Jeg er faktisk gået over til nu, at det bare skal være en slags undermængde af SQL (når det kommer til selects men ikke til inserts), og at den implementation af den semantiske database, jeg har i tankerne (og har skrevet om her i går), faktisk bare skal blotlægges, sådan at denne implementation faktisk bare \emph{bliver} den semantiske database så at sige. Og det særegnede QL (\emph{hvis} man indfører et) skal så bare indføres/bygges i applikationslaget. 

Angående databasen, så skal jeg bare bruge CHAR til typeflaget, således at det bare kan sendes som en ASCII-char over http. Og det jeg så lige har tænkt over, er, hvordan rating-værdierne skal implementeres, og nu har jeg så fundet ud af, at de simpelthen bare skal implementeres som en long, eller rettere en BIGINT. Denne long/BIGINT bør så.\,. hov, eller rettere: Ratingværdien kan være af en arbitrær type (og kommer altså derfor med et typeflag forinden værdien), men den klare standard skal dog være at bruge BIGINT/long. Denne long skal så fortolkes som gennemsnittes for brugerens rating (hvor man selvfølgelig dividerer med  9223372036854775808). Og det smarte kommer så nu: Fordi de sidste cifre jo vil være semantisk fuldstændigt ubetydelige/underordnede (startende allerede fra den 4. --- måske endda fra og med den 4.\ eller endda den 3. --- byte), så kan brugerne altså frit tillade sig at bruge disse (sidste) cifre til at indkode anden semantik i ratingen. En god mulighed kunne jo således f.eks.\ være, at lade de første 4 bytes udgøre ratingmidtpunktet, og lade de efterfølgende 1--4 (hvad der lige giver bedst mening, for måske er selv én byte rigeligt til dette) bytes kode for intervalbredden af ratingen (i henhold til det, jeg har snakket om ovenfor). Bemærk, at selv hvis man nu kun bruger 2 bytes til at kode for midtpunktet, så kan gennemsnittet af alle (eller en gruppe af) sådanne ratings stadig godt fortolkes med en højere præcision. (12:08)

(12:25) Jeg tænkte lige lidt over, om man ikke også skulle have kilde-bruger og timestamp med for hver ikke-SemanticInput-entitet, men nu kom jeg så lige til at tænke på, at man som bruger alt andet end lige altid gerne vil up-rate et nyt upload i en eller anden forstand, typisk ift.\ et eller andet prædikat, som kunne have et passende navn a la `isUseful$<$Type$>$()' --- eller være en relation a la `isUsefulEntityOfType(type)'.\,. .\,.\,Og fordi man alligevel forventer at et hvert upload/insert kommer med sådan en rating lige bagefter, så kan man jo derfor også bare gøre dette til en konvention, nemlig at brugerne altid up-rater.\,. lad os sige `isUsefulEntityOfType(type)'.\,. eller rettere `$<$Type$>$.UsefulEntity==myNewEntity,' hvis man gerne vil formulere det på mere objekt-orienteret vis (hvad jeg jo synes, man bør), (at brugerne altid up-rater dette) med det samme (og altså i selvsamme insert-kommando), når de uploader en entitet. .\,.\,Ja, man kunne endda ligefrem kræve dette fra serverens side for alle nye uploads. 

.\,.\,Hm, eller skal man bare tilføje bruger og timestamps på hver entitet.\,.\, Tja, måske ikke, men lad mig lige lade spørgsmålet stå en anelse åbent.\,. .\,.\,Angående insert-kommandoer, så er det klart, at brugeren bare skal uplaode indholdet, og så er det serveren/databasen selv der sætter et passende ID for uploadet, samt en bruger og et timestamp, om ikke andet hvis vi altså snakker et SemanticInput (hvilket selvfølgelig skal have bruger og timestamp på sig).\,. (12:42)

(13:31) Okay, nu er jeg vist næsten klar til at skrive de sidste ting, jeg mangler at komme ind på, hvorefter jeg så nok så småt kan gå i gang med programmeringen.

Hvis vi ser på, hvad der så skal ske når brugeren logger på hjemmesiden.\,. Hm, eller lad mig starte med at nævne, at der på hjemmesiden, inden man er logget ind, gerne må være lidt about-information, og også gerne en liste af sponsorer, hvilket jeg tror bliver ret vigtigt for hjemmesidens økonomi. Ok. Når man så logger ind, så er noget af det første, der sker, efter at man/browseren/applikationen lige har fået bruger-ID'et i hånden (efter også at have fået oprettet og autoriseret forbindelsen) samt nogle helt grundlæggende andre variable, at applikationen efterspørger en række af start scripts/HTML/XML, der skal loades. Dette kan ske ved, at databasen spørges efter en liste over script (strings), som brugeren har gemt en positiv (skarpt) rating for. Alle disse script/HTML-strings hentes så og loades i rækkefølge efter pågældende rating-værdi, fra lavest (tættets på 0) til højest. Hvert script kan så potentielt set query'e databasen efter flere scripts / mere HTML/XML, eventuelt også på tilsvarende vis, og kan nemlig eventuelt vente lidt med at gøre dette, så den samlede side bedre kan loade sådan lidt ad gangen, hvis nu man har mange ting til at ske i sit samlede start-script. Og så er vi faktisk allerede stort set videre til applikationslaget, for jeg har allerede forklaret om, at hvert script så kan have sit eget XML-input (som kan loades separat fra databasen), og at der også skal være en funktion til at ``flushe'' og opdatere denne data. Nå ja, lad mig dog lige påpege, at databaseentiteterne der koder for brugerens egne indstillinger og præferencer, de kan eventuelt være uploadet til en privatdatabase, som man også har forbindelse til udover den offentlige. Brugeren behøver derfor ingenlunde at lade sine indstillinger være synlige for offentligheden, men kan dog godt vælge det (og på sigt vil dette faktisk nok blive ligeså sikkert i princippet i nogen tilfælde, fordi man så i stedet kan vælge at sørge for at gøre brugerprofilen umulig at sammenkoble med personen.\,.). 

Så ja, nu kommer vi så til applikationslaget, og her er mulighederne selvsagt åbne. Men jeg har dog nogle idéer til, hvor man kunne starte, både på mellemkort sigt og på helt kort sigt, for på den helt korte bane vil jeg nemlig bare implementere et rigtigt simpelt system, hvor brugerne primært bare opretter prædikater og kategorier, og så rater de ressourcer, som loades ind på siden med diverse ``rating-tags'' (og hvor de har nogle forskellige muligheder for at åbne nye kolonner ud fra en lille gruppe af forskellige typer entiteter (hvor vi her altså snakker brugerdefinerede typer)). Hov, og lad mig lige i den forbindelse nævne en kolonne-type, som jeg havde glemt ovenfor, og det er prædikat-kolloner, hvor man ser info om et givent prædikat.\,. hm, selvom dette dog også kunne hører ind under ressourcekolonnetypen.\,. Men ja, dette er jo det jeg skal i gang med at programmere, lige efter at jeg har fået back-end'en og applikationsopstarten på plads.

Angående idéerne til applikationsimplementationen på mellemkort sigt, så handler dette om.\,. .\,.\,ja, eller selvfølgelig vil der være nogle brugerflademæssige ting, som jeg ikke vil implementere i starten, men vil vente med til lidt længere sigt igen. Men hvis vi også ser bort fra dette emne, så er en virkeligt vigtig ting på den halvkorte bane at få implementeret en lille standard for, hvordan brugere kan indstille nogle af de grundlæggende ting omkring deres interface. I første omgang skal brugeren have godkendt nogle grundlæggende scripts, der skal køre i applikationens opstart. Men herefter skal brugeren også indstille nogle flere ting. Så selvom dette foregår i selve applikationslaget (hvor brugerne har total frihed i princippet), så kan vi altså stadig med fordel snakke om, at der skal ligge et nedre lag i dette applikationslag, hvor brugerne kan indstille helt grundlæggende ting omkring applikationen, og endnu mere specifikt omkring hvordan applikation må/skal interagere med databasen, og hvordan den skal tjekke og godkende det data, den får fra databasen.

Her forestiller jeg mig så, at man laver nogle små sprog/filformater til formålene, netop så så mange som muligt af brugerne kan sætte sig ind i disse formater og dermed også være i stand til at ændre dem direkte, uden at skulle lære at gennemskue XML først (hvilket jeg personligt heller ikke bryder mig om; man bliver helt skeløjet).\,. Så vi snakker faktisk en form for config-filer, hvis man kender det. Og i disse configscripts skal brugerne så kunne ændre indstillinger for forskellige ting, og her tænker jeg så særligt på følgende ting. Der skal være et config-script, der bestemmer, hvilke nogle domæner, som applikationen må hente URI'er fra. Eventuelt kunne det endda gøres sådan, at brugeren både bestemmer en RegEx for URL'en, samt bestemmer en salgs RegEx (muligvis binær) for dataen. Og måske kunne brugeren endda eventuelt få lov at vælge en transducer, der oversætter det godkendte (af den ``binære RegEx'' (altså en automaton, men brugeren skal jo kunne skrive den på en eller anden måde.\,.)) format til et nyt format, inden det kan indsættes i applikationens HTML.\,. .\,.\,Men ja, i starten skal dette selvfølgelig dog bare være et spørgsmål om at godkende URL'er, og på lidt længere sigt kan det så også måske handle om at parse og godkende de tilhørende URI'er. Det var den ene ting. (14:15)

En anden ting er at definere nogle brugerdefinerede typer for databasen. Dette bliver nok en ret grundlæggende ting, og altså noget som gøres tidligt i den samlede række start-scripts. Og til hver brugerdefineret type, så skal brugeren for det første kunne præcisere, hvordan applikationen skal verificere, at en entitet har den pågældende type, hvilket typisk vil handle om at spørge en brugergruppe om et specifikt prædikat (der så er taget på den givne entitet). 

Og her kan jeg så passende lige indskyde en paragraf om brugergrupperne. Vi er som sagt i applikationslaget, så dette implementeres bare her, men jeg forestiller mig, at der skal være en bestemt fast syntaks for at benævne en brugergruppe, hvilket altså i adgangspunket skal være en linearkombination af bruger-ID'er, nemlig altså hver med konstanter foran. Disse konstanter skal så tolkes som en vægtning af hver bruger --- som jo også kan være en bot, der implementerer en brugergruppe i databaselaget, når gennemsnittet udregnes. Så hvis bruger nr.\ 123 har stemt 0.1 til en rating, og bruger 456 har stemt 0.5 til en rating, og man bruger linearkombinationen, (3 * 123 + 1 * 456), så bliver resultatet for den givne rating altså et (vægtet) gennemsnit på $(0.3 + 0.5)/(3+1)=0.2$. Men dette er ikke det hele, for man kan så også have lov til at bruge et `inf'-keyword i stedet for en konstant (kun en enkelt dog), som giver en uendeligt vægting af brugeren, hvis brugeren altså har givet en rating. Lad os sige at bruger 123 har givet en rating på 0.1, bruger 124 har givet en rating på 0.2 og bruger 135 har ikke givet nogen rating. Så vil resultatet af (inf * 123 + 2 * 124 + 3 * 135) give resultatet, $0.1$ --- og (5 * 123 + 2 * 124 + 3 * 135) ville i øvrigt give resultatet, $(0.5 + 0.4)/(5+2)=0.128571428\ldots$ (he, jeg har ikke divideret i hovedet i lang, lang tid.\,.).\,. Ok, og i øvrigt kunne der også lige være et `me'-keyword til at benævne sig selv, og så kan man jo med fordel bruge `inf * me' i mange sammenhænge. Og sidst men ikke mindst kan man også sætte en konstant ind på brugerens plads, hvilket jo set i bakspejlet gør det lidt forvirrende, at jeg allerede har sat tal ind på brugernes pladser nu her til at repræsentere bruger-ID'er, men i praksis skal der altså i sidste ende ikke være tvivl om, hvornår et bruger-ID indsættes, og hvornår en tal-konstant indsættes. Og hvor en konstant indsættes, så skal det altså tolkes tilsvarende som, at en fiktiv bruger har ratet pågældende prædikat med lige det tal.\,. nå ja, dette tal vil jo altid være et kommatal (mellem -1 og 1), så selvfølgelig vil man nemt kunne vælge en syntaks, hvor man kan kende forskel (for der er en triviel løsning på dette). 

Angående det med at bruge en konstant fiktiv rating i brugergrupperne, så er det faktisk det jeg selv regner med at gøre i den første implementation af applikationen. Jeg regner således bare med at vise et ratinggennemsnit overalt, som dog lige er ændret ved at det har en vis konstant * 0.0 plusset på, så at sige. Så jeg regner altså med at bruge en brugergruppe a la `(1 * meanbot + 5 * 0.0)' (hvilket jo også bare kan skrives som `(meanbot + 5 * 0.0)') . Her er `meanbot' så et kaldenavn der referere til en grundlæggende bot, der rater alle statement ud fra samlede mængde (ikke-karantænede/-udsmidte) brugeres ratings (og som opdatere disse ratings løbende). 
I øvrigt er det værd at nævne, at jeg så forestiller mig, at denne ``meanbot'' så bare kan bruge de sidste (2--3) bytes i dens ratings til at indkode, hvor mange brugere (ikke-karantænede/-udsmidte), der samlet set har ratet udsagnet på det givne tidspunkt. (14:50)

%..Tager lige en kort.. hold da op, egentligt vildt at den allerede er blevet tre. Nå, men jeg tager altså nok lige en kort pause, inden jeg skriver resten..

(15:33) Okay, for så at vende tilbage til de brugerdefinerede typer, så skal brugerne også (i ``config-scriptet'') ikke mindst kunne sætte et grundfilter for hver type. Alle entiteter som de højereliggende applikationsscripts henter skal så i reglen filtreres med disse grundfiltre (der passer til den relevante type). Bemærk at dette så også i reglen (med mindre brugeren har specificeret noget andet (og har mulighed for at gøre dette)) gælder for alt tilhørende data, som applikationen get'er til en hvis entitet, da dette data jo også vil have en type. Og i tilfælde, hvor noget data ikke kan bestemmes til en af de brugerdefinerede typer, så kan brugeren også sætte et other-filter, som filtrerer alle entiteter, der ikke kan tildeles en type ud fra brugerens konfigurationer. 

Men på lidt længere sigt skal brugerne nok endda også gå ind og kunne bestemme specifikke.\,. Nå nej, nu snakkede jeg om et grundfilter, men brugeren skal så \emph{også} (på sigt) kunne ind og bestemme brugergrupperne for specifikke get-metoder. Lad os f.eks.\ sige, at brugeren klikker sig en på en video-ressource. Nu skal applikationen så hente data til videoen. Lad os så sige, at brugeren gerne vil have både undertekster og annotationer til videoen, hvilket applikationen jo så efterfølgende kan hente/``get'e'' til brugeren. Og her kan man så forestille sig, at brugeren gerne vil bruge én brugergruppe til at vælge, hvilke undertekster er mest passende for brugeren, men bruge en anden brugergruppe til at vurdere, hvilke annotationer er passende for videoen. Derfor skal brugeren altså gerne (på sigt) kunne config'e brugergruppen for hver enkle get-metode tilhørende en type. Dette er også derfor (og man kan også nævne mange andre eksempler, som dog har med det samme princip at gøre), at jeg gerne vil have, at man på sigt går væk fra, at gette al data til en ressource i én samlet liste (hvad man nok gerne vil gøre for nemhedens skyld i starten), og i stedet går over til implementere individuelle get-metoder til hver.\,. ``attribut'' til et objekt / en ressource, så at sige. Og så kan hver bruger nemlig selv config'e disse get-metoder yderligere, og specifikt altså gerne ved simpelthen bare at gå ind og ændre brugergruppen (i form af et linearkombination-udtryk som dem, jeg skrev lige før her ovenfor) for hver enkle get-metode. (15:48)

.\,.\,Hm, og var det det omkring dette nederste lad i applikationslaget (når vi lige ser bort fra QL'et.\,.), eller var der mere, jeg skullle sige i denne omgang.\,.\,? .\,.\,Jeg det må næsten være det.\,. Nice.\,:) Okay, jeg har så stadig nogle flere ting, jeg lige skal tænke lidt over. Nogle er ret små (dem skal jeg bare gå at summe lidt over sammenlagt), og så er der nogle lidt større ting, såsom bl.a.\ QL'et (som jo ikke bare skal være SQL, det er klart, selvom det i høj grad nu bare skal minde om, når det kommer til selects), som jo lige er en af de største todos sammen med at få styr på databasen helt præcis --- og også i øvrigt de der delta-(/remix-)strings! --- som jeg jo skal programmere som noget af det første. Men angående applikationslaget, så mangler jeg også at tænke lidt mere over, ikke de \emph{grundlæggende} filtre, men de efterfølgende filtre, som brugeren skal kunne indstille for applikationen. Jeg har noteret til mig selv, at jeg lige skal huske at nævne her, at brugerne gerne må kunne plotte deres filter-fordelingsfunktioner, når de har konstrueret nogle, men jeg skal jo nok lige tænke lidt mere over hele den del.\,. 

.\,.\,Hm, jeg kan lige nævne, at der gerne også må være et `all'-keyword til at konfigurere type-brugergrupper og -filtre (og get-brugergrupper), på samme måde som at der skulle være et `other'-keyword. Og så gælder konfigurationerne for ``all-typen'' så selvfølgelig bare for alle typer, hvor de for ``other-typen'' bare gælder for de entiteter, der ikke matcher nogen brugerdefineret type. 

Og en anden lille hurtig ting er, at databasen selvfølgelig gerne må slette entiteter igen, hvis de ikke længere rigtigt er i brug (og/eller er nedvurderet tilstrækkeligt af repræsentative udsnit af brugerne). Særligt må databasen jo gerne slette gamle ratings fra bots, hvis ingen bruger dem.\,. .\,.\,Tja, og det vil jo bare vise sig, hvordan det bedst giver mening.\,. Men hvis man sletter entiteter, så kan man bare frigøre pladsen og entitets-ID'et (for den pågældende entitetstype), således at nye uploads kan tildeles disse i stedet. 

Okay, jeg skal altså lige have tænkt lidt mere over de ikke-grundlæggende filtre (dem som brugerne frit kan vælge til og fra og udskifte i deres normale brug af applikationen), men ellers kan jeg altså så småt begynde at gå i gang med at programmere den grundlæggende del (startende med den semantiske database og det grundlæggende QL).\,:) Virkeligt nogle fede tilføjelser i denne omgang! (.\,.\,Altså her over de seneste dage, tænker jeg på.) Fedt at være nået hertil! :) (16:15)

(18:07) Jeg har fundet på nogle flere tilføjelser. Angående string-encodingen, så skal man jo selvfølgelig bare bruge den der htmlspecialcharacters()-funktion. Og det er så både det format, man sender til serveren og det format, man får af af serveren. Når man så skal loade scripts/HTML, så skal man så bare specielt i det tilfælde konvertere tilbage. (Og serveren tjekker selvfølgelig altid, at inputtede strings er af det format.)

Angående QL'et, så tror jeg faktisk, at det bare netop skal være en undermængde af SQL, simpelthen. Og så kan man altså implementere eventuelle mere specialbyggede QL-sprog i applikationslaget (UDA-laget). Så man sender altså sine select statements til serveren, som så parser dem med en automaton (en kompileret RegEx) og sender det videre til serveren, hvis det godkendes.

Når det så kommer til insert statements, så er der lige en anelse mere at sige. For det første vil jeg nok gerne trække det tilbage med, at det kun er ratings/semantic inputs, der får timestamp og bruger-ID. For jeg er kommet i tanke om, at nu hvor man (også) kan tilgå databasen rent SQL-style, så behøver man jo ikke at vurdere alle entiteters ``usefulness''.\,. Så ja, nu tænker jeg faktisk lidt bare, at bruger-ID og timestamp kommer med over alt. 

Det gør så faktisk, at insert-statementsne også bare kan være en undermængde af SQL, hvor serveren så skal tjekke at bruger-ID og timestamp kan godkendes. Og her har jeg så nemlig tænkt noget andet, og det er, at man jo så med fordel kunne gøre det sådan, at hvis timestampet er sat til en fremtidig tid (mere end bare nogle sekunder), så kan serveren vælge at tjekke, om der er plads i en buffer og så putte den midlertidigt over i denne, indtil timestampet bliver aktuelt, hvorefter serveren så kan uploade entiteten til den offentlige database. Og denne buffer skal altså være i en privat database. Dette giver en simpel måde, hvor brugere kan obfuskere upload-tidspunktet, hvilket nemlig kan være godt for at forøge anonymitet. Og så tænkte jeg så også, at en måde at implementere, at entiteter kun bliver uploadet til en privat database så bare kunne være ved at sætte en nul-timestamp (eller bare en der ligger før nutiden). For ellers skal man jo vedlægge et flag, men når man alligevel har pladsen til det.\,. tje, medmindre at der kan være en fordel for brugeren i at holde styr på sine egne private timestamps (for sine privat-database-uploads).\,.(?) (18:24) .\,.\,Oh well, ellers må man jo bare sende et public/private-flag (måske i form af `u' og `r' henholdsvis.\,.) med til serveren sammen med insert-statementet, som så altså bare i sig selv kan være fra en undermængde af SQL.\,. Hm, og hvad med selects, skal kan man også have behov for.\,. ja.\,. Her kan man også have behov for at sige ``søg kun i den offentlige database'' --- og måske endda også selects, skal kan man også have behov for.\,. ja.\,. Her kan man også have behov for at sige ``søg kun i den private database'' (foruden ``søg kun i begge databaser''). Så lad der også bare skulle sendes et char-flag med i købet for select-statementsne også. .\,.\,Hov, jeg skal lige komme ind på, at serveren jo.\,. Nå nej, det kommer sig jo gratis af, at man ikke behøver at inkludere værdier i insert statements i SQL, når disse værdier bliver sat automatisk i databasen. Så serveren behøver slet ikke at vide, hvad bruger-ID'et skal være, og brugerne skal så heller ikke have det med, når kommandoerne sendes til serveren. Ja, jamen så er det da bare det! Og ja, det er så applikationens altså applikationens ansvar at sætte timestampet, bare lige for at understrege dette. Ok! Jamen så bliver QL-delen ligepludselig ikke nogen særlig stor opgave.\,:) (18:35)


(15.02.23, 10:10) Timestamps kan jo også sættes automatisk af databasen, så jeg skal nok hellere lave det sådan, at brugere kan undlader at sende timestamps med, og måske kan de så bare sende et eventuelt delay med til serveren (ved siden af SQL-udsagnet).

\ldots Hm, jeg tror faktisk, at jeg skal bruge TINYINTs til at indkode databasetyperne.\,. %.\,.\,Hov, det har MySQL ikke.\,. ..Åh, jo..

\ldots\ Hm, jeg skal lige tænke over, om man bare skal sige, at man kun har BIGINT/long values til SemanticInputs.\,. men på den anden side, så er det kun en TINYINT/char til forskel.\,. .\,.\,Ja, lad mig bare sige, at det kan være det hele.\,. .\,.\,Men det bør dog være en fast konvention, at \emph{hvis} der indsættes en long/BIGINT, så \emph{skal} de første (én til fire) bytes i long-værdien repræsentere et midtpunkt/gennemsnit for ratingen. (13:54)

(14:21) Hm, det går først op for mig nu, at timestamps fylder mere end 8 bytes.\,. .\,.\,Ah nej, det kan godt være på 7 bytes. Ok, så kan man godt indsætte det som en BIGINT.\,. .\,.\,Og man \emph{kan} endda bruge 8 bytes (går jeg stærkt ud fra), hvis man vil have to decimaler på sekunderne.\,. 

(18:27) Hm, jeg behøver nok ikke den der ``meanbot'' i starten, for lad mig bare starte med at tillade AVG() i queries, og så tænker jeg forresten nu, at man skal tage gennemsnittet på ratingværdier ved at sige AVG(value $>>$ 32) (altså hvor $>>$ er right shift-operatoren (som MySQL vist rigtignok har)). .\,.\,Nå ja, og så skal der forresten lige være et indledende select, hvor man sorterer alle andre end den seneste rating fra for hver bruger--statement-kombination. 

.\,.\,Hm, på den anden side, hvorfor ikke bare bruge den der meanbot, for jeg kan jo altid bare sige, at gamle meanbot-inputs i høj grad skal slettes (altså hvor man ikke nødvendigvis sletter alle gamle.\,. Hov, vent, selvfølgelig kan man slette bottens gamle inputs ad libitum, for indtil man sletter gamle bruger-ratings, så vil de jo altid kunne gendannes!\,.).\,. Ja, så lad mig bare indføre den bot, så.\,. (18:38) 

.\,.\,Hm, jeg kan da egentligt også bare starte med at have en regel om, at nye bruger-ratings altid bare overskriver de gamle (når statementet er det samme), for mon ikke de fleste brugere alligevel helst vil have, at deres gamle ratings ikke bliver bevaret. Og så kan man spare lidt plads i den tidlige database. Så jo, lad mig bare sige det. .\,.\,Hm, men så vil det jo så sige, at der \emph{kan} være en fordel i at gemme gamle bot-inputs. Så lad mig sige.\,. Tja, og dog, for hvis det handler om at spare plads, så vil man sikkert spare mere ved at holde på bruger-ratings og så slette alle bot-ratings, for det vil nu nok være relativt sjældent, at brugere vil ændre deres ratings sammenlignet med, hvor tit der kommer nye ratings til et statement (udsagn) (og dermed hvor tit mean-botten --- eller avg-botten, kunne vi også kalde den --- skal opdatere sin rating til samme udsagn).\,. Ok, så vi siger hold på brugerdata og overskriv al bot-data (altså i starten/betaversionen.\,.). (18:46)


(16.02.23, 14:29) Jeg har nogle flere tilføjelser. For det første er der en tilføjelse om, at serveren/erne faktisk \emph{skal} kræve nogle udsagn-ratings omkring en entitet, som en bruger gerne vil uploade. Og derfor \emph{kan} vi lige netop godt droppe timestamp- og user-felterne for alle ikke-SemanticInput-entiteter. Og grunden til, at serverne bør kræve dette, er at brugerne alligevel altid gerne skal vurdere typerne og kategorierne for en ny entitet. 

Angående uploads, så tror jeg, jeg vil indføre et up- og down-rating knapper tidligt i betaversionen, og så vil jeg nok bare bruge en konvention om at disse ratings skal være på max-værdien af en (signed) long, og at intervalbredden (som så i dette tilfælde vil kunne læses alene på 5.\ byte) så sættes til det samme (som jo er halvdelen af max-værdien for en ulong). Og når brugere så vælger prædikater til et nyt upload, så skal applikationen bare automatisk sende sådanne up-rates med. 

Nå, en endnu mere interessant tilføjelse er, at jeg vil indføre compound predicates, som nærmest kan ses som en slags virtuel entitetstype. Man erklærer dem nemlig ved at vælge en relationsentitet samt en objektentitet (til at sætte ind på nr.\ 2 plads i relationen). Herved oprettes så en ny entitet (med eget entitets-ID --- og med en ny databasetype-tinyint-kode), og det, der så gør den ``virtuel,'' er for det første, at databasen så automatisk kopiere alle ratings fra eksisterende DyadicStatements med lige netop den kombination af relation og objekt og giver den til nyoprettede MonadicStatement, som tilsvarer DyadicStatements'ne, men hvor relation og objekt nu altså er udskiftet med den tilsvarende, nyoprettede CompoundPredicate. Og for det andet skal hver ny rating af enten et CompoundPredicate-MonadicStatement eller en relation med en relation--objekt-kombination, der svarer til et CompoundPredicate, have sin rating kopieret automatisk til den anden udgave af sig selv. 

.\,.\,Hm, lad mig dog lige spørge mig selv igen, om ikke det så var nemmere at fjerne Dyadic-Statement-typen, og så bare nøjes med compound predicates.\,.\,? Hm, jeg føler/husker, at der var en god grund, men lad mig nu lige se.\,. .\,.\,Ja, grunden er jo, at man tit kommer til at holde en entitet i hånden, hvor man så gerne vil søge efter en passende objekt-entitet (``objekt'' som i `sætningsobjekt') ud fra en given relationsentitet, som man også holder i hånden. Men hvis man så kun har compound predicates, så.\,. .\,.\,Ja, så kræver det vel et ret vildt/tungt (tabel-)join, gør det ikke.\,.\,? (14:55) .\,.\,Hm nej, for det kræver jo kun ét join for at opnå et view, hvor man har subjekt, prædikat, eventuel relation (hvis prædikatet er compound) og objekt (hvis prædikatet er compound). Og så kan brugerne bare søge i dette view. Jamen skal jeg så virkeligt fjerne DyadicStatements?? Det virker lidt mærkeligt, for konventionelt er DyadicStatements jo det \emph{eneste} man har, hvis vi tænker på det de konventionelle `semantiske web'-teknologier.\,.(!).\,. (15:01) .\,.\,Oh well, vi har dem jo stadigvæk i form af omtalte view, og ja, det giver jo klart god mening at undgå, at dataen skal kopieres i databasen (af flere grunde), så mon ikke bare, det er det, jeg gør.\,. (15:04)

.\,.\,Det koster os lige en gemt long/BIGINT mere i databasen for hver DyadicStatement, hvor man ikke regner med, at nogen vil være interesseret i at bruge prædikatet (men hvor brugerne regnes med altid bare at skulle bruge objektet, efter at de har subjektet (og relationen) i hånden), men sådan må det jo bare være.\,. .\,.\,Og til gengæld sparer vi en TINYINT for hver SemanticInput, og det må jo faktisk næsten gøre, at det kan svare sig rent datastørrelse-mæssigt. (For mon ikke der bliver flere end 8 ratings pr.\ DyadicStatement i snit.\,. det må der gøre.\,.\,:)) 

Ok, og den næste store ting er så, at jeg i betaversionen vil tillade (og implementere), at brugerne kan loade pre-parsede CSS- og HTML-includes til deres applikation ad libitum, hvor man så særligt sørger for, at HTML'et bare ikke må indeholde andre hrefs eller script-srcs, end hvad brugeren på forhånd har godkendt i en indledende config-``fil,'' som hentes til at starte med (fra brugerens private database-afdeling). Og i øvrigt må der så (selvfølgelig) heller ikke være nogen scripts, der har noget kode-indhold, og som altså ikke henter al deres kode fra en src. Brugerne skal så kunne ændre på deres egne href-/script-src-configs, men hvis brugeren klikker sig ind på denne config side, skal der så bare med det samme komme en skarp advarsel om ikke at ændre eller tilføje nogen kilde med mindre man har dobbelt- eller tripeltjekket, at kilden er sikker, gerne ved at søge på webbet eller ved at søge i den semantiske database / det semantiske netværk omkring kilden, og rigtig gerne ved at gøre begge ting! (hvorfor jeg skrev ``tripeltjekke''). 

Så her får vi altså allerede en ret nem måde, hvorpå brugerne allerede kan gå i gang på sikker vis med at indstille alle mulige præferencer for applikationen. 

Ok, men lad mig nu skifte til en ny sektion, hvor jeg så vil tilføje noter omkring, hvad betaversionen skal sigte imod at indeholde (så altså hvad jeg så småt vil sigte mod at bygge). Jeg har nogle få ting, jeg vil skrive nu, og ellers vil jeg sikkert tilføje ting løbende, imens jeg arbejder. Men hvis jeg kommer på nogle flere tilføjelser til noget af det mere grundlæggende, så tror jeg nok, at jeg bare vil tilføje dem i forlængelse af denne sektion (hvor jeg så bare giver nye dataangivelser, men ikke angiver * for ``tilføjet senere end den oprindelige tekst,'' som jeg ellers lidt fjollet har valgt at gøre for nogen af de ovenstående sektioner). (15:33, 16.02.23)


(17.02.23, 12:39) Jeg kom lige på en rigtig nyttig tanke her i formiddags, som helt klart at værd at skrive i denne sektion. Den er, at man i applikationslaget --- og i min betaversion --- skal indføre standard for at skrive attributter ned for en ny DescribedTerm/DescribedEntity med en tilhørende automatisk oprettelse af relations-statements (som nu altså oprettes via et compound predicate (sammensat prædikat)). Jeg tænker så, at indføre en parser til at parse entity descriptions på formen, ``$<$attribut$>$=$<$værdi$>$,$<$attribut$>$=$<$værdi$>$,\ldots'' Og for hver attribut søges der så på, om der findes prædikat-funktion (altså en relation omdannet til en anden-ordens funktion), der svarer til `$\lambda$value : hasAttribute $<$attribut$>$ = value,' og hvis ikke denne allerede findes oprettes en ny. Herefter uploades så et sammensat prædikat, dannet ved at tage den relevante $<$værdi$>$ og give til input i denne prædikat-funktion. Og når dette prædikat så er dannet --- eller dvs.\ først så søges der jo på, om det allerede er dannet, kan man sige (om end dette tjek så er serverens eller databasens ansvar (men det skal jo nok være databasens)) --- så sørger man så for, at en automatisk up-rating af dette prædikat (som altså fortæller at ``$<$attribut$>$=$<$værdi$>$'' for et af attribut--værdi-parrene i beskrivelse-strengen) bliver givet omkring den nye entitet som uploades med denne beskrivelse. 

Dette giver så et rigtigt godt udgangspunkt for applikationen, som gør at brugere allerede fra start lærer, at attributter skal/bør get'es på semantisk vis via relationer/prædikater. Og samtidigt klarer det også den opgave, jeg alligevel skulle finde ud af, hvor at jeg jo skulle gøre det til en standard, at brugerene får uploadet nogle kategori-beskrivende (m.m.) prædikater om den nye entitet, de er ved at uploade. For nu kan dette nemlig altsammen bare ske på en rigtig nem måde (ikke mindst for brugerne), hvor disse prædikater bare automatisk bliver parset fra beskrivelsesstrengen og uploadet.\,! Så med denne tilføjelse er man altså lynhurtigt bare godt i gang så at sige.(!) 

Lige for at komme mere ind på syntaksen, så vil jeg så nok altså gøre standarden til, at brugerne skal (hvis den parser jeg implementerer skal fungere) udforme beskrivelses strengen ud fra den nævnte syntaks, men hvor whitespace dog er tilladt mellem alle tegnene. Og jeg vil også tillade, at man laver attributter og værdier med længere strenge, hvor der også gerne må være kommaer og whitespaces i, og hertil skal jeg så lige finde ud af, hvordan de skal indkapsle disse strenge. Her kunne man jo bare sige, at det skal bruge gåseøjne yderst, og at alle indre gåseøje så skal escapes med `\textbackslash' (Og hvor `\textbackslash' så i stedet skrives som `\textbackslash\textbackslash'), men jeg har også tænkt på at bruge `\{\}' i stedet, og det tiltaler mig nu helt klart også.\,. .\,.\,Ja, for så bliver det mere naturligt at lave newlines.\,. Plus jeg kunne også bruge `\{\}' som en måde, hvorpå brugerne har lov at bryde syntaksen (uden at forvirre parseren).\,. Hm.\,. (13:09) .\,.\,Hm, jeg kan altså mærke, at jeg hælder til at bruge `\{\}'.\,. .\,.\,Parseren ignorerer så en `\{\}'-indkapslet delstreng, der står imellem to kommaer (eller efter sidste komma), og.\,. Hm vent, hvad med at tillade brug af begge indkapslingsmetoder.\,. Ah, og attributter behøves jo faktisk ikke at indkapsles! Okay, det giver mening. Og værdi-strenge kan så indkapsles enten med `""' eller med `\{\}', og så vil jeg også sige, at alle indledende eller afsluttende newlines *(al whitespace i det hele taget, rettere) bliver ignoreret/slettet for `\{\}'-syntaksen, medmindre altså der står et `\textbackslash' foran. Der må desuden godt være indvendige `\{\}'-parenteser, men hvis man vil skrive et `\}' uden at der først har været et (ikke-afsluttet) `\{', så kan brugeren så gøre dette ved at skrive `\textbackslash\}' i stedet, hvilket tolkes som `\}' --- dog medmindre at der også et `\textbackslash' (eller et ulige antal af dem) lige foran dette `\textbackslash\}'. Og brugen kan også skrive `\textbackslash\{' frit, uden at det tæller med som begyndelsen på en nestet `\{\}'-parentes. Så ja, det er altså min umiddelbare forestilling (nu) for denne syntaks.\,. (13:22)

(14:06, 17.02.23) Ah, i stedet for at indføre den der mean-/avg-bot, så kunne jeg også bare indføre et view med en automatisk beregnet AVG() (eller rettere AVG($x$ $>>$ 32) $<<$ 32), som brugerne så får adgang til. Og ja, i samme view kan jeg i øvrigt også give COUNT()'en for antallet af brugerratings. 

(17:25) Hm, i stedet for at have Compound-/FunctionalTerms, så tror jeg måske, jeg i stedet bare laver DescribedTerms om, så de får et description\_schema (i stedet for bare en description) samt et (nullable) schema\_input. For dette gør så tilmed også, at det bliver mere oplagt for brugerne at definere faste skemaer for nye uploads af entiteter af forskellige (semantiske) typer. .\,. \ldots Ja, og så laver jeg også bare en standard (i applikationslaget) til parseren for, hvordan man skal erklære inputvariablene, og hvordan disse så automatisk skal sættes ind i beskrivelsen/beskrivelsesskemaet, inden at attribut--værdi-parsingen udføres. (17:39)

(18.02.23, 11:22) Okay, jeg tror faktisk, at DescribedTerm (eller hvad jeg ender med at kalde det) i stedet simpelthen skal defineres med en liste af prædikater først til at bestemme type/kategori, og som nr.\ 2 liste skal der så komme en liste af attributter, hvor applikationen så faktisk automatisk selv finder de mest populære attributlister fra hver type/kategori-prædikat og så sætter dem sammen i én samlet liste. Disse attributter skal så tilsammen udgøre alle de ``definerende felter'' for entiteten, man er ved at uploade. Derefter kommer en ny attributliste, som applikationen også prøver at hente automatisk, hvor entitetsforfatteren så kan tilføje data omkring entiteten (altså data, der ikke behøves for at referere til / definere entiteten, men som relaterer sig til entiteten alligevel (og som brugere typisk gerne vil have serveret, når de iagttager entiteten)). Og ja, så skal der altså også være en femte liste, der så holder forfatterens (eventuelle!) inputs i disse datafelter. 

.\,.\,Hm, nu hvor dette så bliver meget specielt rettet mod at oprette ressource-entiteter, ville de så ikke give mening at genindføre en relations-/prædikat-funktion-/funktion-type.\,.\,.? \ldots Ja, for man regner jo ikke med, at nogen vil søge på det specifikke prædikat, der bliver dannet i en tilføj-data-, tilføj-links- eller tilføj-beskrivende/definerende-data/tekst-relation.\,. 
.\,.\,Hm, på den anden side, så kunne dette godt ske lige netop med tilføj-links-relationer.\,. Hm.\,. .\,.\,Hov, men den tilføjede data skal da heller ikke være en del af selve DescribedTerm; det kan bare være en del af, hvad applikationen spørger til, når man vil oprette et nyt term. Og derfor kunne man jo bare lade være med at tilføje data for sådanne relationer --- som så typisk bare vil have en fast liste af prædikater, der definerer relationen, og så en.\,. hov, men hvad man attribut-navnelisten?\,.\,. \ldots Hm, attributterne er jo også i sig selv relationer, så.\,. Okay, lad mig lige tænke over, hvad der bedst giver mening.\,. (12:09) .\,.\,Ah, man kunne vel i princippet bare oprette et ret grundlæggende Apply()/Insert(Sentence)Object()-term-skema.\,. (/-relation).\,. (12:13)

.\,.\,(12:22) Ah, nu ved jeg, hvad jeg gør. Jeg beholder de seneste ændringer i DescribedTerm, men jeg indfører så faktisk også relationer igen, men ikke via DyadicStatements. I stedet indfører jeg dem via CompoundPredicates.\,. /CompoundTerms.\,.  

\ldots (12:41) Hm, nu tror jeg faktisk hellere, jeg vil.\,. Nå ja, det bliver jo egentligt lidt det samme, hvad den databasen angår. Så jeg tror altså, jeg vil indføre CompoundPredicate (ikke CompoundTerm! for det er ikke meningen, at man skal danne andre funktioner end prædikat-funktioner!), og at jeg vil ændre DescribedTerm som beskrevet, og nu forestiller jeg mig så at lægge op til, at CompoundPredicates så altid (måske på nær i få tilfælde) skal ses og bruges som attributbestemmelser. Så når brugeren indfører en relation, så skal de meget hellere se det som, at de indfører en attribut til en vis type/kategori. Og ja, det er jo lige netop disse attributter (i form af hvad man også sagtens kan se/tolke som relationer), som applikationen skal hente i nævnte liste nr.\ 2, når en ny entitet / et nyt term oprettes. .\,.\,Og den store forskel på at se det som relationer og på at se det som attributter er altså, at relationer ofte ses som noget generelt, der giver mening at snakke om for alle entiteter, og som altså derfor ikke har et egentligt domæne så at sige, men hvor attributter i langt højere grad tolkes som havende et domæne, specifikt nemlig et domæne for subjektet i relationen (og også tit for objektet, men det er faktisk ikke så vigtigt for os). Og det vigtige ligger nemlig i, at brugerne gerne må udforme relationerne til meget specifikke typer/kategorier. Og hvis så en relation/attribut kan gå igen på tværs af kategorier, jamen så må man bare tilføje den en passende overkategori, og hvis nu den kan bruges på tværs af overkategorier, jamen så må man bare tilføje den hver især til alle de relevante overkategorier!\,. Simpelthen!\,. (12:54) .\,.\,Hm, og en anden tilsvarende fortolkning er jo så bare, at i stedet for at se relationerne som attributter, så ser man dem bare som domæne-specifikke relationer, hvilket nemlig giver det samme.\,.\,:) (12:57)

.\,.\,Hm, men spørgsmålet er dog, om ikke jeg vil kalde det for attributter frem for.\,. ja, ``domæne-specifikke relationer,'' for det sidste er alligevel en mundfuld, hvis man gerne vil præcisere det.\,. .\,.\,Oh well, men hvis jeg holder mig til at kalde det CompoundPredicates i databasen, så ligger dette jo bare åbent for fortolkning i applikationslaget.\,. 

.\,.\,Ah, men et godt spørgsmål er, om man skal lade CompoundPredicates være førsteklas-sestermer, eller om man i stedet bare skal sige, at de må fremhæves til førsteklassestermer via (Described)Terms (på en eller anden måde.\,.), før de bliver dette.\,.\,? .\,.\,Hov, men de skal jo være første.\,. nå nej, for man kunne jo måske også ændre Statements, lad mig lige se en gang.\,. .\,.\,(Hm, hvis ikke de behøver at være førsteklasseborgere, så kunne man eventuelt ændre Statements til altid at have tre inputs, som jeg også havde det en gang.\,.) .\,.\,Hm, det virker faktisk på en måde rigtigt (i.e.\ at det er det, jeg bør gøre), men lad mig lige overveje, hvordan brugerne så kan tilgå relation/attribut--input/værdi-kombinationen som et prædikat.\,. (13:16) .\,.\,Hm, hvad med at brugere kan oprette ``virtuelle prædikater'' på samme måde, som jeg har været inde på før.\,.\,? .\,.\,Hm, men så skal dette jo også indgå i den fundamentale del af databasen (for det skal jo gemmes, hvilke virtulle prædikater er blevet oprettet.\,. tja, medmindre.\,. hm.\,.).\,. .\,.\,Men lad mig da lige nævne den mulighed, jeg skulle netop til at nævne, hvilket er at oprette en VirtualPredicate-type, .\,.\,som så kommer til at svare helt til CompoundPredicate, bortset fra at når man rater et sådant, så er det i virkeligheden den relaterede relation--input-/attribut--værdi-kombination, der bliver ratet i stedet. .\,.\,Hm, men lad mig lige tænke lidt over det.\,. (13:30) 

.\,.\,Hov, nu fik jeg også lige en alternativ tanke: Hvad med at droppe prædikater, og så bare formulere alt med relationer i stedet?\,.\,. For selv hvs vi tænker på prædikater såsom ``isFunny,'' jamen her kan man jo også bare definere `is(adjective)'-relationen, og så definere alverdens adjektiver. Og hvad angår kategorier, så er det jo også netop ret naturligt, at sige `hørerUnder(Kategori)' og så indputte kategorien `fysik' f.eks.\ i stedet for at tænke på et helt prædikat om at `tilhøre(r)KategorienFysik.' .\,.\,Og ja, selv hvad angår tillægsordprædikater, så er det nok endda også mere naturligt for os (ift.\ hvordan vi typisk tænker og gør med vores naturlige sprog) at tænke i at definere adjektiver frem for hele prædikater. Så ja, det er da lige før, at jeg skal fjerne prædikaterne og så bare kun bruge relationer (ligesom konventionelle sem-web-teknologier). Så skal jeg bare lige overveje det her med, at brugerne gerne også skal.\,. ja, definere domæner til hver relation, men det spørgsmål svarer jo næsten sig selv: Man skal så bare lægge op til i systemet, at hver ny relation bliver tildelt domæner (og især faktisk hvad subjektet angår, selvom objektdomænet også nok bør angives, da det også kan hjælpe med forståelsen af relationen).\,. (13:45) .\,.\,Det skal dog ikke forstås som, at databasen (eller control-serveren) skal verificere disse domæner. I stedet hjælper domænerne bare med forståelsen/fortolkningen af relationen, og ikke mindst gør det nemmere at søge i relationer --- og at finde relationer, der passer på lige det man søger. .\,.,Hm, men vent, for prædikater er stadig nice at søge på, så.\,. Ah, men så søger man jo bare på unikke relation--objekt-kombinationer, når man vil søge på prædikater.\,. .\,.\,Hm, nu tænkte jeg lige på: skal alle termer så ikke bare bestå.\,. nej, det giver ikke mening, lad mig lige tænke videre.\,. .\,.\,Ah, nu ved jeg det måske. Hvis alle prædikater nu bare formuleres som relation--objektinput-kombinationer, kan vi så ikke bare lave typen Predicate, som har disse to felter, og så.\,. ja, er det så ikke nærmest bare det.\,.\,? .\,.\,Ja, som så bare svarer helt til CompoundPredicate fra før, bare hvor Statements så \emph{kun} tager prædikat-input af denne type, og hvor vi så heller ikke behøver at kalde dem ``Compound,'' hvis det jo alligevel ikke er andre muligheder. Hm, jeg tror, det bliver svaret (og så beholder jeg altså umiddelbart, som jeg bliver ved med at sige, de seneste ændringer der for DescribedTerm).\,. (13:59) .\,.\,Hm, jeg skal nok faktisk gå væk fra at kalde det ``termer'' og over til at kalde det Entities i stedet, for i matematik og i formel logik er ``termer'' jo aldrig prædikat- eller relationssymboler, mener jeg (og jeg har også lige søgt kort på det), så ja, lad mig sige `entiteter' i stedet.\,. .\,.\,Ja, og så kan `termer' passende være, hvad man kalder overtypen/-kategorien af entiteter, der ikke er hverken prædikater eller relationer --- eller lister. (14:07)

(14:45) Hm, jeg tror muligvis, jeg vil føje endnu en type til i form af `kendte ord' (eller hvad jeg skal kalde det), som altså er entiteter, der bare er beskrevet med et enkelt ord eller navn, eller en enkelt titel eller sammensat navneord.\,. .\,.\,Hm, eller også kunne man bare implementere dette via mine DescripedEntities, hvor første input så beskriver, at der er tale om ting, der i høj grad bør kunne forstås uden yderligere kontekst end bare ordet/navnet/titlen, og hvor inputtet så er dette ord/navne/denne titel, men det kan jeg lige tænke over.\,. .\,.\,Hm, nej, måske var min første tanke bedre, nemlig med bare at sige, at relationer --- især de meget grundlæggende af slagsen, men også i det hele taget --- meget gerne må indeholde i sig en beskrivelse af, hvordan det resulterende prædikat skal fortolkes (eller rettere forsøges at fortolkes), hvis inputtet er en tekst. Så ja, lad os bare sige det i stedet. (15:00)

(15:57, 18.02.23) Ah, jeg kan godt nøjes DescribedEntities, som jeg har tænkt mig, og så kan de helt basale typebestemmende prædikater, eller rettere relationer, som det jo bliver nu, bare få en tom liste som første input-liste.\,. .\,.\,Og, så kan det nemlig bare være standard, at applikationen klargør en `description'-attribut som den eneste attribut, når første liste er den tomme liste, og nr.\ tre (og sidste (for de ikkebeskrivende attributter bliver jo ikke et faktisk felt i DecribedEntity-typen, men bliver i stedet bare sat via eksterne relationer)) input-liste bliver så altså denne tekstbeskrivelse. .\,.\,Hm, så er det så bare lige at finde ud af, hvilken type description'-attributten (som i: attributnavnet) skal have.\,.\,? .\,.\,Hm, det må jo bare være (small-)tekst-typen, og så skal den grundlæggende fortolkning (som er antaget allerede fra start af, inden man fylder entiteter ind i databasen) altså bare være, at tekster i denne liste opfattes som attributnavne (på samme måde som fortolkningen af felter og feltnavne i OOP). .\,.\,Hm, og så kan man jo sådan set beholde denne fortolkning ret langt.\,. hvilket måske giver meget god mening.\,. .\,.\,Tja, og dog, for man må jo også gerne gøre det nemt for parseren at.\,. Ah vent, men man kunne jo også definere en god `x.hasAttribute(y)'-relation fra starten af, hvor y kan være et tekstinput.\,. For måske er det alligevel dobbeltkonfekt at specificere domænet, når dette allerede bliver specificeret i første inputliste (i DescribedEntity-typen).\,. .\,.\,Ah, men man kunne jo bare se attributter som noget, der i princippet, selvom de jo kan omfortolkes som relationer, er noget helt andet en relationer, i.e.\ har en anden type.\,. .\,.\,Hm, men for at alt dette skal gå op, så skal der jo næsten være en relationsfunktion (altså en prædikat-funktion-funktion), der kunne hedde noget i retning af `hasAttribute,' og som så tager attributnavn først og bagefter værdi, inden det så returnere et prædikat som endeligt kan tages på et subjekt.\,. .\,.\,Hm, og en måde at indføre dette på, kunne jo så eventuelt bare være, at.\,. hm nej, men måske at give Predicate to undertyper, hvilket så kan være.\,. Hm, okay der er to muligheder angående denne tanke: Man kan enten sige, at relations-inputtet i Predicate-typen godt kan være en tekst, hvor.\,. ah ja (tja), hvor teksten skrives som en relation, og hvor `has' derfor altid sættes foran automatisk, når applikationen skal parse en attribut og lave den om til en relation/et prædikat. Men jeg vil faktisk langt hellere gøre det sådan, at tekst-relationer altid bare skrives som attributter, og at `has' altså aldrig gemmes i databasen, men at `has' i stedet bare kan sættes foran i applikationen, når denne skal vise en liste over relationer, hvor disse tekstdefinerede relationer også kommer med.\,. eller endnu bedre: man kunne sørge for at alle tekstdefinerede relationer printes efter fulgt af et ` ='! For umiddelbart, som jeg lige kan se det, så vil dette virke overalt (både når hele prædikatet (eller hele udsagnet for den sags skyld!) printes, og også bare når relationen vises for sig)! .\,.\,Fedt!! (16:34)

(17:23) Ah, og vi kan forresten passende blande nr.\ 1 og nr.\ 2 liste sammen til én, nemlig således at hvert tekstinput i denne liste så bare opfattes som et attributnavn. Og den anden type input i denne liste, som man så typisk gerne vil se (medmindre vi skal gøre det til en klar restriktion), er så input af prædikat-typen. .\,.\,Hm, jeg tror nu nok, jeg vil undlade at gøre det til en fast ting, at resten af inputtet skal være prædikater, og måske skal dette ingen gang være en standard. Man kunne således også forestille sig, at applikationen (samt brugernetværket) også fint kan tolke kategori- og adjektiv-inputtyper, hvorved applikationen så selv automatisk finder hhv.\ relationerne `belongsTo(category)' og `is(adjective)' frem og uploader de relevante prædikater om den nye entitet dannet ud fra disse. Så ja, lad os sige, at input-databasetyperne også sagtens kan være DescribedEntities af vilkårlige custom-typer og -kategorier. (17:32, 18.02.23) .\,.\,Hm, og skal liste nr.\ 2 så bare give input kun til attributterne, eller hvad gør vi her.\,.\,? .\,.\,Hm, i princippet kunne listen indeholde input til både attributterne og DescribedEntity-relationerne.\,. .\,.\,Ja, lad mig bare sige det sådan, og så er det altså op til brugernetværket samt applikationslaget at sørge for, at nr.\ 2 liste fortolkes på denne måde, og at parseren i applikation altid kan genkende relationsentiteter (beskrevne), således at den automatisk kan danne de rette prædikater hørende til et nyt upload. Ok! 

(19:05) Hm, det kan også være, at man bare skal lægge kraftigt op til, at brugerne kan gøre brug af at definere simple relationer ved at skrive et attributnavn efterfulgt af `='.\,. .\,.\,Hm, jo lad mig faktisk gøre sådan, for det er jo ikke alle, der er vant til attributter, og man kan jo også sige, at der vel må være en god grund til, at vi har det med at bruge verber i daglig tale. Fint. Så jeg TTexts skal altså i reglen fortolkes som verber, medmindre de slutter med `=,' hvorved de så skal tolkes som første del af en attribut-erklæring --- og hvor man altså altid udelader det indledende `has,' der ellers ville gøre det til verbum i stedet (hvis man nemlig så også erstattede `=' med `er lig')!\,. Ok. (19:13, 18.02.23) \ldots (Hov, det er vist bedre at bruge VARCHAR i stedet til små tekster.\,.)

(22:24) Predicates kan selvfølgelig også bestå af et (beskrevet) prædikat samt den tomme liste som input. 

(19.02.23, 8:53) Det hele (i overført betydning) forsimples en del, hvis vi i stedet kræver, at attributter også skrives med punktum foran, og ikke bare med `=' bagefter, for så kan alle tekst-(/varchar-)relationer nemlig tolkes som verber, bare hvor man så har en konvention om at `$.<$attribute$>$=' tolkes som `has $<$attribute$>$ equal to.' 

.\,.\,Nå ja, og lad mig også pointere, at man nok bare vil bruge `.type=' for prædikater og relationer, og så lade `.type=term' være default (underforstået hvis ikke andet er sagt). Og så vil de typiske term-entiteter, som uploades, have en nr.\ 1-liste (en ``categorizing list'') bestående først af en række prædikater (med databasetypen Predicate! (ikke DescribedTerm)) efterfulgt af en række ``beskriv hvad kendetegner dette (denne) term specifikt (inden for den kategori du lige har valgt via prædikaterne)''-relationer. 

.\,.\,Hm, skulle man egentligt dele denne ``categorizing list'' op i to lister?.\,. Hm, hvorfor ikke.\,.\,? (9:07) .\,.\,En ``categorizing list'' og en ``specifying list''.\,. .\,.\,Hm, og man kan jo egentligt ligeså godt sørger for at dele det op, så DescribedTerm dermed får tre hovedfelter (eller ``hovedkolonner'' hvis man tænker på det som en tabel i stedet for en type). Ja, det må være bedst sådan. (9:13) .\,.\,Ah, og dog, for man vil jo tit gerne bruge dem sammen. Hm, jamen så må nr.\ 1 input jo bare være en L2List (længde-to-liste).\,:) .\,.\,Hm, men hvordan finder jeg et fornuftigt tabel-kolonnenavn til ``categorizing predicates and relations for specification''??.\,. .\,.\,He, ``catepreds and specirels''.\,.\,x) .\,.\,Hm, det er faktisk lige før det virker, hvis jeg putter underscores mellem hver forkortelse også, for fonetikken (og rytmen i det) gør vist faktisk, at det er til at huske.\,. he.\,. Men lad mig lige tænke.\,.\,:) (9:24) .\,.\,Hm, hvad med bare ``CPs and SRs?''.\,. (9:26) .\,.\,Ah, jeg tror, jeg vil kalde kolonnen `cpred\_and\_srel\_lists.' (9:28) .\,.\,Ah, eller jeg kunne endda bare kalde det `cpreds\_and\_srels.'

(11:04) Hm, eneste problem med min attribut-sytaks er, at den ikke er så naturlig, når der kan være mere end én værdi (hvad der oftest kan).\,. .\,.\,Ah, vent! Lad mig da bare bruge kolon til sidst (i stedet for `='), når man regner med, at der typisk/ofte vil være flere end én værdi! (11:09)

(18:01) Ah, jeg kom lige på en idé, som jeg nu hurtigt derefter kan se, faktisk løser et Russell-paradoks, som jeg faktisk ikke rigtigt har tænkt på indtil nu, nemlig at man ikke kan have et isPredicate(), der siger, at det selv er et prædikat. Og løsningen (som jeg altså kom på inden jeg tænkte på, at det løser det paradoks, og at idéen --- eller en anden idé der løser samme paradoks --- derfor er nødvendig) er at se Predicates, hvor første input, nemlig relations-/prædikat-inputtet (som jeg i øvrigt bare kalder relation i databasen), er en tekststreng (varchar), som.\,. ja, eller rettere at se første input i disse tilfælde som ``anonyme prædikater/relationer'' i den forstand, at man ikke direkte kan tage nogen prædikater eller relationer på dem. Dette er nærmere bestemt fordi, de aldrig får et ID i databasen --- eller dvs.\ de har et ID til den pågældende tekststreng (varchar), men denne tekststreng bør ikke i sig selv tolkes som et prædikat eller en relation; kun som en datastreng af chars. Ja, denne datastreng vil kunne forbindes med en semantisk fortolkning, men ID'et referere altså til de \emph{u}-fortolkede dataobjekt. Det er kun, når man putter dette data ind som første input i Predicate-typen, at strengen bliver fortolket (som et prædikat eller en relation i stedet for en karakterstreng). Og dermed kan disse fortolkede prædikater eller relationer altså siges at være anonyme, fordi de ikke får noget ID i databasen, der referere semantisk til dem. 

Men hertil skal det så siges, at man jo godt kan indføre en relation, der siger `has (useful) relation (or predicate) interpretation' --- eller tilsvarende: `is (useful) relation (or predicate) lexical item.' Og på den måde kan brugerne godt finde en måde alligevel at lave.\,. tja, jeg skulle lige til at sige ``lave en fællesmængde af alle prædikater inklusiv de anonyme, der bruges i databasen,'' men mon ikke vi så vi alligevel bliver nødt til at glemme håbet om så at få selve `is (useful) relation (or predicate) lexical item' med i denne mængde, det går jeg ud fra (for ellers får man sikkert Russells paradoks). Men ja, dette var nu alligevel også bare en sidenote, for det er også helt fint, at der er et lille antal anonyme prædikater/relationer, især hvis man bare bruger dem til at komme i gang med semantikken, og altså ikke bruger dem aktivt i den efterfølgende brug af systemet. 

Så lad mig defor sigte efter, at finde på nogle gode grundlæggende anonyme prædikater og relationer, der kun er beregnet til at skabe at udgangspunkt for resten. Bemærk i øvrigt, at dette nok gør standarden omkring `$.<$attribute$>$='-syntaksen overflødig i det helt grundlæggende plan, men derfor kan man godt stadig gøre brug af denne standard i et nedre lag i applikationslaget alligevel, nemlig fordi jeg regner med, at forfatter til (beskrevne) prædikater og relationer gerne skal føje en `.identifierSuggestion' til sådanne, i hvert fald til den de regner med skal bruges meget i det nederste lag af applikationen (altså nederste lag af, hvad jeg kalder ``applikationslaget'' (se ovenfor for mere om, hvad jeg mener med dette)).\,. Dette er dog bare, hvad jeg lige umiddelbart tænker; det kan også være, at `.identifierSuggestion' slet ikke bliver nødvendigt, hvem ved?\,. (18:27, 19.02.23)

\ldots (18:49) Hm, hvad med at have `isPredicate,' `isRelation,' `isCategory,' og `isTerm'-/`isObject'/`isInstance'/\ldots som de (eneste) grundlæggende (``anonyme'') prædikater, og så have `.lexicalItem=' som den (eneste) grundlæggende relation? .\,.\,Hm, eller i stedet for `.lexicalItem=' kunne vi også bare have `.definedBy=', hvilket både er mere elegant og lettere forståeligt/genkendeligt, og samtidigt er det også mere generelt, fordi man så oplagt kan sige, at værdien/sætningsobjektet både enten kan være en ``lexical item'' eller en ``description'' (altså en lidt længere tekstbeskrivelse).\,. Hm.\,. .\,.\,Ja, og lad mig så bare opfordre til at.\,. hm, vent, hvad med at have begge relationer alligevel (altså have både `.lexicalItem=' og `.description=')?.\,. .\,.\,Hm nej, måske ikke, for måske vil man jo gerne netop have, at `.description=' \emph{ikke} bliver en ``anonym'' relation. .\,.\,Hm, nu hælder jeg faktisk næsten lidt tilbage til bare at have `.definedBy=', som så kan gøre double duty så at sige, for måske gør det alligevel ikke noget, hvis `.definedBy=' er en anonym relation.\,. .\,.\,Ah, jeg er i tvivl, så lad mig lige tænke over det, og lad mig også tænke over, om der er en måde helt at undgå anonyme relationer på.\,. Hov, forresten, prædikater bliver jo aldrig helt anonyme, for man kan bare bruge den resulterende Predicate-entitet som nyt prædikat-input (lige præcis i disse fire tilfælde og ikke andre.\,.).\,. 
\ldots Ah, jeg tror det kan løses, hvis bare jeg lige indfører en ny databasetype Relation (ligesom Predicate).\,. Hm, men spørgsmålet er bare, om det er det værd.\,. (19:24) .\,.\,For jeg kunne vel også bare indføre `.definingLexicalItem=' som den (eneste måske) grundlæggende relation.\,. .\,.\,Ah, der \emph{er} en stor fordel ved at indføre en Relation-type, for det kan nemlig lige præcis bruges til at tillade relationer defineret alene ud fra lexical items, men uden at dette så kommer til at koste brugerne, fordi de så ikke får noget relations-ID af sådanne definitioner. .\,.\,Hm, og så kunne man måske godt endda sige, at Relations-typen specifikt er for at danne relationer ud fra lexical items.\,. Hm.\,. .\,.\,Hm, hvad med at jeg i stedet bare opretter en ny type, der hedder LexicalItems, og så løser alle problemerne (måske) herved?!\,.\,. (19:35) .\,.\,Nej, for jeg vil nok gerne kunne skelne typen med det samme, men hvad i stedet med at jeg indførte typen VerbalClause, som altså netop er Relation-typen, hvor input kun kan være en ``lexical item''-streng? .\,.\,Og så skal min `$.<$attribute$>$(= $|$ :)'-syntaks bare være underforstået, når det kommer til, hvad man betegner med en `verbal clause.' (19:42) .\,.\,Hm, eller hvad med at lave en Relation-type, hvor input kan være to forskellige ting (ligesom for min nuværende Predicate-type), og hvor Predicate så også.\,. Nej vent, den kan jeg beholde, som den er, men til gengæld kunne jeg måske prøve at lægge op til en konvention om aldrig at bruge beskrevne til andet end med det samme at fylde ind i.\,. Hm nej, det duer måske ikke.\,. .\,.\,Ah, jo! Man kunne måske sige, at nyoprettede.\,. Hm, måske ikke.\,. .\,.\,Hm, nu har jeg muligvis lyst til at gå tilbage til `isPredicate,' `isRelation,' `isCategory,' `isObject,' og `.definingLexicalItem=' som de eneste grundlæggende/``anonyme'' prædikater og den eneste grundlæggende/``anonyme'' relation hhv. (19:55) .\,.\,Ja, og så må brugerne altså bare indføre attributter via DecribedTerms, hvilket jo egentligt også er meget fornuftigt, for så kan attributterne forklares, plus man kan tilføje andre varianter og former (bl.a.\ ved at omformulerer dem til normale lexical items) af dem, enten med det samme eller efterfølgende. (19:59, 19.02.23)

(20:20) Ah nej, nu tror jeg, jeg ved (nogenlunde), hvad jeg gør i stedet. Jeg indfører følgende grundlæggende typer: Relation, Category og Object (udover Predicate, som jeg allerede har). Og ligesom at Predicate ``selv ved'' om dens ``undertype'' er en `relation med input,' `e omfortolket tekst' eller en `prædikat defineret af sig selv givet som et DecribedTerm' (hvor sidstnævnte nu bare skal erstattes med undertypen `beskrevet prædikat' og så skal DescribedTerm-typen slettes), uden at det ændrer databasetypen af Predicate-instansen, så skal tilsvarende altså bare gælde for de andre tre grund-(ikke-data-)typer (Relation, Category, Object). Jeg tænker så faktisk at indføre endnu en type kaldet LexicalItem, som altså er en.\,. nå nej, vent, dette behøves nok ikke. Nej, never mind; man inputter bare textstrenge i disse tilfælde, og så er omfortolkningen (altså ``derefereringen'') jo bare indforstået her. .\,.\,Ah, og hvis man nu alligevel skal bruge mindst to input-BIGINTs til alle disse fire typer, nemlig fordi beskrevne entiteter (som der nu er fire typer af, nemlig i form af én undertype til hver af de fire ikke-data-typer) jo alligevel skal have to lister, jamen så kunne man måske bare sige, at hvis nr.\ 2 input ikke er den tomme liste for en beskrevet undertype, så er nr.\ 2 input simpelthen bare en (valgfri) ``description''.\,.\,!\,:) .\,.\,Fedt!!\,:) .\,.\,Hov nej, ikke for en beskrevet undertype! (for der vil de to inputs jo være de to lister (med ``cpreds'' og ``srels'')) men i stedet altså for den.\,. ja, hvad skal vi egentligt kalde den?\,.\,. Hm, lad mig for nu kalde den for den `leksikalt beskrevne undertype,' men jeg ændrer nok disse kaldenavne. .\,.\,Hm, ja, nej, lad mig egentligt hellere bare kalde denne undertype (som der er fire udgaver af for hver ikke-data-type) for den `simple undertype,' simpelthen. (20:38)

(20.02.23, 14:17) Jeg har overvejet nogle ting i dag omkring kategorier (også i går aftes) og ``koncepter'' (bare i dag), og nu er jeg så lige kommet på en idé, der muligvis kan løse de ting, jeg gerne vil løse, på en elegant måde (set fra det grundlæggende (database-)lag). Idéen er at starte med at give de ikke-simple entiteter en liste af relationer efterfulgt af en liste af lister, hvor hver liste så i denne liste liste så skal inputtes som relationsobjekt i den relevante relation fra den første liste (og hvor den nyoprettede entitet så bliver relationssubjektet). Hm, og så kunne man i øvrigt stadigvæk dele det op vertikalt i kategoriserende felt-input og specificerende felt-input.\,. .\,.\,Nå nej, det behøver jeg nok ikke, når nu jeg forestiller mig, at brugerne skal gøre stort brug af kategorier (hvad de skal!\,.\,.), for så bør en specifik (under-)kategori gerne indeholde al den relevante information, som jeg før nu her ellers har tænkt mig, at ``cpreds''-listen skulle indeholde. .\,.\,Ah, men vil det så sige, at en kategori (Category) også gerne selv skal indeholde information om den ønskede srel-liste?\,.\,. 
\ldots Hm, det ville være ret smart, hvis man kunne gøre det sådan, men problemet bliver jo muligvis, at det så bliver svært at ændre dette.\,. .\,.\,Hm, medmindre man måske tilføjede en grundlæggende relation til kategorier a la ``.OptionalField:''.\,. .\,.\,Hm, men alternativt kunne man så i stedet have ``.Field:'' (hvor felt-relationerne så rates ud fra vigtighed), altså i stedet for at gøre dette til en indre, fast ting i hver kategori.\,. Hm, ja, mon ikke det bliver svaret, og så er det bare spørgsmålet, om man ikke så kan gøre de ikke-simple entiteters input mere simpelt.\,.\,? 

.\,.\,Lad os se, måske kan man så erstatte cpred-listen med kategorier.\,. tja, lad mig bare tage én ting ad gangen. Så de ikke-simple entiteter kan have en liste af kategorier for det første, hvor relationen ``belongs to''/``.Category:'' er underforstået.\,. Herefter skal der så komme en liste med.\,. hm, ja, det bliver jo så en liste af prædikater, men disse prædikater dannes så automatisk af applikationen (i ``applikationslaget'') ud fra brugerens input til diverse felter, hvilket så kan deles op i beskrivende felter og datafelter (og som hver især tildeles en `vigtighed' via brugerratings (som brugere giver i forbindelse med den relevante kategori)). Hvis entiteten tildeles mere end én kategori, så loades alle relevante felter bare fra alle kategorierne (og ordnes stadig efter `vigtighed,' men måske opdelt i grupper af kategori alligevel). Bemærk i øvrigt, at et ``felt'' defineres af en relation, så felter kan nemt gå igen på tværs af kategorier. Nå ja, og en stor pointe ved at bruge `kategorier' er, at de hver især kender deres egne overkategorier, og dermed kan (og skal!) de også loade alle felter fra overkategorien.\,. Hm, men måske skal man så også kunne fjerne felter fra en overkategori igen ved at nedstemme dem.\. nej.\,.\,! For ressourcer vist i en inderkategori skal også kunne vises i en overkategori, så alle felter fra en over-/forælder-kategori skal arves til underkategorierne!\,. Ok, så langt, så godt. Nu kommer jeg så til, hvad der ellers kunne være af nyttige relationer udover ``.Category:'', som man kunne benytte, når man opretter nye ikke-simple entiteter.\,. (15:18)

.\,.\,(15:22) Hm, jeg tror faktisk allerede, jeg har en rigtig god idé om, hvad den muligvis sidste relation kunne være udover ``.Category:''/``belongs to''. Og nu har jeg i øvrigt også lige fundet ud af, at jeg hellere bør kalde relationen for ``belongs to'' end ``.Category:,'' og det kommer jeg nemlig til om to sekunder. Jeg tror den muligvis sidste relation skal være ``is related to''. Og fælles for ``belongs to'' of ``is related to'' er, at de er beregnet til (i hvert fald som en af deres primære opgaver) at udgøre en barne-liste-/barne-kolonne-mulighed i relationsobjektet, som i disse to tilfælde enten er en kategori (som entiteten tilhører) eller en term --- og jeg tror nemlig, at jeg vil gå tilbage til at kalde det Terms --- (som entiteten er relateret til). Dette er så i modsætning til alle ``felterne,'' hvilke er beregnet til at angive ting, der er interessante at få vist, når man er på (har selekteret) entiteten. (Og for lige at præcisere, så er altså i modsætning til det andet, for ``belongs to'' og ``is related to'' handler nemlig om at føje ting til henholdsvis kategorien eller termen (nemlig under særlige underfaner, som henholdsvis kunne hedde `Subcategories' og .\,.\,`$<$type$>$s related to this $<$type of this entity$>$''), når brugeren har selekteret denne kategori/dette term.\,.).\,. Hov, der kunne nu måske godt være en ``is related to'' for hver ikke-data-type. Og måske skulle jeg så droppe den konvention, som jeg skulle til at foreslå, hvad angår ``.Category:'' vs.\ ``belongs to'', hvilket nemlig var at bruge førstnævnte syntaks udelukkende for felter, for det virker til at den også kan blive gavnlig for relationer. (For så kan man nemlig passende opdele ``is related to'' i: ``.RelatedTerm:'', ``.RelatedPredicate:''.\,. hm.\,.) 

Okay, virker umiddelbart som nogle gode standarder, men jeg tror lige, jeg må tænke lidt over de her ``Concepts'' (altså muligvis en `koncept'-type), som jeg har tænkt over i dag\ldots\ (15:45) .\,.\,Ah, men er hele pointen ikke bare, at man så nu bare kan indføre Koncepter, som en overkategori af Termer, og for nyoprettede prædikater og relationer, kan man så føje sådanne koncepter til som relationsobjekter i relationen, ``.RelatedTerm:'' (som så i virkeligheden næsten ligeså godt kunne hedde ``.RelatedConcept:'' i stedet.\,.).\,.(?) (15:51) .\,.\,Tjo, tja.\,. Hm, måske skulle man bare sige, at de to første inputs er en liste af kategorier og en liste med (specificerende) prædikater, men at vi derefter så har et tredje (optionelt) input .\,.(som muligvis kan deles op i to), som består af en liste af først en relationsliste (hvor man så kan have ``.Related[...]:''-agtige relationer), og derefter en liste af inputlister, hvor hver af disse input lister så gives til den relevante relation. Hm, det lyder umiddelbart lidt kompliceret, men det kunne måske give god mening sådan.\,. (15:56, 20.02.23) 

.\,.\,Og lige for at præcisere: Jo, så `koncepter' bliver bare en underkategori af Terms. Ah, jeg tror faktisk, at jeg virkeligt er nået til et fornuftigt punkt her.\,:) 

\ldots Ah, på når lige, at det måske ville give mere mening bare at implementere dette tredje input (inkl.\ funktionaliteten omkring det) udelukkende i applikationslaget.\,. (16:15) .\,.\,Hm, man kunne også gøre det, at man rigtig nok implementerer det i applikationslaget, men at man så bare også giver mulighed for, at brugeren kan vælge at inkludere de resulterende prædikater dannet ud fra dette ``tredje input'' i specifikationsprædikat-listen. Ja, ok, så fordi der jo er den mulighed, så er der ingen grund til ikke at gøre det sådan. Så lad os sige, at ``tredje input'' bliver implementeret i applikationslaget, og at ikke-simple entiteter så i databaselaget derfor bare kommer til at have to input-felter, nemlig en kategori-liste og en specifikationsprædikat-liste.\,:) (16:21, 20.02.23)

\ldots (17:01) Ah, nu ved jeg det. Endnu bedre: Der skal bare være ét felt for de undertyper, jeg førhen har kaldt DescribedEntities (og som jeg til tider i dag har kaldt de ikke-simple undertyper), nemlig et felt bestående rent af prædikater. Og så implementeres resten simpelthen i applikationslages. De første prædikater i denne liste vil så typisk bare være (et fåtal af (ofte bare én!)) ``belongs to $<$category$>$''-/``.Category:$<$category$>$''-prædikater. Og nu hvor jeg nemlig tænker, at underkategorier skal kende deres egne overkategorier, så er det nemlig ofte tilstrækkeligt kun at give én kategori. Og dermed behøver jeg altså ikke længere at tænke i at separere den ``kategoriserende del'' fra den ``specificerende del'' af inputtet, for den ``kategoriserende del'' vil nu typisk kunne klares med meget få (ofte bare ét) prædikater. Nice, nice.\,:) (17:09, 20.02.23)

(18:34) Okay, jeg tror så faktisk også, at jeg går tilbage til at gøre det utypet i det grundlæggende lag igen, når det kommer til ikke-data-entiteter --- og selv endda for prædi-kater (så jeg fjerne Predicates-typen igen) --- således at ikke-data-entiteter udelukkende gives typer på semantisk vis. Jeg tror så, jeg vil lave tre ikke-data-entitets-undertyper: Den ``simple'' som beskrives ud fra et `lexical item' og en `description' (valgfri), ``prædikat-beskrevne entiteter'' som altså beskrives ud fra én prædikatliste, og som den tredje undertype ``sammensatte entiteter,'' som jeg så egentligt kun har i sinde at bruge lige netop til at danne prædikater ud fra en eksisterende relation og et relationsobjekt. .\,.\,Hm, skal jeg så prøve at sørge for, at der kan blive en tabel eller et view med alle entiteter på én gang.\,. eller måske bare alle ikke-liste-entiteter.\,.\,? .\,.\,Hm, hvis vi tager alle ikke-liste-entiteterne, nemlig Users, Statements (ikke SemanticInputs), de tre typer ``ikke-data-(ikke-bruger-eller-udsagn)-entiteterne,'' samt resten af ikke-liste-datatyperne, så har de jo alle samme højst to inputs.\,. Og hvis tekst- og binær-typerne bare får en reference til en underlæggende datatype --- som man måske så ikke kan se i interfacet med applikationslaget (når man ser fra applikationslaget) --- så kunne dette altså nok godt lade sig gøre.\,. Hm.\,. (18:54) .\,.\,Hm, og hvis alle bare er i samme tabel, nemlig en tabel (altså en databaserelation) over alle entiteter (og lister og semantiske inputs regnes altså så ikke for entiteter .\,.\,hm, jeg kunne også kalde dem units i øvrigt.\,.), så sparer vi vist også noget plads, for så behøver hver entitet(/``enhed'') nemlig kun at holde én TINYINT, nemlig den der beskriver entitetens egen (entitets)type, i stedet for at skulle holde TINYINTs for alle input-tabelkolonner. Ja, jeg tror faktisk, at det bliver det her, jeg gør.\,. men jeg kan så lige se på, om SQL har en måde at forene søjler på (det har det sikkert), og i så fald kan jeg jo godt lave.\,. Hm, nej, jeg tænkte at lave alle tabellerne for sig også, og så oprette den samlede entitetstabel som et view, men så går det ikke, hvis hver underliggende tabel kan have kollisioner imellem ID'erne.\,. .\,.\,Lad mig lige skifte paragraf i øvrigt.\,. (19:04)

.\,.\,Hm, en mulig løsning, hvis man gerne vil have de separate tabeller kunne dog være, at sørger for, at alle entiteter af samme type har den samme unikke række af mest betydende bits.\,. Hm.\,. .\,.\,Hm, det ville måske gøre det bedre i forhold til, hvis man kommer i risiko for at mangle long-adresser, også muligvis hvad angår muligheden for opskalering, hvis man sørger for at dele typerne op, så lad mig lige tænke lidt over det.\,. .\,.\,Hm, atten milliarder milliarder.\,. .\,.\,Ja, så vi kommer ikke til at mangle long-addresser.\,. .\,.\,Okay, jamen så lad mig sige.\,. Tja, hm.\,. .\,.\,Jo. Jeg har lige tjekket, at man godt kan forene (med alias og union) tabeller i SQL, og ja, jeg har lyst til at beholde en tabel for hver entitetstype og så bare forene dem til én samlet i et (såkaldt) view. Og jeg vil så sørge for at deres ID'er ikke kolliderer simpelthen bare ved at starte fra hver deres mest betydende byte (gerne med så mange 0'er på de mindst betydende bits i denne byte som muligt, hvorfor ikke?\,.). Dermed kan ID'erne overføres direkte as is til det samlede view, og dermed for vi altså heller ikke behov for nogen TINYINT-typeflag overhovedet på denne måde. Fint (fedt)!\,.\,.\,:) (19:28)

(21:23) (Nu hvor det grundlæggende er utypet, så bliver Russull-paradokset vist heller ikke noget problem overhovedet, \emph{hvis} altså det overhovedet ville være det i den typede udgave, det er jeg ikke helt sikker på alligevel. Men det er også ligemeget.)

(21.02.23, 10:18) Ej, jeg fik så mange gode idéer i går aftes. Jeg vil lige skrive et par af dem her, og så vil jeg gå ned og skrive resten i forlængelse af den næste sektion. Lad mig nævne her, at lister, ligesom tekster, også bør være med som (førsteklassesborger-)entiteter. Dermed skal der også bare være én listetype, der så bare holder en længe og en underlæggende liste (som ikke er i en tabel som kan ses i interfacet med applikationen). Og så skal brugerne i stedet bare kunne bede serveren om at get'e alle eller en andel af alle elementerne i den liste (som så sendes til applikationen), og så kan applikationen videre finde d af, hvad dem vil med disse. 

Angående om brugere og semantiske inputs skal regnes for entiteter: Tja, måske ikke i starten (første version/betaversionen), men jeg bør alligevel sørge for at deres ID'er ikke kolliderer med resten, hvis nu de på et tidspunkt skal gøres til entiteter. Og hvis de på det tidspunkt holder for meget data i sig (i deres ``tabelrækker''), så kan man jo bare gøre noget tilsvarende, hvor man lader dem holde en reference til resten af deres data (enten i form af en reference til en privat tabel eller i form af en reference til en liste-entitet). 

Men en af de klart største idéer, jeg fik i går aftes, var omkring, at jeg skal væk fra det med at sende SQL-kommandoer fra applikation til serveren, for jeg skal i stedet implementere, hvad der svarer lidt til det QL, jeg havde tænkt på, men hvor queries'ne simpelthen specificeres i HTML-attributterne! Så skal applikationen læse disse attributter, som eksempelvis kunne være nogle a la: querySubjekt=$<$entity ID$>$, queryRelation=$<$entity ID$>$, queryObject="get", askUsers=$<$``user group'' arithmetric expression$>$, numberOfElementsToGet= $<$number$>$, maxDateForInput=$<$date$>$, filters=$<$list of references to filters to use --- possibly in the shape of HTML div IDs where filter data (predicate IDs and parameter values) --- can be found$>$, allowedHRefs=$<$list of references to allowed hrefs --- also possibly in the shape of div IDs$>$.\,. Applikation skal så læse alt dette, men \emph{ikke} sende det direkte til serveren! I stedet skal det bare sende mere simple quries, hvor de kun lige er de første tre attributes her i denne liste, der bliver brugt plus lige en enkelt bruger --- eller brugergruppe, hvis databasen er begyndt at indeholde sådanne (for det emne skal jeg nemlig også lige genoverveje). Applikationen sender så bare flere af disse queries af sted til serveren, hvor den måske bare spørger om 100 eller deromkring elementer ad gangen, hvad ved jeg (på stående fod)?\,. Og så sætter applikationen selv de lister, den får (med tilhørende ratings fra spurgte bruger/brugergruppe), sammen til den endelige liste, som så skal blive til den liste af entiteter, som brugeren skal se i sidste ende. Herefter kan den så begynde (via AJAX) at bede serveren om at få serveret indhold omkring disse entiteter, hvilket jo så typisk vil ske ved at query'e hver enkelt element i listen efter nogle relationsobjekter. Og dette kan så også forgå på sammen måde, for applikationen starter jo så bare med at generere den HTML, der skal være omkring indholdet i hvert element, og de forskellige divs i denne HTML kan jo så også bare få qeury-attributter sat, sådan at applikation efterfølgende kan læse disse (i rækkefølge én ad gangen i listen) og så (via AJAX) query'e serveren for indhold til hver enkelt indholds-div i dem.\,!\,:) 

Bemærk derfor, at brugere der ombygger applikationen for sig selv og andre brugere, de behøver derfor kun at dele HTML og CSS med hinanden. Jeg kan altså derfor udelukke al JavaScript (mener jeg), når det kommer til applikationsudvidelser delt mellem brugere internt igennem sem-netværket. :) 

Nå, jeg har nogle flere ting fra i går aftes, jeg gerne vil sige, men da de relaterer sig meget til applikationslaget specifikt, så lad mig gå ned i næste sektion (som i skrivende stund kun har to paragrafer) og skrive idéerne der. Og hvis jeg finder på flere ændringer til det grundlæggende lag, så vil jeg nok bare oprette en ny sektion at skrive det i den (for jeg kan mærke, at der er for mange afhængigheder i det på tværs af lagene, så jeg ender nok bare med at skrive alle nye idéer i kronologisk rækkefølge alligevel.\,.). Ok.\,:) (11:09, 21.02.23)

(13:21) Nå, nu kommer jeg alligevel tilbage til denne sektion og tilføjer følgende: Ved at sørge for at compound predicates får deres eget most significant byte i deres ID'er, så ved man altid, når man har et prædikat i hånden, om det er et (sammensat) relationsprædikat eller ej. Og derfor kan man godt omdanne SemanticInputs, hvis man vil, så at der igen bliver en prædikat--relationskolonne (hvor prædikaterne så \emph{ikke} må være sammensatte prædikater), og endnu en kolonne med eventuelt (nullable) input, hvis prædikat--relationsentiteten i førstnævnte kolonne er en relation. Og når en bruger vil rate et sammensat prædikat, jamen så gives der bare én rating, nemlig til det samentiske input med relationen i. .\,.\,Hm, og måske bliver det faktisk nemmere alt i alt at implementere gennemsnittet via en bot-bruger. Og så kan control serveren bare løbende bede databasen om at opdatere ratingværdien (samt dato) for dette semantiske input. .\,.\,Hm, og selvom dette egentligt hører til i næste sektion, hvis vi snakker om betaversionen, så lad mig da bare sige, at hver bruger bare har én rating pr.\ prædikat, og at man altså ikke gemmer gamle ratings. For jeg regner jo alligevel ikke med at implementere den der ``maxDateForInput=$<$date$>$''-mulighed i betaversionen. Og det forøger også kun anonymiteten, at gamle rating (og tidspunkter) ikke bliver gemt. Og ja, lad mig så nemlig også bare undlade at gemme datoer (eller dato-tider for den sags skyld) for semantiske inputs i betaversionen. (13:34)

.\,.\,Ah, og så skal nøglen til semantiske inputs faktisk bare være bruger, predikat/realtion og (nullable) relationsobjekt (altså alle sammen ID'er), for hermed bliver dette jo unikt for hvert semantisk input! (13:42) (Og hvis man bruge automatisk voksende tal som ID'er, så vil disse ID'er jo kunne afsløre tidspunket alligevel, hvis de alle sammen er synlige oppe i applikationslaget.) .\,.\,Og fordi jeg er ret overbevist om, at SemanticInputs aldrig skal være med som førsteklassesborger-entiteter --- om så de bliver synlige for applikationen eller ej --- så er der altså ikke nogen risiko ved at bryde mønstret med at bruge BIGINTs som ID'er. *(Hov, jeg skulle selvfølgelig have sagt `relations\emph{subjekt}' i stedet for `objekt,' det er klart. I øvrigt tænker jeg, at denne sammensatte nøgle så nok skal ordnes efter subjekt først, så bruger, og så relation/prædikat-entitet. (18:13)) 





\section{Mål for betaversionen}

(15:35, 16.02.23) Okay, helt kort vil jeg bare lige skrive lidt om, at jeg nu forestiller mig, at der i en undermenu af fold-ud(men muligvis konstant ude, hvis vinduet er stort nok)-menuen skal være følgende ``over-kategorier,'' som man kan trykke på og få vist en liste til højre for. Der skal være ``populære (så altså ordnet efter popularitet) term-kategorier,'' ``populære prædikat-kategorier,'' ``populære relations-kategorier'' og ``populære prædikater'' (ikke prædikat-kategorier men simpelthen bare prædikater straight up).\,. Det kan være, jeg finder på / kommer i tanke om flere.\,. I listevisningerne for alle disse skal der selvfølgelig altså være en popularitetsrating, så man kan up- eller down-rate entiteten på den pågældende liste. For alle kategorier skal der så også være en knap til at få en ny kolonne med underkategorier og en knap til at få en kolonne med entiteter inden for den kategori (som også bare ordnes efter popularitet --- eller faktisk rettere efter usefulness --- som en standard ting).\,. .\,.\,Hm, jeg vil stadigvæk have det sådan, at man også skal kunne klikke på en vilkårlig entitet og tilføje den til sit ``arbejdsbord.'' Og nu tænker jeg nemlig så (og dette er en af de ting, jeg specielt gerne ville nævne), at dette arbejdsbord simpelthen bare skal være en XML/HTML struktur, som brugeren er fri til at redigere (og hvor en ny redigering så kan flushes til den private database). Og i al sin enkelthed skal denne XML/HTML-struktur så bare indeholde en række variabel-definitioner, hvor brugeren giver variabelnavne til alverdens entitets-ID'er --- og hvor strukturen altså i første omgang ikke er betydende for andet end brugeren selv, idet denne så skal kunne implodere og eksplodere tags i editoren. Men strukturen må gerne følge en standard, der så gør at applikationen automatisk kan indsætte nye variabeldefinitioner i denne struktur (og på en passede plads), når brugeren klikker `gem til arbejdsbord' på en entitet vist i en liste. 

.\,.\,Hm ja, og lad mig ikke sige så meget mere i denne omgang, for nu fik jeg nævnt alle de ting, jeg gerne ville skrive om. Når jeg så bygger på min prototype, så kan jeg tilføje flere ting omkring, hvad jeg gerne vil sigte mod i starten. (15:56)


(11:47, 21.02.23) Okay, det kan være, at jeg egentligt fik sagt det meste (og det vigtigste) ovenfor i forrige sektion. Jeg har også en lille idé om, at ``fold-ud-menuen fra venstre'' måske bare skal være en kolonne-/søjletype i stedet i applikationen, som altså så kan foldes ud fra alle andre søjler. For så kan man også nemt folde denne søjle ud i overlayet, når man besøger andre hjemmesider (med visse genkendelige URL'er). Det overlay forestiller jeg mig jo skal kunne foldes ud fra højre i form af en søjle, og hvis brugeren så bare kan folde, hvad jeg før så som ``fold-ud-menuen,'' ud til venstre for denne søjle, så kunne overlayet jo komme rigtig godt og nemt fra start herved. Og så kan man jo også bare folde andre søjletyper ud ad libitum fra den indledende søjle i overlayet. .\,.\,Ah, og hvis man så designer enkeltressource-søjlen, så den selv kan genkende, om den.\,. Tja, ellers hvis bare man laver en speciel søjle til overlayet (som jo selvfølelig skal kende URL'en for hjemmesiden), .\,. Ja.\,. Jeg har faktisk ikke mere at sige om det, for ja, man laver bare overlayet som en speciel søjletype til formålet, som så kender til den nuværende URL, og som så bare er specielt beregnet til at fungere på andre hjemmesider.\,. Ah, men vent. En første udgave af overlayet kunne jo bare være at bruge den normale enkeltressource-søjle! Dette er ikke den optimale løsning, men så er man til gengæld nemt fra start, og brugerne vil så derfra have incitamentet til selv at lave/forbedre den indledende overlay-søjle. Fedt nok, og hermed vil jeg altså nok bare nøjes med at bruge den normale enkeltentitetssøjle, som benyttes på hjemmesiden, som den indledende søjle i overlayet. :) .\,.\,Hov nej, man vil jo sikkert også gerne have en ratingsøjle, der tager udgangspunkt i en specifik ressource (og hvor titlen for entiteten så kan vises i toppen af søjlen). Så det er selvfølgelig bare \emph{den} søjletype, som jeg skal gøre til den indledende søjle i overlayet. Og så kan brugerne så også trykke sig fra den søjle og hen til den normale enkeltentitetssøjle, hvis de vil det, så ja, dette vil være et rigtigt godt udgangspunkt i overlayet. (12:05)

.\,.\,Lad mig lige prøve at finde frem til noget omkring optimering af database-queries.\,. 
\ldots Hm, har lige læst en smule om clustered indexes, og vil også læse lidt mere, men jeg tror allerede jeg kan svare på noget, som jeg også tænkte på i går aftes, nemlig om ikke bare jeg skulle nøjes med altid at lave relationsobjektet være det, som skal get'es i en query i betaversionen (altså sådan at queryObject="get" altid er underforstået). Det vil nok sige, og så bliver det bare applikationens opgave at sørge for, at ``belongs to''- og ``is related to''-relationerne altid uploades både forlæns og.\,. Hm, men hvad så med ratings?\,. hvad med om man i stedet lavede en slags ``virtuel \ldots''.\,. tja, eller også kunne det også bare være applikations opgave også at sørge for, at ratings af prædikater med de relationer i sig altid bliver givet identisk to steder.\,. Hm, det må jeg jo lige tænke over. Men lad mig lige læse videre.\,. (12:39)

\ldots\ (17:56) Okay, jeg har læst lidt, og blevet en smule klogere. Det korte af det lange er bare, at jeg på et tidspunkt nok skal oprette en partitioning af SemanticInput-indexet --- med flere partitions særligt for DescribedEntities.\,. Hm, måske kan jeg endda faktisk lave det specifikt for Term-entities, selvom jeg nu ikke længere har denne type forskel, for selvom alle entiteter (altså hvad jeg lidt ser som ``semantiske entiteter'') har den samme type i princippet, så kan jeg jo godt give dem forskellige mest betydende bytes, således at man i praksis kommer til at kunne kende forskel på deres under typer (og f.eks.\ i forbindelse med en partitionisering).\,. .\,.\,Men ja, og det er rigtig godt (og fornuftigt), at jeg nu gør databaseimplementationen skjult i (interfacet med) applikationslaget (for jeg har nemlig også i sinde at insert også bare skal beskrives i et JSON-format, eller noget i den stil). For det gør, at jeg også har mulighed for selv at eksperimentere med andre databasetyper, hvis jeg nu f.eks.\ finder ud af, at hierarkiske databaser i virkeligheden er bedre egnet til formålet (hvad måske ikke lyder helt tosset.\,.). 

.\,.\,Nå, men noget andet jeg lige skal overveje, som jeg kom i tanke om, imens jeg skrev forrige paragraf her, er at jeg lige skal genoverveje.\,. Hov nej, never mind.\,. Ja, eller ikke never mind, for måske har jeg en tilføjelse, men det kan være, at det bliver en lille en.\,. (18:08) .\,.\,Okay, jeg har lige lavet en tilføjelse til forrige sektion. (18:13) Og tanken om at ordne den sammensatte nøgle efter subjekt først, så bruger, og så relation/prædikat-entitet, er en jeg fik tidligere i dag i øvrigt. Og som jeg forestiller mig applikationen nu, så tror jeg virkeligt langt de fleste queries kommer til at tage udgangspunkt i ét subjekt ad gangen, hvortil man så for et fåtal af forskellige brugere/bots spørger efter nogle prædikater og relationer (og muligvis nogle forskellige for hver bruger), og hvor man så for hver prædikat bare henter en rating og for hver relation henter én eller flere af de elementer, der er rates højest af pågældende bruger/bot. Så dermed tror jeg altså, at langt de fleste queries fra brugerne i almindelighed vil blive super effektive at eksekvere (hvis vi altså ordner indexet på lige præcis denne måde)!\,:) (18:21)

.\,.\,Nå ja, og så skal det endda siges, at jeg i første version af sem-netværket/hjemmesiden nok bare vil (starte med at) have det sådan, at brugerne altid bare ``spørger'' avg-botten om gennemsnittet og antallet af ratings. Og så kan jeg altid udvide derfra. (For eksempel kunne en af de første tilføjelser være at brugerne også kan query'e deres egne ratings, hvilket man så kan forestille sig typisk vil blive brugt således at brugerens egen rating trumfer avg-bot-ratingen.) :) (18:25) 

\ldots Hov, det kan forresten også godt være, at det kan give mening ikke at have rela-tion/prædikat-entiteten med i det her composite clustered index, hvis man altså overhovedet kan vælge det, når nu denne tabelkolonne \emph{er} med i den primære nøgle.\,. Hm.\,. 

\ldots Ah, nu kom jeg lige på, gad vide om ikke, der kunne være en måde at sørger for, at hver subjekt--bruger--prædilation( fik jeg lige lyst til at kalde det)-række får én reference.\,. Tja eller rettere: Hver subjekt--bruger--prædikat-række får en rating værdi som den eneste ikke-nøgle-kolonne, og hver subjekt--bruger--relations-række for så i stedet.\,. hm, hvad med at de får, et fåtal, måske bare én eller to, entitets-ID'er, som så skal være det/dem, brugeren har ratet højest for pågældende relation, og derefter kan i sidste ende så være en liste med andre entitet--rating-par (ja, for man skal forresten også have ratingen in-line/on-page i rækken for hver relationsobjekt man har in-line/on-page i rækken.\,.).\,. (19:02) .\,.\,Ah, eller man kunne også slutte med to ting: først en VARBINARY, som inkluderer et antal entitets-ID--ratingværdi-talpar mellem 0 og et lille tal såsom.\,. hov, nej, det skal måske ikke være et lille tal.\,. Men ja, dette kunne man gøre, og så eventuelt slutte af med en nullable BLOB eller større VARBINARY, som man så ved bliver gemt off-page fra tabellen.\,. Hm, nu kommer så et oplagt spørgsmål i forlængelse af dette, for det kunne jo så også være, at man i stedet skal dele SemanticInputs op i tre tabeller, nemlig én med prædikater og.\,. Tja.\,. .\,.\,Hm, tanken var at dele det op i.\,. Ah, jo! Og så kunne man lave et samlet indexed view over alle tre tabeller!! (19:13) .\,.\,Tja, og dog; det gør det vel egenligt ikke meget anderledes fra, end hvis man laver én indexed tabel.\,. Hm, men jeg hælder nu altså meget til det der med den der VARBINAY til, hvad vi kunne kalde `.:'-relationerne (altså de relation, hvor man forventer meget.\,.).\,. Ah, men vent, bliver det ikke nærmest kun den omvendte ``belongs to''-relation, og den/de omvendte ``is related to''-relationer, der kommer til at få mange relationsobjekter pr.\ bruger/bot, som jeg tænker mig at betaversionen skal fungere.\,.\,? .\,.\,Hm, jo, men det ændrer faktisk muligvis ikke på, at det med den der nullable VARBINARY som en kollone i SemanticInputs måske kunne være ret effektiv. .\,.\,Hm, tjo ja, men måske skal man bare have to tabeller (dog ikke tre). For hvis man putter `.:'-relationerne, altså nærmere bestemt dem med mange relationsobjekter pr.\ bruger/bot, i sin egen tabel, så kan man tilgå denne, når man skal navigere videre fra den entitet/ressource, man har selekteret, hvor prædikat-og-`.='-relationerne -- og også relationer, hvor man bare forventer et fåtal af relationsobjekter pr.\ bruger.\,. måske.\,. --- så meget mere bruges i sammenhæng med, at entiteten/ressourcen enten skal placeres et sted på en entitets/ressource-liste (i en applikationssøjle), og at datafelter specifikt relateret til ressourcen skal hentes/get'es lige efter, at entiteten er blevet placeret.\,. Hm, men hvis jeg regner med, at disse to ting skal foregå i to separeret i tid efter hinanden, jamen så \emph{er} det måske en helt fin idé at dele det op i tre databasetabeller.\,.\,:) (19:31) Hm, lad mig lige tænke over det hele.\,. 

.\,.\,Hm tja, men hvem siger, at man ikke kunne have lyst til at prefetche felt-dataen, det lyder da som en meget fornuftig idé egentligt. Eller rettere, man prefetcher jo nemlig bare long-/BIGINT-adresserne på dataen, så ja, hvorfor ikke prefetche dette som standard?\,. Og så kan det jo godt være, at nogen af entiteterne bliver filtreret fra alligevel i listen, men derfor kan det jo stadig være smart, at sende den data med dem alligevel (da det jo bare drejer sig om et fåtal longs for hver ressource). Hm, jamen så kunne man måske passende dele SemanticInputs op i maximum to tabeller, sådan at prædikater og datafelt-relationer er i den samme tabel. (19:38) .\,. .\,.\,Hm, og da jeg ikke kan tro, at det vil give meget mening at prefetche elementer fra f.eks.\ underkategorier, kategorielementer eller relaterede entiteter, så vil det nu alligevel give fin mening at separere mange-objekt-relationerne over i sin egen tabel. .\,.\,Hm, men man kan nu stadig godt lave et view over alle tre tabeller, og dette kan jo så være det view, som brugerne ser (oppe fra applikationslaget af). 

.\,.\,Og ja, lige for at gentage, så er det gode jo, at applikationslaget alligevel ikke kan se, hvordan.\,. Hm, tja, medmindre at applikationslaget dog lige skal vide.\,. ja.\,. Det kan være at queries så også lige skal holde information om, hvordan man gerne vil prefetche data til ressourcerne, når man spørger efter en liste af ressourcer. Men det kan jeg jo bare sige, at sådan skal det være; brugerne skal også definere, hvordan ``felt-dataen'' hentes for hver ressource, i samme qeury som også beder om listen. .\,.\,Hov vent, men prefetching giver jo kun virkelig mening, hvis man spørger den samme bruger/bot om datafelterne, som man også spørger om listen.\,. Hm, og det kan jeg jo ikke regne med, i hvert fald ikke, hvis jeg gerne vil have det sådan.\,. ja, nej, det giver ikke mening. Det giver kun rigtigt mening at adskille det hele i tre omgange af queries (hvor den indledende query også deles op efter bruger.\,.).\,. Hov, måske er jeg faktisk helt på vildspor her. Lad mig summe over det hele, og så vende tilbage, når jeg har noget fornuftigt at sige.\,. .\,.\,Hm, men jeg kan lige sige: Det giver rigtignok slet ikke mening at tænke i at prefetche lange lister. Og dermed kan vi altså roligt sætte mange-objekt-relationer over i deres egen tabel, hvis det er.\,. .\,.\,Hm, og prædikater og få-objekt-relationer må meget gerne være i samme tabel, så så langt, så godt.\,. (20:00) 

.\,.\,Hm, og man vil nok i øvrigt også gerne have opdelte bots, så de hver varetager noget meget specifikt, og derfor vil man sikkert typisk gerne bede om alle de relationer fra en bot, som den har ratet, når først man har valgt overhovedet at bruge den.\,. 

.\,.\,Ah, okay, man skal regne med at prefetche feltdata-entitets-ID'er for alle ressourcer i sammen omgang som, at man henter prædikat-ratingværdier om ressourcerne, og dette gælder så uanset om man henter feltdata og diverse prædikater fra samme bruger, eller om man måske både henter forskelligt feltdata fra forskellige brugere(/botter) og også henter forskellige prædikat-ratinger fra forskellige bruger. Man prefetcher altså bare så meget som muligt her (men dog ikke mange-objekt-relations-data), når først man henter prædikat-data fra entiteten alligevel. .\,.\,Tja, eller måske skal brugerne i applikationslaget også kunne vælge at slå denne feltdata-prefetching fra i visse tilfælde, hvis man regner med at skulle vægte virkeligt mange ressourcer og skære dem ned til ganske få (og derfor gerne vil have hver hentning af prædikat-data til den enkelte ressource til at gå så hurtigt som overhovedet muligt). Men ja, ellers er en god sigtesnor altså, at felt-data gerne skal prefethes sammen med prædikat-dataen, når applikationen er i færd med at danne en ny liste ud fra en brugerdefineret ordning--filtrering. Og det er meget rart for mig at kunne have dette i baghovedet.\,. (20:23)

\ldots (20:37) Ah, og forresten, nu hvor jeg regner med at fylde mange-objekt-relationerne over i sin egen tabel, så giver det ikke mening det med VARBINARY'en. Jeg kan i stedet bare have én tabelrække pr.\ objekt, hvilket er meget dejligt at tænke på. 

(22.02.23, 10:18) Som jeg også tænkte på i går aftes: jeg føler ikke, at der er nogen grund nu til at putte mange-objekt-relationerne over i sin egen tabel, så. Måske især ikke.\,. ah, især ikke fordi man jo.\,. nej.\,. .\,.\,Nå, det kan man tænke over på sigt, hvordan man eventuelt kan dele det op igen for at styrke performancen, men i starten kan jeg bare have det hele i samme tabel. .\,.\,Ah, men jeg kunne måske i det mindste sørge for at give de grundlæggende mange-objekt-relationer, som jeg regner med, skal bruges meget, nogle særlige leading bytes, hvorfor ikke?\,.\,:) 

(11:51) Hm, måske giver det faktisk en smule bedre mening at have brugeren først i SemanticInput-nøglen.\,. Jeg er i øvrigt begyndt at kalde SemanticInputs for Statements bare, selvom det første er en smule mere korrekt. Men nu hvor jeg ikke har en Statement-tabel, så synes jeg alligevel det giver mening at omdøbe SemanticInputs til Statements. Og så er det bare underforstået.\,. Tja, måske ændrer jeg det faktisk tilbage, men lad mig nu se.\,.

.\,.\,Ah nej, det giver rigtignok mest mening at have subjektet først i nøglen, og især hvis man måske sørger for løbende at vedligeholde indexet, så ordnen af bruger--bots'ne forøges at holdes således, at bots der oftes bruges sidder tæt sammen i ordnen, og især hvis deres brug også er korreleret.\,:) (11:59)

.\,.\,Hm, jeg tror jeg vil kalde det for StatementInputs for nu.\,:) (12:01)

(15:46) Hm, jeg kan ikke have object=NULL i StatementInputs, hvis object skal være en del af nøglen. Nu har jeg så lavet det om så 0 er reserveret som ID til at signalerer, hvad der svarer lidt til NULL. Men problemet er så lige, at jeg ikke sparer den plads. Og nu kom jeg så til at tænke på, at det næsten er en smule synd at bruge SQL, når nu jeg bruger så mange konstante felter/kolonner så langt hen ad vejen.\,. Hm.\,. .\,.\,Hm, ja, jeg må jo lige læse om andre databaser også. .\,.\,Men lad mig nu bare lige færdiggøre SQL-implementationen først, og så også bare bruge den i starten, indtil jeg får taget mig sammen til at prøve at implementere den semantiske database i en anden type (underliggende) database.

(16:32) Ah, jeg er lige kommet i tanke om, at mit system med at bruge den mest betydende byte ikke duer, når vi skal til at inkludere data-termer såsom datetimes og longs. Så nu vil jeg i stedet lave et konstant type-flag i hver tabel, som teknisk set bliver en del af term-ID'et, hvis jeg kan.\,. \ldots\ Ja, for jeg venter bare med at indføre typeflagene til Term-viewet, hvor de så bliver virtuelle kolonner. (18:02) .\,.\,Og det bliver i øvrigt et ikke-indexed view, så formålet er med andre ord altså bare at bruge dette view i compiletime.\,. .\,.\,Hm, hvorfor jeg jo egentligt ikke behøver at lave unions på kolonnerne.\,.\,:) (18:06)

\ldots Hm, nu overvejer jeg at droppe at have dataentiteter som førsteklassesborger-termer, og så samtidigt bare sige, at det kun er object i StatementInputs, der behøver et type-flag (og dermed altså gøre, at dataentiteter kun kan indgå som relationsobjekter i udsagn).\,. (18:36)  .\,.\,Tja nej, jeg tror bare, jeg beholder det sådan her for nu (hvor alle termer bare har et typeflag, og hvor datatermer er ``førsteklassesborgere'').\,. (18:46)

\ldots\ Hm, det giver egentligt ikke rigtigt mening det jeg har gjort med at kræve at den første byte er 0x00 for ikke-data-typer, så det fjerner sikkert igen (må jeg lige gøre i morgen). Og så kan jeg lige se på, om ikke jeg også skal putte AUTO\_INCREMENT tilbage på ID'erne, det ville jo nok ikke være helt dumt.\,. (23:06)

(23.02.23) Hm, jeg kunne nok spare en masse listebygningsværk, hvis jeg i stedet for beskrivende/specificerende felter i Termerne bare har en forfatter-siger-bot.\,. Og jeg regner alligevel med at have den bot, så hvorfor ikke.\,.\,? (10:09)

\ldots Hm, så skal jeg så til at lave nogle relationer for hvert af de grundlæggende felter, men der kan jeg jo også bare bruge mine `has lex item'- og `has desciption'-relationer. Desuden vil jeg nok tilføje en relation a la  `has abbreviated lex item' som en af de grundlæggende, så der bliver tre.\,. (10:24) .\,.\,Og jeg regner forresten stadig med at beholde type-flaget, og så kan jeg dermed også overveje, om jeg gider at slæbe rundt med en masse `.Type='-relationer også, eller om det bare skal være underforstået.\,. Tja, jeg kunne vel godt have dem med, men.\,. Tja, og dog.\,. 

(10:42) Jeg overvejer at lave ratingværdien om til en var-binær i stedet.\,. \ldots (10:53) Ja, lad det være sådan. Men det skal så stadig være sådan, at hvis man højre-shifter den ned til en int (eller en long), så skal man stadig aflæse midtpunkts-/gennemsnitsværdien, i hvert fald hvad brugernes ratings angår. 

Hm, jeg tror faktisk jeg vil beholde en SimpleTerms-tabel, men så omdøbe den til FundamentalTerms.\,. *(Har nu døbt den tilbage.\,. *Hm, men jeg skifter nu nok tilbage igen.\,.) .\,.\,Hm, jeg overvejede lige kort at skifte tilbage til at kalde det Entities, men man skal faktisk i stedet bare se prædikater og relationer mere som henholdsvis mængde og mængdelære-relationer, hvis man ser på det matematisk *(/formel-logisk). Og så er det først i udsagn-inputsne.\,. som jeg næsten kunne omdøbe tilbage til `semantiske inputs'.\,. at prædikat-mængderne og relations-mængderne bliver vakt til live og bliver fortolket som faktisk prædikater og relationer. .\,.\,Nå, men pointen omkring at have en FundamentalTerms-tabel er så, at denne så kan være ret kort, og at brugerne fra applikationslaget så bare kan hente den hele på én gang, nemlig på en måde, der adskiller sig fra, hvordan brugerne henter ting på normal vis (nemlig via opslag i SemanticInputs-tabellen). 

.\,.\,(11:28) Ah, på den anden side, hvad angår Term vs.\ Entities, så får vi jo nu et ret begrænset antal typer, så.\,. Hov nej, never mind! For prædikater og relationer får jo ikke sin egen type alligevel, så nu handler typerne egentligt bare om at skelne.\,. Nå ja, vent, typerne bliver helt de samme, som de lige var; jeg ændrer ikke i dem.\,. Spørgsmålet er, om jeg skulle blande ``simple'' og ``standard'' terms sammen til én type, men det tror jeg faktisk heller ikke alligevel. 

\ldots\ Hm, angående ratingværdien: det kunne også være, at man skulle dele det op i først en int (eller long), der beskriver ratingen, og så have var-binær-strengen bagefter.\,. (16:05) .\,.\,Ja, lad mig helt klart sige det.\,. 

\ldots Hm, jeg bør måske også beholde RelationalPredicates-tabellen også.\,. (16:27)

%Jeg skrev på et tidspunkt "id <= 0x0011111111111111," men det skulle jo self. have været "id <= 0x00FFF..." i stedet.

(24.02.23, 10:09) Jeg vil faktisk gå tilbage til kun at have en BIGINT som id til hver entitet, og så vil jeg lade serveren og databasen om.\,. Hm vent, eller skulle jeg ikke bare sætte start-værdien til noget forskelligt for.\,. tja, men hvem siger, at jeg får tabeller for hver type.\,. .\,.\,Hm, lad mig egentligt også lige læse lidt mere om indexes.\,. \ldots Ah, ``B-træer,'' og hvor man giver plads imellem inserts på pages'ne, indtil der er fyldt op: Lyder ret nice.\,. (10:22)


(15:52, 25.02.23) Hm, jeg kan forsten lige nævne, at jeg nu tænker at inkludere en `created\_at'/`updated\_at'-dato i SemanticInputs, som så altså bare \emph{ikke} inkluderer tiden (men kun datoen). Og nu kom jeg så lige til at tænke på, at man eventuelt kunne gøre denne dato til den sidste del af nøglen (den primære), for på den måde kunne man jo netop åbne op for, at brugere og bots kan få deres gamle ratings gemt (hvilket nemlig kan være gavnligt, hvis nu man eksempelvis mister tillid til en brugergruppe, men gerne stadig vil benytte dens gamle vurderinger). 

(18:32) Jeg tror heller, jeg vil lægge op til en ``.$<$abbr lex item$>$:''-syntaks i stedet for ``.$<$abbr lex item$>$='', for jeg regner lidt med, at MySQL FULLTEXT search også ser `:' som et whitespace, ligesom den vist gør for `.'. 
.\,.\,Tja, på den anden side, så kan man jo også søge på starten af ord, så måske er det faktisk ligefrem at foretrække at bruge `=', hvis den ser `=' som en del af ordet. Ja, så lad mig da bare skifte tilbage til `=', for det kan vel i så fald ikke skade.\,. (18:39)

(19:22) Hvis en bruger føjer noget til en kategori (i.e.\ rater noget med den som subjekt), som brugeren ikke selv har ratet som en underkategori af nogen kategori, så bør applikationen helt klart spørge brugeren, om ikke de vil rate kategorien som en underkategori af noget (sådan at brugeren kan få gavn af kategori-systemet, bl.a.\ til at få vist forslag til prædikater fra forælderkategorierne og mere).\,:) 

(19:48) Tror i øvrigt bare, jeg bruger local storage til ``arbejdsbordet.'' 

(20:03) Man kan selv definere sine egne full-text stopwords, så det er jo dejligt. Jeg tror i øvrigt muligvis jeg vil gå væk fra at udskifte `has' med `.'.\,. Det overvejer jeg i hvert fald.\,. Og så tænker jeg nemlig også at indlede lex items med en parentes med subjekt-typen i (for relationer og for prædikater), og ende dem med en parentes med objekt-typen, hvis vi snakker en relation.

(20:15) Jeg tænker forresten bare, at der skal være en separat søge-søjle (i applikationen). Og når man så vælger en term fra søgningen, så tilføjer man jo bare denne til arbejdsbordet. .\,.,Alle lister, der figurerer rundtomkring i diverse søjler (.\,.\,ja, bortset fra f.eks.\ søge-søjlens søgeresultats-liste.\,.), skal så have en `tilføj term' knap, hvor man kan tilføje en term fra sit arbejdsbord.

Brugere skal også kunne gemme nye inserts/uploads, de arbejder på (bare i local storage). Dette kan bl.a.\ bruges til, hvis de lige vil bruge noget tid på at finde flere termer, som den nye term skal relateres til. (20:31) I øvrigt kan det også være, at de skal kunne åbne en allerede uploadet term igen for så at lave ændringer og nye tilføjelser i den (i hvert fald på sigt.\,.). 

(20:43) Hm, jeg tror så, jeg vil droppe ``full lexical item,'' og så bliver ``abbreviated lexical item'' jo bare konsekvent til ``lexical item.'' 

(21:58) Hm, det kan være, at jeg også skal lave en `prædikater relevant for denne kategori er også relevant for:'-relation, hvor det så er denne, der gør at kategorier kan arve prædikatforslag fra andre kategorier, og hvor denne relation så pr.\ standard opvurderes, når brugeren opvurderer `.subcategory='-relationen (men hvor denne anden relation så gerne skal vises under, så brugeren slev kan indstille vurderingen væk fra standard-opvurderings-værdien (som måske i øvrigt bare er at give relationen selvsamme rating, som `.subcategory='-relationen fik.\,.)).\,. 

(22:42) Der kan også være et (mere konstant) ``arbejdsbord'' vandret i toppen med brugere/bots/brugergrupper (som (sidstnævnte) altså også er implementeret via bots), hvor brugeren kan skifte mellem, hvilken bruger/bot bliver spurgt i alle efterfølgende queries (indtil brugeren skifter igen). I øvrigt tænkte jeg også lige på, at man måske kunne lave et særligt `(brugerkategori) bør få oprettet en brugergruppe-bot til sig''-prædikat, hvor serveren så kan sætte (og løbende justere) en tærskel for, hvor mange brugere skal have opratet dette prædikat, før at den så opretter en brugergruppe-bot til at kopiere alle brugerne i denne brugerkategori (vægtet over en vis tærskel --- og af en given brugergruppe, som skal specificeres i prædikatet.\,. (så prædikater bliver altså herved teknisk set en relation.\,.)), selvfølgelig ved at den først tager et vægtet gennemsnit for brugergruppen (vægtet ud fra en forudbestemt vægt, som altså også indgår i prædikatet) og så giver stemmer til alle relevante.\,. hm, og domænet for brugergruppen kan også være specificeret på forhånd, måske.\,. alle relevante termer indenfor et vist domæne (muligvis) i form af dette gennemsnit --- og hvor opt\_data så kan indeholde antal stemmer i alt.\,. Det var lidt rodet, og jeg må overveje emnet mere i morgen, men ja, rart lige at få det nævnt.\,. (22:53)

(26.02.23, 9:03) Jeg kom i tanke om, at man jo kunne implementere mine ``simple brugergrupper,'' som jeg vit før har kaldt dem, simpelthen ved at pege på en kategori, eller rettere et prædikat (som ikke nødvendigvis behøver at være dannet af ``tilhører kategori $x$''), og en tidligere brugergruppe til et bestemt tidspunkt. Dette giver så i første omgang en ny brugermængde med en særlig vægtning, altså en brugergruppe. Men man kan så videre gøre denne brugergruppe mere dynamisk ved faktisk at definere brugergruppen, som de brugere medlemmerne af denne proto-brugergruppe stemmer ind i den endelige brugergruppe. Alle medlemmer af protobrugergruppen kan så fra start automatisk have ratet som selv op (med et prædikat, der siger: ``tilhører den endelige brugergruppe''). Men hvis de så begynder at give andre brugere positive ratings derfra, jamen så gør en del af deres andel i den endelige brugergruppe nu til de brugere, de har opratet (selvfølgelig vægtet ift., hvor højt de har ratet sig selv (som typisk vil være den maksimale rating, 1), og hvor de samlede vægte som en bruger deler ud af altid automatisk normeres så de tilsammen summer op til, hvad den givne brugers egen vægtning var i protobrugergruppen). (9:14)

Nu overvejer jeg så også lige, om ikke jeg skal sætte ``rat\_val'' (rating value) ned til bare en char som standard.\,.\,? .\,.\,Og her er disse simple brugergrupper jo så et godt eksempel på, at man dog også har brug for muligheden til at kunne bruge flere bytes til at kommunikere sin data (altså f.eks.\ når man vil uddele af sin brugergruppevægt til andre brugere).\,. .\,.\,Jo, fint, det gør jeg, for jeg behøver jo forresten ikke at finde på standarder til, hvordan man kan bruge denne (``optional data''-)varbinary. For den kommer nok ikke rigtigt til at blive brugt før.\,. Nå nej, avg-botten skal jo også bruge den.\,. .\,.\,Ah, men så kan den indledende standard (hvor man nok gerne vil gøre efterfølgende standarder bagudkompatible med denne) bare være, at hvis der kun er én byte i var-binær-strengen, jamen så bør den simpelthen bare tolkes som nr.\ 2 byte i en SMALLINT-rating (sådan at der altså kommer flere (binære) decimaler imellem -1 og 1). (9:22) 

(26.02.23, 21:55) I ``start-indstillingerne''/filter-indstillingerne skal brugerne bare vælge både et prædikat og en (bruger/bot/)brugergruppe sammen som et par for hver vægtning/filter. 

(27.02.23, 15:31) Hm, det er godt nok ikke så effektivt (pladsmæssigt), hvis jeg saniterer tekstinputtet, før det kommer ind i databasen i stedet for efter.\,. .\,.\,Hm, og på en måde er det ene vel lige så sikkert, som det andet, for jeg skal alligevel bare implementere saniteringen i ét lag (medmindre jeg vil verificere i et andet, men det tror jeg ikke), og i så fald handler det jo bare om, at man sikrer sig, at man gør det (korrekt) over det hele i det lag.\,. .\,.\,Så ja, lad mig sanitere under udtrækningen fra databasen.\,. .\,.\,Hm, men er det så control-laget, eller.\,. Ja, det må vel være i control-laget, for dette skal jo gerne sende læseklare HTML-elementer til browseren.\,. 
.\,.\,Ja, ok. Jeg tror på, at dette er en fornuftig nok måde at gøre det på.\,.  

(18:18) Hm, mon der findes en god måde at undgå forfatter-/skaber-botten på, hvor det så i stedet kommer an på.\,. Hm, brugeren første upvote?\,.\,. Hm, måske skal jeg bruge forfatter-botten alligevel.\,. 

.\,.\,Hm, men så kræver det jo, at jeg også har en basal relation, der siger noget i retning af: ``denne bruger valgte dette prædikat om dette subjekt,'' og så skal man jo til at bruge lister med det system, jeg har (og det vil jo ikke være super fedt, vel?\,.).\,. (18:22) .\,.\,Hov, nå nej, det er jo bare at lade forfatter-botten kopiere de første bruger-inputs, hvad snakker jeg om.\,. (18:24) Ja, så det er vel stadig det jeg gør.\,. .\,.\,Lad mig forresten kalde den ``creation bot'' i stedet.\,. (18:28)

(28.02.23, 11:32) Ah, jeg skal jo selvfølgelig også have en tabel over RelationalPredicates (alligevel).\,.

(11:46) Ah, jeg kom lige til at tænke lidt igen på mine ``simple brugergrupper.'' For det første, skal brugergrupperne jo gerne være en slags bots --- måske gerne af sin egen undertype --- og så skal skaberbrugerne til brugergruppen (altså dem fra hvad jeg kaldte ``protobrugergruppen'' i forgårs) jo bare rate en relation som siger: `(bruger) hører til (brugergruppe)'.  Så nu tænker jeg altså, at hver ny brugergruppe, som måske altså har en særlig undertype af botsne, så skal defineres ud fra en tidligere brugergruppe samt en slutdato --- som dog kan sættes med tilbagevirkende kraft, så det altså ikke er en deadline, men en dato, der altid bliver sat på en dato, der ligger senere end den. Når slutdatoen så er sat, så dannes en ny --- konstant! (og måske skulle jeg dele det op i konstante og dynamiske brugergrupper, come to think of it.\,.) --- brugergruppe ud fra skaberbrugergruppen med dens eksisterende vægtning og altså ud fra, hvordan disse brugere har up-ratet `(bruger) hører til (brugergruppe)'+`ny brugergruppe'-prædikatet for andre brugere. (11:58) .\,.\,Så lad mig også lave en tabel til disse konstante brugergrupper.\,. Nå ja, og så er det altså meningen, at en tidligere brugergruppe ligesom ansøger om, at oprette en ny konstant brugergruppe, hvor de er forfatterne. Først allokeres den nye brugergruppe altså så af serveren, og hvis den nye brugergruppe så godkendes med en given slutdato (som ligger før godkendelsesdatoen), så kan brugergruppen få sat et signal flag i sin tilhørende tabel, som siger at brugergruppen er live, hvilket vil sige at serveren nu aktivt varetager, at kopiere ratinger (med passende vægte på) fra brugerne i brugergruppen (med live-flaget) og inputte dem med brugergruppe-botten som ophavsbruger (altså user\_id i SemanticInputs). 

Nå, inden jeg tænker over, hvordan ``dynamiske brugergrupper'' skal implementeres, så lad mig lige nævne, at jeg nu måske tænker, at begrænse Texts til en begrænset TEXT(n)-datatype. Og så kan jeg lade 0xC0 være længere tekster, som så kan indføres senere, når siden går fra at være mest af alt et web-indeks til at være en side, hvor selve indholdet er gemt (så man henter det direkte fra siden). *[Nej, jeg beholder bare TEXT-typen (altså den maksimale TEXT(n)) som den eneste i starten, for så kan alle eventuelle begrænsninger bare ske i et øvre lag, ved at hver bruger bare får en begrænsning på de bytes, vedkomne kan uploade (pr.\ tidsrum).] Og så kan det være, at jeg vil lade 0xD0 være diff-tekster/sammensatte tekster, men det kan jeg jo bare finde ud af på sigt. 

Nå: dynamiske brugergrupper.\,. (12:19) .\,.\,Hm, de kan få sin egen bot-undertype, selvfølgelig, og kunne måske bare være, hvor man ikke sætter nogen slutdato for den nye brugergruppe? .\,.\,Ja, og i øvrigt kan man jo godt have en dynamisk brugergruppe som skabere til en konstant brugergruppe, for så er det jo bare underforstået, at det er vægtene ved udgangen af slutdatoen i skaberbrugergruppen, der skal gælde, når det kommer til at beregne vægtene i den nye konstante. Ok! Nemt! (12:22)

Det er jo underforstået, at ``Bots'' refererer til Native Bots, så måske jeg skulle kalde dem det i stedet. Og så er det i øvrigt også oplagt at tænke på, om ikke tredjeparter også skal have mulighed for at lave bots, f.eks.\ til at varetage brugergrupper. Og hertil må man jo bare sige: jo, det kan sagtens blive en ting på sigt. Så tænker jeg, at dette så bliver en undertype til User-typen, og hvor tredjeparter så ansøger om at få en sådan speciel brugerprofil, hvor der så naturligvis kan høre særlige privilegier til, sådan at tredjepartsbots måske kan få lov at indsætte et større volumen af data pr.\ tid i form af de ratings, de indsender. 

Super. Så nu har jeg en god plan for brugergrupperne!\,:) (12:27)

(13:07) Ah, og ``avg-botten'' bliver jo bare den første brugergruppe (som så er dynamisk).\,.

(14:02) Hov, jeg tror nu, at jeg vil gå tilbage til, at det kun er standard-termerne, som bruger det system med den tabel, der pt.\ hedder NextIDPointers.\,. 
%
%%.\,.\,Hm, nu overvejer jeg egentligt, om man ikke bare skal sige.\,. .\,.\,Hm ja, måske skulle man faktisk.\,. .\,.\,Tja, nej.\,.
%
\ldots Nah, på den anden side, det fungerer også fint sådan (med NextIDPointers som den er). (14:25)

(18:47) Hm, jeg tror jeg vil gå tilbage til en ``.$<$noun describing the Object$>$:''-syntaks, men så vil jeg sige, at navneordet gerne må være i flertalsform, når vi snakker en én-til-mange-relation (i stedet for en én-til-én-relation, hvor navneordet så til gengæld bør være i entalsform). Og punktummet står så bare i stedet for `has as one of its' (hvor $<$pluralized noun$>$ så følger efter), når vi snakker én-til-mange-relationerne (i stedet for at stå i stedet for `has a/an'). \ldots\ Og jeg tror jeg vil sige, at navneord skal capitalize'es, både for faktiske navne ord og for relationer, der følger denne forkortede syntaks. (20:19)

(21:24) Ah, jeg kom lige på en god idé. Jeg vil også lave en ReversedSemanticInputs-tabel, hvor obj\_id og subj\_id så er byttet om i primærnøglen (og dermed i dets clustered index). Og så skal man kunne oprette reversions af existerende relationer, således at alle deres inputs bliver kopieret over i ReversedSemanticInputs, bare med ombyttes obj\_id og subj\_id, selvfølgelig. Jeg kan lige tænke lidt mere over, hvad man skal gøre for at (søge om at) oprette disse.\,. ``to-vejs''-relationer, men i første omgang kan jeg da lige sige, at jeg forestiller mig, at det skal benyttes for bl.a.\ ``.Lexical item:''-relationen, og for ``(Category).Elements:''-relationen. .\,.\,(Hm, lad mig forresten lige kopiere min nuværende beskrivelse af ``.Lexical item:'' ind som en (ikke-renderet) kommentar under denne paragraf.\,.) (21:32) 

%Kopieret:
	%This relation states about its subject and its object, the latter of which should be a text string that is part of an English sentence with a meaning attached to it (i.e. a lexical item), that the following is true: The object (a string) forms a lexical item that can be seen as defining the subject.
	%
	%For instance, if the subject can be referenced by a noun, then the object could be a string forming that noun. And if the subject is a relation that can be referenced by a verb, then the object could be a string forming that verb.
	%
	%A special example of the latter case is if the subject is this very relation descibed by this description. In that case, the object could be the string: 'can be referenced by the lexical item given by'.
	%
	%However, a shortened version of this lexical item might also do, and in fact even prefered in some cases, especially for relations such as this. This is why ".Lexical item:" has been chosen for the original lexical item of this relation. We thus propose the following standard for shortening lexical items of relations. 
	%
	%If possible, lexical items of realations should formulated according the syntax: ".<capitalized noun describing the object>:". If it is expected that users will generally be interested in querying for several fitting objects for a given subject, the noun should be pluralized. In that case, the '.' can be seen as standing in the place of 'has as one of its'. But if, on the other hand, it is expected that users will only be interested in querying for the best fitting object for a given subject (as is the case for this relation), the noun should simply be in its singular form. And in this case, the '.' can be seen as standing in the place of simply 'has' (or 'has a/an').
	%
	%Furthermore, parentheses might also be included at the beginning or at the end (or both) of the lexical item, such that the contents of these parentheses denote the intended type of respectively the subject and the object. For example, a relation that states that its subject is a subcategory of the object, both categories, the lexical item of that relation might be formulated as "(Category).Subcategories:(Category)". And as another example, a relation that states that its object is of the category referenced by the subject, the lexical item might be formulated as "(Category).Elements:". (Note that since the subject could be any category here, it does not make sense to include a type specification for the object). This latter example especially highlights the point of being able to specify the type this way, since it helps give meaning to what we mean by 'Elements' in this case. If the lexical item had been simply ".Elements:" on the other hand, it could reference a bunch of other relations as well, such as "(Molecule).Elements:" and so on.
%


(21:55) Hm, lad mig give to-vejs-relationerne en bestemt typekode, sådan at systemet bare automatisk gør sådan, at hvis et sem-input med en to-vejs-relation bliver indsat, så skal det omvendte input også indsættes i ReversedSemanticInputs. Og så skal jeg i øvrigt også have en fundamental relation der siger: ``.Lexical item of the inverse''. 


(01.03.23, 11:25) Jeg skrev om ude i kommentarerne under den næste sektion, at jeg ville bruge en speciel relation for at springe en kategori over, så at sige, nemlig for kategorier over relaterede prædikater til en kategori. Men hvis vi f.eks.\ tænker på kommentarer til videoer eller (SoME-)posts osv., så vil man jo nok også gerne kunne kategorisere disse i visse tilfælde (f.eks.\ hvis der er meget diskussion under et post). Så nu tror jeg faktisk, jeg vil tilbage til den løsning, jeg tænkte på lige inden den idé, hvilket var simpelthen at begynde at bruge funktioner igen, og så lave særlige funktioner til at bygge afledte kategorier. Disse afledte kategorier kan så fungere lidt ligesom `relevante relationer' for en kategori.\,. og ja, faktisk tror jeg så måske, at man vil erstatte rigtig mange én-til-mange-relationer med afledte kategorier i stedet.\,. .\,.\,Men ja, lad mig lige få sagt færdigt, at man så up-rater de afledte kategorier for kategorien over de termer, som de afledte kategorier afledes af. 

.\,.\,Hm, spørgsmålet er jo så nu: Skal alle én-til-mange-relationer så bare erstattes med kategorier.\,. ja, selvfølgelig på nær i hvert fald, ``.Elements'' og ``.Subcategories''.\,. .\,.\,Hm, måske er dette faktisk ikke en helt dum idé. .\,.\,Så når man up-rater relationer for (termerne i) en kategori, så vil det (i den tidlige version) handle om én-til-én-relationer (hvor objektet dog jo kan være en liste), og ellers up-rater man afledte (afledede?) kategorier i stedet, når altså vi snakker om at tilføje de knapper til termerne (som de vises, når man har klikket på dem i en liste), der folder nye lister ud (og som altså ikke bare folder data om termen ud i samme applikationssøjle). .\,.\,Lyder altså ret fornuftigt, hvis jeg selv skal sige det.\,.\,! (11:43)

\ldots I øvrigt kunne man jo også gøre det på sigt sådan, at når elementer vises til en kategori, så vises også en række af de mest populære underkategorier i toppen, sådan at man har muligheden for at trykke på disse og så ændre kategorien til en underkategori for samme søjle (medmindre man mellem- eller ctrl-klikker, eller klikker på en højre- eller venstre-pil inden for feltet). Bare lige en lille bemærkning, der var værd at nævne.\,. (11:58)


\ldots\ (14:07) Nu har jeg tænkt lidt over, hvordan det så kommer til at spille sammen med det her med ``ReversedSemanticInputs,'' og jeg er kommet frem til, at det jo faktisk går rigtig godt sammen, for så er det jo nok bare de to fundamentale kategori-relationer, der skal være to-vejs, samt relationer der refererer til (fulltext-searchable) strings, såsom `.Lexical item:' og `.Keyword string:'. For alle andre to-vejs-relationer skal jo nu som regel implementeres via `(Category).Elements:'. 

Så har jeg så også lige tænkt over, at man jo nok næsten burde samle NativeBots og UserGroups til bare UserGroups. Og så har jeg endda gjort mig nogle tanker om, at man kunne erstatte rat\_val og opt\_data med først en TINYINT NOT NULL og så en nullable SMALLINT (i.e.\ en short). Og så kan de to ting nemlig fortolkes som noget forskelligt, alt efter om user\_id er ID'et på en faktisk bruger eller en brugergruppe. (14:15) .\,. Hvis det er en faktisk bruger, så kan TINYINT'en signalere den faktiske rating. .\,.\,Hm, og måske skulle shorten (SMALLINT'en) bare altid være NULL, hvorved man jo også kunne dele SemanticInputs op i to og så lave view til brug for alle queries.\,. (14:25) .\,.\,Hm, lyder ikke dumt. Og for brugergrupper tænker jeg så, at det er shorten (.\,.\,ja, og hvis man laver et view behøver man jo forresten heller ikke at blande kolonnenavnene sammen for de to, så shorten kan godt hedde rat\_val.\,. tja, nej, men måske rat\_avg.\,.), der repræsenterer ratingværdien. Og så skal TINYINT'en til gengæld repræsentere det mindste tal $-128\leq n \leq 127$, hvor der gælder, at $2^n > x$, hvor $x$ her betegner en vægtet sum over antallet, der har afgivet en stemme for udsagnet (vægtet med brugergruppens vægte; de samme vægte som rat\_avg udregnes med). (14:31)

(14:34) Nå ja, jeg skulle jo også skrive, at forkortelserne af lexical items for relationer nu ikke behøver flertalsendelser. For nu opretter man jo kategorier i stedet.\,. Nå ja, og det er forresten noget, som jeg skal tænke noget mere over, for det er jo så ikke sikkert, at man skal bruge, hvad jeg nu kalder ``DerivedTerms,'' alligevel (til andet end prædikater).\,. .\,.\,For nu tænker jeg jo faktisk, at man tilføjer én-til-mange-relationer til termerne i en kategori, kald den $c$, ved at up-rate den specifikke én-til-mange-kategori for $c$ ud fra en (fundamental) relation a la: ``.RelevantCategoriesForElements:''. (14:41) Og så skal navnet på denne kategori jo hellere skrives af brugerne selv (i stedet for at parses fra et lex-item). Så ja, jeg tror altså ikke alligevel, der bliver behov for DerivedTerms (i hvert fald ikke i tidlige versioner; hvem ved, hvad der bliver behov for i fremtiden?\,.).\,. (14:43) .\,.\,Så det kan altså være, at jeg går tilbage til at kalde den RelationalPredicates i stedet.\,. Tja, eller også beholder jeg det bare, som det er nu, for det skader måske ikke, at holde muligheden for funktioner åbne, også selvom jeg nu har svært ved at se, hvad de skulle gavne (andet alså end til at lave prædikater med), men jeg kan jo lige tænke lidt over det.\,. (14:45) .\,.\,Hm, måske kunne lige netop en funktion til at reversere en relation være brugbar.\,.\,? (14:49) .\,.\,Tja, og dog, for det er nok bedre bare at lave en speciel tabel over.\,. Hm.\,. .\,.\,Hm, alternativt kunne man lave en tabel med alle de fundamentale relationer (som så inkluderer alle én-til-mange- og alle to-vejs-relationer, som jeg tænker det nu), og så kan der måske bare være et flag i denne tabel, der afgør, om de er to-vejs eller ej.\,. (14:56) .\,.\,Og fordi de så bliver fundamentale, så kan jeg måske endda bare nøjes med at give deres lexical items og descriptions som kolonneværdier i stedet for, at de skal bootstrappe deres egen semantik, for det bliver jo nemlig nok virkeligt sjældent, at brugerne vil query'e efter disse fundamentale relationer. Og når de gør, hvorfor så ikke bare gøre det på en separat introduktionsside, i stedet for at query'e efter dem i selve det semantiske træ?\,. (14:59) .\,.\,Hm, og bare fordi de ikke bootstrapper sig selv, men at deres semantik er beskrevet i deres tabelkolonner, jamen så kan man jo stadig godt bruge dem på sig selv og hinanden. 

.\,.\,Okay, og måske putter jeg også de grundlæggende kategorier ind i samme tabel (og så skal omtalte flag bare kunne vælge imellem flere typer end bare relationstyperne), og så kan jeg jo kalde den tabel for FundamentalTerms. Cool.\,.\,:) (15:06)

\ldots\ (17:10) Skråt to-vejs-relationerne! For de bliver nok alligevel ikke særligt brugbare i praksis. I stedet må brugerne altså bare manuelt up-rate relationen i begge dens udgaver (som hver især er skabt separat), eller også må man implementere en sådan automatik i applikationslaget. Jeg kom også ret hurtigt i tanke om, efter at jeg skrev forrige paragraf (og gik mig endnu en tur i det her totalt lækre vejr, det har været), at jeg jo ville få brug for DerivedTerms netop til at lave derived categories af. Men nu har jeg sidenhen faktisk tænkt noget lidt andet. Men lad mig starte med at sige, at jeg faktisk også tror, at der ikke bliver nok behov for derived/relational predicates. For det vil alligevel nok næsten altid være ift.\ en `belongs to: (Category)'-relation, at man ville bruge det, og her kunne man jo eventuelt i stedet bare gøre sådan, at brugere kan lave intersections mellem flere kategorier.\,. tja, eller.\,.(?) Det vil jeg faktisk lige tænke noget mere over.\,. Men ellers kan jeg sige, at nu hvor så mange semantiske inputs kommer til at handle om at up-rate termer som elementer af kategorier, så vil jeg adskille disse semantiske inputs for sig i sine egne tabeller. I første omgang har vi så en sem-input-tabel, hvor udsagnsdelen så bare består af en kategori (i stedet for subj+rel) og et element-term (i stedet for obj). Og her kommer så hvorfor, at man måske alligevel ikke behøver DerivedTerms, for så kunne en anden tilsvarende tabel bestå af kategori-funktions-input (i stedet for subj), en kategori-funktion (i stedet for rel) og så et element-term (i stedet for obj). (17:22) .\,.\,Hm, men måske får man så alligevel brug for DerivedTerms, for mon ikke man alligevel også får brug for, at.\,. tja, og dog.\,. Ville have sagt: ``brug for at kunne tage fat i den afledte kategori som et selvstændigt term,'' men hvorfor egentligt?\,.\,. (17:24)

.\,.\,Jeg skal i øvrigt også nævne, at jeg nu forestiller mig `.Subcategories:' også som en afledt kategori. 

.\,.\,Hm, i bund og grund er det vel kun, hvis man har brug for `belongs to'-prædikater til afledte kategorier, at man har brug for at kunne behandle dem som selvstændige termer.\,. .\,.\,Hm ja, og i så fald, så skulle man vel hellere bare have en DerivedPredicate-type.\,. (17:31) .\,.\,Ja, jamen så er det vel bare det, jeg gør. Så prædikater kan altså nu afledes (monadisk) af kategorier, og særligt også af afledte kategorier, hvilket jo så nok bliver den eneste måde, at ``ophøje'' en afledt kategori til et *(en) term, så at sige.\,. (17:34)

.\,.\,Og fordi jeg ikke tror, at.\,. .\,.\,Hm, overvejer, om DerivedPredicates så skal deles op i to tabeller.\,. men hvorfor ikke, kan man sige.\,. Ok.\,. 

.\,.\,Hov, men ift.\ derived prediates.\,. ah, så skal man så bare sørge for, at disse bliver sat automatisk.\,. eller?\,.\,. (For det bliver jo alligevel en del arbejde.\,.) Hm.\,. (17:40) .\,.\,Hm, men er det mon så bedre, at man i stedet for derived predicates så bare gør sådan, at man kan tage intersections af kategorier (og så i stedet også sørger for, at derived categories bliver oprettet som termer.\,.).\,. (17:42) 

.\,.\,Hm, men er det så ikke lige før, at alle prædikater bare skal være kategorier også.\,.\,? .\,.\,Hm, det ville ændre det en del, for så skal man ikke længere hente en masse termer til en liste, hvor man så samtidigt skal hente prædikat-værdier for dem; man skal i stedet bare hente termer fra lister.\,. Hm, men dette er jo ikke nødvendigvis mere effektivt.\,. .\,.\,Hm, men man kunne jo eventuelt så gøre `belongs to:'/`.Elements:' til en to-vejs relation (nemlig ved at man med andre ord bare sørger for at have to eksemplarer af hver kategori-input-tabel).\,. (17:49) 

.\,.\,Hm, og hvis man gør det sådan, at prædikater bliver kategorier, så kan man bare sørger for, at hver kategori for et præfiks, der fortæller, om titlen er et navneord (i flertal) eller et prædikat --- eller et adjektiv (så man sparer `is' i titlen(/tagget)).\,. (17:55) .\,.\,Hm, rent praktisk kunne dette give god mening, men jeg kan på den anden side ikke særligt godt lide, at prædikater kaldes ``kategorier''.\,. Hm.\,. .\,.\,Nå, jeg må jo lige tænke lidt over det hele.\,. (17:57, 01.03.23)

.\,.\,Hm, ville det give mening, hvis prædikater ligesom altid bare hørte til en kategori.\,.\,?\,.\,. (18:02) .\,.\,Hm, måske overtænker jeg det en smule nu.\,. 

(02.02.23, 14:17) Fik tænkt lidte videre i går aftes og fik et par idéer, og så har jeg tænkt en del videre i dag og fået en del flere gode idéer. Nu tror jeg, jeg er ved at have den. Jeg har tænkt mig, at det grundlæggende lag, altså databasen, skal laves ret meget om. Nu skal semantiske inputs bestå af en tabel med (prædikat\_id, rat\_val (short), og obj\_id) som primærnøgle (og vist nok som det eneste i den tabel). Og så skal hvert prædikat bygges i en tabel med (user\_id, subj\_id, relations/kategori-funktions-ID) som primærnøgle, og hvor selve prædikat-ID'et så altså er den eneste ikke-nøgle.\,. Nå ja, eller det vil sige, man kunne jo godt have.\,. .\,.\,Hm, måske skulle man bare have to kopier af denne tabel: den ene hvor (user\_id, subj\_id, relations/kategori-funktions-ID) er primærnøgle, og den anden hvor pred\_id er primærnøgle.\,. Fint.\,. (14:26) .\,.\,Pointen med at kalde det kategori-funktioer er så, at en bruger kan til hver kategori vælge en liste over kategori-funktioner, som skal danne de knapper, der forekommer, når et element vises (i en liste eller for sig selv). Når man så trykker på disse knapper, så får man altså en liste af alle objekter --- eller rettere så mange man vil have, måske fra højest til lavest rating, der hører til det givne prædikat\_id, der jo så aflæses i (user\_id, subj\_id, kategori-funktions-ID), hvor subj\_id jo så er det givne element, og hvor kategori-funktionen selvfølgelig er den valgte. (14:32) .\,.\,En funktion kan dog godt vide, at den selv er ``en én-til-én-relation,'' hvorved brugeren som regel kun vil få serveret det højest ratede objekt på listen, medmindre brugeren specifikt beder om den anden mulighed. Disse funktioner er også altid typede, idet de som minimum i hvert fald altid angiver objekttypen. Og denne type angives i form af en kategori. Dette bliver særligt relevant, når jeg om lidt når til, at brugere også for hver kategori kan up-rate `skabeloner' til denne, som så kommer til indirekte at bestemme, hvordan element- og element-liste-visningerne skal være for den kategori. Og ja, hvis en kategori-funktion så erklærer, at objekterne er af kategori $x$, så vil denne afledte kategori altså også arve samme `skabelon,' som kategori $x$ har. 

En skabelon er så også en funktion (ja, jeg er pludselig gået all-in på funktioner, sjovt nok), der tager en kategori som input, og som så indeholder en masse information, som applikationen skal læse og bruge til at indstille visningspræferencerne (altså i form af HTML og CSS). Særligt skal denne information også definere en række kategori-funktioner, som skal bruges til diverse ``knapper'' i HTML-skabelonerne. Tillige bør der så være --- og ja, man kan sikkert gøre det på mange måder, men nu foreslår jeg lige det her --- være en højereordnesfunktion, der tager en af disse knap-kategori-funktioner og spytter en ny kategori ud, nemlig en kategori over ``generelt relevante funktioner'' for knap-kategori-funktionernes kategorier.\,. Okay, det bliver helt klart en smule indviklet nu, men vi skal nok finde hoved og hale i det.\,. Men ja, pointen er så, at når brugeren trykker på en knap, så allerede uden at nogen brugere har givet input, så vil der allerede fra start være nogle forslag i toppen af kategori-listen (når brugeren har trykket på den givne knap), som den afledte kategori altså arver helt oppe, ikke fra dens forælderterm, men fra forældertermens egen kategori (altså den kategori som forældertermet er et element af). Og herfra kan brugeren så selv vælge at tilføje nye termer til denne liste, som så kan vises side om side med disse start-foreslag --- og brugeren kan endda også nedvurdere termerne, som er en del af startforslagene, hvis de har lyst. (14:47)

Nå, den mest tunge øvelse for databasen er jo generelt, når den skal hente en masse termer og sortere dem. Så det er også dette arbejde, jeg har forsøgt at optimere med disse nye tanker. Nu handler det jo i høj grad om (efter man lige har fået det relevante prædikat-ID), bare at pege på et prædikat-ID, og så få et antal elementer fra toppen eller fra bunden af den tilhørende liste (som nu er ordnet efter rating!). Hvis man så skal lægge yderligere vægtninger/filtre over, så vl jeg \emph{ikke} længere have det sådan, at der så skal laves seeks *(search, rettere; vi snakker altså søgningen i logaritmisk tid) på hvet enkle term. Nu skal sådanne søge-/filterindstiller dannes ud fra sammensætninger af kategorier! Så man beder altså bare databasen om et antal lister af termer fra forskellige prædikat-ID'er til at starte med. (Man behøver ikke at bede om den fulde liste hver gang, og det er jo altid dejligt, hvis hver liste er så begrænset, at databasen kn skal læse listen fra en eller måske to pages.) Databasen serverer så også alle de tilhørende rating-værdier, nu kan applikationen så tage den mindste liste, og ordne termerne efter ID. Så kan den for alle de andre lister gøre det, at den går igennem listen og laver seeks på den mindste liste (den ordnet efter ID), og så smider termen væk, hvis den ikke er på listen. Hvis den dog er, jamen så gemmes ratingen fra den givne liste sammen med de andre gemte ratinger for det element. Til sidst får man så en fællesmængde af alle lister, hvor der for hver term på listen står alle de relevante rating ud for termen. Til sidst kan man så lave den aritmetik man synes for at kombinere disse ratings til en samlet rating, g så kan man ordne listen efter denne (måske uden at smide de grundlæggende ratings væk i hukommelsen (hvis nu brugeren vil ændre vægtningen f.eks.)). (15:01) 

Bum. Så det er altså sådan, jeg tror, det skal komme til at fungere nu.\,:) (15:01)

(03.03.23, 11:23) Mit forslag fra i går var ikke så godt. Det er rigtigt nok, at skabelonerne skal definere nogle kategori-funktioner/relationer, so bruges til at give startforslag til visse afledte kategorier af termerne, som skabelonen handler om at definere HTML og CSS for, men disse relationer skal bare være relationer a la: ``.Relevant predicate suggestions:' og ``.Relevant comment subcategories:''. 

Bemærk i øvrigt, at selvom det altså giver god mening at kalde dem kategori- --- eller prædikat- --- funktioner, nu hvor de tages på et subjekt og en bruger og spytter et pred\_id (som også kan tolkes som et ``kategori-ID'') ud, så kan vi altså også sagtens stadig se dem som relationer, ligesom vi har gjort hidtil. Men ja, fordi man så gerne skal formulere disse relationer hver især som et navne ord (i flertal eller i ental alt efter relationstypen (altså én-til-én eller én-til-mange)), så giver det jo også dermed fin mening også at omtale dem som prædikat-/kategori-funktioner. 

Nå, en vigtig pointe er så for det første, at pred\_id ikke bliver et selvstændigt term. Disse prædikater bruges kun til at definere selve listerne af elementer, som vises i applikationen. Hm, måske skulle jeg dermed faktisk begynde at kalde dem sets (mængder) i stedet.\,. .\,.\,Ja, lad mig det. For både `kategorier' og `prædikater' bliver jo nemlig også hver især en type, eller rettere en kategori (for typer er mere grundlæggende --- såsom `sets'/`mængder'), af termer. (11:36) En anden vigtig pointe er så, at prædikat-termer jo dermed nu ikke direkte fører til applikationslisterne, dem vi altså nu kalder `mængder,' men i stedet kræver dette så en `fulfills'-/`.Fulfilling terms:'-relation. Prædikat-mængden dannes jo nemlig ved at sammensætte (user\_id, subj\_id, set function ID), hvor subj\_id så er prædikat-termen, og hvor ``set function ID'' så er `.Fulfilling terms:'-relationen. (11:41)

En tredje, ny, pointe er også, at ingen af de to tabeller faktisk skal reverses! For nu vægter/filtrerer jeg jo lister via ``intersections,'' hvis vi kan kalde det det. Og når det kommer til keywords (og altså FULLTEXT-searchable Strings), så vil jeg hellere bare indføre en relation a la: `is a relevant keyword (/lexical item) for:'. Som en af hovedkategorierne i applikationen vil jeg så have en pseudo-kategori, som altså er et søgefelt på keywords i databasen. Når man så har fundet og valgt et ønsket keyword, så kan man så se, hvilke termer er relateret til dette via (some user, keyword/lexical item, `.Related (semantic) terms:' .\,. / `.Related Terms:')-mængden. (11:50) .\,. / `.Related s-terms:'.\,. .\,.\,Anyway, så derfor behøver vi altså ikke nogen tilbagegang i det semantiske træ --- i hvert fald ikke som en del af det helt grundlæggende. I applikationslaget kan man så stadigvæk gøre sådanne, at visse ratings automatisk bliver carbon-copied og givet til en tilsvarende reversed relation også, men ja, dette er i så fald altså udelukkende oppe i applikationslaget. (11:53)

(12:24) Nå ja, og jeg overvejer at gøre rat\_val til en TINYINT igen.\,. .\,.\,(12:31) Ah, måske kunne man godt få brug for en ekstra tinyint for de normale brugere også, for dette kunne jo bruges til at.\,. Nå ja, til enten at give usikkerhedsbredden på ratingen, som jeg har tænkt før, eller måske bare at give en selvdefineret vægt imellem 0 og 1, sådan at brugeren selv kan sætte sin effektive brugergruppevægt ned for den specifikke rating.\,. Hm, interessant at overveje, hvad der giver mest mening af de to muligheder, det må jeg lige gøre.\,. (12:34)

.\,.\,Men ja, for brugergrupper kan den første byte så være ratingen (fra -127/127 til 127/127), og så kan den næste byte udgøre en vægtet sum for, hvor mange har afgivet stemme til ratingen.\,. hm, og måske kunne man endda også bruge nogle bits fr nr.\ 2 byte og sætte dem over i forlængelse af den første (for yderligere præcision).\,. Tja, og dog.\,. (12:37) .\,.\,Nej, en skala med en opløsning på 127 til begge sider er rigeligt. Og så kan stemmeantals-vægten jo hermed blive den eneste kolonne, som ikke indgår i nøglen. 

Jeg er forresten ikke sikker på, at jeg får brug for.\,. hm datoer.\,. jo, måske.\,. (12:40)

Hm, stemmeantals-vægten kunne faktisk sagtens være en del af primærnøglen alligevel, og altså nemlig komme lige efter ratingværdien.\,. (12:45) .\,.\,Jeg kunne kalde det for en signifikans-indikator, hvilket jo så både kan bruges, om vi taler brugergruppe- eller bruger-versionen af, hvad værdien betegner. 

.\,.\,Hm, jeg tror, at det vil være meget nemmere generelt for folk at forholde sig til tanken om en stemmevægt frem for en afvigelsesbredde, så lad mig bare sige, at det er det, vi gør! (12:50) Og så spiller det egentligt også meget godt sammen, for så kan man bruge ``rating weight'' for både brugergruppe- og bruger-versionen, og så behøver jeg ikke at dele SemanticInputs op i to tabeller. .\,.\,Tja, selvom det burde man nu næsten alligevel, om ikke andet så bare for på en nem måde at sikre sig, at der bliver to filer.\,. nå nej, dette betyder jo ikke helt så meget alligevel. Nå, det er også lige meget nu; det kan jeg altid lave om på, hvis det er.\,. 

(Hvis jeg inkluderer datoen, så skal den selvfølgelig ikke være en kolonne i SemanticInputs, har jeg indset nu (pga.\ effektiviteten).\,.)

(04.03.23, 10:01) Jeg kom i tanke om i går aftes, at fordi alle semantiske inputs jo alligevel tager udgangspunkt i brugere og brugergrupper, så kan hver bruger(gruppe) jo egentligt godt selv have deres egen fortolkning af en relation, uden at det gør noget, så derfor kan man godt udelade beskrivelserne som en del af det grundlæggende lag. Jeg skal selvfølgelig beskrive de grundlæggende Termer i databasen, men brugerne behøver i princippet ikke at holde sig til de beskrivelser.

Så tænkte jeg også noget andet, og det var, at `skabelonerne' jo også kan indeholde et valg om en bruger for hver relation/kategori-funktion (der så sammen med det selekterede term selv giver en `mængde'). Så kan en brugergruppe naturligvis bare pege på sig selv ret ofte, hvilket også måske vil være lidt mere effektivt (for når man skifter bruger, så skifter man helt sikkert også til en anden disk page.\,.), men de kan altså også pege på andre, hvilket kan være rigtig praktisk, tror jeg på. (10:08) 

.\,.\,Nå ja, og nu overvejer jeg altså, at lave en tabel for alle relationer som en del af det grundlæggende, således at relationer defineres unikt ud fra objekt-navneord, subjektkategori, objektkategori og et er-én-til-én-flag. Og det er det; ingen beskrivelse. Og så kan hver gruppe dermed i princippet vælge deres egen fortolkninger, der hvor der kan være tvetydigheder --- eller bare gradbøjninger af (og altså rettere sagt mange versioner af), hvad relationen helt præcist indebærer. (10:13)

(10:22) Hm, og så kunne jeg også lave en tabel over kategorier, som så faktisk ikke skal have meget andet i deres grunddefinition en en titel, og så overvejer jeg endda lidt nu, om ikke man så skulle gøre obj\_noun og kategori-titlen til FULLTEXT-searchable kolonner for sig selv?\,:) Det tror jeg, jeg vil gøre.\,. 

\ldots Hm, men hvis det ofte er enkelte ord, så er full-text nok lidt overkill, når man bare kan bruge et non-clustered index.\,. \ldots (Ja, det er det jo selvfølgelig. Jeg ser lige, hvad jeg gør helt præcist.\,.)

\ldots (11:20) Hm, skulle man mon indføre en grundlæggende prædikat-type, som så kan blive en slags kategori-til-(under)kategori-funktioner.\,.\,? .\,.\,Ah, nå nej/ja, det svarer jo bare til `relevante prædikater,' så det får jeg allerede.\,. .\,.\,Tja, og dog, for det kan måske være meget smart at kunne.\,. Ah, men jeg skal jo finde en måde at brugerne skal kunne instantiere intersections (fællesmængder) på, så det skal jeg få inkluderet.\,. (11:26)

(12:23) Hm, måske er det i virkeligheden nemmere bare at bruge decimaltal, når det kommer til at dele de forskellige typer ind i forskellige auto\_increment-startpunkter.\,. 

(12:39) Jeg skal have fundet ud af, hvad jeg gør med ``standard terms, set ID pointers, creators and dates''\ldots 


(05.03.23, 9:43) Jeg fik en masse gode idéer i går. Lad mig starte med at nævne, at jeg nu forestiller mig, at alle standard-termerne (som man måske kunne kalde s- eller r-termer (for hhv.\ semantic, standard og resource, regular *(mest for ressource-term, dog))) samt kategorier skal defineres alene ud fra en kort titel samt en pointer (et ID, i.e.) til en henholdsvis en kategori eller en overkategori, om vi snakker et r-/s-term eller en kategori.\,. hm, r-term giver faktisk mest mening, for kategorier er jo også semantiske.\,. Ja, og så kunne s-termer i øvrigt betegne alle ikke-data- og ikke-konstruerede termer.\,:) 

Nå, det helt store nye er så, at med disse ændringer (og hvor hver bruger i princippet selv kan vælge deres egen beskrivelser (selvom hver titel--kategori-pointer-kombination udgør en unik r-term eller kategori (med ét ID))), så giver det pludselig vildt god mening, at fortolke hele det semantiske træ som et slags filsystem (med filsti-agtige stier).\,! Nu vil jeg derfor prøve at beskrive syntaksen for disse ``filstier''.\,. hm, lad mig bare kalde dem paths.\,. eller s-paths.\,. hm.\,. Nå, lad mig beskrive syntaksen for disse stier. (9:54)

Vi starter med at vælge en bruger (i starten af stien). Hm, det gør jo forresten også, at hver bruger skal have.\,. Nå nej, man kan jo godt bruge et bruger-ID, hvis ikke brugeren har et unikt alias i systemet.\,. Nå, og så kommer en række kategorier og underkategorier, separeret med `$>$.' .\,.\,Hov, måske skal der faktisk være to udgaver af `$>$,' lad mig lige tænke mig om en gang\ldots 

\ldots (10:47) Okay, jeg har tænkt mig lidt om, og nu har jeg en faktisk mere simpel syntaks, der også faktisk minder mere om gængse filstier. Lad mig faktisk bare starte med at prøve at definere syntaksen.

Vi har:

%$Path := UserIdent\ \texttt{/}\ Set\ |\ UserIdent\ \texttt{/}\ Term$
%
%$UserIdent := ident$
%
%$Set := Set'\ |\ Set'\ \texttt{\&\&}\ Set$ 
%
%$Set' := (Set)\ |\ Set''\ |\ Set''\ \texttt{||}\ Set'$ 
%
%$Set'' := Term\ \texttt{.}\ Relation\ \texttt{/}\ |\ ident\ \texttt{/}$ 
%
%$Relation := ident$
%
%$Term := Term'\ |\ Category\ \texttt{/}\ Term'$
%
%%$Term' := $ ..(11:18)...
%
%%(11:34) Hm, jeg skal lige overveje nogle ting... ...(11:44) Okay, lad mig prøve igen..

$Path := UserIdent\ \texttt{//}\ Set\ \texttt{/}\ |\ UserIdent\ \texttt{//}\ Term$

$UserIdent := ident$

$Set := Set'\ |\ Set'\ \texttt{\&\&}\ Set$ 

$Set' := Set''\ |\ Set''\ \texttt{||}\ Set'$ 

$Set'' := (Set)\ |\ Term\ \texttt{.}\ Relation\ |\ ident$ 

$Relation := ident$

$Term := Category\ |\ Set''\ \texttt{/}\ ident$

%Hm, kunne det være sådan her..? (12:03) ..Ja, det fungerer vist, for man kan altid se, om stien slutter med en skråstreg, og hvis det gør, så skal det parses som et Set, og hvis ikke, så skal det parses som en Term.. (12:06) ..Og så tænker jeg, at Category skal indebære følgende syntaks:

$Category := Category\ \texttt{/}\ ident\ |\ ident$

\ 

Når jeg skriver $ident$ og ikke $id$, så er det for at præcisere, at det ikke behøver at være et BIGINT-id, men at det også sagtens (og som regel vil være) en streng-identifyer.\,. (12:13)

.\,.\,(12:17) Hov nej, det kan godt være, at vi lige skal gøre sådan, at $Category$ ikke kan komme efter.\,. .\,.\,efter.\,. Hm nej, måske fungerer det; jeg tror ikke $Category$ kan være andet end i starten med denne syntaks, vel.\,.\,? (12:20) .\,.\,Nej, så måske fungerer det altså, som den er.\,. (12:22)

.\,.\,Lad os sige, at det virker for nu. Og lad mig så sige, at jeg så tænker, at `Elements'- og `Subcategories'-relationerne henholdsvis må (og bør) forkortes med bare `e' og `s' i stierne. Dermed kunne vi f.eks.\ navigere til underkategorien rockmusik med stien: `userid//Media/-Music.s/Rock music'. Men hvis `Rock music' så er defineret med `Music' som sin overkategori (husk at hver kategori er unikt defineret ud fra overkategori plus titel), så kan applikationen altså også omdanne denne sti til den ækvivalente sti: `userid//Media/Music/Rock music'. Så en skråstreg i kategori-præfikset betyder altså det samme som `.s/', men hvor underkategorien så bare allerede har den givne kategori før `.s''et som sin definerende overkategori. Hvis derimod `Rock music' er defineret ud fra en anden kategori, jamen så må man bare beholde `.s/' i stien. Hvis man så vil se en liste (eller nærmere bestemt en `mængde') over elementerne i `Rock music,' så kunne stien så se sådan her ud: `userid//Media/Music/Rock music.e/'. (12:36)

Jeg forestiller mig også at brugere selv skal kunne definere forkortelser for relationer og andre ting, men det vil jeg nu nok undlade at implementere i betaversionen. 

Nå ja, og hvis i øvrigt at et element af en kategori har denne kategori som dens definerende kategori, så kan $ident$ (altså i `$Set''\ \texttt{/}\ ident$'-underproduktionen) bare være termens titel. Og tilsvarende gælder for kategorier, hvorfor at et kategori-præfiks fra `$Category$'-produktionen altid vil bestå af navne/titler frem for BIGINT-ID'er. (12:41)

Hvis ikke et element eller en underkategori har kategorien som sin definerende kategori.\,. ja, så skulle man måske faktisk indføre, at brugere kan lade kategorier ``med-adoptere'' andre kategoriers børn.\,. For eksempel kunne vi, hvis `Rock music' er defineret ud fra en anden kategori end `Music,' gøre sådan at `Music' bare vælger at (eller rettere at brugeren vælger at lade `Music') adoptere `Rock music' som sit barn også. .\,.\,Ja, og så vil man endda igen kunne erstatte `.s/' med `/', for det kræves så selvfølgelig bare, at en kategori ikke må adoptere flere børn med samme titel --- i hvert fald ikke uden at lave aliasser for dem. Og der kan man bare se, så får vi jo hermed også allerede en mulighed for, at brugere kan lave forkortelser (nemlig via aliasser, hvis man altså bare gør, at en kategori også kan ``adoptere'' og omdøbe sine egne børn). Nice nok. (12:46) 

.\,.\,Nå ja, jeg mangler forresten også lige nogle afgrænsnings-suffikser på $Set$sne\ldots (12:51)

.\,.\,

$Path := UserIdent\ \texttt{//}\ Set\ \texttt{/}\ |\ UserIdent\ \texttt{//}\ Term$

$UserIdent := ident$

$Set := Set'\ |\ Set'\ \texttt{\&\&}\ Set$ 

$Set' := Set''\ |\ Set''\ \texttt{||}\ Set'$ 

$Set'' := Set'''\ (\texttt{[}\ num\ \texttt{]})? $ 

$Set''' := (Set)\ |\ 
	Term\ \texttt{.}\ Relation\ (\texttt{(}\ Range\ \texttt{)})?\ |\ 
	ident\ (\texttt{(}\ Range\ \texttt{)})?
$ 

$Relation := ident$


$Range := \mathrm{TBD,\ but\ perhaps\ something\ like\!:}\ \ 
	num\ \texttt{;}\ (num)?\ |\ 
	\texttt{;}\ num
$

$Term := Category\ |\ Set\ \texttt{/}\ ident$

$Category := Category\ \texttt{/}\ ident\ |\ ident$

\ 

\noindent(Nu fik jeg også lige rettet $Set''$ til $Set$ for $Term$-produktionen.\,.)

.\,.\,Så er det så meningen at \texttt{\&\&} betyder en intersection (fællesmængde) af mængderne, og \texttt{||} betyder en union (foreningsmængde). Begge disse ting handler altså så at sætte flere mængder sammen (ved at man først ordner efter term-ID'et), og for begge ting beholdes alle ratings fra hver indgående mængde, således at det altså først er i applikationslaget, at den endelige aritmetik og listesortering foregår (og hvor brugerne nemlig så kan ændre sorteringen for listen, uden at skulle query'e serveren igen). Forskellen er så bare lige, at for \texttt{\&\&} fjernes alle de termer, der ikke indgår i begge mængder på hver side af operatoren, inden at listen/mængden serveres til browseren, og altså til applikationen, der kører i den. (13:21) 

.\,.\,Åh, og jeg skal også lge forklare, at jeg med $(\texttt{[}\ num\ \texttt{]})?$ for $Set''$ altså tænker, at $num$ her skal repræsentere et maksimumantal på, hvor mange termer, man gerne vil have serveret fra mængden (hvis størrelsen overstiger dette $num$).\,. Hm, jeg skal forresten også have tænkt over, hvordan man vender rangen om (og altså negerer relationen), men det må jeg bare lige have mente at finde ud af på et tidspunkt.\,. (13:25)

.\,.\,Hm, man kunne måske bare angive dette via $Range$en. Lad mig i øvrigt lige erstatte $num$ i $Range$ med $float$ og $num$ i $\texttt{[}\ num\ \texttt{]}$ med $int$, sådan at det bliver:

\ 

$Path := UserIdent\ \texttt{//}\ Set\ \texttt{/}\ |\ UserIdent\ \texttt{//}\ Term$

$UserIdent := ident$

$Set := Set'\ |\ Set'\ \texttt{\&\&}\ Set$ 

$Set' := Set''\ |\ Set''\ \texttt{||}\ Set'$ 

$Set'' := Set'''\ (\texttt{[}\ int\ \texttt{]})? $ 

$Set''' := (Set)\ |\ 
	Term\ \texttt{.}\ Relation\ (\texttt{(}\ Range\ \texttt{)})?\ |\ 
	ident\ (\texttt{(}\ Range\ \texttt{)})?
$ 

$Relation := ident$


$Range := \mathrm{TBD,\ but\ perhaps\ something\ like\!:}\ \ 
	float\ \texttt{;}\ (float)?\ |\ 
	\texttt{;}\ float
$

$Term := Category\ |\ Set\ \texttt{/}\ ident$

$Category := Category\ \texttt{/}\ ident\ |\ ident$

\ 

Her betegner $float$sne i $Range$en jo så selvfølgelig min og maks på, hvilke nogle ratingværdier, man gerne vil query'e efter. (13:34)

.\,.\,Hov, det var forkert at rette $Set''$ til $Set$ i $Term$. Lad mig lige tænke over, om det skal rettes tilbage til $Set''$, eller hvad.\,. .\,.\,Hm, måske skulle rette det tilbage, og så også bare rette $Set$ til $Set''$ i $Path$.\,.\,? (13:40) .\,.\,Ja, lad mig bare gøre dette for nu. Så får vi:

\ 

$Path := UserIdent\ \texttt{//}\ Set''\ \texttt{/}\ |\ UserIdent\ \texttt{//}\ Term$

$UserIdent := ident$

$Set := Set'\ |\ Set'\ \texttt{\&\&}\ Set$ 

$Set' := Set''\ |\ Set''\ \texttt{||}\ Set'$ 

$Set'' := Set'''\ (\texttt{[}\ int\ \texttt{]})? $ 

$Set''' := (Set)\ |\ 
	Term\ \texttt{.}\ Relation\ (\texttt{(}\ Range\ \texttt{)})?\ |\ 
	ident\ (\texttt{(}\ Range\ \texttt{)})?
$ 

$Relation := ident$


$Range := float\ \texttt{;}\ (float)?\ |\ \texttt{;}\ float
$

$Term := Category\ |\ Set''\ \texttt{/}\ ident$

$Category := Category\ \texttt{/}\ ident\ |\ ident$

\ 

Nå, det kan være, at jeg lige vil gå mig en lille tur, men jeg har altså til gode at snakke om, hvordan brugere skal kunne up-rate relationer og skabeloner --- og endda andre brugere/brugergrupper, som man vil kopiere næsten fuldstændig, på nær lige at ens egne ratings kommer og overskriver deres --- og om hvordan prædikater nu bare skal implementeres via relationer, men det må jeg alt sammen skrive om, når jeg kommer tilbage (.\,.\,dog ikke sikkert, at jeg når at skrive det hele i dag, men det må jeg se.\,.)\ldots (13:47)

\ldots\ (15:30) Okay, lad mig lave det om, så at brugeren også bliver en del af $Set$-produktion-en.\,.

\ldots Hm, lad mig faktisk lige prøve først at lave syntaksen, uden `.s/' $\to$ `/' -forkortelserne, det er sikkert nemmest!\,.\,. (15:59)

\ 

$Path :=  Set\ \texttt{/}\ |\ Set\ \texttt{/}\ ident$

%$Term := Category\ |\ Set\ \texttt{/}\ ident$


$Set := Set'\ |\ Set'\ \texttt{\&\&}\ Set$ 

$Set' := Set''\ |\ Set''\ \texttt{||}\ Set'$ 

$Set'' := Set'''\ (\texttt{(}\ Range\ \texttt{)})?\ (\texttt{[}\ int\ \texttt{]})? $ 

%$Set''' := \texttt{(}\ Set\ \texttt{)}\ |\ 
%	UserIdent\ \texttt{/}\ Category\ ident\ \texttt{.}\ Relation\ |\ 
%	ident
%$ 

$Set''' := \texttt{(}\ Set\ \texttt{)}\ |\ 
	Set'''\ \texttt{/}\ ident\ \texttt{.}\ ident\ |\ 
	ident\ |\ 
	User
$ 

%(16:09) Ja, det blev noget nemmere, og nu skal jeg bare lige huske, hvordan jeg laver et tilde i monospace font.. ...(16:22) Okay, det er åbenbart: \texttt{$\mathtt{\sim}$}$.. ..Ah, eller bare \mathtt{\sim}..

$User := \mathtt{\sim}\ |\ \texttt{/}\ ident$ 

$Range := float\ \texttt{;}\ (float)?\ |\ \texttt{;}\ float$

\ 

(16:27) Ok, så fik jeg lavet ovenstående syntaks. Dette var rigtignok noget nemmere.\,. .\,.\,Hov, ændrer lige $Set'''$ i nummer to underproduktion (eller bare produktion? (kan ikke helt 100 huske terminologien.\,.)) af $Set'''$-produktionen til $Set''$ i stedet for.\,. .\,.\,Hm, tja, men så burde jeg også ændre $Path$.\,. Okay, lad mig lige ændre det tilbage, og så i stedet finde ud af, hvad jeg gør i stedet.\,.  .\,.\,(16:41) Hov, det lyder mærkeligt, men er det ikke ligefør, at det (altså $Set'''$ i nr.\ 2 underproduktion) skal ændres til 
$Set$ i stedet.\,.\,??\,.\,. .\,.\,Nej, så kommer det til at blive svært at gennemskue --- også selvom det måske kunne give mening rent syntaktisk (men så skal man altså spidse for meget øjne, havde jeg nær sagt.\,.).\,. (16:44) .\,.\,Okay, så lad mig prøve at lave det om, så der skal være en parentes, hvis der er unions og/eller intersections før et slash.\,.


\ 

\ 

\ 

\ 

$Path :=  Set\ \texttt{/}\ |\ Set\ \texttt{/}\ ident$

%$Term := Category\ |\ Set\ \texttt{/}\ ident$

$Set := Set'\ (\texttt{(}\ Range\ \texttt{)})?\ (\texttt{[}\ int\ \texttt{]})? 
$ 

$Set' := \texttt{(}\ Set''\ \texttt{)}\ |\ 
	Set\ \texttt{/}\ ident\ \texttt{.}\ ident\ |\ 
	ident\ |\ 
	User
$ 

$Set'' := Set'''\ |\ Set'''\ \texttt{\&\&}\ Set''$ 

$Set''' := Set\ |\ Set\ \texttt{||}\ Set'''$ 

%(16:09) Ja, det blev noget nemmere, og nu skal jeg bare lige huske, hvordan jeg laver et tilde i monospace font.. ...(16:22) Okay, det er åbenbart: \texttt{$\mathtt{\sim}$}$.. ..Ah, eller bare \mathtt{\sim}..

$User := \mathtt{\sim}\ |\ \texttt{/}\ ident$ 

$Range := float\ \texttt{;}\ (float)?\ |\ \texttt{;}\ float$

\ 

\ldots Sådan.\,. (17:03)

(19:20) Jeg har nogle flere tanker/idéer. Men det kan godt være, at jeg mest bare tænker i aften (som jeg jo tit gør), og så venter med at skrive i morgen. Men jeg vil dog lige nævne, at det jo nok ikke passer, det med at serveren smider termer væk fra en intersection, inden den serveres til browseren, for det er jo nok i selve applikationen, at union-/intersection-algoritmerne foregår. Og dermed kan alle queries til databasen nok egentligt koges ned til: ``(user\_id, subj\_id, rel\_id)($Range$)[int]''.\,.\,!\,.\,. .\,.\,Tja, på nær selvfølgelig lige, når man query'er efter data, og måske hvis man kan full-text-search'e på f.eks.\ keyword strings.\,. (19:26)

(19:31) Hov, og det giver nok slet ikke mening at strække Sets ud som sin egen tabel for SemanticInputs.\,. Lad mig lige genlæse om B-træerne, bare lige for at være helt sikker.\,. .\,.\,Hm, det ser faktisk umiddelbart ud til, at det \emph{giver} mening, men mon ikke man kan finde en løsning, hvor bladene i B-træet kun gemmer et offset *(nej, en værdi som skal tilføjes et nøgle-offset, rettere) af den samlede nøgle, det må jeg lige finde ud af på et tidspunkt.\,. (19:36)


(06.03.23, 9:43) Det kan være, at det på et tidspunkt kunne give mening at bruge en hierarkisk database i stedet, hvis ikke kompressionsalgoritmen er så effektiv til at komprimere nøgler, som den kunne være. Men det kan nu også sagtens være, at en rel.\ database såsom MySQL vil holde helt fint. Pointen er i hvert fald bare, at jeg skal sørge for at gøre interfacet åbent over for, hvordan det grundlæggende lag er implementeret. Og nu hvor interfacet fra applikationslaget og til control- og databaselaget kommer til at være på formen ``(user\_id, subj\_id, rel\_id)($RatingRange$)[$ListRange$]'' (ja, jeg skal også lige have rettet lidt i grammatikken (syntaksen) ovenfor), jamen så kommer det til at blive nemt at gøre dette interface åbent overfor ændringer i backend-lagene, for det kræver bare, at ``(user\_id, subj\_id, rel\_id)'' gives i et mere fleksibelt format (end at man giver dem som longs). Og hermed tror jeg faktisk, at jeg vil genindføre typeflag, som så netop bliver et præfiks på user\_id og subj\_id i dette format. Jeg tænker, at begge disse så kan gives som nogle (sikkert næsten altid to) hexadecimaler, efterfulgt af et komma, efterfulgt af en ny (variabel!) række hexadecimaler, der giver resten af ID'et (og hvor alle ledende 0'er altså kan skæres væk!). Og for rel\_id kan man jo nok bare nøjes med ID-hexadecimalerne, og alt andet end lige lade typeflaget være underforstået (hvis det mangler). (9:55)

Og det kommer jo så ret meget til at definere den semantiske database (hvis vi ser bort fra data-gets m.m.), som herved altså kan ses som en abstraktion over den egentlige databaseimplementation, hvilken jo så netop har friheden til at ændre sig. 

Bemærk, at det med stisyntaksen, som jeg begyndte at beskrive i går, det foregår alt sammen i applikationslaget, og dermed kommer brugerne altså også på et tidspunkt til at kunne ændre alt dette fuldstændigt. (9:59)

I går fik jeg også tænkt noget mere over, hvordan brugerfladen skal gøres åben overfor brugerændringer og alt det, og jeg synes, jeg virkeligt er kommet frem til noget godt nu. Applikationen skal have en liste over JavaScript-funktioner i hukommelsen. Eller rettere, den skal have en struktur af ID--funktionspar, hvor ID'et så gerne faktisk skal være en reference til en JavaScript-program-term i databasen, hvor scriptet kan læses. Brugerne har ikke selv adgang til at ændre i denne liste, medmindre de aktivt installere en browserudvidelse til at gøre netop dette. Ellers er alle funktionerne i listen kun nogle, der er godkendt af (og muligvis skrevet af) hjemmesiden selv. I hver brugeres Term-kategori, som jo er kategorien, der indeholder alle termer (inklusiv sig selv i princippet) kan de så up-rate JavaScript-program-termer ud fra en passende relation. Alt dette er dog \emph{kun} implementeret oppe i applikationslaget, så relationen for at up-rate JavaScript-program-termer behøver ikke at være speciel i det grundlæggende lag, og vigtigere: kategorien af JavaScript-program-termer er ikke noget fundamental kategori. Disse ting er bare noget, som hjemmesiden sørger for er der fra start, men de er altså ikke noget, som det grundlæggende lag behøver at kende til. Nå, men ved så at up-rate JavaScript-program-termer for denne relation, så kan brugeren signalere til applikationen, hvilke JavaScript-programmer på listen gerne må bruges af applikationen til visning af diverse mængder og termer. Og hvis brugeren har installeret en browserudvidelse, som tilføjer flere funktioner til listen, så skal brugeren altså stadig signalere til applikationen herved, at denne også vil gøre brug af disse funktioner (altså ved at up-rate dem for omtalte, ja, vi kunne kalde den ``ønskede JS-funktioner''-relationen). Hvis en bruger så ``logger sig på'' en anden brugers semantiske træ, og ikke har de samme funktioner på sin egen liste, jamen så kan brugeren få en lille advarsel om, at der måske vil gå kludder i visningen, og at visningen i hvert fald muligvis ikke vil være, som at pågældende bruger selv vil se tingene. Okay. Lad mig skifte paragraf og så forklare, hvordan applikationen så videre benytter disse JS-funktioner. (10:17)

For alle kategorier, inklusiv den ydre ``Term-kategori,'' kan brugere så up-rate data, som de godkendte JS-funktioner så kan læse. I princippet er alt frit for, men man kunne jo passende gøre bruge en vis standard fra start af, som siger at hver datapakke også i starten angiver ID'et på den JS-funktion, som er tiltænkt til at benytte den indeholdte data, bare for en god ordens skyld. (10:20) Dette data kan så beskrive, hvordan JS-funktionen skal opbygge forskellige visninger i applikationen --- f.eks.\ forskellige søjler, hvis man gerne vil have en applikation, der følger, hvad jeg forestillede mig, inden jeg kom på det her med ``filstierne'' (som jeg dog nu ikke er helt så sikker på). 

Selvom man i princippet kan gøre hvad man vil herfra, og dermed i princippet også godt kan bryde ud af denne standard, så tror jeg at følgende standard også vil være rigtig fornuftig til at starte med. Den går på, at man siger, at hver JS-funktion alt andet end lige skal tage ansvar for hele applikationens visning. Med andre ord altså at man alt andet end lige kun gør brug af én JS-funktion ad gangen. Så jeg forestiller mig altså nogle JS-funktioner, som sammen med den efterfølgende data, der gives til dem --- som jo godt kan være både HTML- og CSS-kode! --- hver især alene kan stå for hele applikationens indretning. Og hvorfor forestiller jeg mig så, at man alligevel skal have en hel liste af dem?\,. Jo, fordi her JS-funktion nemlig også skal være ansvarlig for, at den ikke kan gives noget data, som for den til at opføre sig malicious.(!) Og hermed vil de tidlige JS-funktioner altså nok være ret skrappe, hvad angår det data, som gives dem, nemlig ved at parse dem ret hårdt for f.eks.\ HTML-tags, der kan være farlige, osv. (10:30) Men når man så langsomt gør JS-funktionerne mere og mmere åbne (uden at komme til at gøre dem farlige (forhåbentligt)), så vil det jo være smart, hvis man også beholder de gamle. Så det vil sikkert blive sådan i starten, at hver ny JS-funktion tilføjet til listen vil udvide en gammel funktion, sikkert sådan at hvis den nye funktion fik det samme data, så ville den opføre sig på samme måde. Sammenlagt vil vi derfor nok få en række eller et træ af JS-funktioner, hvor børnene ofte er bagudkompatible med deres forældre. Denne liste er som sagt en som hjemmesiden selv udelukkende står for at bestemme, på nær hvis brugerne stoler på deres egen evne til at verificere JS-funktioner, og gør brug af browserudvidelser til at tilføje ting til denne liste (og dermed måske være på forkant af de andre brugere). Men derfor kan det jo sagtens være, at disse brugere også gerne vil holde sig til de samme principper, nemlig med at se alle JS-funktionerne som et træ, hvor børnene i reglen gerne skal være bagudkompatible med deres forældre. (10:36)

Og derfor, når en bruger ``logger sig på'' en anden bruger, der har tilladt flere (måske nyere) JS-funktioner, som den på-loggende bruger ikke selv har godkendt (enten via up-rates eller ved ikke at have installeret den fornødne browserudvidelse), så kan det jo dermed alligevel blive muligt, at brugeren stadig kan se meget af det samme, som ejeren af ``kontoen'' ser, netop pga.\ den mulige bagudkompatibilitet (fordi den på-loggende brugers JS-funktion stadig kan indsætte de fleste ting, som ``ejeren af kontoen'' ville få vist). (10:40)

Okay, hermed har vi så et system, hvor brugerne i princippet selv kan bygge oven på og ændre ad libitum. Lad mig så forklare lidt mere om, hvad jeg forestiller mig, at de tidlige JS-funktioner skal gøre. Jeg forestiller mig, at brugere så for hver kategori (ikke bare for Term-kategorien) kan brugere up-rate %..
HTML- og CSS-data for forskellige passende relationer til, hvordan forskellige felter og lister skal vises for elementerne i kategorien. Vi kan jo starte med at tænke på, hvordan elementerne skal vises i listen, man får serveret, når man bader om kategoriens elementer. Hertil kan der så være en relation der siger ``desired HTML for showing elements,'' som man så kan up-rate HTML-data til. Der kan også være en relation, hvor man kan ændre selve den omkringliggende HTML for elementvisningen. Her kunne man f.eks.\ forestille sig, at når brugeren klikker sig ind på elementmængden til kategorien, så vises underkategorier faktisk også i en liste til venstre for elementerne. Og dette kan man sagtens implementere via denne ``omkringliggende HTML til elementvisningen''-relation, for hver HTML-template har nemlig inden begrænsninger på --- udover de begrænsninger der er sat med vilje selvfølgelig --- hvad HTML'en kan query'e serveren efter; det behøver f.eks.\ ikke kun at være elementer til kategorien, bare fordi disse ligesom er temat / den centrale del af denne visning. (11:00) 

Lad mig lige allerede nævne her, at en vigtig pointe med det hele er så, at en underkategori så altid arver indstiller fra en overkategori, medmindre at brugeren har valgt (via up-rates), at underkategorien selv skal overskrive de gamle indstillinger og tilføje nye indstillinger til sine underkategorier. .\,.\,Ja, det er faktisk ikke så meget mere at sige om dette nu her, men lad mig bare lige understrege, hvor vigtigt denne pointe er for det hele ved at slutte denne paregraf af med et udråbstegn. ! (11:03) *(11:08) Nå jo, jeg havde mere at sige om det. En vigtig ting at forklare er, at kategorier ikke arver fra deres ``definerende overkategorier,'' som jeg har kaldt dem, nødvendigvis, men fra deres overkategorier i den nuværende $Path$.\,! Dermed kan visningen for en kategori altså ændre sig afhængigt af, hvordan brugeren navigerede hen til kategorien! (11:11) 

Nå, og hvad angår den indre element-HTML, så vil denne jo også indeholde knapper, som brugeren kan trykke på (og med specifikationer af, hvad der så skal ske ved tryk på disse knapper). Dette kan jo så f.eks.\ være at udfolde flere felter for elementet (og/eller at vise mere af diverse tekstfelter, som måske er afkortet i en umiddelbare listevisning). Knapperne kan så også specificeres (alt sammen via den samme HTML-data, nemlig den omkring ``den indre HTML for elementerne'') så de åbner ny sider. (11:08) .\,.\,(11:11) Jeg forestiller mig så nu, at nye sider generelt åbnes ved at angive en $Path$ til applikationen, og altså bede applikationen om at åbne denne sti. 

Lad mig i den forbindelse forresten indskyde, at selvom de her stier er implementeret ind i applikationen, og at applikationen godt kan køre på samme side, så forestiller jeg mig dog, at $Path$s også gerne skal kunne opdateres vi GET-metoden, nærmere bestemt således at brugeren kan toggle mellem GET og POST metoden, alt efter om brugeren vil have, at browseren gemmer navigeringshistorikken eller ej. (11:15)

Nå, men er det så kun de to relationer, nemlig den om ``omkringliggende'' og ``indre'' HTML for elementvisningen, som brugerne skal (kunne) up-rate HTML-data for? Nej, for en kategori har jo ikke kun `.Elements'/`.e' som sin eneste relevante relation. Det samme skal kunne gøres for `.Subcategories'/`.s'-visningen (hvor man altså også kan dele det op i indre og omkringliggende HTML, hvis man vil). Og der er også andre relationer, f.eks.\ er der jo selve alle disse relationer, som bruges til at vælge HTML-data (eller anden data; det behøver slet ikke at have form som HTML; det kommer alt sammen bare an på, hvordan JS-funktionen(/funktionsfamilien), man bruger, er defineret). For ikke at få et uendeligt antal relationer til dette, så kunne man så have én relation til at indstille præferencerne for visningen af disse lister, som nemlig så også kan bruges til visningen af selve den liste, hvor man indstiller visningen for sådanne lister (sådan at det valgte (mest up-ratede) visningsdata for denne relation altså også kommer til at definere visningen for relationen selv). (11:24) 

.\,.\,Bum. Og det forklarer sådan set allerede meget godt, hvordan jeg nu forestiller mig, at fundamentet i applikationslaget skal være opbygget på. Nu bør jeg så lige prøve at omdefinere $Path$en en gang (og give nogle forklaringer på ændringerne), og så vil jeg ellers begynde at ændre i min databaseimplementation.\,. (11:26)

.\,.\,Hov, lad mig lige sige, at jeg sikkert kommer til at lave mange ændringer i denne syntaks løbende. Men det gør ikke så meget, for det.\,. Nå ja, det skulle jeg måske også lige overveje: Er det samme JS-funktion, der skal parse $Path$en, når siden opdateres med en ny sådan $Path$ (enten via GET- eller via POST-metoden)?\,.\,. .\,.\,Hm, det synes jeg faktisk på en måde, men lad os så faktisk sige, at der i stedet for at være tale om en enkelt funktion for hver ID i JS-funktions-listen, så faktisk skal være tale om et helt namespace af funktioner, nemlig således at nr.\ to element i hver tupel i denne liste (nemlig hvor første element så er JS-program-term-ID'et) så er.\,. Hm, nå, det er faktisk også lige meget, hvad strukturen helt præcis kommer til at blive, men pointen er bare, at hvert samlet element (om så disse er tupler eller ej) i omtalte JS-liste altså definerer et helt namespace af funktioner, som applikationen kan benytte, hvis brugeren også tillader denne brug via up-rates for ``gyldig JS''-relationen for Term-kategorien. (11:35)

Nå, men lad mig så sige, at nu forestiller jeg mig en syntaks for $Path$ mere a la:



\ 

$Path :=  Set\ \texttt{/}\ |\ Set\ \texttt{/}\ ident$

%$Term := Category\ |\ Set\ \texttt{/}\ ident$

$Set := Set'\ (\texttt{(}\ RatingRange\ \texttt{)})?\ (\texttt{[}\ ListRange\ \texttt{]})? 
$ 

$Set' := \texttt{(}\ Set''\ \texttt{)}\ |\ 
	Set\ \texttt{/}\ ident\ \texttt{.}\ ident\ |\ 
	ident\ |\ 
	User
$ 

$Set'' := Set'''\ |\ Set'''\ \texttt{\&\&}\ Set''$ 

$Set''' := Set\ |\ Set\ \texttt{||}\ Set'''$ 

%(16:09) Ja, det blev noget nemmere, og nu skal jeg bare lige huske, hvordan jeg laver et tilde i monospace font.. ...(16:22) Okay, det er åbenbart: \texttt{$\mathtt{\sim}$}$.. ..Ah, eller bare \mathtt{\sim}..

$User := \mathtt{\sim}\ |\ \texttt{../}\ ident$ 

$RatingRange := float\ \texttt{;}\ (float)?\ |\ \texttt{;}\ float$

$ListRange := int\ |\ int\ \texttt{..}\ int$

\ 

Desuden forestiller jeg mig også (foruden det med at `.s/' skal kunne forkortes til `/' givet visse omstændigheder, jeg har snakket om), at man skal kunne definere macro-variable, sådan at gentagne første dele af $Path$s i stedet kan defineres som en macro, som så både brugeren kan bruge, hvis denne vil skrive en $Path$ selv, og som applikationen kan bruge, når denne vil vise/printe en $Path$ (måske den pågældende for ``siden'') for brugeren. (11:45, 06.03.23)

(11:52) Nå ja, jeg har faktisk også lige et par flere ting, jeg skal nævne omkring syntaksen. For det første så tænker jeg nu, at manglen på $\texttt{[}\ ListRange\ \texttt{]}$ skal signalere, ikke den fulde mængde, men at serveren bare skal servere den første og bedste term fra mængden (altså den med højest rating --- eller lavest, hvis $RatingRange$ startere med den laveste float af de to). Så manglen på $\texttt{[}\ ListRange\ \texttt{]}$ svarer altså med andre ord til $\texttt{[}\ 0\ \texttt{]}$ (eller $\texttt{[}\ 1\ \texttt{]}$ hvis man 1-indekserer). 

En anden ting er, at jeg også forestiller mig, at ting såsom domæne- og/eller syntaks-begrænsninger på hrefs også skal implementeres via JS-funktionen, eller rettere JS-biblio-teksprogrammet, bør vi hellere sige. Men her skal brugere jo også gerne kunne ændre disse indstillinger (i hvert fald avancerede brugere), og her forestiller jeg mig så, at dette kan ske ved at brugen uploader præference-data specifikt også til Term-kategorien (for man må regne med at disse begrænsninger skal være globale og ikke bare tilknyttet en bestemt underkategori). Og så kan jeg i øvrigt også lige nævne i denne forbindelse, at det med at bruge `$\texttt{../}\ ident$' for skift-bruger-syntaksen jo faktisk giver god mening rent intuitivt, for så starter alle $Path$s altid på brugerens egen Term-kategori. Og de globale begrænsninger (bl.a.\ på JS-programmer og hrefs) man sætter her kommer så også til at gælde, når man går over på andre brugeres Term-kategorier, nemlig fordi man starter på sin egen. Dette er selvfølgelig rent for bruger-intuitionens skyld; syntaksen er jo bare et symbol på, hvad der foregår. Men i forhold til at forstå, at når man kommer fra en given overkategori, så vil de følgende kategorier arve indstillinger fra denne, jamen så giver de jo god mening, at man altid starter på sin egen Term-kategori, for alle kategorier vil jo altid arve ting fra denne kategori (om ikke andet så i hvert fald begrænsninger på JS-programmer). Følte lige, det var værd at nævne også. (12:05, 06.03.23) 

(14:59) Jeg tror faktisk, at lader typeflaget være en (fixed) streng af tre chars i query-formatet i stedet (som altså ikke er begrænset til hexadecimal-karakterer, men kun til ASCII-karakterer). For så kan jeg altid indføre en ny standard oveni senere, der også kan bruge færre karakterer. 

Desuden mangler jeg faktisk at nævne noget ret vigtigt (som jeg jo faktisk lagde lidt op til i går), og det er, at brugere også simpelthen skal kunne vælge bruge andre brugeres (og selvfølgelig særligt bruger\emph{grupper}s) indstillinger til de kategorier, de har lyst til. Dette foregår så ved, at de simpelthen for kategorien vælger at benytte brugergruppens (lad os bare sige brugergruppe kun, selvom en bruger i princippet også kan bruge en anden bruger, men det vil være meget mere almindeligt og anvendeligt at benytte bruger\emph{grupper} her) stemme, når det kommer til at up-rate input-data til JS-programmet (som dog stadig skal godkendes specifikt af brugeren selv), i stedet for sig selv. Ja, og brugeren kan også bruge en blanding af sin egen stemme og en brugergruppes stemme. Så med andre ord: Brugeren kan stadig vælge at up-rate diverse input data til en given kategori, men brugeren skal også have mulighed for at ``få andre til at hjælpe sig med dette arbejde'' så at sige, nemlig ved for en speciel relation --- som kunne hedde noget a la: ``desired users to decide applikation preferences (for this category)'' --- at rate andre brugere eller brugergrupper op, enten alene eller sammen med sig selv. Og alt efter hvor meget ratingen overstiger en vis tærskel (f.eks.\ 0), kan den samlede stemmevægtfordeling så være herefter. Dette giver så signal til applikationen, at alle (HTML-)input-data-relationer (som jeg snakkede om her lidt tidligere i dag) skal have deres mængder vægtet med denne vægtfordeling. Hermed kan man altså få en applikation, der kan forbedre opdatere sit udseende også selvom man ikke selv gør noget aktivt, men nemlig fordi en af de valgte brugergrupper så up-rater nogle andre indstillings-(JS-)input-data til kategorien. Og husk at disse indstillinger kan have indflydelse på alle de termer og mængder, man kan navigere hen til fra denne kategori (og dermed alt hvad applikationen kan vise en, når man har navigeret fra denne kategori). Jeg har så nævnt at underkategorier dog godt kan overskrive indstillinger fra forældrene, og her kan man jo så passende gøre det sådan, at det også vil være den samme vægtfordeling, der skal gøre sig gældende i spørgsmålet om, om en underkategori til den givne kategori skal overskrive dennes indstillinger (og selvfølgelig også hvordan de i så fald skal overskrives). Med andre ord vil det være naturligt, at alle underkategoriernes data-input-relationer også arver stemmevægtfordelingen fra den givne overkategori, altså den vægtfordelingen der valgtes ved at rate brugere og brugere grupper ud fra en relation (med den givne overkategori som subjekt), der siger ``desired users to decide applikation preferences (for this category --- and its subcategories!)''.\,.\,:) (15:21)







\section{Hvad jeg gerne vil sigte efter med det basale applikationsdesign}

*[(25.02.23)] (11:50) Jeg har tænkt lidt over, hvordan udgangspunktet skal være for applikationsbrugerfladen, eller rettere hvad man gerne bør sigte imod (for betaversionen behøver ikke at inkludere det hele). Her i formiddages fik jeg også lige nogle gode nye idéer, som jeg vil fortælle om lige efter denne sektionsintro. Jeg regner så med at prøve at gå igennem mine seneste tanker omkring emnet, og så vil jeg nok lade sektionen (denne) stå åben efterfølgende, så jeg kan vende tilbage med flere idéer, til den grundlæggende opbygning af applikationen (eller i hvert fald udgangspunktet for den). Jeg vil så også.\,. Hm, enten vil jeg starte en ny betaversion-sektion, eller også vil jeg bare føje til den forrige, men uanset hvad, så vil jeg i hvert fald gå videre til, når jeg har skrevet om ting til denne sektion, gå over til så at skrive om, hvilke nogle hjørner jeg så kan skære i starten. For den første version af hjemmesiden behøver altså ikke at inkludere alle de detaljer, jeg beskriver her, og derfor vil jeg altså have en separat sektion, hvor jeg så skriver om, hvilke nogle ting i applikationsbrugerfladen, jeg \emph{ikke} vil implementere til at starte med. (11:58)

Og nu vil jeg altså lægge ud med at beskrive de idéer, jeg har fået her i formiddags, og så vil jeg i øvrigt også snakke om vigtigheden i at bruge ``kategorier.'' .\,.\,Hm, på den anden side så har jeg vist ikke snakket så meget om kategorier overhovedet, så lad mig egentligt tage det mere fra grunden i stedet, og så snakke om kategorier først.

Det kan virke lidt underligt, at introducere ``kategorier'' som noget rigtigt grundlæg-gende; næsten ligeså grundlæggende som `prædikater' og `relationer.' (Dog ikke helt længere, for `kategorier' bliver ikke længere en del af det grundlæggende (database-)lag, men det bliver i stedet bare noget virkeligt grundlæggende i applikationslaget.) Hvorfor ikke snakke om `mængder' eller `klasser;' begreber som er meget mere ``matematiske'' så at sige?\,. Jo, fordi begrebet om `kategorier' har en helt særligt fordel. Vi kan se kategorier som en slags lav-niveau repræsentation af mængder (hvis vi altså tager udgangspunkt i \emph{standardmodellen} for mængdelære), bare hvor kategorier dog godt kan indeholde sig selv. For vi kan nemlig se dem som ``kasser'' med skilte på, hvor vi så kan putte referencer til andre ting --- eller til den givne kasse selv --- ned i disse kasser. Nå, men at de kan indeholde sig selv, og at man derfor kan have en ``kategori af kategorier,'' som kan indeholde sig selv, er nu ikke forcen ved kategorier. Den store fordel kommer, når vi begynder at benytte begrebet om `underkategorier.' For hvis jeg siger, at $x$ er en god underkategori til $y$, så er det allerede en rimelig naturlig fortolkning af den sætning, at jeg mener at $x$ er gavnlig at se (tidligt) i en liste, hvis man som bruger beder om at se $y$'s underkategorier. Men hvis jeg derimod f.eks.\ sagde, at $x$ er en god \emph{undermængde} af $y$, jamen så ville folk i almindelighed rynke på panden og sige: ``jamen, alle korrekte undermængder af $y$ må da være lige gode, ikke?'' Selvfølgelig kan man prøve lave en specifik relation, der siger lige præcis siger: ``$x$ er gavnlig at se (tidligt) i en liste, hvis man som bruger beder om at se $y$'s underkategorier.'' Men pointen er så bare, at man får utroligt meget forærende (i forhold til hurtig intuitiv forståelse), hvis man så også bare kalder det `kategorier' og `underkategorier' i stedet; så er der langt kortere for brugerne til at forstå, hvad pointen med underkategorierne er! (12:13) %..Føler mig effektiv på tasterne i dag..

Så kategorier skal altså være en helt central ting i applikationen, forestiller jeg mig --- i hvert fald når folk vil lave semantiske søgninger, og ikke bare vil søge på keywords (hvor jeg i øvrigt nu tænker at benytte et full-text index på String-typen til gavn for dette (i stedet for at brugere manuelt skal bedømme relevante keywords --- det kan de også, men med et full-text index er vi meget hurtigere i gang fra start)). Og ja, man kan i princippet så starte med `kategorien over kategorier' som den mest grundlæggende ting (.\,.\,hvor man så må regne med, at den selvsamme kategori ikke bliver ratet højt som gavnlig underkategori, btw). Herfra kan man så søge efter underkategorier ved et følge træet ned herfra (imod hvad man søger efter) ved at følge kanter, der repræsenterer en grundlæggende `.subcategory='-relation. Nå man så er kommet til en underkategori, der virker lovende, så kan man så vælge at få vist termer, der hører til denne underkategori (i stedet for at bede om yderligere underkategorier). Disse termer kan så herfra ordnes og filtreres ud fra prædikater. Og så kan man altså forhåbentligt finde den eller de ressourcer, man er interesseret i.

Dette beskriver nok den mest almindelige semantiske (\emph{manuelle}) søgning, man kan forestille sig. Men der er også andre usecases, hvor brugerne har brug for nogle andre relations-kanter at følge. Lad mig lige tænke over, hvilken én jeg vil skrive om først, og så vende tilbage.\,. (12:26)

%I øvrigt, hvad angår navn, jeg kan egentligt ret godt lige SemNet, men det er nu også bare næsten lidt for.. 00'er-agtigt.. *Det er et okay navn. Jeg har også i tankerne: SNet, S-Net, s.net, sem.net, sema.net..

%..Hm, en af mine idéer (den vigtigste) her fra i formiddags er, at man nok kan implementere bruger-dataen simpelthen via kategorier og almindelige ratings omkring disse. Nu overvejer jeg, så om kan gøre noget tilsvarende for filtre/prædikatvægtninger, eller hvad man nu lige skal gøre der.. (12:55) ..Jeg er i øvrigt kommet frem til, at filtre--vægtninger nok skal åbnes som en barne-søjle, der så kommunikerer direkte til forældersøjlen (og nok kun denne), når brugeren laver opdateringer i filter--vægtnings-præferencerne, men det skal jeg nok komme ind på.. ..Hm, jeg tænker jo forresten, at filter--vægtnings-prædikaterne bare kan være den selvsamme liste, som vises for `relevante prædikater' til termen.. ..Hm ja, og så er det bare spørgsmålet, om, og i så fald hvordan, indstillingerne til disse prædikater skal gemmes.. ..Hm, og hvad med grundfiltrene..?.. 

%...Hm, brugere skal nok bare være entiteter fra starten, og så bør brugerne bare advares mod at lave offentlige profiler med en spcifikt identitet angivet, medmindre man er klar på at blive vurderet af andre. Jeg skal i øvrigt også lige finde ud af, hvordan brugere sletter.. ah, men hvis hver dataentitet bare gemmer uploadende bruger, så kan forfatter-botten jo bare slette felt-vurderinger om uploadet, hvis pågældende bruger ønsker det.. Ja, det må være fint nok.. 
%Lad mig i øvrigt lige sige, at min anden idé fra i formiddags handler om, at der både skal være en ".related predicate=" (er gået væk igen fra at bruge ':') -relation \emph{og} en ".subcategories of related predicates="-relation for hver term (og særligt hver kategori-term). På den måde kan en kategori altså i praksis bruges som sig selv og som den afledte kategori af relaterede prædikater (til den kategori) på én gang, uden at man først skal navigere fra førstnævnte til sidstnævnte kategori for at nå frem til "subcategories of related predicates," når det er det, man ønsker. Med andre ord bliver den afledte "related predicates"-kategori altså nu en slags "anonym kategori," der ikke behøver at oprettes, men som bare automatisk følger med hver kategori (og andre typer termer), nemlig ved at man konstruere omtalte relationer, som så at sige springer det led over, at man ellers først skulle navigere til denne afledte kategori (som så nu er "anonym"/underforstået i stedet). ..Men dette skal jeg altsammen også skrive om i den renderede tekst. Nu vil jeg dog først tage en gåtur (i det virkeligt fine vejr *(he, nå, det var faktisk ikke særligt meget sol at komme efter, og det var endda også lidt koldt og blæsende --- så endda nogle (meget) små snefnug til sidst på turen)) og tænke over filtrene/vægtningerne... (13:46)
%... (14:35) Okay, jeg tror jeg ved, hvordan det skal være med filtrene og grundfinltrene. Det bliver simpelthen også, at brugerne rater filtre op under en grundfilter-kategori. Og så kan applikationen bare vide, at hvis de rater over en vis (væsentligt større end 0) tærskel, så skal applikationen initiere dem fra start af. Og hvis de er lige under den tærskel, så skal de bare vises, når brugeren går ind i, hvad der så kommer til at svare til grundfilter-indstillingerne, men som altså nu også bare er nogle termer ordnet i kategorier og underkategorier via (i dette tilfælde specifikt brugerens egne) ratings. Og så skal der også bare være en anden form for kategori, som handler om både at sætte filtre og vægtninger, men hvor det så er meningen, at de samme prædikater som benyttes her også vises, når brugeren indstiller et filtrene--vægtningerne for en specifik kategori/term. Så brugeren kan altså bryde disse indstillinger midlertidigt --- og hvis brugeren vil, kan denne jo også bare gemme ændringerne som en ny start-indstilling.. Ja, lad mig kalde det "grundindstillinger" og "startindstillinger," disse to forskellige ting. Og så er forskellen altså, at "grundindstillinger" derimod ikke vises, når brugeren skal lave en specifik indstilling for en term/kategori, men i stedet skal brugeren altså helt ud og ændre i sine grundindstillinger, nemlig i en del af brugerens samlede semantiske træ, der ligger mere yderligt, hvis brugeren vil ændre disse. Nå, nu skrev jeg godt nok, at man skulle have specielle "kategorier" med hhv. gundinstillinger og startindstillinger, men idet jeg skrev det, kom jeg til at tænke på, at det jo nok hellere skal implementeres via specielle relationer, som tager kategorier som subjekt. For på den måde kan brugeren lave forskellige grund- og start-indstillinger for hver kategori (hvor underkategorier skal arve overkategoriens indstillinger), og det var nemlig en del af mine tanker omkring det. Så ja, det må være sådan i stedet. Og hermed bliver disse indstillinger altså også bare en del af det normale semantiske træ (som udspringer af 'kategorier af kategorier'), ligesom at 'relevante prædikater' også bliver det samme. Så når brugeren vil ændre på, hvilke grundindstillinger, hvilke startindstillinger og hvilke relevante prædikater skal vises for en given kategori og alle dens underkategorier, så gør de det altså bare ved at rate dertil egnede relationer (med pågældende ønsker som relationsobjekter i disse) med kategorien som subjekt. Og hvis brugeren så vil ændre i sine indstillinger, eller hvis denne eksemepelvis vil søge i prædikater, som brugeren har brugt før, jamen så kan de bare vælge den "brugergruppe," der kun består af dem selv, når de vil query'e det semantiske træ. I øvrigt kan brugeren nemlig også oprate de kategorier, der indgår i alt det her, sådan at brugeren for denne visning (der kun viser termer, som brugeren selv har ratet) kun ser alle de relevante kategorier, og altså ikke en lang liste som også inkluderer alle mulige kategorier, som brugeren ikke har gemt nogen indstillinger for. (14:57)
%*Nå ja, jeg glemte lige at nævne, hvad jeg kom til at tænke på sidst imens jeg skrev dette, nemlig at der dog stadig gerne må være et "arbejdsbord" i applikationen, som jeg har tænkt mig, men hvor dette arbejdsbord så bare er helt ustruktureret, således at det bare er de nyeste tilføjelser, der bliver vist først, og hvor appkilaktionen måske heller ikke nødvendigvis gemmer ting i denne liste imellem sessioner (ikke som standard i hvert fald), men at hvert arbejdsbord altså bare glemmes, når en session lukkes. (15:13)

(14:57) Jeg har nogle gode noter ude i kommentarerne over denne paragraf (og efter den forrige renderede paragraf). Jeg har dog også i sinde at gentage de ting her i den renderede tekst i denne sektion. Først tilføjer jeg dog lige nogle få flere kommentar-noter lige under denne paragraf (og før den næste renderede paragraf). 

%..(15:00) Hm, jeg vil bare i hvert fald for det første lige nævne, at dataentiteter selvfølgelig bare "slettes" ved at dataen i dem nulles. Nå ja, og så vil jeg også lige nævne, at hvis nu man gerne vil lave en forælderkontrolleret applikation over dette system, jamen så må man næsten lave en slags browser, der kun kan starte på denne sem-net-hjemmeside, og hvor man så \emph{ikke} kan ændre i grundfiltrene (i hvert fald ikke i visse af dem). Og samtidigt bør man så have nogle specifikke whitelistede href-domæner, som er de eneste brugeren må følge, også selv når brugeren har navigeret over til de hjemmesider (så børnene ikke kan navigere videre til forbudte domæner fra de domæner heller). (15:04)

\ldots (15:19) Hm, nu hvor jeg har skrevet så meget ude i kommentarerne (dog i et ikke særligt detaljeret sprog, så jeg skal helt klart skrive det igen her i den renderede tekst på et tidspunkt), så lad mig bare lige nævne, hvad der var min idé nummer to her fra i formiddags, og så kan jeg lige sige nogle flere ting om den også. Jeg forstiller mig, at alle termer, og særligt kategorier, skal have to relationer, som man kan gøre brug af (og som altså nok især er gavnlige for kategorier), nemlig `.relevant prædikat=' (er nemlig gået væk fra at bruge `:') og `.underkategori af relevante prædikater='. På en måde ville disse lister egentligt være mere naturlige at vise som børn af en kategori, som kunne hedde: `kategori over relevante prædikater til kategori $x$,' hvor $x$ så ville være den kategori, man startede på. Men ved brug af de to omtalte relationer kan vi altså springe dette mellemled over, således at brugerne altså ikke behøver at oprette denne afledte kategori for hver af de mere normale kategorier. Nå, men imens jeg skrev dette, kom jeg så til at tænke på, at dette faktisk ikke relaterer sig så direkte til den ting, som jeg gerne ville nævne, alligevel (og som jeg ikke har nævnt ude i kommentarerne heller). For den ting handler i stedet om en tredje relation, som bare kunne hedde `.relevant kategori='. Tanken er så, at hvis man eksempelvis vil se en liste over kendte hunde, jamen så kunne man eksempelvis starte med at navigere hen til en zoologisk kategori, og så finde termen `hund.' Men fordi man ikke er interesseret i de generelle koncept `hund' (og generelle informationer om hunde), så kunne man så måske være heldig her at finde en ``relevant kategori'' af `kendte hunde' (og hvis ikke, kunne man jo så selv tilføje denne). En alternativ rute ville jo være fra starten af at vælge en overkategori af specifikke dyr, men det vil jo være rigtigt godt, hvis der er mange gode veje i det semantiske træ til, hvad man leder efter. Så dermed kunne denne relation altså også blive gavnlig. Bemærk i øvrigt også, at denne relation også kan bruges på kategori-termer, nemlig som en måde at finde relaterede kategorier til en given kategori (f.eks.\ hvis nu man står på kategorien `hunde' i stedet i vores eksempel), som altså ikke hverken er under- eller overkategorier til kategorien, men som er relateret mere ``søskendeagtigt'' eller mere ``horisontalt'' så at sige, hvis vi forstiller os træet som groende nedad (selvom jeg nu tænker det meget som groende mod højre i hovedet.\,.). (15:38)

%..Lad mig også lige hurtigt nævne herude i kommentarerne, at jeg virkeligt synes godt om, at brugerne nu får meget større encitament til at benytte kategorierne (og putte ting i kategorier), fordi dette nu jo hjælper deres egen brugermuligheder direkte. Og dermed så bliver der altså en endnu mere forstærket sammenhæng mellem, hvad jeg ser som systemets ben i form af `semantisk strukturede ressourcer' og så til `tag-rating'-benet, som (i.e. sidstnævnte) jo nok er det ben, hvor meget af brugerinteressen ligesom skal/vil udspringe af i starten. Og det er nemlig rigtig dejligt, hvis brugerne så også hurtigt kommer i gang med at få glæde af det andet ben i idéen, nemlig benet omkring den semantiske træstrktur af ressourcerne. I øvrigt kan jeg nævne, at jeg også ser et trejde "ben" på næsten lige fod med de to første, og det er benet, der handler om "brugerdrevne algoritmer --- bygget på anonym og ikke mindst fuldstændig gennemsigtig (og frivilig) indsamling af data." Jeg ved godt, at der er flere elementer i det ben, men ja, når man samler disse dele af idéen (altså dem jeg nævnte her inden for gåseøjnene), så synes jeg altså, at dette også udgør et vigtigt ben i den samlede idé, som kan ses på ret meget lige fod med de to første. (15:47)


(07.03.23, 11:01) Nå, jeg har faktisk skrevet en del mere om applikationsdesignet, og også om (vigtige) ændringer i det grundlæggende system i den forrige sektion, som egentligt hedder ``mål for betaversionen'' bare. Den version er altså pt.\ hvor de nuværende planer for hjemmesiden og systemet er bedst forklaret. Og nu tænker jeg faktisk at gøre noget lidt fjollet, og det er at afslutte denne sektion med at forklare om ``mål for betaversionen.'' Nærmere bestemt har jeg tænkt mig lige at notere nogle få ting om, hvordan jeg tror, jeg vil starte med at indrette brugerfladen i første omgang.

En vigtig ting er, at jeg nok vil prøve at fokusere meget på den relation til Term-kategorien (se forrige sektion for at forstå, hvad jeg snakker om), hvor brugere skal godkende href-domæner og -syntakser(/grammatikker). Og ja, lad mig lægge vægt på syntakser/grammatikker, for jeg forestiller mig, at dette skal ske specifikt ved at brugerne kan up-rate RegEx-koder for, hvilke URLs er okay at hente ting fra. Måske kan man btw også indføre en modsvarende blacklist-relation til at blackliste URL-syntakser, det vil måske faktisk være en ret god idé. 

Angående JS-biblioteket, så vil jeg bare have ét i JS-listen (se forrige sektion), som gør at brugere kan definere HTML for elementerne, hvor de kan sætte attributter stort set ad libitum, og hvor de kan bruge næsten alle tags på nær script-tagget, men dog hvor alle hrefs kun bliver aktiveret, hvis brugeren har whitelisted (og ikke samtidigt blacklisted) en URL-syntaks som URL'en falder ind under. Der skal så også være særlige attributter, der fortæller applikationen, at den indre HTML i tagget skal AJAX-get'es vi en query til databasen, nemlig når det kommer til ``felt-data'' eller data-entitets-data. Så længe jeg bare kan få det sådan, at brugere kan definere HTML, der selv query'er for elementets felt-data eller data-entitets-data (eller anden ``definerende data''), og hvis applikationen også kan get'e ressource-instanser fra andre whitelistede hjemmesider (og det skal jeg lige finde ud af, hvordan jeg gør --- forhåbentligt bare via AJAX, hvor en URL med et vilkårligt domæne forhåbentligt kan gives), så er jeg tilfreds. 

Jeg forestiller mig så faktisk, at denne HTML i starten kun skal være for, når man har klikket sig ind på et element, enten så element-boksen udvides i en liste, eller så man kommer hen på elementets egen side --- så to HTML-definitioner skal der være plads til. Og når elementerne vises i en liste, så for man simpelthen bare vist deres definerende data, i.e.\ deres navn og deres forælderkategori. Og de samme ting skal gælde for andre relationer såsom `.s'/`.Subcategories'. Så ja, til hver relation skal brugere altså.\,. .\,.\,Hm nej, lad mig sige, at for Term-kategorien kan man up-rate HTML til diverse relationer udover `.e'/`.Elements', og så er det bare de to udgaver af element-visningerne, som man så er fri til at justere for hver kategori (og altså ikke bare for `Terms'). (11:27)

Jeg tænker så, at der bare skal være en liste over visningsindstillinger (hvilket altså hver især bliver et par.\,.).\,. Nej vent, der skal være tre HTML-indstillinger mindst fra start, for man skal også kunne indstille, hvordan elementer vises i lister allerede fra start af. Ok. Nå, men hver ``visningsindstilling'' kommer så til at bestå af mindst tre HTML-definitioner. Og jeg tænker så, at der bare skal være en lodret liste til venstre, hvor alle visningsindstillinger er indeholdt, men hvor den øverste på listen altid er den mest relevante, nemlig den som svarer til den sidste kategori med visningsindstillinger tilknyttes sig i ens $Path$. Og den næste kan så være den sidste kategori med visningsindstillinger, hvis man følger termets ``definerende path,'' hvis disse to muligheder altså giver noget forskelligt. (Og her er den ``definerende path'' altså den, man får ved hele tiden at følge forælderkategorierne tilbage til `Terms'). Men ja, alle de resterende visningsindtillinger kan også bare vises neden under disse én til to mest relevante i samme liste. 

Jeg vil også bare lave en liste med selekterede termer, som jeg har haft tænkt mig før. Så kan brugerne trykke på dem for at komme hen til deres term-sider (igen), eller de kan selektere dem, hvis de skal indsætte noget, eller hvis de skal konstruere en ny mængde at query'e for. Og når vi taler om mængder, så skal der også bare være endnu en liste (og jeg tænker at alle de tre nævnte skal være lodrette og til venstre (måske hvor man kan folde dem ud og ind --- eller måske som undermenuer i en fold-ud-menu)), som indeholder allerede query'ede mængder. Så når en bruger har bedt serveren/databasen om en mængde, så gemmer browseren den altså, og holder faktisk bare på den indtil at en vis hukommelsesbuffer bliver fyldt op, eller selvfølgelig hvis brugeren clearer listen eller logger ud/skifter bruger. (11:40) Hvis brugeren så beder om den samme mængde igen, så kan applikationen i princippet bare kigge i denne mængde (når jeg får det implementeret), og så hente den herfra, hvis den stadig er der. 

Så forestiller jeg mig også en vandret liste i toppen med selekterede brugere/bruger-grupper (som bevaret på tværs af log-in-sessioner). Og en vandret liste lige under denne med sammensatte brugere/brugergrupper, nemlig altså hvor hver sammensat bruger(gruppe) er et aritmetisk-agtigt udtryk, som jeg har snakket om før, som altså minder om en linearkombination af bruger(grupper). Brugeren kan så vælge imellem disse i forbindelse med, at brugeren skal til at bede om en ny mængde (i.e.\ ved at klikke på en knap, der fører til en mængde-query). (11:45)

Hm, og hvad mere skal jeg egentligt sige.\,.\,? Selvfølgelig er tanken så.\,. Nå jo, jeg skal sige, i forbindelse med ``overlayet,'' at.\,. .\,.\,Jo, at det skal være sådan, at når et Term bliver forbundet med en URL, så.\,. Hm, skal jeg så have en slags to-vejs-relation til dette?\,. lad mig lige tænke mig om en gang.\,. (11:48) .\,.\,Jo, i applikationslaget må jeg implementere en slags to-vejs-relation til at sige: ``kan findes (informationer m.m.\ om) på denne URL,'' hvor brugere både kan up-rate URL'er for givne termer via én udgave af denne relation, og hvor de også kan up-rate termer til en given URL via den omvendte udgave af relationen, og hvor applikationen så altså sørger for, at ratingen bliver givet begge steder. (11:52) .\,.\,Og det er jo selvfølgelig denne omvendte relation, som overlayet skal query'e for, når brugeren er på en hjemmeside, hor URL'en har et ``hit'' (som også er up-ratet over en vis tærskel) i den semantiske database. (11:53)

.\,.\,(11:56) Hm, jeg tror faktisk, at jeg vil undlade at implementere $Path$en til at starte med, og så bare lade visningsindstillings-listen ``huske,'' hvor brugeren kom fra.\,. 

(08.03.23, 8:52) Jeg er kommet i tanke om, at jeg for en del dobbeltkonfekt, hvis jeg ligger op til at gøre brug af `Categories'-kategorien, så jeg skal på en eller anden måde have gjort, så at det ikke bliver oplagt at bruge denne. Dette kunne jo mske løses ved at indføre en skarpere typeforskel mellem kategorier og andre termer, men lad mig lige tænke lidt mere over det nu her.\,. 
\ldots Hm, nu kan jeg faktisk godt se en brug for `Categories'-kategorien, så lad mig bare sørge for, at brugerne starter på.\,. Tja, det må jeg lige finde ud af, men jeg kan sikkert finde en måde at gøre, så det bliver meget mere oplagt at tænke i at ordne kategorier i et underkategori-af-underkategori-træ, udspringende fra `Terms,' frem for at lade det udspringe fra `Categories'.\,. (9:07) .\,.\,Ah, måske jeg bare kan gøre det ved at sætte en lille advarsel ved `Subcategories'-relationen for `Categories,' der siger: ``Overvej først, om.\,. hov, eller rettere ved tilføjelsen til denne relation, der lige forklarer, forskellen mellem at tilføje underkategorier til `Terms' og til `Categories'.\,. (nemlig at `Categories' kan bruges som en ekstra over-inddeling, hvis man er interesseret i kategorier, man ikke normalt er interesseret i at se først på `Terms'-underkategorilisten).\,. (9:15) .\,.\,(Hm, der \emph{er} forresten en typeforskel på kategorier og std-termer; det er forkert at sige andet (ville bare lige nævne/præcisere det.\,.)

\ldots Ah, man skal jo bare gerne starte på `Standard Terms'-kategorien i applikationen, og så skal man altså derfra klikke sig op til `Terms,' hvis man vil derhen.

(15:39) Jeg tror faktisk, at jeg vil gå væk fra at have data-kategorier overhovedet. Så hvis man vil finde en tekst eller lignende, så må man søge i std-termerne. Og `Keyword strings' skal så implementeres som en pseudo-kategori, hvor man \emph{kun} kan søge efter nøgleordene, og hvor der altså ikke er hverken en `Subcategories'- eller en `Elements'-relation.\,! .\,.\,Brugere \emph{kan} så i princippet godt selv oprette alle disse kategorier, hvis de virkeligt vil, men hjemmesiden skal altså ikke selv lægge op til, at det er sådan man skal finde data-termer (men at man altid skal finde dem som en underkategori af.\,.).\,. Ja, det skal jeg faktisk lige finde ud af, for det næste spørgsmål bliver jo så om, hvad man skal gøre med `Categories,' `Relations,' og `Users and bots'.\,. (15:44) .\,.\,Hm, det skal nok være det samme, nemlig at de skal være underkategorier til `Terms' (hvilket data-termerne også er; jeg opretter bare ikke selv disse underkategorier (i hvert fald ikke fra starten af)), men jeg bør næsten lige overveje, om jeg ikke kan finde på en bedre navngivning til ``Standard terms''.\,. .\,.\,Ah, hvad med `Entities'.\,.\,! Det bruger jeg jo ligesom ikke til andet nu, kan man sige.\,.\,! (15:52) .\,.\,Hm tja, måske. Jeg har nemlig forresten ikke lyst til at kalde det for resources, for det er altså bare lidt misvisende, ift.\ hvad det egentligt er.\,. .\,.\,Ah, måske vil jeg slet ikke kalde det noget (andet end `termer'), for måske skal jeg slet ikke bruge `Standard terms'-kategorien!\,.\,. (16:01) .\,.\,Ja, for jeg kan simpelthen også bare undlade at have `Relations' og `Categories' med fra starten også (da jeg jo alligevel ikke tror, de bliver vildt brugbare i starten). .\,.\,Og så har vi vel bare `Terms' som hoved-/``hjemme''-kategorien, og så `Users' og User groups' (og måske en overkategori til sidstnævnte to) til at starte med, eller hvad?\,.\,. (16:04) .\,.\,Ja, sådan må det næsten være.\,.\,:) (16:06)

(16:37) Ah, måske skulle jeg faktisk fjerne obj\_cat\_id fra Relations.\,. .\,.\,Ja, og hvis/når brugerne så på et tidspunkt vil få gavn af den, så kan de bare implementere den selv, så at sige, nemlig via en relation i stedet (og ikke en tabelkolonne).\,. (16:40)

(17:42) Ah, jeg tror bare, det skal være `Categories,' der skal være den yderste kategori (hvor man så starter med en mængde af dens elementer), og som så ikke indeholder sig selv. Og så skal jeg nok også putte obj\_cat\_id tilbage i Relations.\,. 

(18:22) Okay, obj\_cat\_id skal forblive ude. Og den store pointe bliver så, at visningspræ-ferencerne i høj grad skal hentes direkte fra træet af ``definerende kategorier,'' hvilket også vil sige, at brugerne ikke behøver at up-rate nye termer for de givne kategorier, som er definerende for disse termer. Og dermed kan vi altså sagtens have alle de her forskellige fundamentale kategorier, der deler termerne op efter deres \emph{type} (hvor ``typen'' altså er den, der afgør, hvilken databasetabel termen hører til), uden at de behøver at blive brugt i praksis i form af at brugere up-rater elementer og underkategorier til dem. De kan primært altså bare (i starten om ikke andet) bruges til, når ny termer skal \emph{defineres}, hvilket så netop også bliver meget betydende ift., når visningspræferencerne skal indstilles. Super.\,. (18:28)

%.\,.\,(18:34) Ah vent, eller måske skal `Categories' bare være en fundamental kategori, der ikke tilknyttes noget term.\,. 
%
%.\,.\,Hm, jeg tror faktisk næsten, jeg bliver nødt til at adskille typerne ad for alvor (nemlig sådan at `Terms' bliver den forhenværende `Standard terms').\,. Hm.\,. (18:38) 
%...Tja, jeg tror det går fint bare med at have de her fundamentale kategorier, som i starten kun bruges til at indstille visningspræferencer.. (18:49) ..Ah, men jeg behøver da egentligt slet ikke 'Categories' så.. ..Nå jo, til 'Subcategories'.. ..Hm ja, men kan det så ikke netop bare være en u-instantieret kategori, som jeg lagde op til der kl. 18:34 for tyve minutter siden..? ..Tja, men hvorfor ikke bare instantiere den. Ok, fint. Så jeg opretter altså 'Categories,' men det er ikke sikkert, at den vil have nogen praktisk funktion overhovedet (for det kan være at det så at sige bliver 'Terms,' der "sørger" for det hele..). (18:55)




(13.03.23, 16:43) Ah, jeg tror, at man i stedet for at up-rate HTML-skabeloner for individuelle relationer, så skal man bare up-rate én skabelon (i.e.\ den bedst ratede) for en given kategori, og så kan denne skabelon kalde sig selv rekursivt, så at sige, og kalde andre skabeloner, som så bestemmer, hvilken HTML skal komme frem, når man trykker på diverse knapper i skabelonen --- hvilke nu altså ikke nødvendigvis er bundet op på en relation hver især! I stedet beskriver skabelonen bare fuldstændig, hvilken HTML skal komme frem, når man trykker på en knap, og \emph{denne} (barne-)skabelon kan så \emph{eksempelvis} vælge at sende en AJAX-query til en relation (men jo også mske eventuelt til flere relationer). Nå, og den store pointe, jeg så lige har fundet på, er at man til en sådan skabelon (for en kategori (eller rettere for elementerne i denne)) også skal kunne up-rate kategori--skabelons-par, således at hvis den pågældende skabelon er i $Path$en, og man i denne path query'er termer, hvor visnings-skabelonen ikke er defineret som en del af den samlede skabelon, så kan applikationen i første omgang så gå over og søge i disse kategori--skabelons-par for at finde den nærmeste overkategori i termens ``definerende overkategorier,'' og hvis der findes et match her, så for termen så den skabelon fra det kategori--skabelons-par med den nærmeste overkategori. Og hvis ikke der er noget match her, så kan applikationen i sidste ende bare følge hele listen af ``definerende overkategorier,'' indtil den støder på en overkategori, som har en skabelon defineret for sig (hvilket muligvis kunne være `Terms'-kategorien som rosinen i pølseenden). Lad mig prøve at gentage det.\,. Så for en given kategori kan man i første omgang up-rate en skabelon, som definere en HTML-visning, der bl.a.\ kan indeholde knapper, som så kan kalde andre skabeloner, inklusiv skabelonen selv rekursivt. Men denne skabelon kan nu altså også bare query'e mængder og termer, uden at skabelonen definere, hvordan disse termer vises, i en listevisning eller en alene-visning (m.m.). Så skal applikationen så selv finde frem til, udenom den givne skabelon, hvordan disse termer skal vises. Og her kan den så altså i første omgang kigge i eventuelt up-ratede kategori--skabelons-par til samme kategori for at finde den nærmeste overkategori her, og så bruge den korresponderende skabelon i dette par, eller den kan i sidste ende (hvis dette ikke giver noget) simpelthen bare følge rækken af overkategorier (som slutter på `Terms'), indtil den støder på en kategori, som selv har en skabelon up-ratet for sig (over en vis tærskel skarpt større end 0!), og når den finder en skabelon herved (hvad den altid vil gøre, hvis bare `Terms' har en skabelon up-ratet for sig), så kan denne skabelon altså så vælges til term-visningen. (17:03)


.\,.\,For resten tænker jeg igen at starte med at implementere $Path$en allerede nu her (skal snart i gang med front-end'en). Jeg har dog nogle rettelser til dens grammatik, men det gider jeg ikke lige at skrive om; jeg vil hellere bare prøve at bygge det.\,. (17:04)

.\,.\,Nå ja, og lad mig lige sige, at nu hælder jeg faktisk mest over imod at kalde systemet/siden for openSDB i stedet.\,. (17:05)


(16.03.23, 9:38) Okay, jeg tror, jeg er nærmere nu på, hvordan skabelon-halløjet skal implementeres overordnet set. Jeg forestiller mig nu, at skabelondefinitioner i første omgang bør bestå af en liste af tre lister (hver især af variabel længde, som henholdsvis indeholder javascript programmer, HTML-tekster og CSS-tekster. Javascript programmerne skal så ikke loades af siden, men i stedet kan siden bare læse dem og se på, om de er indeholdt i en liste over JS-programmer, hvis funktionaliteter er inkluderet i det nuværende kørende JS-program i browseren/applikationen. Hvis ikke JS-programmet genkendes, så kan applikationen give en advarsel til brugerne om, at den valgte skabelon altså muligvis ikke får den ønskede rendering, når HTML-teksterne indsættes på siden. Og hvis applikationen genkender JS-programmet, men ikke har disse funktionaliteter med i det nuværende kørende JS-program, så kan applikationen måske eventuelt se på, om man kan gøre noget for at loade de funktionaliteter alligevel, muligvis ved at stoppe andre del-programmer sådan at der ikke bliver en kollision ved at loade de ønskede funktionaliteter. Bemærk dog, at dette dog er noget der \emph{eventuelt} kunne blive \emph{en smule} nyttigt, men jeg regner dog altså ikke med, at det bliver særligt nyttigt i praksis; man kan nok komme rigeligt langt med bare at sørge for, at applikationen bare har en liste af programmer, som den kan køre, hvis der er behov for det, hvor der bare allerede er sørget for i forvejen, at disse programmer ikke kolliderer i deres semantik. Ja, det vil klart være det mest praktiske, bare at sørge for dette.\,. Okay, nå, men både HTML- og CSS-teksterne må derimod godt loades af applikationen direkte fra listen, for her sørger man nemlig bare for, at de loades ved køre i gennem et tjek-og-verifikations-program, der for det første kører htmlspecialchars modsat, men også i samme omgang tjekker, at syntaksen overholder en vis grammatik, hvilket for HTML'ens vedkomne også indebærer, at script-tags er ulovlige i syntaksen. .\,.\,Hm, og hvad i øvrigt med links.\,.\,? .\,.\,Hm, applikationen kunne jo i forvejen have en umiddelbar whitelist over URL-syntakser, som kan bruges.\,. .\,.\,Hm, og så skal brugerne selv kunne tilføje whitelistede hjemmesider via et specialt prædikat (som implementeres som en relation med en kategori som subjekt, ligesom alle andre prædikater, og her skal kategorien selvfølgelig bare være overkategorien, `Terms'), og kan så også tilføje blacklistede hjemmesider til et andet prædikat, hvilket så bl.a.\ også giver mulighed for at overskrive og fjerne hjemmesider i applikationens start-whitelist. .\,.\,Men spørgsmålet er så, om dette virkeligt skal indgå i parsingen af HTML-teksterne, eller om ikke man kan gøre noget smartere.\,.(?)

\ldots Okay, svaret på det sidste spørgsmål her er meget simpelt, for man gør jo også bare links ulovlige i parsingen, men så kan man tilgengæld lave nogle klasser/attribut-specifikationer, som siger til et inkluderet JS-program, at elementet gerne skal udskiftes med et links, \emph{hvis} altså at linket også først kan godkendes fra listen over whitelistede syntakser (og hvis selvfølgelig den ikke matcher nogen blacklistede syntakser heller). Ok, men jeg har dog nogle andre ting, jeg også lige overvejer.\,. 

\ldots Nå, jeg har overvejet lidt omkring, JS-programmet, men er nu ikke kommet frem til noget vigtigt, der er værd at nævne. Okay, men lad mig færdiggøre denne tråd om skabelonerne. Vi er faktisk næsten i mål, for når man så har disse skabelondefinitioner (en liste af tre lister), så mangler man også lige én information mere for at have sig en skabelon, og der er et tal, der fortæller, hvilken HTML-tekst i listen, man starter på. Husk nemlig på, at HTML-teksterne/-delskabelonerne kan kalde sig selv og andre HTML-delskabeloner, og det er altså dem i denne liste. Men det kan være, at forskellige kategorier kan bruge samme skabelondefinition, men hvor man bare starter på forskellige start-HTML-delskabeloner, og herved kommer dette tal altså ind i billedet, for så kan alle disse kategorier referere til den samme skabelondefinition, men bare have hver deres tal. Så en `skabelon' bliver altså hermed en liste af to ting: et tal, og så en skabelondefinition (som altså igen er en liste af tre ting, nemlig JS-/HTML-/CSS-tekst-lister). (11:17)

Nå, det gode er så dog, at jeg bare kan starte med at have ét JS-program --- og én CSS-fil i øvrigt --- og så bare definere alle HTML-delskabelonerne, som jeg vil bruge til prototypen, ud fra dette/disse. Og herved vil jeg så også bare helt undgå at implementere noget som helst omkring de her skabelon-up-ratings (som brugeren kan gøre for hver kategori i princippet) lige i starten (indtil jeg lige kommer i gang og for testet at hele applikation-til/fra-database-kommunikationen er kommet op at køre og fungerer nogenlunde korrekt). Så lige i starten definerer jeg altså bare lige nogle få HTML-delskabeloner.\,.

Nå, men til gengæld er en anden vigtig ting omkring brugernes mulighed for at bruge forskellige brugergrupper automatisk til forskellige valgte kategorier, men det virker nu også som en ret stor opgave alt i alt, så den må jeg også lige gå at summe lidt over, imens jeg laver en grundlæggende applikationsprototype.\,. (11:26)


(18.03.23, 14:01) Jeg vil begynde at kalde dem `elementære termer' i stedet for `standard-termer.'

(19.03.23, 8:39) Jeg tror faktisk, at jeg gør mængder til (en type af) (afledte) termer.\,. .\,.\,Hm, og så udkommenterer jeg nok den `selectSetFromSecKey()'-procedure, som var min originale selectSet(), og omdøber selectSetFromSetID() til `selectSet()'.\,. .\,.\,Hm, og så sender jeg elementnummeret med i selectSetIDFromSecKey().\,. 


%(21.03.23, 18:01) Jeg tror lige jeg vil brainstorme lidt over front-end-delen. Lad mig lige nævne, at det faktisk er en rigtig god ændring, den med at mængder nu også er termer. Nå, front-end-delen.. Jo, for det første skal term.php (i min indtil videre private GitHub-mappe) starte med at parse en path, som bare er en række catID'er separeret med forward slashes. Og efter sidste skråstreg kommer så et vilkårligt termID. ..Nå ja, og stien må også gerne eventuelt starte med en bruger(gruppe). Serveren skal så faktisk ikke tjekke, om stien i sig selv "holder" (nemlig ved at tjekke ratingværdier for ".s" og muligvis ".e"-relationen (sidste i tilfælde af..)).. Hov, måske skal man alligevel lave forskel på sidste slash.. måske ved at klemme et "/e/" imellem.. for at kunne kende forskel. Nå, men forholdet er faaktisk ikke vigtigt, for stien skal egentligt bare bruges til at finde op til tre ting fra starten af: bruger(gruppe), præferencekategori, og det endelige term. Serveren kan så tjekke, at den valgte bruger(gruppe) er en del af brugerens whitelistede brugergrupper. Hvis ikke, så vælger serveren bare brugerens standard query-brugergruppe og printer en lille advarsel til brugeren. Denne bruger(gruppe) bruges så til, sammen med kategori-delen af stien, at finde frem til den rette præferencekategori, nemlig ved at følge stien op til 'Terms' og tage den første kategori, man støder på, som er en af query-brugergruppens erlærede præferencekategorier. Præferencerne (hvilket bl.a. vil sige HTML'en) loades så fra denne præferencebrugergruppe og termet sendes så til brugerens browser sammen med passende yderligere data. ..Nå nej, for inden da skal serveren også lige slå op i præferencekategoriens grundfilter-whitelist og -blacklist. Bemærk i øvrigt, at hvis ingen præference er up-ratet tilstrækkeligt for den givne præferencekategori, så er det fordi query-brugergruppen hermed har valgt, at præferencekategorein bare skal arve den pågældende del-præference af sin forælder (rekursivt, hvis denne forælder heller ikke har "overskrevet" sin egen forælders præference, hvad denne del-præference angår). Nå, hvis whitelist-ratingen eksisterer og er over en hvis grænse, og hvis ikke blacklist-ratingen eksisterer og er over en vis grænse for termet, så kan serveren så sende termet til brugeren, og ellers skal den sende dataen må en måde, så browseren ved at den ikke skal vise termet (\emph{hvis} termen sendes overhovedet). Bemærk at whitelisten og blacklisten nu kan være mængder hver især, da mængder jo som sagt nu er termer. Så brugeren kan altså up-rate to mængder til 'Term'-kategorien, som så kommer til at udgøre brugerens "grundfilter." (Og serveren slår så bare op via selectRating(), som jeg har defineret den nu.)
%Nå, og html'en bstemmes altså også (rekursivt) ud fra præferencekategorien. Og så skal jeg lave et system, sådan at f.eks.\ knapper og forms kan have attributter, som kan referere til termet selv, til den givne præferencekategori, til brugeren selv eller til den nuværende valgte query-brugegruppe. Så er der et JS-program, der læser disse attributter og tildeler knapperne m.m. den rette funktionalitet.
%En ny idé er så også, at knapperne og forms'ne også skal have adgang til at læse fra og skrive til datastrukturer, både en XML struktur, som ikke renderes, og også en struktur i local storage, hvis brugerens browser har sådant. Her skal man måske endda lave en slags script-divs, hvor brugeren kan definere små programmer, som divere knap-/form-attributter så kan referere til, for at fortælle hvilken datastruktur-ændrende handling, som knappen/formen skal have, når man trykker på knappen/på submit-knappen. Så skal jeg skrive et lille bibliotek af instruktioner, som så interpretes fra pågældende script-divs. Alternativt kunne jeg tillade en undermængde af JavaScript inden i script-tags, men jeg tror faktisk, at det her med at lave sit eget lave data-script-sprog som står i (ikke-renderede) div-tags er en bedre løsning her til at starte med. (18:32)
%(19:31) Det kan faktisk også bare være en JS-objekt-datastruktur i stedet for en XML-struktur (altså også for den struktur, det ikke gemmes i local storage (men som ophører hver gang brugeren lukker siden)). 
%(22.23.03, 11:34) Nej, XML er bedre, men det kan jeg vende tilbage til...
%(23.03.23, 10:26) Jeg var vildt træt i går, fordi jeg ikke fik sovet så meget, men i dag har jeg heldigvis sovet længe. Men selvom jeg ikke fik kodet så meget, så fik jeg alligevel tænkt en del, og kom frem til nogle rigtig gode ting. Lad mig prøve at opsummere i den renderede tekst..

(23.03.23, 10:27) Jeg har nogle få noter ude i kommentarerne over denne paragraf, som jeg lige vil prøve at inkorporere i den følgende opsummering også.\,. .\,.\,Nå, lad mig starte med at sige, at jeg i de noter skrev om, at jeg ville lave et lille scriptsprog, som kan transpiles til JS. Det vil jeg ikke længere; nu vil jeg (og er lidt i gang med at) definere en undermængde af JS i stedet som brugerne så kan bruge. Jeg har så lagt op til i går, at det skulle være en undermængde af jQuery-JS, men sådan tror jeg faktisk ikke helt det bliver alligevel. I stedet skal alle biblioteksfunktioner og -metoder importeres fra moduler i starten af scriptsne. Og her kan man så kun importere fra moduler, som er i en vis godkendt mappe (eller undermapper af denne). Og man kan så selv definere nye funktioner i scriptsne. Hm, og jeg kan egentligt godt lade brugerne loade flere scripts, hvilket så gør, at de slev kan definere biblioteker (men ikke moduler). Idéen er så, at preprocessoren automatisk omdøber alle identifiers, således at de får nogle præfikser, der er (meget) nemme at undgå at bruge af webudviklerne til omkringliggende JS-program. Og ikke nok med det, så kommer der faktisk typer indirekte i sproget, fordi preprocessoren sørger for at lade præfikset afhænge af konteksten for den første deklaration. Derfor kommer man så ikke til at kunne genbruge en variabel til en anden type (det knne man godt, men så ville semantikken ikke nødvendigvis være bevaret fuldstændigt før og efter præprocesseringen, og det vil jeg nok gerne have, at den er). Nå, og jeg har faktisk simpelthen tænkt mig bare at definere syntaksen ud fra et RegEx pattern, hvilket vil sige at syntaksen ikke må indeholde rekursion. Men det gør faktisk ikke så meget, så det tror jeg faktisk, jeg vil gøre! Fordi brugerne stadig kan definere rekursive funktioner, så kan de stadig i princippet få præcis det samme flow i programmerne (hvis man ser bort fra ekstra funktionskald). (10:47) %2 sek..
.\,.\,(10:56) Så lige for at gå tilbage til modulerne, så kan præprocessoren jo også bare sætte præfikset på de importerede funktioner (og eventuelt variable) i selve import-statementet. Dermed kan både modulerne og brugerscriptsne altså begge skrevet uden at tage hensyn til, hvad de endelige præfikser bliver. 

Lad mig så tale lidt om sikkerheden i scriptsne. For det første skal man sørge for, at scriptsne kun kan tilgå variable inden i den pågældende term-div/start-div (som serveren har startet med at servere, inklusiv det script, som brugeren har valgt for det). Ved at sørge for, at scriptet er (eneste) barn af denne div, så kan scriptsne bare starte med (eller præprocessoren kan sætte dette på automatisk) en variabeldefinition, der selekterer div-elementet. Og så skal alle funktioner godkendt i modulerne altså sørge for, at de kun tilgår DOM-elementer, der er efterkommere af denne div. Funktioner kan så tilføje og ændre børn til denne div (og ændre dens attributter), og de kan læse børn fra den. Hermed kan man altså også implementere en datastruktur, som funktionerne løbende kan læse og skrive til, som en XML/HTML-struktur indenfor start-diven, som man så bare sørger for ikke bliver renderet. Funktioner må også gerne læse fra og skrive til en hvis mængde variable i local storage, nemlig variable, der alle også automatisk har fået sat et præfiks på sig, så ingen af dem kolliderer med variable, som webdeveloperne bruger. Desuden skal html-specialkarakterer holdes uden for alle strenge, så dermed skal alle HTML-børn altså indsættes og ændres via tilegnede funktioner, ikke via direkte streng-printning. (11:11) .\,.\,Nå ja, og derudover skal man også holde alle links ude, både i form a link-tags, men også i form af expressions, f.eks.\ i CSS-attributter (og andre attributter). Så f.eks.\ ikke nogen `url()'-udtryk. I stedet indsættes links via specielle divs, som det omkringliggende program så kan, gerne efter.\,. Ja, eller rettere: scriptsne skal gerne kunne kalde et.\,. Ah, men så behøver vi ikke nødvendigvis sådan en link-div-repræsentation. Så kan vi bare lave en speciel modul-funktion, som kalder en yderliggende link parser, der så tjekker, om linket passer med en link-syntaks, der allerede er godkendt af brugeren, og som så enten giver grønt lys til at indsætte linket, eller fortæller at funktionen i stedet skal indsætte et dødt dummy-link. Og en sidste ting, jeg har tænkt på, er så, at funktionerne ikke direkte må tilgå input-handleren (men gerne query-handleren). I stedet må funktionerne sende input-requests'ne til en yderliggende queue i DOM'en. Hvorvidt disse requests så skal vente her på bruger-godkendelse, eller om de automatisk skal sendes videre til serveren med det samme, det er så op til brugeren. Men fordi brugerne jo også kan læse hinandens scripts, så vil folk nok ret hurtigt få tillid til, at de bare automatisk kan sendes videre, når det er --- i det mindste altså, når afsender scriptet er en af det scripts, som brugeren har meget tillid til. Hm ja, og derfor kunne man altså gøre sådan, at input-funktionerne, der sender til queue'en også kan vedhæfte et script-ID, der fortæller hvilket script er afsender på inputsne. (Bemærk desuden at rating inputs kan fortrydes af brugeren, fordi denne har adgang til sine seneste inputs (RecentInputs) og kan overskrive dem, hvis brugeren har lyst.) .\,.\,Jeg har forresten overvejet at tilføje en undo- eller en slet-recent-input-sql-procedure, men det er ikke sikkert, at det bliver nødvendigt. (11:28)

Nå, lad mig så gentage fra kommentarerne, at serveren så bare i starten får en bruger-(gruppe) (optional), en kategori-sti (optional), og et term-ID til sidst (required). Serveren slår så for det første op, om bruger(grupp)en er godkendt af den pågældende bruger (altså den der kommer med forespørgslen), og hvis ikke, så vælger serveren bare brugerens standard bruger(gruppe) i stedet (og tillægger også noget data med den returnerede HTML i sidste ende, der fortæller dette). Hvis brugeren ikke er logget ind, at matcher serveren bare i stedet med en standard liste af mulige brugergrupper, og hvis ikke der er et match her, så vælger den bare den mest standard brugergruppe. Kategori-stien bruges så efterfølgende til at bestemme visningspræferencerne.\,. Hm, jeg kan mærke, at jeg faktisk ikke har lyst til at gentage det, jeg skrev i går, så se ude i kommentarerne, hvis man er interesseret i at læse om, hvordan jeg mener, at dette bør gøres. Samtidigt (før eller efter) skal serveren også aflæse den valgte bruger(gruppe)s grundfilter præferencer. Her tænker jeg nu, at man i første omgang læser et prædikat, der afgør, om bruger(grupp)en har videredelegeret denne opgave til en anden brugergruppe (og altså bare kopiere indstillerne fra en anden bruger(gruppe)). Hvis ikke nogen brugergruppe overstiger en vis tærskel, så vælges bruger(grupp)en selv igen til dette formål. Hvad en en nu B(G) vælges til dette formål eller ej, så slår serveren nu op i to prædikater (som i øvrigt implementeres via relationer med `Terms' som subjekt (eller som objekt, om man vil (alt efter hvad vej man fortolker relationen))), nemlig i et prædikat for en whitelist og en blacklist. Begge disse bør defineres i form af et mængde-ID, hvor serveren så simpelthen slår op i disse mængder (og bemærk at mængder godt kan være konstante, hvis pågældende brugergruppe er ikke-dynamisk (inklusiv hvis brugergruppen er ``ended'')). Term-ID'et tjekkes så for, om det kan godkendes ud fra den valgte whitelist (som i øvrigt godt bare kan være en ``is a meaningful and concise term''-mængde, hvis man vil bruge en rigtig inklusiv whitelist) og blacklist. Hvis ikke den kan det, så sørger serveren igen for at fortælle dette i den endelige HTML, men hvis den kan, så sender serveren jo bare term-diven samt alt andet relevant data. Serveren sender så det valgte script *(nej, \emph{de} valgte scrits, for jeg kom jo lige frem til, at der godt må være flere) (som altså så vælges ud fra kategori-stien, hvad jeg ikke lige har beskrevet her) som det eneste *(nej, for der kan godt være flere scripts) barn i denne div (og indsætter den relevante data i form af attributter til denne div). .\,.\,Nå ja, der kan godt være flere scripts, som jeg lige har bemærket i nogle indsatte parenteser. Når brugeren så får HTML siden, så beskriver bruger-scriptsne så, hvordan denne term-div/``start-div'' skal renderes, nemlig ved i første omgang at beskrive, hvilke nogle funktioner skal kaldes, når dokumentet er klart. Og når det omkringliggende dokument er klart, så kan funktionerne så gå i gang, og opbygge hele det interface, som brugerne kommer til at bruge til den centrale del af applikationsinterfacet, nemlig til at navigere rundt i termer på siden og eventuelt uploade input selv. (11:55) %2 sek..

\ldots (12:17) Så med disse nye idéer, så tror jeg altså virkeligt, at jeg er tæt på at opnå, det jeg gerne vil, kan man sige. For jeg tror ikke, det kommer til at tage lang tid at lave et god undermængde af JS.\,. Hov, lad mig forresten lige slå fast, at siden så primært kommer til at blive en AJAX-side, nemlig hvor det er browseren selv, der sørger for eventuelt at skifte URL'en og eventuelt gemme dem som ``bogmærker'' (hvis jeg har forstået bookmark.create() ret.\,.). Så i brugerscript-biblioteksmodulerne bør jeg altså også på et tidspunkt tilføje nogle funktioner, der kan skifte URL-headeren, og som kan kalde ``bookmark.create(),'' eller hvad den nu hedder. Nå, men tilbage til at sige: Så jeg tror ikke, der kommer til at gå vildt lang tid med det. Og jeg har allerede database-queries nogenlunde på plads, og det kommer sikkert ikke til at tage vildt lang tid at få hul igennem til inserts/inputs. Så skal jeg jo lige skrive den server-procedure, jeg lige har beskrevet, og jeg skal lave den der queue og sådan. Og ikke mindst skal jeg lave/oprette et login-system osv., men altså alt i alt, går der nok ikke så lang tid, før jeg kan nå til et punkt, hvor jeg kommer til at programmere interfacet, ikke som webdeveloper, men i princippet som bruger! Selvfølgelig skal jeg jo løbende føje flere og flere biblioteksfunktioner til, og der kommer til at ligge en masse arbejde i at fejlteste, for ikke at tale om at oprette login-systemet og sådan. Så der er stadig en masse arbejde forrude, men jeg tror ikke, der går lang tid, før at jeg får et system, som jeg ønsker mig, hvor man tydeligt kan se, hvordan applikationen er ``user-driven.'' :) (12:28)

.\,.\,Selvfølgelig kommer der så også til at lægge en del arbejde i at få interfacet derhen, hvor jeg gerne vil have det, men det bliver altså rart at nå til et punkt, hvor jeg i princippet gør dette som ``bruger'' mere end (eller ligeså meget som, om man vil) som web-udvikler. .\,.\,Jeg kom også til at tænke på, at jeg lige skulle nævne, at ``overlayet,'' som jeg kalder det (som i øvrigt skal implementeres via iframes), så bare kan implementeres ved at vælge en speciel brugergruppe til at bestemme sine visningspræferencer, som specialiserer sig i netop ``overlayet.'' Man kan så i princippet også query'e en sådan special-brugergruppe på hjemmesiden selv, hvorved man så vil få overlayet serveret som HTML på selve hjemmesiden (ikke i en iframe). Men her er det så bare beregnet, at det er overlay-browserudvidelsen, der skal GETte denne HTML og putte det ind i en iframe på andre hjemmesider, som brugeren besøger (og som browserudvidelses kan genkende og/eller kan se, har relevant data omkring sig i den semantiske database). (12:36)

(24.03.23, 10:14) Hm, jeg tror faktisk, jeg vil kræve ungarnsk notation.\,. (Så brugerne sætter selv disse præfikser på, og så sætter preprocessoren bare et yderligere præfiks på også.)

(25.03.23, 12:01) Man kunne også kalde det en ``user-\emph{programmable} application'' (UPA) i stedet.

(18:31) Det jeg før har tænkt på med sammensatte tekster og delta-tekster, det må brugerne hellere bare selv implementere i applikationslaget, hvis der kan blive behov for det. 

Nå, noget andet er, at jeg jo er begyndt at programmere JS-undermængde-parseren i front-end-delen (altså i JS). Og så tænkte jeg faktisk, at brugerne så selv skulle verificere programmer, og så bare holde en liste i local storage over script-tekst-ID'er, som de allerede har verificeret (og som de kan huske, at de har verificeret), så de ikke behøver at køre parseren på ny, inden de loader scriptet i starten, når de lukker siden op. Hm, og måske kunne dette også give mening, egentligt, så lad mig lige tænke noget mere over det.\,. (18:36) 
.\,.\,Hm, måske giver det egentligt fin mening at gøre det sådan, og så skal applikationen bare kunne kalde en JS request handler, der så serverer.\,. Hm, serverer teksterne råt, men hvordan får man så lige præfikserne.\,. Ah, præfikserne ville så skulle sættes på lige inden upload til databasen.\,. (18:41) .\,.\,Ja, så applikationslaget sørger faktisk bare for lige at oversætte input-programmet til et verificerbart format (uden mærkelige whitespaces og med de rette præfikser), inden de uploades (bare som en tekst på normal vis) til databasen. Og så kører applikationslaget også selv verifikationsprogrammet, når scriptet hentes ned igen (i det oversatte format som det blev uploadet i). (18:45)


(26.03.23, 10:43) Jeg kom frem til i går i sengen, at det må skulle være sådan, at serveren kun.\,. Ah vent, men så skal serveren også selv parse programmerne.\,. Okay, så det er der muligvis ikke nogen vej udenom.\,. tja, medmindre at man kan bruge eval() til at køre scriptsne i applikationslaget efter at de er konverteret til ``usikkert'' format.\,. Hm.\,. (10:45) .\,.\,Ah, nå nej, nu kom jeg i tanke om, hvad jeg bør gøre. Jeg bør implementere parsingen begge steder, men i serverlaget bør parsingen dg kun lige række til at sikre, at scriptsne udelukkende består af funktionsdefinitioner.\,. Ja, og måske også klasse-definitioner sidenhen, men vent nu lidt.\,. (10:49) .\,.\,Ja, jo. Serverlaget skal også parse, men kun for at modulerne kun består at definitions-statements uden nogen sideeffekter, når scriptet køres, så længe funktionerne altså aldrig kaldes. Hermed bliver URL-linksne ikke farlige i sig selv (altså hvis man taster dem ind i browser-søgefeltet), så længe man bare ikke loader dem som script-sources på min hjemmeside uden at parse dem i applikationslaget først. Og så tænker jeg nemlig nu, at alle brugerscript skal være moduler --- altså ikke nogen main-procedure-scripts. Eller rettere, der skal være main-procedure-scripts, men disse skal --- ligesom i C --- i stedet definere en funktion kaldet `main' (plus præfikser!). Og når applikationen så har parset alle de relevante moduler til et samlet program, så kan applikationen så loade et script, der definerer en main-funktion, hvorefter applikationen så selv kan kalde denne main-funktion, og så skal inputtet til denne simpelthen bare være det HTML-element, som main-programmet skal holde sig inden for. (11:02) .\,.\,Yes, det var sådan, at jeg skulle gøre det (og skulle lige indse, at det så kræver, jeg også parser til en vis grad på serversiden).\,:) 

(13:17) Hm, hvis void- og ec-funktioner skal kunne tage arrays, object, og callb.\,. hm, vent.\,. Ja, nej, helt generelt skal jeg bare sørge for, at funktioner aldrig kan overskrives, og dermed heller ikke defineres --- om ikke andet så bare for en sikkerheds skyld --- inde i funktioner, hvad end disse er rene eller urene. Og i rene funktioner skal jeg så også bare sørge for, at arrays og objects ikke må ændres heller.

(13:59) Ah, jeg kan da egentligt ligeså godt bare droppe restriktionen om, at ikke-rene funktioner skal være ``void''- eller ``ec''- (exit code) typer. Lad mig da i stedet bare sige, at funktionerne kan få et `pure'-præfiks med sig, hvis og kun hvis de er rene.

(27.03.23, 11:02) Nå, jeg har tænkt en del over JS-undermængden, og regner med at skulle lave nogle ting om. Jeg tror måske, jeg lige skal tænke en anelse mere, så lad mig lige gøre det.\,. 

(13:23) Okay, det har taget lidt tid, men nu tror jeg endelig, jeg har styr på, hvad jeg gør.\,. .\,.\,Lad mig starte med at nævne, at jeg var gået over til at overveje at bruge en syntaks meget ligesom TypeScript, i stedet for at bruge type-præfikser. Nå, men nu vil jeg i stedet bare sørge for, at alle ikke-brugerdefinerede funktioner, som kan kaldes i bruger-scriptsne, bare selv skal tjekke, om inputtet er korrekt. Der kan så være nogle halv-globale variable, som sættes i starten af det script, der kalder den givne brugerdefinerede main-funktion. En af disse variable kan så være det div-element, som funktionerne ikke må bevæge sig uden for. I starten af hver biblioteks-html-element-funktion kan denne så tjekke, at input er efterkommer(e) af dette div-element. Nå, men det gode er så, at hvis man i fremtiden vil gå over til også at bruge en statisk typetjekker til at eliminere nogle af disse runtime-tjek, så kan man godt implementere dette så det er bagudkompatibelt med de ikke-typede brugerscripts!\,. For man kan nemlig i så fald lave en delvis typetjekker, der bare sørger for at typetjekke de variable/udtryk, der gives som input til de (fremtidige) biblioteksfunktioner --- og brugerdefinerede funktioner --- som så kræver inputtet tjekket på forhånd (statisk). Typetjekkeren skal så kunne type variable og funktioner automatisk, hvis det er muligt (ligesom alle moderne funktionelle sprog). Dermed kan brugerdefinerede funktioner, der er skrevet før typetjekkeren kom til, så også muligvis types, hvis det er. Og finten er så, at typeinformationen gemmes i en separat fil, som også uploades til databasen. På den måde kan typetjekkeren altid uploade typeinformationer om tidligere bibliotek (bruger- eller developer-defineret) på et vilkårligt tidspunkt. Og hvis et script, der skal bruge statisk typebestemmelser, importerer funktioner fra et JS-modul, så kan man så slå op i modulets separate type-informationsfil, for at få denne --- og hvis ikke denne information er kompileret, så kan man bede serveren om at kompilere den. Ok, lad mig så zoome lidt ud og forklare, at script-bibliotekerne består af to--tre filer uploadet i databasen. For det første er der den obligatoriske kildefil, som brugeren har udarbejdet, og som kan læses af både mennesker og af en transpiler. Formattet af kildefilen behøver ikke at være begrænset til JS, men i starten vil det bare være en undermængde af JS. Men på et tidspunkt i fremtiden kan dette udvides til et sprog a la TypeScript (TS), hvor man altså nu også har lov til at give typeinformationer med til bl.a.\ funktionsdeklarationer, hvis nu ikke typen kan bestemmes statisk (fordi den er tvetydig). Og fordi alle bruger-udarbejdede scripts alligevel skal transpiles uanset hvad, så gør det altså ikke noget, at man på et tidspunkt udvider det, så det ikke længere nødvendigvis er en undermængde af JS (f.eks.\ altså ved at tilføje TS-agtig syntaks). Transpileren oversætter så programmet til et nyt program, som \emph{er} en undermængde af JS, og som derfor kan loades direkte i browseren. Det er så også denne transpiler der tilføjer de præfikser til alle identifiers, således at programmet ikke kan tilgå andre funktioner og variable, end dem der er lovligt for det at tilgå. Serveren får så en bot til at up-rate det transpilede program som et ``kompileret/transpileret program'' til kildekode-filen. Brugere kan så selv verificere kildekoden i applikationslaget, og hvis verifikationen lykkes, kan de så loade scriptet (inklusiv de scripts det importerer (som selvfølgelig derfor også skal være med i verifikationen forinden)) og køre et nyt script, der kalder main-funktionen. Hm, og i øvrigt kan transpileren sørge for at præfikserne også afhænger af kildekode-ID'et, således at man kan loade flere uafhængige brugerscripts på én gang uden at skulle bekymre sig om kollisioner. Nå, og den tredje, eventuelle fil er til den omtalte typeinformationsfil, der altså ikke nødvendigvis behøves at findes for at scriptet kan verificeres. Det behøves den kun, netop hvis scriptet, eller et af de scripts der importerer fra det, skal bruge denne typeinformation for at kunne verificere visse typer statisk, nemlig hvis visse funktionsinputs typer afhænger af denne information, og hvis pågældende funktioner kræver at pågældende input får deres typer verificeret statisk. Og det er det. Hermed kan jeg altså glemme alt om.\,. Nå ja, vent, for jeg skal også lige hurtigt sige, at typeinformationen også up-rates på samme måde meget ligesom det kompilerede/transpilerede program, nemlig ud fra en passende relation og med kildekode-filen som subjekt. Cool, og hermed kan jeg altså glemme om typetjek for nu, men hvor jeg ved, at hvis nu man på et tidspunkt gerne vil indføre det for at eliminere nogle runtime-tjek, som i stedet kan tjekkes statisk, så kan man gøre dette på en bagudkompatibel måde.\,:) (14:13)

(16:14) Nu fik jeg lagt op til, at typetjekker-udvidelsen bliver implementeret i serverlaget, men man kan også implementere noget tilsvarende i applikationslaget med en browserudvidelse, hvis det endeligt er.\,.

(29.03.23, 20:40) Jeg går tilbage til at bruge type-præfikser (eller suffikser!), men kun for arrays og objekter, samt også funktioner der returnerer hhv.\ arrays eller objekter.

(30.03.23, 11:15) Ah, og det gode er, at bare fordi jeg kræver typerestriktioner på navnene nu, så betyder det ikke, at disse restriktioner ikke kan tages væk og erstattes med automatisk typebestemmelse i fremtiden.

(01.04.23, 11:35) I starten tror jeg faktisk bare jeg nøjes med at have det sådan, at scripts ikke bliver transpilet overhovedet, sådan at både brugere og serveren arbejder i det script-format hele tiden, der indeholder alle præfikserne osv. (og også alle kommentarerne og ekstra whitespace). Og så kan jeg på et tidspunkt bare lave et system, så de kan transpiles, og så brugerne kan arbejde uden alle de præfikser, når der begynder at blive behov for det. 

(01.04.23, 18:39) Jeg gider ikke debugge to steder på én gang (det ville være lidt dumt), så jeg tror jeg venter med at oversætte parseren til PHP også. Så jeg vil altså bare for nu lade serveren acceptere alle scripts (som jeg så sørger for at lade applikationen parse inden), og så kan jeg debugge parseren der i første omgang (imens jeg også tilføjer lovlige funktioner til sprog-undermængden), inden jeg på et tidspunkt også implementerer den samme parser på serveren. 

(04.04.23, 16:16) Hold da op. Jeg skrev lige en commit-kommentar, at jeg har svært ved at fokusere nu, men nu kom jeg lige til at tænke på noget, der måske lige har givet mig lidt second wind (måske, nu ser vi.\,.). Jeg kom til at tænke på, at jeg jo egentligt, nu hvor jeg ikke tillader nogen metoder overhovedet (inkl.\ (implicitte) getter- og setter-metoder).\,. hm, vent, eller ville jeg egentligt ikke hele tiden kunne gøre dette?\,.\,. Okay, jeg er stadig lidt sumpet i hjernen.\,. Lad mig se en gang.\,. .\,.\,Ah, jo, uanset hvad, så \emph{har} jeg førhen (for nyligt, self.) været bekymret, i hvert fald til tider, om at give brugere lov til at håndtere ubegrænsede objekter på et niveau, hvor disse får lov til at holdes af variablene i sproget. Ja, og jeg har nemlig også på et tidspunkt tænkt, at man \emph{måske} kunne lade brugerne lade variable holde objekter, som de selv har bygget på en begrænset måde, men ikke f.eks.\ HTML-element-objekter osv. Ja, men nu er jeg jo kommet frem til, at brugere faktisk godt må kunne bygge arbitrære objekter, for selv hvis det lykkes dem at bygge noget a la Function-objekter eller andre umiddelbart farlige ting, jamen så kan de alligevel ikke tilgå nogen af deres metoder (når nu jeg endda slet ikke har metoder med i sproget (hvilket muligvis på et tidspunkt kan erstattes af, at man bare begrænser metode-navnene, ligesom jeg gør med for funktionsnavne (og variabelnavne))). Og så har jeg jo tænkt, ``det var da dejligt,'' men åbenbart glemt, at dette så også medfører, at brugerne jo så kan blive frie til at gemme alle de objekter, de vil i variablene! (Lige for at gentage dette: Jeg tænkte altså først, at selv \emph{hvis} det skulle lykkes dem at lave ``farlige'' objekter a la Function-objekter, så ville det ingen gang gøre noget alligevel, men nu tænker jeg jo så: Jamen, hvis det ikke gør noget, så lad dem da bare håndtere alverdens objekter frit, \emph{også} selv Function-objekter osv.) Og dette slog mig altså lige nu her, og dermed slog det mig så også, at dette jo betyder, at jeg så nærmest bare kan kopiere jQuery til en vis grad her til at starte med --- altså hvor jeg så bare wrapper alle de ønskede jQuery-funktioner i ``upaFun\_''-wrappere (så bare med en mere funktionel/procedural virkemåde i stedet for OOP)! :) (16:35) .\,.\,Og hermed blev udsigten til at få lavet et omfattende nok UPA-bibliotek pludselig meget kortere!\,!\,:\texttt{D}\textasciicircum\textasciicircum\ 

.\,.\,Selvfølgelig skal jeg lige sikre mig, at de returnerede objekter (f.eks.\ jQuery-objekter) ikke kan indeholde noget følsomt/privat data fra brugeren, men det er vist også det.\,.\,:) 


(05.04.23, 14:39) Nå, jeg har indset, at det alligevel ikke er så lidt, for det er ikke sådan bare ligetil at tjekke, om et objekt er et legalt jQuery-objekt. Så jeg er gået i gang med så småt at implementere en API, hvor brugerne giver selectors som input til funktionerne, og altså ikke jQuery-objekter. Så ja, det bliver ikke helt ligeså nemt at lave den API, som jeg troede her i går, sidst jeg skrev, men det skal nu stadig nok være en rimelig overkommelig opgave.\,. (14:42)

(17:20) Jeg fjerner ikke-array-objekter fra JS-undermængden igen, sådan at ingen expressions må returnere ikke-primitive eller ikke-array-af-primitive typer. Ingen upaFun-funktioner må altså returnere andet end primitive typer, eller (evt.\ multidimensionale) arrays med primitive typer som deres blade!


(12.04.23, 09:02) %Haha, skrev selvfølgelig 12.04.93 først.xD
I går aftes kom jeg frem til noget omkring, at jeg nok, fordi man jo kan definere Content-Type headeren (og fortælle browseren, at den ikke skal tolke outputtet som HTML), kan undlade en masse tjek i serverlaget. Og måske kan jeg endda undlade at verificre JS-moduler helt, for det er jo kun web developers, der er i ``fare'' for at benytte et farligt script fra hjemmesidens domæne. Og hvis jeg bare omdøber UPA\_modules, så navnet indeholder ``DO\_NOT\_TRUST\_WITHOUT\_VERIFICATION,'' så burde der jo ikke være nogen ko på isen.\,. vent.\,. Hm, måske i forhold til.\,. Hm, i forhold til CSP, eller hvad det nu hedder, men der må man jo bare sige, at hvis developers godkender.\,. Tja, eller endnu bedre: Man må bare sørge for at signalere tydeligt til andre developers, at CSP-whitelisting af hjemmesidens domæne selvfølgelig bør ekskludere UPA\_modules\_DO\_NOT\_TRUST\ldots\ (9:12)

(18:30) Ah, den løsning går desværre nok ikke alligevel. Jeg skal nok sørge for at tjekke alt input i serverlaget, også inklusiv JS-moduler.\,. \ldots (19:12) Hm, eller måske.\,. Jeg skal i hvert fald lige tænke noget mere over det.\,. 

(13.04.23, 9:49) Okay, jeg kommer ikke til at lave parsing for diverse filtyper. I stedet vil jeg bare sørge for, at det altid tjekkes, at den hentede binære ressource altid tjekkes for at være højt nok ratet i en vis mængde. Og det samme skal også gælde for moduler, just in case.\,. .\,.\,Nå ja, og for URL-links, selvfølgelig. Nå ja, og her tænker jeg så, at man primært skal bruge en whitelist-mængde, og måske kan man så også bruge et eventuelt blacklist RegEx-pattern som et ekstra filter til en given mængde, for mere personlige præference-indstillinger. Det er klart at brugere, der ikke er logget ind, jo bare skal bruge nogle af de af hjemmesiden whitelistede brugergrupper, så for alle queries hvor brugeren ikke er logget ind, skal serveren altså tjekke ratingen ift.\ bestemte faste mængder (ikke ``faste'' som i `konstante;' mængderne er dynamiske). Og for brugere der er logget ind, der kan disse altså selv ændre disse indstillinger, og så tror jeg lidt bare, jeg må sige, at her er det brugernes eget ansvar ikke at godkende brugergrupper, som har fare for at loade farlige links og/eller loade korrumperede og/eller farlige (f.eks.\ potentielt farlige at downloade, hvis nu man kommer til at åbne dem som programmer). Der er ingen grund til sige, at det ikke må være brugernes eget ansvar (og man sørger jo lige for at give en advarsel, inden de får lov at godkende nye brugergrupper), for de har jo allerede dette ansvar, når de bruger søgefeltet i en browser, eller når de bruger søgemaskiner. Jeg bør dog selvfølgelig stadigvæk sørge for, at alle moduler verificeres som min undermængde her af JS. Men.\,. Tja, spørgsmålet er så lige, om jeg også skal lade serveren.\,. Hm.\,. Alternativt kunne jeg også give ansvaret helt til serveren, hvilket ville være mest effektivt (fordi man så kan gemme verificerede moduler i en bestemt mængde), men kommer dette ikke muligvis til at begrænse mulighederne for at udvide denne undermængde.\,.\,? (10:09) .\,.\,Ah, nej, for det kræver bare, at man på et tidspunkt åbner op for, at brugere også kan bruge andre mængder til at whiteliste JS-scripts!\,.\,. .\,.\,Hm, jamen skal det så bare være i serverlaget, at al JS-parsingen foregår?\,:) (10:12) .\,.\,Ja, simpelthen!\,:)\textasciicircum\textasciicircum\ 

(11:45) Hm, men nu kan jeg vel så ikke rigtigt cache ressource-godkendelser i local storage i browseren, hvis det bliver serverens ansvar?\,.\,. (Ikke at det nødvendigvis gør særligt meget, men det er jo godt lige at tænke over.\,.) .\,.\,Hov, det er jo faktisk egentligt bedre sådan her, ift.\ effektivitet altså, for serveren kan jo godt chache ressourcer, der bruges meget, og browseren skal jo alligevel loade ressourcerne via HTTP requests, så ja, man ville ingen gang spare noget ved lookups i local storage.\,:) (11:49)

(12:47) Jeg skal lige have overvejet nogle ting omkring full-text searches, og også omkring multiple title/objNoun queries, men det vil jeg bare gøre i løbet af i dag (og måske i morgen også).\,. 

%(16:03) Ret sjovt (og lidt irriterende) at jeg bare har gået og brugt en ikke-eksisterende String.prototype.test().!xD Men jeg kom lige i tanke om, at jeg jo alligevel skal oversætte metoden i alle parsing-programmerne, så det gør faktisk ike så meget, heldigvis. Og egentligt også rart nok at vide, at JS altid kompilere sine RegEx'er på en eller anden måde, inden de tages i brug, hvilket er fornuftigt. 

(16:06) Angående full-text searches så bliver svaret egentligt rigtig simpelt: Det skal simpelthen bare \emph{kun} være KeywordStrings, at man kan søge i med FULLTEXT searches. Og det man så typisk vil gøre her, er, at man så med det samme tilføjer en relation (og en bruger), sådan at man finder frem til en mængde af termer, der passer godt på de indeholdte nøgleord i den valgte streng (som så typisk vil indeholde en overmængde af de nøgleord, man selv har tastet ind). Og alle andre søgninger i databasen skal så simpelthen bare være semantiske søgninger, foruden primær- og sekundærindekssøgninger (hvilket også inkluderer sekundærindekssøgninger på term-titler m.m.). (16:12)


(24.04.23, 12:10) Kopieret fra commit message: ``Oh, I just realized something. I was leaning towards abandoning the syntax check (including even for JS programs), and now I just realized how doing so would actually just provide a perfect opportunity to showcase the potential for semantic technologies when it comes to program semantics verification..! So I'll keep the outer ideas about the UPA, including getting script from textID's in the SDB, but I will put a pin in all the ideas about automatic verification (and thus about my JS subset) for now.''

.\,.\,Well, I'm putting a pin in syntax-checking the JS subset, but I can still propose a standard of using various `upaf\_', `upav\_', `upai\_', `upak\_' prefixes, such that it is much easier to verify, that the user script does not cause any unwanted collisions. (12:16)

\ldots Let us actually just gather all that to one `upa\_' prefix, why not?\,. (12:55)

(25.04.23, 16:12) Okay, with my new insight that I ought to cancel all the automatic syntax analysis (for my ``JS subset''), that brings me directly to the front-end. And today has been about reconsidering and thinking about the design that I want to start implementing for the application. Luckily I have had a clear head today and have reached some good conclusions.

First of all, I will stick to my earlier idea about designing it in terms of ``columns.'' Each column has its own vertical scroll, and they can stand together next to each other, with a vertical scroll if there are more than the window can contain. If the screen/window is small enough, the columns size are resized such that the screen/window contain a whole number of columns, perhaps only one (e.g.\ for mobile devices). When scrolling horizontally, the scroll automatically moves such that no column is only half visible. When the mouse hovers near the sides of the window, a button to rotate the columns by one column width appears.

A column for a given term then contains a header, which can be collapsed (automatically upon scrolling down, if the window is small enough), a main part and a footer below, which can also be collapsed. The header can in principle contain a bottom to view different viewing settings, but I will only implement that later on. Otherwise the viewing settings is chosen by the script that opens the column, which is, however, supposed to look up the user's viewing preferences beforehand. Well, let me actually get to that later, and focus more on the possible contents of the columns for now.\,.

I imagine that the header contains different tabs, which each renders a different page for the main part of the column (with different data in it). The footer remains the same however, despite which header/main tab is chosen. For category terms, two central header tabs could then be `Subcategories' and `Elements,' just to give a good example. Choosing `Subcategories' should then load a main part which queries the set of subcategories for the category, and similarly for the `Elements' tab. Hm, and let me actually give some examples of tabs.\,. For elementary terms, the standard tab would be one which contains data about the term. Which data should appear then in the main part for this tab should then depend on viewing settings for the defining category of the term, but more on that in a bit. Two other very important tabs are then one that renders a main part containing ratings for the element, where the user can then of course give their own ratings, as well as a tab which shows.\,. Wait no, that is for categories: Category terms should have a tab with filter settings, such that the users can choose.\,. well, choose what appears to be settings for how the elements are sorted *(Well no, cause the lists won't be sorted exactly according to the chosen settings, but the settings might still look much the settings for adjusting a sort order.\,.) in the category --- and also for what terms are filtered away from the list, but underneath this appearance they will actually be determining some settings for an algorithm that queries the database efficiently and then also applies some additional processing for constructing the list that the user then sees. .\,.\,It's hard to describe here, but I think I have a good overall idea of how this can be implemented in a good way.

The footer also have its own tabs at the top, but these tabs, unlike for the header tabs, are meant to contain a more homogeneous list of data relevant to the term --- and which are not central or important enough to show in the main part. But in principle the header and footer can contain duplicated taps (with the same script for rendering the data!) .\,.\,Ah, but in general, the footer is intended for showing lists of terms that are related to the relevant term of the column by the same relation. The intension is thus to have only one relation per footer tab, and for each footer tab to then render a list of object terms to that relation (with the columns term as the subject). I hope this makes sense.\,. .\,.\,Whereas the header tabs are meant to give potentially inhomogeneous data fields for the main part of the column. So while the footer is going to works exactly like the header + main parts, the difference mainly lies in the fact that the main part is intended to include all the data that is most relevant to the term, possible with several relations making up the layout, and the footer tabs are meant to contain only one relation, and especially relations that didn't get included in the main part. Okay, I feel like I'm rambling a bit to much now; I hope it makes sense (somewhat) as I have put it now.\,. %(17:04)

The footer can actually also be expanded to fill out the whole column. And by a press of a button, it should be semi-collapsed down to the bottom of the column again. I imagine that the footer contains a few special tabs meant to adjust the viewing options themselves. .\,.\,Hm, I actually feel a bit tired now, and I also feel like I can do some more thinking before continuing, so let me just do that (and then return later in the evening or tomorrow morning).\,. (17:10)

(26.04.23, 10:00) I have thought more about how to implement the application. Let me start by mentioning some things about the columns, that I didn't get to yesterday. It should generally be the case, that when you middle- or control-click on a tab (from the header or the footer), the tab content should be rendered in a newly opened column to the right of the relevant one. .\,.\,Hm, and what else?\,.\,. .\,.\,Hm, I actually think that was it for the overall design. Let me therefore now continue by describing how to make all this highly modular.

When you open a new term in a new column, a script is then run which is responsible for constructing the main flow of that column, including the header with its tabs and the footer with its tabs, as well as deciding which header/main tab we start on, and whether the footer should be visible from the start or if it should be collapsed. Each term type will then typically have their own script, and whats more, any category can also overwrite its parents script, such that elementary terms will get the column-rendering options defined by its ancestor categories, where each subcategory can overwrite part of the rendering options of their ancestors. And I say rendering option\emph{s} in plural because there are a lot more scripts to run than just the outside one (hence why I say that the rendering options should be highly modular). Besides the main script for the column, which I will henceforth call the ``(outer) column script'' as to not confuse it with the main script of the application (the UPA) itself, (besides this column script,) there are first one script for each tab which this column script calls when it need to render a new (including the initial) tab. The column script will also potentially call some scripts that sets up listeners, which can then listen for data sent by a child tab (including if the tab is opened in a new column! (that still makes it a ``child tab'')) and then perhaps send that data on to other child tabs. I will personally need this when I need to implement text annotations (which has to be implemented rather soon after the first part, which is the system that deals with ratings and sorting via those ratings, since the annotations are now very important for verifying user scripts (in a more community-outsourced way)), since I would like for desktop users to be able to see how their new annotation will look on top of a text, while they are constructing it in a (child) column next to it. But in my first implementation.\,. Oh wait, I might also need it for sortings.\,. Yeah, I need it there as well, if a want users to be able to adjust the sorting settings in one column, and then be able to click and get the relevant category column to update with the new sorting settings. Okay, so I should actually make this signal handler for the script for rendering category columns.\,. %(10:26)
%...(10:42)
\ldots When the column script loads the tab scripts, it doesn't do it directly. The column script instead defines/uses some keywords, such as ``subcategory list'' or ``comment section,'' and then run a procedure from the application main script to get some functions that loads these things. Each of these functions are in principle defined from running their own script.\,. Okay, this is going to a bit complicated, so let me think about it, and about how to explain it\ldots (10:49)

\ldots\ (13:18) Okay, I've come up with several ideas about what to do. First of all, the UPA actually don't load just one main script in the beginning. It start by querying the ``preference user'' for a whole set of initial scripts, which are then executed in order from highest rated and down until a certain lower threshold (above zero). Among other things, these scripts define a class for loading content into an HTML element, given a key pointing to a function (e.g.\ for loading a ``comment section'' or a ``subcategory list'' etc.) as well as some inputs for that function. And the scripts then also load settings into this class, each of which defines or redefines a key by associating it with an actual function (e.g.\ a function to load the contents of comment section given certain input). For instance, we could have that the first script in the sequence defines this class, then the next script could define a bunch of ``content keys,'' as I will call them from now on, and associates a function with each of them. Then the next script might define some new content key--function pairs, and might even redefine some of the keys from the second script (since this might be easier to do rather than to write one script that does it all for each specific user preference; it will often be better to just specify preferences by overwriting previous keys). Now, the class in question then also implements signal handling for its children, meaning first of all that every time a child is loaded from a instance of said class, that instance then adds a child key--jQuery object pair to a list over active ``child processes,'' so to speak. Each ``child process then also holds.\,. Oh wait, the parent should not hold jQuery objects directly, but should hold a ``pointer'' (in the sense of how JS works regarding reference types) to the child object, which by the way are instances of the same class, and each child instance should hold a ``pointer''/reference to its parent. Each child can then send signals to its parent, who can then either react directly on these signals, and/or it can send these signals on to a collection of its other children.
So far so good, and in terms of loading the content that an instance of the class (children and parents alike), each instance.\,. Hm, let me actually think about just a few things before continuing.\,. (13:38) .\,.\,Hm, let me first of all call the class a `ContentLoader,' why not?\,.\,. (13:39) .\,.\,I by the way plan now to make the footer just another child of the column's content loader, but I need to think about, whether I should actually also do the same for the header, or if a should stick to wanting to treat that one specially.\,. (13:41) .\,.\,Yeah, cause the tabs of the header should each be associated with its own content loader.\,. .\,.\,Hm, let me think.\,. (13:44)

\ldots (14:47) Okay, I have finally landed on a solution, I think. The header will not be a special part of the class's API, but will just be another child, which then means that I have to implement serious signal handling from the get-go, since the header then has to communicate to its parent when new tabs are selected. Furthermore, having divs/containers that can render content associated with several content loaders, and not just one, is not a part of the basic API either, but rather the parents simply adds a new div/container / content loader child when a new tab is pressed, and then simply hides the previously active child div/container (and perhaps in some cases give the child a signal to empty itself, such that the garbage collector can free that memory again). So having a multi-purpose div that can render several different types of content, will actually just be implemented by having several divs which the parent can then switch between such that only one is ever visible at a time. 

.\,.\,And there we pretty much have it. I want to mention, that I then also want to even implement the box that contains all the mentioned columns as an instance of this ContentLoader class. New term columns will then have their own content loader attached to it, but if column opens up a child as a column next to it, instead of opening up the child within itself, what happens is (the way I intend to implement it) that the content loader implementing the column just widens to the width of two column, and then indeed opens up a column within itself, but just where it appears to be a new column that is outside of the parent. I will then just make the horizontal scroll snap to, not the actual border of the content children, but rather to multiples of a given column width. So when a column is now actually the width of two columns (and appears to \emph{be} two columns instead of one), the scroll will just snap to the middle of this expanded column, instead of only being able to snap to its edges. %(15:04) ..Hm, what else to say?.. I feel like that covers a lot of it, and I have already mentioned that the footer will now just be another child of the column's content loader (and so will even the header).. ..Oh:

.\,.\,Oh, and I should also mention that the script are now no longer modules: The set of scripts that the UPA loads (sequentially) in the beginning are now loaded as normal scripts (with the ``use strict;'' command). These script, however, should make sure to use `upa\_' prefixes for all globals, but they are free to overwrite each other's functions, and to change each others global variables, not least (which will be used to change content key--function pairs). .\,.\,Hm, let me think, however, if I need to also be able to use modules.\,. Oh, and I should mention, that the content loaders can also import scripts dynamically, when they need to render some content types, that are not frequently enough loaded to be included in the set of initial scripts. (This by the way means that I must include modules as well, but let me think about that in a moment.\,.) Such dynamic (more dynamic than the initial sequence of script (which are technically ``dynamically loaded'' as well, as with all scripts in JavaScript, but not ``as dynamic'' as those who uses the import() function)) modules can be loaded after looking up further preferences from the ``preference user,'' in particular for rendering terms of special subcategories, which the ``preference user'' has defined such that the rendering options overwrite option from the ascendant categories, but has nevertheless not included as part of those scripts that need to be fetched from the server immediately when starting the UPA (i.e.\ the scripts in the aforementioned set). Thus, the user can navigate to a new term, the UPA can discover that one of the ascendant categories of that term overwrites some rendering options, then the UPA can import() the required script for defining the new content types that terms of this category requires, and then the UPA can proceed to load the contents of the column of that new term (with content types that are not specified in the initial sequence of scripts). .\,.\,Okay, let me think about some of the details regarding this process, including the things about using both module and non-module scripts, and then I'll get back here\ldots (15:23) .\,.\,(15:28) Oh, I have also completely forgot to mention some further modularity when it comes to loading and then rendering contents of the leaf content loaders / content containers (i.e.\ the ones with no ContentLoader children themselves), but let me also just get to that after having thought for a bit\ldots (15:31)

\ldots\ (18:01) The UPA should use modules!\,. And then these modules should just add globals to the window or to local storage manually. And when they do, they should either prefix all these globals with a the same prefix, or the should add only one global object, whose properties are then the global variables. The prefixes aren't predetermined, and in principle the users can choose whatever, but in practice most user scripts will build on top of a previous API, and each of these UPA APIs will have their own special prefix/global object (initialized by the first script in the sequence of initial scripts). A user who want to add a preference-defining script to an existing API/library should then use the same prefix/object as that API/library, otherwise their script should not be accepted by the community and/or the developers. The rest of the webpage, the ``non-UPA part'' so to speak, should by the way also use it own modules, or should at least not add any global variables to the window. 

About the content loader ``leaves,'' let me first mention that I forgot that these will also need signal handling, so this signal handling will absolutely have to be something that I try to implement immediately (for this ContentLoader class). Now, in my thinking break here, I also had the idea that some content loader leaves might not be attached to any HTML element, namely since they can also simply be responsible for loading data(/content) into a JS object, instead of into a HTML container on the page. This could for instance be when loading a set of terms. The content loader should then signal to its parent, when the data is downloaded and ready, and then attach this data to the signal (or a subsequent one). Typically a loading of a set will also require subsequent queries to the definitions/data associated with a term ID. Either by signal from the parent or by itself, the JS object content loader can then query the database for this data, and then signal its parent once again, when all or some of the next batch of data is ready. The parent can then load this data (from both batches, one before the other) into another child (via signals of course) for which the boilerplate HTML has already been loaded in the meantime. This second child will then know where to put this data. Now, notice that if another user wants to change the HTML for the list that renders the given set in our example, they will then only have to make changes to the child that loads this boilerplate. .\,.\,In fact, since a parent can also make changes to its children directly, without signals involved, one could design list container child to consist of a parent which has a protocol for inserting the received data into an already-loaded boilerplate HTML child container. This boilerplate content loader will then \emph{only} have to define the boilerplate HTML, nothing else. And users who wants to overwrite previous preferences for the list (boilerplate) HTML with their own then only have to add a script that changes this exact content type (of the list (boilerplate) HTML), nothing else. And since this just require changing one HTML template to something slightly different, such a script will be easy to verify by the community / the developers. By the way, the mentioned HTML boilerplate will also include CSS classes, which means that users can make big changes just by changing some CSS classes to something else in the markup. And if the users needs to set some special CSS properties that aren't part of the existing CSS library (of the UPA ``script family'' that the user wants to build upon), the user can of course also very likely set these in a clear way that isn't hard to verify (by the community / the developers) either. So this is how the users will be able to change the HTML of various content types by adding/changing only small scripts without much logic contained in them. And of course (it almost goes without saying), users should also be able to add scripts that redefines existing CSS classes slightly, which means that a few lines of CSS (can will often not be very hard to verify as safe) can change the application's appearance pretty significantly. (I have already written some code a short while ago that exemplifies how UPA script can append CSS to the head of the document, and that is also the intention here; that users can add script that alters the application by doing exactly this.) (18:39)

(19:10) I should also mention that users who are logged in can always load and run the scripts that they have uploaded themselves. And let me also mention that the ``more dynamic'' scripts doesn't have to use import(): We can also implement dynamic script by inserting module scripts the same way as is done for the sequence of initial scripts (where these scripts can then change and/or add to the (prefixed) global variable(s) manually for the window).

\ldots (19:30) Ah, and the initial input that a content loader needs is also just given by signals. This also means that the parent can initialize the child instances without them activating before they receive their first signal to activate, which should then of course include a payload of the needed inputs. 

(27.04.23) jQuery already has custom events, so I actually don't really need to implement much.\,:) .\,.\,Hm, I maybe even don't have to actually make a class, cause another solution could just be have an function that initializes all content loader children within an element by running a function that reads the content loader class off each child as an attribute (how the content loader class should be defined anyway), and then simply branches to the initializing function.\,. no wait, actually, it should just set up an event listener for ``activation,'' and then define the content loader function to run upon that activation. Yeah, this seems to be the way. And a parent also does not need to keep a list of its children, cause we can always simply utilize jQuery for traversing (both up and down) at any point. (10:03) .\,.\,Yeah, so a ``content loader class'' will now not be a JS class, but simply a HTML class, which is initialized by its parent element, at first simply to listen to the first `activate' signal (for which it will then call the content loader function associated with the given content loader/container class).

(10:20) Let me use a new HTML attribute for the content loaders and call it `content-key'. I could also use the class attribute and add a `contains-' prefix to it to make the syntax better for selecting it for CSS styles, but I don't actually think the the content loader containers \emph{should} be selected for CSS.\,. Hm, not especially so, at least.\,. .\,.\,No, let me indeed use a spacial `content-key' attribute, which is then not intended to be used for defining CSS for the div; only CSS classes should be used for this. (10:26)

Before I get going, however, I should also briefly just mention, that I actually only intend to implement more complicated ``user groups'' later on, and in the beginning, I will thus only use one ``user group''/native bot, and that is just an average rating bot, biased a bit towards zero, such that the first couple of ratings cannot move the combined (zero-biased average) rating far away from zero. (10:30)

(28.04.23, 9:36) I think I know what to do about the user groups / native bots. I think I should have a private row (that no one can query) for RecentInputs denoting the time of the ratings. For each user group there can then be a bot with access to the database, which continuously scans the recent inputs and changes the ratings of the user group accordingly. When a scan begins, this bot then records the time (just before the scan starts). It then only looks at the changes between its last recorded time (for its last scan) and the one it just recorded. For each ``recent input,'' it then looks at the last input before the last scan's beginning time and also the last input before the current scan's beginning time (but not any inputs that a newer than that (i.e.\ uploaded during the scan)). As a defining feature, each user group then has to have an algorithm/formula/function that can update a rating when knowing a users former rating and a new one, and still maintain an invariant. For instance if the invariant is an unweighted arithmetic mean, the formula would be something like
$r_{comb, fin} = r_{comb, init} + (r_{ind, fin} - r_{ind, init})/N$, where `comb' stands for `combined,' `ind' is for `individual' (i.e.\ the user behind the given input), and `fin' and `init' stands for `final' and `initial.' When the scan is done, the bot overwrites its old `time of the last scan' with the new time and wait for the time of the next scan. A central program/bot can then also scan each user group to get the least `time of the last scan' and then apply a clean up procedure to RecentInputs for all inputs that lies before this least time. This cleanup procedure should then gather some of the inputs if the user has changed their opinion many times recently for a given set--object pair, and it should not least turn timestamps into dates, such that the `sensitive information' of the exact time of the input (which we will treat as such), is transformed into what we will see as `non-sensitive information,' namely the date of the input.

Now, such algorithms might have a little drift away from the exact right rating due to imprecision in the formulas. There might therefore also be a bot which very rarely will simply take a user group formula, not the relative one but the absolute one for obtaining the ratings given all user inputs (which should however still have a form where the combined rating can be constructed piece by piece, without having to keep all the user ratings in memory at once.\,.), and then goes through the entire RatingInputs table to calculate the combined ratings. Of course, this calculation will also not be 100\,\% precise, and precision isn't even \emph{that} important for the system anyway, so these procedures should just run very rarely (and perhaps be there more for backup purposes, really.\,.). But yeah, this is my new plan for the user groups, once it finally becomes time to implement them (more than just the standard zero-biased mean bot). Users should then be able to upload descriptions of the user group algorithms, that they will like to see (which will likely often be similar to previous algorithms but only which some changed parameters, probably often in the form of a set (so a set ID) of users where the ratings of the users in that set will then give the weights to the average). The user community can then up-vote various user group description that they would like to see, and the developers can then continuously initiate new user group bots that the community wants --- and discontinue old ones that are no longer used/wanted as much. The developers should also actively give suggestions for new user groups themselves. And these suggestions might often be due related to some machine learning-like statistics, namely where the developers measure yet another statistical tendency (in terms of correlation eigenvectors) and then tries to create a user group with weights according to how much each user fits (or more precisely is projected upon) said correlation eigenvector. (10:19)


(30.04.23, 10:07) Okay, I think I know what to do now.\,. If we look at contentSpecIndex in t2 now, I will make that into a class and absorb the functions in it (into methods). Then I will make at hold a contentSpecIndex object as a property, and actually then say that modules should be allowed to change this array as side-effects. But the modules should still export whatever ContentSpec instances the define/redefine. .\,.\,Hm, let me think for just a second before continuing, about whether this is really the optimal way to go.\,. (10:12) .\,.\,Sure, why not.\,.\,! Okay, and this means that later modules that imports content specs from an earlier module will have the side-effect of changing the --- oh, and I think I will call the contentSpecIndex class something like ContentLoader --- changing the ContentLoader instance that all the modules import. But because each module also export their newly (re-)defined content specs directly as variables, later modules will know that if they import these, then that is what they will get.\,. Hm, or maybe there is a better solution (which I just remembered my earlier idea for).\,. Let me think.\,. (10.19) %..Hm, thinking out loud *(or rather "on the keys") just for a bit: Maybe I should let ContentLoader hold a structure of other ContentLoaders.. (10:21) ..Or maybe I could keep a seperate struct over ContentLoader names / combined ContentSpec names.. (10:24) ..A "content spec(ification) index," btw.. ..Hm, no.. ..or yes.. ..(10:35) Hm, I don't think I need to gather them together; a "set" of ContentSpecs should just use clear and informative event strings, and define a clear specification for how the content is supposed to work over all.. I think.. maybe.. 
\ldots\ (11:54) I think I'm just about to have it, finally.\,. %..Let me think on the keys again, so ContentLoaders chould contain other ContentLoaders. And when a new script/module changes something quite fundamental about a ContentLoader, then there should definitely not be any side-effects, and the changes should be exported as a ContentLoader rooted in the "production" (to lend a term from Grammars), i.e. the content key, which is the outermost "production" that has either its HTML or its event semantics changed.. (11:59) ..Yeah, and should I even have side-effects to begin with after all..? (i.e. now that we can "package" subproductions and gather them in "child content loaders"..) ..Hm, or maybe the root content loader can just be assembled top-down in the end, by importing the content loaders/spec in order from the parents going to the.. (children..) well, maybe not.. Let me think a bit more (off keys).. (12:04) ..Hm, maybe a top-down constructor *(at the end..) is really just all that we need..!.. (12:05) ..(12:10) Oh, now I just had the idea (and think) that we should build all content loaders on top of a sort of tree of semantic definitions for the contents (mainly defining what their children can be and what the signals does).. Hm.. ..Hm, I could also see a way of implementing this tree via the ContentLoader class itself, together with some checkers that checks that modules do not build upon a part in the tree, that has already been built upon.. Hm, I think I'm close to the answer.. (12:15) ..Yeah, I think a good solution could be that we do indeed apply the changes as side-effects, but then just make sure that any module that changes either the HTML or the event semantics of a content loader in the tree increments some property denoting the "modification level" of whatever thing the make changes to (e.g. the HTML or a certain group of signals), and also makes sure that these levels has not been altered since the parent module that the.. main ContentLoader.. was imported from before making these changes (throwing an error if these levels have been increased in the meantime between running the parent module and the current one). (12:22) ..Let me copy this to the rendered text..

\ldots Copied from comments: ``.\,.Yeah, I think a good solution could be that we do indeed apply the changes as side-effects, but then just make sure that any module that changes either the HTML or the event semantics of a content loader in the tree increments some property denoting the ``modification level'' of whatever thing the make changes to (e.g.\ the HTML or a certain group of signals), and also makes sure that these levels has not been altered since the parent module that the.\,. main ContentLoader.\,. was imported from before making these changes (throwing an error if these levels have been increased in the meantime between running the parent module and the current one).''

.\,.\,Yeah, so I think my solution will be, that each module just imports the same main ContentLoader and then navigates to the given child content loader (cause now I think ContentLoaders should hold other ContentLoaders as children) that the module wants to alter. It then makes sure to check that the properties denoting modification levels of dependency groups within the ContentLoader are not above what the current module expects (or throws an error otherwise), and when the module finishes, it also makes sure to add and/or increase such dependency group modification level properties before exiting. Nice.\,.\,:) (12:30)

(14:02) Okay, and each ContentLoader should indeed hold other ContentLoaders (not ``ContentSpecs''), and should actually just hold their keys themselves. So when having to load a nested template, the ContentLoader simply searches all its children for a matching content key (which the children hold). And if no match is found, the task is actually handed over to the parent (a new idea of mine). So that way, child content loaders can use content ``productions'' that are defined above them at their parents. Now, if someone decides to add a ``content production'' from a parent in an environment, where it hasn't been before, that module should then probably also add a ``dependency group'' to the parent in question.\,. Hm, well that depends.\,. *(No, if a child starts using a production from an ancestor, that ancestor then has to ``konw,'' i.e.\ by setting or increasing a certain dep.\ group's mod.\ level for it.) But anyway, this is how it will be, and then this also brings me to commenting on these ``dependency groups'' again (which should contain a name/key, a description of the dependency, and then of course a ``modification level''). Cause the really good thing about these dependency groups is that the don't have to be set immediately when the dependency is.\,. well, caused, so to speak. Instead the users can actually just wait until they first start to make changes that reveal and/or create potential dependency issues. Then these users should first make a script that adds the relevant dependency groups to the given ContentLoader(s) that they want to modify, and then they can go on to make a new script/module after that, which uses these dependency groups to signal that the new changes might change how the content production functions in a way that is not necessarily compatible with the changes of other users. Then when other users want to make new changes, they can either build upon these changes, and perhaps increase the relevant dependency levels, or they might also start from the same script/module that initializes those dependency groups, but then go in another direction with them and thus follow said script/module up with a different script/module that starts incrementing the modification levels of these dependency groups. This was a bit complicated, so let me formulate it again. When a user wants to make some changes that might be incompatible with other user's changes, they should then (if this has not been done by others) add a module that initializes some new dependency groups, with modification levels all at zero, and then do nothing else. When they then go on to make a module that makes the given changes that are perhaps incompatible with others' changes, they should make it import the dep.\ group-defining module and then increase the relevant modification levels by one. Other users can then make new modules building upon this script, or they can let build upon the aforementioned (parent) script that initialized the dep.\ groups with mod.\ levels to zero (or they can of course also start from an even earlier ancestor module). So there we go. I hope this makes sense; now I will start implementing all this. (14:27) %(Well, perhaps after training break here at 15:00..)

(01.05.23, 11:53) I'll change the ``dependency groups'' to just be arbitrary ``modification signals'' that can be objects with an arbitrary set of properties. The can then also for instance contain ``reserved content keys.'' Now, a more important thing that I should also note, is that user modules are still okayed for use in groups, or more precisely in `sets.' This actually means that the same thing that we try to achieve with these ``modification signals'' can also in fact be achieved purely with the semantic database.\,. okay so I actually have to consider if we should even have the ``modification signals,'' I guess, but I strongly suspect that I will keep them, though.\,. Anyway, by grouping modules into sets --- and providing semantic documentations (in the SDB) to each module set --- we can actually achieve something similar to what the mod.\ signals tries to achieve. (These signals will just mean that these sets might be able to get much larger.) By grouping modules into sets, we can start with a small set of modules for the application/website where the modules don't care too much about the modSignals (and about repeated content keys and such), cause the limited size of the set makes it so that it isn't so hard to verify new modules against the old ones. And the initial modders --- and the developers --- will likely be able to maintain a good overview of the dos and don'ts of this initial UPA library. The moment that things start to get a little complicated, the modders and developers can then document the library so far an gather it into one module. And then new module sets can be made with this initial UPA library as the first okayed module in these new sets. Then modders and developers can add new modules to each set, which will then each be a branch of the UPA. .\,.\,So yeah, in total the point is that there is a lot of things we can do to partition the user (and developer) modules up into groups and to document the intended semantics (and the dos and don'ts), so we shouldn't worry too much about the modSignals (which I \emph{will} definitely keep, I'm pretty certain %*(13:05):
*(Oh yeah, absolutely.\,!)%
) in the beginning. In other words, let us not be too defensive as programmers in the beginning. Let us instead just assume that all the initial UPA content loaders will be refactored well-before the libraries start to get big enough that the modSignals start to become important.

(12:25) If we ever want to introduce what I was about to make in terms of ``ContentManagers,'' if say we at some point want/need to speed the programs a bit up, then these can just be implemented by adding a module that holds an array of such ContentManagers (which then does not have to be of a special class but can just be any object really) associated with a certain ContentLoader (which the given module modifies). And in an inward or outward callback, the.\,. %wait, and also this CM array can also be initialized dynamically by these inward/outward callback function, which is perhaps often better, actually. ..No wait, probably not (let me out-comment this)..
.\,.\,a CM key can then be added to the startMarker of the content production. Any subsequent callbacks, or other subsequent functions/scripts, can then at any point query the startMaker for the CM key, look it up in the aforementioned CM array (which should also be imported --- or should be initialized by the same module that uses it --- or could also in principle be initialized dynamically by an inward/outwardCallback by letting them attach it to window), and thus obtain access to the CM object, which can then be queried, modified and/or used to apply a method (one of its) on some element or piece of data. (12:38)

(15:48) There is one apparent weakness to my planned system so far, and that is that it seems very rigid in terms of being able to go in and solve/remove a bug/fault for a module already in use, due to the fact that texts are pretty much constant in the database. But there is an easy solution to this (which we have to use), and that is to say that the server is allowed to map requested scripts/modules to other ones, so that if a bug needs fixing in a script already in use, then the developers can just fix this bug in a new text and then map the old text ID to this new text (when it comes to scripts/modules and only that). Scripts that imports from the now remapped text ID does then not have to be remapped themselves in order to include the bug fixes in practice, but the developers might still want to remap these after a time, since this.\,. well actually, never mind, cause when querying scripts in the SDB interface UPA, the community can just make sure to implement that the remapped script are shown first thing (just with a visible note that the user is watching a later version, not the original). But yeah, the developers should however still also remap scripts that uses the old IDs that has since been remapped, at least after a time (so that each little debugging doesn't require an immediate remapping of a lot of text (also since this would cause a lot of remappings, leading to more dead texts in the database)). (16:00)

(06.05.23, 13:28) A remainder for myself to talk about my so-called ``wish ratings,'' that I remembered about this morning. But I'll do that later today; right now I need to go for a walk.\,. 
\ldots\ (16:18) Okay, let me write about it now. I'd almost forgotten about those ``wish ratings,'' but they will be very important as I see it. Now, I think they should actually be implemented by adding more bytes to the rating values. And maybe I will make it an early standard that a the first rating byte represents the mean, the next represents a spread of precision, and the third will represent a wish for modification and/or for future versions of the term (as a signal to the creator of RW (real-world) thing that the term represents). All these three bytes have signed values ranging from -1 to 1, going from -127 to 127. And then -128 means null/``not given,'' which can for instance be used (in our case with the three rating parameters) if wanting to upload a wish rating, but not a precision specification or/nor the standard (mean/midpoint) rating itself (and thus users can even express wishes (for modification, future versions or future RW things in the same category as the given one) without having to also express their opinion on the given term at hand). (16:27)


\section{Continued working notes while making the application}

(07.05.23, 12:32) I'm considering making changes to the SDB (i.e.\ the backend database system). I've already decided to convert to decimal IDs, to group all users and bots (native as well) in to one table (``Users''), and to make the sets homogeneous, but the last point requires some further thinking. I now think that I will make some fundamental sets, instead of categories, be the entry points for the database (as the ``roots'' of the ``graph,'' so to speak). Then I can perhaps.\,. Hm.\,. or maybe I should use ``meta-categories''.\,. %(12:37)
.\,.\,Okay no, I don't need meta-categories, 'cause we can can just use relations (with the Terms category as the subject) --- which I will by the way include a obj\_cat\_id on top of their subj\_cat\_id. .\,. %(12:43)
.\,.\,Hm, I btw think that I might stick to calling it Terms and Elementary.\,. Hm, no I should figure out something better.\,. .\,.\,Hm, what about Entities (as in: `database entities') and Terms?\,.\,. (12:48) .\,.\,Hm, that does seem like it could be a good idea.\,. 
.\,.\,Okay, so with this I have Entities of a small variety of `types,' including Relations, which can take any Entities as their subject/objects, and Categories, which always have Terms as their `elements.' .\,.\,Okay, this seems good, but let me think for a little bit.\,. (12:54) .\,.\,And if users really want to have categories of Relations and/or of Categories, they can just implement these meta-categories as as Terms, and then make a corresponding pair of `Subcategories' and `Elements' relations. (12:57) .\,. .\,.\,Oh, or they can just take the relevant fundamental set and make some relations to yield subsets.\,. well okay, that is the standard thing to do, but that does not give quite the same category--subcategories--elements system, so if they want a system exactly similar to that, they can do as I just wrote.\,.\,:) (13:01) .\,.\,Hm, but about the fundamental sets: All sets should probably have a subject and a relation, so maybe.\,. .\,.\,Hm, how about having a category.\,. Or a term.\,. hm, called `Enitities'.\,. Hm.\,. .\,.\,Ah, or how about a term called `This SDB'.\,.\,?\,:)\,.\,. (13:07) .\,.\,I like that (a lot.\,.).\,.

.\,.\,Hm, I probably don't need categories to have obj\_cat IDs, then.\,.(?) .\,.\,Oh wait, I can't even \emph{use} categories now for relations!\,.\,. Hm.\,. (13:19) .\,.\,But I guess I \emph{could} use sets instead.\,. (13:20) .\,.\,Hm, I guess I need to decide if I even need it, for while it is a good way to make a relation more clearly defined, couldn't we just instead simply allow relations to be ambiguous (their semantics depending on the subject).\,.\,? (13:24) .\,.\,Yeah, why not?\,.\,!\,:) (13:26)

\ldots Ah, but the Relations should, however, still know their subject and object \emph{types}, which then means that I can lose those for the sets.\,. .\,.\,Hm, this makes it quite nice, cause all of a sudden, types only appear in tables Relations, Lists and Creators; all other tables can make do with just the numerical part of the IDs.\,. (13:48)

(08.05.23, 10:09) Oh, now that users can trust the UPA more, I don't need RecentInputs for anything other than.\,. well, than for the native bots, but perhaps also external bots.\,. Hm.\,. .\,.\,(Let me call them `internal bots,' actually, btw.\,.) .\,.\,Well, external bots will be at a big disadvantage anyway, so maybe it doesn't make too much sense to.\,. well.\,.

.\,.\,Hm, I do want external bots to be able to participate, so it would actually be much easier if users could just have a standard random delay (with a standard spread, that is) to all their inputs, and then they should just be able to adjust this spread for any new rating if they want it to go through immediately.\,. Hm, so how do I implement this.\,.\,? (10:22)

.\,.\,Okay, so what I will do is to put a (now public) timestamp back on RecentInputs, and then for now just let that timestamp be the actual one. Then at a later point, I will make a private RecentInputs as well, which should include a user-specified spread as well. I should then also implement a ``bot,'' or a server procedure rather, that scans the private RecentInputs, rolls some dice, and then move the private inputs over to the public RecentInputs table depending on these dice rolls (or rather an RNG), the spread and the actual timestamp. And when they are moved over, the new timestamp will be they time of this movement, not the actual timestamp. (10:30)

(22:16) Ah, I just realized that we can't let users run their own scripts freely, 'cause then users might leak their password and thereby fool someone into logging on as their user, whereby malicious code can be run in the victim's browser. So yeah, I guess all code has to be reviewed first.\,. 


(23.05.23, 11:27) Okay, object nouns are the standard for the Relation strings, but this semantics can be escaped by prefixing the string with e.g.\ ``adj:'' or ``verb:'' or ``rel:''. I intend to use the first two examples here especially for Predicates (which will be a sort of ``virtual type'' in the SBD), where the subject should then be a category, the adjective or verb should be taken to relate to the object, and verbs should use singular.\,. well, verbs.\,. .\,.\,They should be inflected in the singular (present) case.\,. .\,.\,This is a much better solution than what I had in mind before about e.g.\ cutting out `elements' at the end of strings to yield the adjectives. (11:33)

\ldots (12:22) Hm, let me call the category--verb/adjective combination `Predicates,' and let me then call the more general subject--relation combination `Classes.' Then Classes and Predicates will actually be much more visible as types in the application than Sets, I think; Sets will be more the concern of developers/developer users.\,.

(24.05.23, 14:31) I've just come home from a little walk, where I had the realization that I can just make the Predicate Column into the Relation Column instead (and then just automatically insert the subjID held in the input data). This also means that I will actually (seemingly) only need the EntityColumns to begin with, which also makes things simpler.\,:) So let me start implementing these new ideas.\,.


(25.05.23, 10:22) I had many good (probably) ideas yesterday evening, I'm still not done thinking about them, 'cause its actually at a point now where I foresee that there might be big changes to the database and the semantical system itself. Let me think a bit on the keys in comments below this paragraph (in the source text) to keep me on toes about it for a bit.\,.

%Okay, der er flere ting, men jeg er nu bl.a. blevt ret sikker på, at kategorier og termer skal holde en (nullable) definerende entitet. Jeg havde også (i første omgang) nogle idéer i går om, at objNoun skal hedde relText (eller noget lignende) i stedet, og at der så altid skal være prefikser, der fortæller, hvilken type lexical item (ved ikke hvad ordet hedder på dansk) det er, og også samtidigt (implicit) hvordan dette skal tolkes som en relation. ..Jeg kan også lige nævne, at jeg også fik den idé, at kommentarer --- og andre "Appendices" (kom på at bruge det ord i sengen i går aftes/nat) --- skal være kategorier. Nå, men disse tanker gør så, at det bliver lidt redundency ift. prædikater (som i subjekt + relation) og kategorier, så jeg vidste at jeg skulle tænke videre i dag. I morges her i badet kom jeg så på: Mon ikke man kunne bruge min præfiks-idé for termer også, og så bare samle alle mine tre "semantiske entiteter" til én (nemlig til "Termer")?!.. Så det er altså de idéer, jeg skal tænke videre over nu.. ..Hagen er jo, at det lige bliver en tand mere kompliceret, når.. hm, når man skal arbejde med en masse præfikser, men det skulle vi jo alligevel, så nej, måske bliver det ikke \emph{mere} kompliceret.. Hm... (10:37) ...(10:49) Hm, jeg overvejer at lade termer og relationer smelte sammen, men stadig.. Hm, nej det giver ikke så meget mening, men jeg bliver nødt til at finde ud af, hvordan jeg stadig får fremhævet brugen af hhv. definerende superkategorier og kategorier... (10:51) ..(10:56) Ah, det gik lige op for mig, at jeg er fri til at gøre subject nullable i Sets, og dette ville jo være rigtig godt i et sådant nyt system, hvor relationer bare er termer igen (og dermed nemt kan blive prædikater). Og i og med at jeg jo nok gerne vil beholde det felt i, hvad der så ville blive den kommende Terms tabel, der definerer, hvor termen udspringer fra (altså de nuværende definerende kategori- og superkategori-felter), så kunne prædikater så bare også få lov at udsringe fra en kategori, sådan at man stadig har den nyttige ting med. Men nu bliver det så bare ikke "subjektet" af prædikatet, men det bliver, meget mere intuitivt, noget som prædikatet holder som en del af dets definition. Okay, det kommer altså til at blive nogle rigtig gode ændringer, de her, når jeg bare lige får dem udtænkt færdigt..!.. (11:01)
%...(11:24) Hm, I just had some good ideas to shift the nomenclature.. An important part is to use "Classes" a lot more, since it has the derived word 'subclasses,' which has a very similar semantics as 'subcategories.' My ideas are then to use 'Categories' as an outer division of terms, which is supposed to not just tell you what kind of term, we are talking about, but is also gonna be used by the application to "figure out" how to present that term (interface-wise). So we should be able to divide all terms into Categories and non-categories, where most non-categories should then be the "elementary terms" that springs from a category.. But these are not the only ones, cause then we also have predicates and relations, which "springs from" something different.. (I'm just think out loud now..) Then there are some virtual types that we should (probably) call 'Classes,' which consists either of a predicate term or a subject entity plus a relation term, and whose object types are always Terms (not other entities) to be considered Classes. A more general word that also includes predicates / subject + relations that take whatever types as their objects (not necessarily Terms) can be called Sets. This then means that I should change the name of what I currently consider Sets to something else, such as maybe 'RatingSets,' or something like that.. (11:37) ..Yeah.. But I actually don't know exactly yet how predicates and relations will even define their object types, so let me think some more.. (11:38) ..Hm, or should all object types simply just be terms, and then you always have to wrap the other types of entities up in Terms (having them as/in the.. "specifying field"..) before you can refer to them.. hm, and thus also before you can even define them.. So other types of entities should then always be created as either the part of creating a new Term, or the other way around: A new term should always (automatically) be created when e.g. a User or a RatingSet is created.. Hm, maybe..
%...(12:23) Ah, now I know! Categories.. Well, that means.. Okay, Categories \emph{should} be specail after all! And, since we now have out Classes, which are made up of relation [+ object] (I think I will finally exchange what I've been calling subject and object in the database), and which can have the nice relation to.. them.. ..'Subclasses'.. (Hm, but how to use a relation on a virtual time, something to think about there..) ..Since we have Classes, Categories are now free to be more specific in what they can hold in their "defining field." So the idea that I just had might very well work, and that is to let Categories always hold a description text, which then specifically define, not what's \emph{in} the category, but how the defining field and the specifying field (as well as the title/string/text, I guess) is to be interpreted! (12:31) ..Well, only problem is that the defining field will then always be a category, but I guess that's fair; then the categoriy descriptions will just define how the specifying field is to be interpreted.. That means that predicates has to hold the category.. that they "spring from" (is supposed to be understood in relation to, more precisely in this instance), which actaully makes the most sense anyway, come to think of it. (12:38) So is that almost it? Then categories always hold a category, but since Categories are not Terms, the semantics doesn't have to be the same, and when it comes to categories, the defining category can then be understood as always being a supercategory. (12:41)

(12:41) Okay, to summarize my new ideas from the comments above this paragraph: 

Relations will be swallowed by Terms, but Categories will remain as a separate entity type. Sets will be called RatingSets from now on, and will now have the `subject' last in the primary key such that the sets will contain rating and subject (not object) pairs (although this interpretation can still be escaped, but I will exchange the words (I try not to write `terms' too much when I'm not writing about Terms.\,.)). *(Oh, and I forgot to say here, that the object field will now be nullable for the RatingSets table, which means that relations (.\,.\,hm, which I guess `verbs' or `verbal clauses' is actually a more fitting term for, but anyway.\,.) can now be predicates as well.) Categories will have a super\_category field, a title and a description, which describes, not what is \emph{in} the category, but how the Terms using said category (or a subcategory thereof) as a defining category is to be interpreted, not least in terms of their specifying field. The Terms, as alluded to, has a category field, a title, and a specifying field (whose interpretation related to the Term is described in the defining category's description). .\,. .\,.\,Relations are now also Terms, as said.\,. Oh, and all other entities than cat.\,. Hm.\,. .\,.\,Hm, it would actually be nice if Categories was also a kind of term, so they could share the same ID range, thus eliminating the need for the use of the type characters when it comes to relations.\,. Yeah, so I could either have a tinyint (char) deciding if the defining field as a supercategory or a category, or I could perhaps just use negative integers for categories, how about that.\,.\,? Hm.\,. .\,.\,Hm, actually, even though it feels a bit hacky, I think I \emph{will} do that, i.e.\ save the byte, and then the application can just always turn that plus or minus sign into either a t or a c prefix.\,. Hm, I could do that, but let me actually think about some more.\,. (13:02) .\,.\,(13:04) Oh wait, do I even need for relations to be able to refer to Categories?\,.\,! 'Cause I have the Classes now.\,!\,.\,. well, except these are still not actual terms.\,. Hm, how about just not using relations at all but.\,. oh this is actually great.\,.\,!\,.\,. but only use predicate terms, which can just hold their objects as part of the defining field (and remember we still have the List entities).\,. .\,.\,So the RatingSets table will just consist of a userID and a predicate termID.\,. (13:09) .\,.\,Hm, maybe I will lose Patterns, but that is not so important right now.\,. .\,.\,Okay, to get back to the thoughts about the predicates and the Classes, now the Classes.\,. .\,.\,hm, couldn't we actually say that ``a predicate has these and these subclasses,'' and people would know what is meant?\,.\,. .\,.\,Sure; with an automatic reinterpretation of the subject (or object.\,.) predicate as a `class.' Nice! Fine, that simplifies the terminology: Now we are free to use `predicates' much more.\,:) .\,.\,Oh, and couldn't we even say that a term can have a ``subclass,'' and then it could quite easily be learned that that just means: Reinterpret the term as a class of things that fits the term definition (be it one or many), and then a subclass of/derived from that term is just a subset (but ordered after usability) of the things that fit that term?\,.\,:\texttt{D} .\,.\,Yeah, I think so; I think we can perhaps just spray the term ``Subclasses'' everywhere (i.e.\ having it as a potential tab of all Term Columns).\,.(!):\texttt{D} (13:25) .\,.\,And that can btw come with another ubiquitous tab: `Related terms.'\,:) 

.\,.\,Okay, so now my previous Category--Term navigation will just be a navigation of Terms, namely where the users can have the main navigation tabs: Elements, Subclasses and Related Terms. .\,.\,Hm, and then ``subclasses'' is either understood as terms with a narrower understanding.\,. oh wait, no, that is the general understanding; Terms that takes the current terms and narrows it down so that it fits more specific ``elements.'' For instance, a subclass of the term `Music' could be `Jazz music,' and a subclass of the predicate `(is) Funny' could be `(is) Witty.' (13:34)

%..(13:39) Nå, men jeg skal lige have fundet ud af, hvad jeg gør med kategori-ID'erne.. nå nej, pointen var jo, at de nu \emph{ikke} behøver at være Termer, og derfor godt sagtens kan få deres eget typepræfiks (men relationerne, eller rettere prædikaterne, behøver ikke typeangivelser, for de bruges kun om Termer).. Okay.. 

(13:58) Predicates' defining categories should define whether the predicates speak about the term is self (and its relation to the database and/or application (so on a meta-level)), or if the predicates should be instead be understood as speaking about the thing that the term refers to (so on a non-meta-level). .\,.\,And what else?\,.\,. .\,.\,Hm well, let me also mention that I'm thinking about whether I even need the Category entity type, or if a should just use texts instead (i.e.\ a ``defining description'' rather than a ``defining category''). Oh yeah, and the other thing that I'm also considering, is whether I should let the (Rating)Sets be re-absorbed into SemanticInputs (but perhaps not.\,.).\,. (14:03)

(17:43) I might actually keep the name Sets after all, and I might also let Patterns be.\,. .\,.\,(17:50) Hm, now I'm considering actually just.\,. keep a global id counter and then use that in all the ``Entity'' tables.\,. (And I'm also considering reintroducing types and make the predicates untyped.\,. but yeah, why not just use the same global id counter.\,.\,?).\,. .\,.\,No, 'cause then you'd have to look in all tables (of there's no types at all).\,. 

.\,.\,(17:57) Oh, I might actually keep Categories, and even keep the titles, cause they can still be used to specify in what contexts the Terms are to be interpreted.\,. .\,.\,Okay, so I'm actually probably just going to add a description field to Categories.\,. .\,.\,And apart from turning relations into predicates (and count them as Terms) and letting all terms hold a specifying field as well, I might then not actually change too much from how it has been until now --- well, at least not in terms of the database, for the change of not using Categories but just using Terms in their place in the application (and using a Subclasses tab instead of the Subcategories tab), that is of course huge.\,. Hm, but let me think some more.\,. (18:02) .\,.\,(18:05) Ah, or I could just make Terms hold a char denoting the type, and then.\,. then have all ``data Terms'' hold the data entity id in the spec.\ field, and this then makes it natural to also have a title for all data terms, but why not!?\,. .\,. (18:07) .\,.\,Hm, it perhaps seems a little redundant for KeywordStrings and Patterns, but.\,. .\,.\,But the title could just be nullable.\,.\,!\,.\,. .\,.\,Yeah.\,.(!) (18:09) .\,.\,Yeah, and this means that we can now give different titles to the same text, and then automatically treat them as two separate Terms.\,. (Not that you couldn't achieve such things before, but I don't know, I really like this idea.\,.\,!\,.\,.) .\,.\,No that \emph{is} actually something.\,! I thought about using it for attaching the user id to a comment before, and now I just realized that without these text titles, that would be much harder. 'Cause then one would either have to include it in the text, which is bothersome, or you would have to rely on a bot to look in the.\,. Creations table, but no, you couldn't even do that, attaching a user to a text would just be quite troublesome without being able to.\,. well okay, now that Terms can hold a spec.\ entity, you could do it.\,. oh wait! What am I saying! No, I still need to figure out how to make sure that users can sign their terms.\,. .\,.\,Oh, or maybe not! (18:20) Maybe a Category description can just state that part of the semantics attached to the term relies on knowing who created it, and thus that one needs to look in the Creators table to be able to get the full interpretation of those kinds of Terms. Nice!\,:) (18:22)

.\,.\,Oh wait, no, there's a few thinks left to consider in regards to all that, so let me think on.\,. (18:32) \ldots (19:09) Maybe I should let the Sets hold the object type, and then use the type chars everywhere where it is necessary (which probably won't be in a lot of places---for instance not in the spec.\ field, since here the types can be defined in the beginning of the description instead.\,.).\,.

.\,.\,Okay, I think this will work well. The system is not very much different from what I had before: Basically, the relations are now turned into predicates instead, of the Term type, and all Terms then have a spec.\ id (where the type is described in the Category description) --- and the Categories now have a description field as well. .\,.\,But that is pretty much it in terms of the database, isn't it.\,.\,? (And then in the application layer, we'll now let Terms do a lot of the duty that Categories did (though not all; not defining viewing preferences, e.g.).) (19:22)

(26.05.23, 9:10) I wanna call Categories Contexts instead in the database. And I think I might also remove the secondary index (and uniqueness constraint) for Terms and Contexts, especially after I realized that that wouldn't work very well at all for a distributed semantic database, which is what I hope we'll get in the future (at which point we can start calling the system the Semantic Web (the term taking the place of what will then probably start to be known as the `old *(.\,.\,or OWL.\,.) Semantic Web,' or something like that.\,.)). \ldots\ (10:37) Then again, maybe we should keep the secondary indexes.\,.

%(27.05.23, 9:24) Okay, jeg tror jeg vil sløjfe descriptions igen fra Contexts og lade denne i stedet være et "semantisk felt" (rating-baseret).. Men nu står jeg overfor at sjulle overveje, hvordan man måske kan specificere forskellige renderinger af prædikater i titel-teksten, så lad mig lige prøve at tænke lidt på tasterne (måske lidt on--off).. ..Nå, jeg tror måske allerede, jeg ved, hvad jeg kan gøre:

(27.05.23, 9:37) I think I will let the description be a ``semantic field'' instead, i.e.\ decided by ratings. And I think I might know what to do for the predicate titles in terms of rendering them. My idea is.\,. Well, first of all, one could have a placeholder for the relation object in the title text. This could be \$ or something like that. And my new idea is then to first of all use curly brackets around what part of the predicate sentence should actually be printed when the predicate title is rendered (above a ``semantic field'' or above a rating). Then I'm also considering using normal parentheses to further mark that part of the sentence can be left out of the title, if the application wants to render it more compactly. So an example could be a predicate title of: ``is \{funny (as a \$)\}''. The \$ and the parentheses should then be escapable using either \textbackslash\ or repeated characters.\,. (9:46) .\,.\,Hm, repeated characters is actually better when it comes to the parentheses, so let us say that.\,. (9:51) .\,.\,But anyway, I can now see that I also kinda need to know the word classes of the category Terms (which are now no longer a special type in the DB, which is why I don't capitalize it here).\,. .\,.\,Hm, how about just doing something similar.\,.\,! I could thus say that for category Terms, the contents inside the normal parentheses should be printed when wanting the singular word, and the curly brackets should be printed when wanting the plural word.(!)\,.\,. Hm, but how do we then tell the application to use.\,. Oh, but that is for predicates, but still, how do we.\,. oh, never mind: Users can already with this system define predicates like ``is one of the \{Actors (of \$)\}'', and also like ``is the \{Director (of \$)\}''. Nice.\,. (10:01) .\,.\,Hm, let me mention that I intend to use square brackets for when the spec.\ field is a List, and just like for arrays in programming (typically) say that one can write ``\$[1]'', ``\$[3]'', ``\$[1][3]'', etc. (I don't know if we want 0-indexig or 1-indexing.\,.) But another question is: Do we tell predicates like ``is \{funny (as a \$)\}'' to use the singular category noun explicitly somehow.\,. or do we just say that predicates should always use the singular version.\,.\,? .\,.\,Oh, and what about category terms like Music.\,!\,.\,? (10:09) .\,.\,Oh wait, users get to write a specific title for all spec.\ entities,x) so I guess there is no need for.\,. well, trying to account for different word classes. .\,.\,Great, well that should mean that me two ideas here for using parentheses and curly brackets for predicates and for category terms.\,. .\,.\,Oh wait, the last missing piece is then just, I guess, to introduce a syntax for fetching either the singular or the plural noun with \$.\,. .\,.\,Oh wait, there could be a problem with specific titles for specific spec.\ fields because it changes what title to search for.\,. Hm.\,. (10:24) .\,.\,(10:30) Hm, I have a new idea of using a syntax of ``(opt1/opt2/opt3)'' and then use e.g.\ ``\$(2)'' for choosing an option.\,. And then.\,. Ah, and then I could just always use curly brackets to cut away what's not inside and then use a syntax of e.g.\ ``\$\{2\}'' to denote that you should cut the outside part away two times in e.g.\ ``is \{\{funny\} as a \$\}''. Hm, and then I need to escape with \textbackslash\ instead; otherwise it'll get confusing. (10:35) And one could then also make titles like e.g.\ ``is \{\{funny\} as a \{\$\}\}'', in which case \$\{2\} will give us ``funny \$''. (10:37) And I \emph{should} actually use 1-indexing for all these bracket types, even for the square brackets (which fetches an entity from within a list). Nice, I'm quite happy with this, umiddelbart.\,:) (10:39)

.\,.\,(10:57) Hm, but even though I think I will stick to these ideas, I think I can actually avoid the parentheses, i.e.\ ``(opt1/opt2/opt3)'', if I just use ``is \{\{funny\} as an instance of \$\}'' instead.\,.\,:) .\,.\,Hm, although it would be nice with something a bit shorter in the middle.\,. .\,.\, ``is \{\{\{funny\} being\} an instance of \{\$\}\}''.\,.\,? (11:06) .\,.\,Oh wait, let us 0-index, and let (0) then be the option of not choosing any of opt1/opt2/opt3 etc.\,:) (11:07) .\,.\,Yeah, and I do think I will use predicate sentences on forms like ``is \{\{\{funny\} being\} an instance of \{\$\}\}'' a lot.\,:) (11:08)

.\,.\,Ah, and Context can just also just the same syntax of curly brackets to explain how the specifying entity should be interpreted (at the end of their title, preferably).\,!\,. (11:20)

(14:17) I just thought about: well what about the fact that we are no longer able to use a Relation as (partial) input in another Relation in order to e.g.\ say that a field is a relevant one for a certain category. But I just realized that we have our Patterns!\,. Så we can just upvote a Pattern instead, which the application can then use to make one or several searches for, not Relations, but rather predicate (Term) titles.\,!\,:) (14:20)

.\,.\,Oh, and I also realized something else important on the walk that I've just come home from: Actually we \emph{shouldn't} (generally) use objects (in the from of category Terms) for adjective-like predicates after all (I think)! I think it might be a lot better to just let that be a job for the (native) bots, namely to take a set of popular categories and then create subsets for each.\,. well, or perhaps sets of category--predicate pairs, and then make it so that each of these sets represent the predicate conjunction of simultaneously being part of the given category and being rated as fulfilling the given predicate.\,:) (14:27) .\,.\,(So to underline: This means that we will (probably) \emph{not} even need a lot of those ``is \{\{\{funny\} being\} an instance of \{\$\}\}''-like predicates (even though they are smart if we ever need such); instead we can just use: ``funny''.) (14:30)

(31.05.23, 9:42) I thought in the bed last night about how one would query a list of all the users and their ratings for a given predicate and subject. And that lead me to the conclusion that I should actually scrap sets as an entity type and absorb Sets into SemanticInputs. Since we can compress tables, this should still be fine (actually perhaps as good) in terms of getting the rating--subject sets stored compactly on the disk(s). I will then just use the secondary index that I already need ending in a rating, and then let it end in the userID column just before that. This will let me make another query procedure that selects pairs of users and ratings. Since any given subjects is normally unlikely to be rated by more users than in the ten thousands or so, it will be very rare anyway that anyone querying user--rating pairs wouldn't just want to query for them all at the same time. So there is certainly no need to add another secondary index that ends in the user column (not at this point, and it might even never be needed). (9:52) .\,.\,Oh, and for using what sets currently implement, one can just use a Term (with a context that defines it as a set) holding a list of a predicate and a user.

(01.06.23, 11:16) I'm wondering about how much we should use Contexts for disambiguating when we can probably rely a lot on.\,. Oh yeah, using the \{\} syntax will probably be better a lot of the times.\,. .\,.\,Yeah, so let's use that for the ``Terms'' Context as well (but not for the ``Relations'' Context).\,.

.\,.\,Hm, but should I actually use that () syntax as well.\,. (11:26) .\,.\,The () syntax, i.e.\ the one about ``(opt1/opt2/opt3),'' is too complicated, and we should rather just make sentences like ``is a useful instance of the \{Subcategories\} of the term \$'', i.e.\ where the \$ is preceded by noun of what the \$ title refers to, such the the \$ title functions just like that in the sentence: a title (similar to a proper noun). 

(02.06.23, 18:25) I've just had a few good ideas: Users should be able uprate Predicates and Relations for other Predicates and Relations such that the former is automatically suggested for sets (for further sorting/filtering) formed from the latter. And for the General Info page, and for ``semantic fields'' in general, users should be able to uprate Predicates and Relations for a given field, together with the main Relation of the field and the element ContentKey of (the SetList of) that field. But here, they are not just suggestions! They can also be some that are automatically applied to the set initially. And herby the application will already get a bit of the thing that I envisioned for my so-called (by me) ``wiki idea''.\,! This is a very good thing, 'cause I really want scientists and professionals to join in as soon as possible, and this thing about pages that can very in detail when you adjust some predicates, I think that make the application start more quickly to compete with other knowledge sharing sites, such as e.g.\ Wikipedia.\,. .\,.\,Anyway, I see it as a good idea to have implemented in the early versions of the app. There is also one more thing that I will mention here now (.\,.\,if I haven't already), and that is that Users should be able to uprate ``render-as-a''-Contexts for individual Terms, such that these terms, when rendered in the form of a Column, can get another effective Context than the one they are defined from (meaning that several users can agree on using the same Term for giving ratings to, but view it with different rendering preferences). (18:41)

(20:22) Ah, modSignals should just be implemented semantically instead. And at least to begin with when we make the UPA an actual UPA, we should not allow the users to just mix up an use modules at random from a set. Instead we should just confirm the proposed main scripts alone. One could then at some point make it more free, such that the users can import individual modules more dynamically, and not just use the same group of OK'ed main modules, but on the other hand, it might also turn out that users will be able to get the same freedom from just being able to uprate ContentKeys for certain things, like I want to do already from the beginning with the ``semantic page fields'' for the Term's `General info' page. (20:30)

(03.06.23, 10:26) Because I will make it so that only the main modules are OK'ed and adopted individually, I can just serve them from the server, and it also means that they can be minified (each main module and its sub-modules individually). I therefore also plan to move the application source code to the html/src folder, and start splitting and naming the files, following standard conventions. But I guess, should I still keep UPA\_scripts.php and potentially serve some sub-modules for user-made main modules from the database, or should I.\,. Oh wait, just because we keep UPA\_scripts.php, it doesn't mean they \emph{have} to be served from the database. But it's nice that user-made modules can refer to other modules by their entity ID, like how it is for the current UPA\_scripts.php, so let me keep it like that! .\,.\,I will not.\,. use it myself.\,. or wait, should I then still use it myself (as I've done so far).\,.\,? (10:37) .\,.\,Hm, maybe I could.\,. well, if I do both, so to speak, then I have to change UPA\_scripts every time I create a new module.\,. .\,.\,Hm, alternatively I should just introduce UPA\_scripts when we introduce the UPA part of the application.\,. .\,.\,Hm, maybe I \emph{should} just change UPA\_scripts for each new module.\,. (10:48) .\,.\,(10:55) Okay, I think I know what to do. We can actually scrap UPA\_scripts.php completely, and I can refactor the source code of the application in a more conventional way (in terms of files/filenames and directories). When introducing the UPA part of the application, we'll just use a syntax for importing modules via their entity ID, namely where programmers simply \texttt{import [\ldots] from "t$<$number$>$"}. Now, this syntax \emph{could} actually be made to function as is, if one makes some alias rules (i.e.\ via .htaccess for an Apache server), but maybe we won't need to make it function: Maybe we'll just stick to rewriting each import statement whenever a user-made main module, together with its submodules, is validated and adopted. (11:04)

(13:22) Oops, I have forgotten that the text type character is now `x.' So: \texttt{import} [\ldots] \texttt{from "x$<$number$>$"}. *(Or just \texttt{import "x$<$number$>$"}.)

(05.06.23, 17:37) Before I took a walk, here earlier, I happened to look at that elemIDHexStr type in query\_handler, and thought that I should probably rethink my Lists. And on that walk it then occurred to me, that I should of course also just simply implement Lists as Semantic Contexts, like I intend to do with searchable Strings (which I before that intended to implement via the former ``Patterns'' table). So there we go: Now I intend to remove Lists from the database, and implement them, when needed, via a ``Lists'' Semantic Context instead.

\ldots Oh yeah, and I might also then just implement comments by letting them hold the user ID in the comment Text itself (with a certain format).\,. Well, I might do that, or I might use Lists, I'll see when it comes to that.\,. (18:18)

(07.06.23, 13:42) Okay, I think that the whole list of predicates in the drop-down menu for the SetHeader should be set globally. I then think that.\,. .\,.\,Hm yeah, I think that users should then uprate Lists of.\,. well.\,. (13:47) .\,.\,(13:55) Okay, ideally we should actually have several sets of predicates that can each have different user weights attached to them.\,. .\,.\,And of course we should then just start by using only one of such sets.\,. .\,.\,How about just numbering these predicate sets.\,.\,?\,.\,. (14:02) .\,.\,Perhaps by simply changing a number in the Predicate title, and then just halt the predicate set search once the first predicate title number is reached where there is no predicate in the set above a certain rating.\,. (14:06) .\,.\,(14:10) Ah, or perhaps one could just (potentially) divide the rating range up into different intervals, with different global user weight variables associated with them (and each with some default user weight values that the variables start with).\,.\,!\,.\,. .\,.\,Oh, but what about reoccurring predicates, then?\,.\,. Do we just not allow that?\,.\,. (14:12) .\,.\,Sounds reasonable enough to not allow repeated predicates (with different userWeight arrays).\,. .\,.\,I think this might be the solution, and then we should of course just start by having only one userWeights array for the whole rating range (above a certain threshold, that is). (14:14)

(08.06.23, 9:57) I'm going to make SetField more versatile, and make it so that one can also give it input sets to mix with whatever it is going to query for. And I'm actually removing the SetHeaderDropdownMenu completely, making the sorting predicates something to be stored globally instead. Then the SetHeader should just have a checkbox for if you want to include the extra sorting predicates or not (whose default value can depend on data input). And at some point, there could also be a number to choose, which then chooses which of the user's stored sorting preferences to use. \ldots\ (And then I should make a sorting options Column where users get a fixed number of maximal sorting options to store, and when they can then define and change/adjust each one (where the number is then what you chose in a given SetHeader).)

(12:58) I just had the thought: Wouldn't it be much better if we simply had a FULLTEXT index on the Term titles instead of having the KeywordStrings table? (Especially because it would allow us to treat the search result as a set, which can then be combined with other sets, without having to make a (relatively) expensive join first.) I should think more about this *(later, that is).\,. 
\ldots Hm, or we could let KeywordStrings hold its best match (decided from a.\,. predicate + user.\,.).\,. and then continuously update it.\,. Hm, or not.\,. (13:14)

(16:12) Okay, I'm thinking about several things now, but let me just mention a thought: I probably won't even need the Lists (Context) for Comments, since the user can just be looked up in the Creators table instead.\,!\,.\,. (16:13)

(17:46) I've thought and have had some good new ideas. %..It's very hot right now, though, but let me see if I can write them down now.. ..Hm, two seconds.. ..Hm, let me just think about a certain detail concerning the database first instead.. ...(18:03) Ah, maybe I can just use spec_type = /^[0-9]$/ for rankings.. *(spec_entity_t) ..I've btw also just figured out how to perhaps use the parent contexts.. (18:07) ..No, I shouldn't use spec_entity_t; I need to make a new table, call it Strings.. ..(or KeywordStrings..) (18:17) ...(18:47) Ah, and I'll make the the spec. entity into the title (removing the title column) of Terms, and then its entity type will just often be Strings.!:) ..(And predicate titles will then be stored as part of the parent Context, but I'll get to that (and more), when I resume the rendered notes..) ..(I think that I will not include any FULLTEXT indices, by the way..) (18:51)
%(20:56) I'll keep the Term titles, such that the Strings table will only be used for searches --- well, no: they will also be used for uprating relations for e.g. the General Info page. And I probably won't use the {}-tyntax at all now; instead each layer should just be a Context (with the layers above being parent contexts).

%(09.06.23, 10:41) Ah, MySQL always uncrompress the pages before reading and.. well, not necessarily before writing, but still, I'm pretty sure that the compression does not depend on which bytes on the page belongs to which columns. And this means that I should probably not worry about splitting SemanticInputs up, or about adding e.g. a context_id to it.
%(13:02) Have realized, that instead of the RankedStrings table, that I've been about to make, I should just use VARBINARY(255)'s for ratVals once again, especially because of the fact that compressed pages of sets with a constant ratVal length can be compressed such that the length byte doesn't really matter. And the big idea for going back to VARBINARY(255) is that it allows us to make sets over Terms, where the ratVals can act as index keys for the Term titles/def_str's.!:D (13:07)

%(10.06.23, 11:09) I'm probably gonna change the database again by letting data entity IDs match the IDs of the (then required) Terms that wrap them, and now I'm perhaps also going to merge SemanticContexts and Terms.. But I just had an unrelated thought, which is the reason that I'm writing here: If the CPU always needs to uncompress the InnoDB pages in memory, then perhaps it \emph{does} makes sense to factor out the set key, still.. It seems that it would.. So yeah, let me actually do that.. (11:13)

\ldots

%(14.06.23, 8:25) Jeg fik ikke sovet så meget i nat (sikkert meget pga. varmen (ikke mindst pga. manglende vind)), så der går nok lidt tid, før min hjerne kommer op i nogenlunde ordenlige omdrejninger. Men jeg kan da prøve at starte dagen med så at skrive lidt noter her i stedet (bl.a. nogen som jeg fik tænkt her tidligt i morges i sengen)..:
(14.06.23, 8:29) I never got to write all my ideas from last time down, not even in the source comments. I have some more now, which I will try to write about now.\,. .\,.\,First of all, I recently planned on having a SortingOptionsColumn, but now that I've realized that the basic ``SetHeader'' should be hidden by default (unless the (combined) set is empty), I've also just come to the conclusion, that I can let the users mange the sorting options there. So now I imagine a drop-down menu of bars each containing a predicate, a ratTransFun option, queryParams options, and userWeight options. Firstly there should be the predicates which the SetList is based upon. And if the user clicks a button to extend this menu with sorting options, there can be first a new bar with a sorting option selection menu (where each sorting option has an identifying number or, more likely, an identifier string/name). Then there is a number of similar predicate + etc.\ bars, depending on which option identifier is chosen. Now, when the user then changes these sorting options (the bars below the initial ones), the data should  be stored in memory, and there should then be a button at the bottom to ``save changes'' to the given sorting option. %(8:42) ..to sek.. ..tilbage. (8:49)
.\,.\,And when the user saves, I then need to implement that the Sorting Options are then uploaded and stored in terms of ratings to certain predicates. Hm, which reminds me that I should make a Statement Context.\,.

.\,.\,Let me then also write about some ideas that I thought about last evening. I thought about the browser expansion, and the fact that I should really just advise that users use Google or other SEs to search for known things, and then use the browser extension to see the SDB entries on the URLs that the search hits (and for users to uprate associated terms for the URLs that might pop up on Google searches). At some point we can also implement a semantic word search on-site, by letting users type in search strings and then break these apart into several predicates of ``is related to this word.'' Then the users should basically see these the same as for the Sorting Options, where they can change parameters for each word, but where they can also correct/change the words themselves --- and add new ones to the list. But this is for the future: In the beginning we should rather just make use of existing web SEs and then the browser extension, like I was just saying. Now, some ideas about the browser extension is then that it should not only look at the current URL of the sites that you visit, but it should also take all anchors (links) on a webpage and make it so that hovering over them, perhaps wth the shift key held, should make the extension window, if open, take the given URL and make a search (via a special URL Column) and show a list of the relevant terms of that URL (with ratings meant to signify how much these terms are related to the URL --- and/or perhaps (also) a rating to signify how useful it currently is to look at the info of the SDB of the term.\,. well, maybe that's to complicated, but anyway.\,.).\,. The good thing is that this can then also be used for seeing if links are safe, and it can be used to, anonymously!, gain information about a link without having to query the WWW for it.\,! .\,.\,I really think this good be seen as quite useful for a lot of people, and be a good selling point of the app/browser extension. (9:07) .\,.\,It could even limit the nuisance of well-known phenomenon of clickbait a little further down the line.\,. .\,.\,Yeah, I really think that a lot of users might be quite happy about such an extension, and that it good be one of the SDB's good ``selling points.'' And since this kind of browser extension also then makes it easier to search for things, since you can just get as close as possible at first via a quick Google search, and then ``walk'' the rest of the way ``semantically'' (i.e.\ via the ``TermNavigation'' tabs).\,:) (9:13) 

\ldots By the way, the menu that I talked about should also at some point be able to contain potential filter predicates, which are not used by the SetList (and thus not part of the ``predSetDataArr''), but which can subsequently be looked of (or rather, the ratings can be looked up) for each list element, and these elements can then be collapsed if the rating for the/a filter predicate is above or below a certain limit. (9:35)

\ldots\ (11:47) When uploading and saving the Sorting Options, we should probably save them in the form of a JSON object (as a Text, which is then the subject of a Predicate holding the Sorting Option identifier as its def string). Luckily, such a JSON object can be verified non-recursively with a RegEx, which is nice, 'cause a will likely need to implement this before release.

%(13:10) Hm, I just got the thought that maybe I could remove the Instances Relation and make it the implicit Relation whenever you use a non-predicate as a predicate.. Because doesn't that also sorta fit with saying that subjects fulfilling a predicate are.. hm, a sort of instances.. maybe not.. ..Hm, but maybe I could do it still, and then just say that "Instances" in the context of a predicate refers to "Instances that fulfill the predicate to some degree" (a negative degree as well..).. ..Maybe.. (13:14) ..(13:17) Uh, if the standard interpretation of a predicate/non-predicate term + subject/instance term is: "aplies to"..!! ..:) That could work..!.. (13:18) ..(13:20) Or perhaps better, if I just change the tab name from "Instnces" to "Applies to"..:)..

(15.06.23, 10:11) I got a very overview yesterday of what I need to do for the main part of the app before the first release. (I didn't get much sleep, so that pretty much all I could do: think about things.) I also got the idea to make Lists a part of the initial semantics almost, namely by introducing a \$s[$n$] ($n\geq 0$) syntax for the def strings, where it is then understood that the format of such strings should be a comma-separated list of decimal integers denoting Term IDs. Then \$s[0], for instance, takes the first ID in the list and ``de-references'' it, both semantically and in terms of how the def string should be rendered.

About what I wrote in the source comments yesterday, the semantic inputs should indeed have their semantics slightly changed, or rather extended (in a backwards-compatible way), such that the statement that is rated is ``$x$ applies to $y$.'' Now if $x$ is a predicate, we can see that the semantics is unchanged. But if $x$ is another term such as a category term, we see that the statement can now be seen as being semantically equivalent as the ``Instances'' (i.e.\ ``is an instance of'') relation taken between $x$ and $y$. This means that we can then make an ``Applies to'' tab, which uses the same functionality for both predicates and non-predicates, implementing the predicate set page for predicates and the Instances page for non-predicates.\,.\,!\,:) So there we go, that is what I will do.\,:) (10:28)

.\,.\,(10:39) So for Terms Column, or rather non-User/-Text/-Binary Term Columns, we should just start with the following tabs: Info, Ratings, Subcategories, Applies to, Related terms, and Context. For the other Terms, lets call them the Data Terms, the ``Subcategories'' and ``Applies to'' tabs should just be removed, and the Info tab should just hold the basic data and nothing else, initially. (And let me underline that I'm only talking about the first release version here.) Now, about the non-Data Terms, the ``Subcategories'' tab should of course just be a set view of the ``Subcategories'' relation, and similarly for ``Related terms.'' The ``Applies to'' tab should be almost the same, but here, the Term of the Column \emph{is} the ``predicate'' of the set view, directly.  The ``Ratings'' tab should include one set view of two predicates combined, namely the ``\{Relevant ratings \}generally \{of \}Terms which are derived from the \{Context, \$t\}'' predicate (where \$t is then the Context of the Term of the Coulmn), and the ``\{Relevant ratings of \}the Term, \{\$t\}'' predicate (where \$t is the Term of the Coulmn).

The ``Context'' tab should include set views (with not too large initialNums) of the predicates that are relevant for Terms like that of the Column and all other Terms derived from the Context, in particular the ``\{Relevant ratings \}generally \{of \}Terms which are derived from the \{Context, \$t\}'' predicate as a good example. It should also include predicates used for the ``Info'' tab.

*(Oh, I need a ``Supercategories'' tab also (which can come after ``Related Terms''.\,.).)

The ``Info'' tab should contain a set view of all relevant ``semantic fields'' of the Term, which like the ``Ratings'' tab should %(10:59) to sek.. ...%(11:17):
\ldots (11:18) should consist of two predicates: one for the Context in general, and one for the specific Term at hand. I imagine that these predicates should all be ``noun predicates,'' such that what is uprated for these two predicates are in fact simply the ``Nouns for predicate definitions'' (see initial\_inserts.sql). The elements of this set view is then PageFields that contain a title, given by the noun in question and then a set view of the relevant predicate --- oh, and with initialNum also given via user ratings, so.\,. Hm, how do we actually do this (without getting repeated fields).\,.\,? (11:23)
\ldots (11:36) Oh, well, I'll perhaps figure this out later. I'm thinking about using a separate rating for each Term--noun or Context--noun pair.\,. wait, or maybe it is much better to just use the noun for that rating.\,.\,! Yes.\,.\,! Okay, so I'll do that.\,. .\,.\,And users can then go to the Term Column of a given noun to rate what initialNum it should have. But in the first version, I think I'm simply going to let all semantic fields start with one element (i.e.\ initialNum = 1), and then perhaps have a rather large incrementNum of e.g.\ 20. And then each field should just be collapsible, perhaps such that one only sees the title initially, and not even the first element. Yeah.\,. (11:42) .\,.\,Great. And let me note, by the way, that I will not implement any searching among these ``semantic fields'' for the Info page as part of the release version of the application. (11:44)

Okay, now on to the SetView and the topic of how the users should be able to sort the sets. I've decided, first of all, that the SetHeader is always hidden at the beginning (showing only a small bar with a drop-down button). When dropped down, this header should contain first a menu of the initial predicates of the set and then a menu where users can add additional sorting predicates. For a later version, I also intend to add a menu to add ``filter predicates,'' but let us just leave these ones out of the first version (not because they are hard to implement, but because they won't be too useful initially anyway). Now, until yesterday, I thought I needed to implement a way for users save various sorting options that they could then choose from later on. And while I want to implement this at some point, I finally realized at some point yesterday, that because the initial options for choosing the ratTransFun and the queryParams should be quite limited anyway, there is really no need for the users to be able to save their adjustments. So instead I can simply just use a set of ``Predicates that are useful for Sorting Options for sets''.\,. hm, what about Relations, by the way, will we need such for sorting?\,.\,. (11:55) .\,.\,Hm no, I actually don't think we do (at least not for the release version). If users want to e.g.\ sort using a predicate of ``is related to Term $x$,'' then they can just uprate that whole predicate.\,. well, that's the only thing to do here anyway.\,. .\,.\,Oh well, I think that Relations (that then automatically uses the Term of the Column as the object) won't be needed in the release version, so let us just say that for now. The users should then simply uprate predicates for.\,. well, okay, now the question is: Should they uprate it for a \emph{single} predicate of ``is a useful sorting predicate,'' or should it be ``is a useful sorting predicate for Terms derived of the Context, \$t'' instead? I think what I will do is keep the second option open by simply using ``is a useful sorting predicate for Terms derived of the Context, \$t'',\$t = the ``Terms'' Context, as the single predicate to uprate sorting predicates for. And a future version of the application can then extend this to also look for sorting predicates uprated for other relevant Contexts of the given Term. Yes, let us do that!\,:) (12:04)

Now, the reason why the setting won't be complicated enough that the users need to be able to save them, is that initially they should only include a couple (not all) of the possible queryParams, and they should only use ratTransFuns on the linear form $f(x) = a x$, where $x$ is the rating when interpreted as an \emph{unsigned} (i.e.\ non-negative) integer. *(Oh, or interpreted as a singed integer; that actually makes no difference.\,.) Then for cutting ratings out below a certain threshold, the user should just simply adjust ratingLo instead. (12:09) .\,.\,Oh, and importantly, I will only use one kind of userWeightArr for the release version --- and only use one ``user group'' bot as well --- and that is the userWeightArr consisting of the query user (times $\sim$$\infty$) and the ``zero-biased unweighted average bot'' (times 1). So there will even be a need to for any menus regarding choosing users and weights for the sorting options in the release version.\,:) (12:14) All, the predicate menu points of the SetHeader menus therefore need for the release version, is just: a factor for the ratTransFun (rating transformation function, btw), an isAscending check mark / radio button, a ratingHi and a ratingLo, and possibly also a queryNum.\,. yeah, I guess so. And most of the times, the user will only need to adjust the factor, and perhaps the ratingLo.\,. and that's really it.\,. :)

The SetHeader should btw also cotain the button to add another predicate bar to the sorting options menu, and each predicate bar should have a button to select/change the given predicate, selection from the list of predicates taken directly from the (single) \textit{``is a useful sorting predicate for Terms derived of the Context, \$t'', \$t = the ``Terms'' Context,} predicate. (12:23)

(12:49) I forgot to mention/think about the contentKeys of the semantic fields.\,. Now, I'm wondering about allowing repeated predicates/field titles versus not allowing different contentKeys for the same predicate/field title.\,. 

Oh, by the way, once we want to allow for more complicated ratTransFuns, I also thought yesterday about defining these via an alternating list of slope factors and x-axis values, such that we start from 0/-1 (depending on if it's unsigned or signed) and then draw a line with a slope slope given by the first number until the rating (x-axis) value of the second number, if the list does not just contain the single number, in which case it is just a linear curve. From there the list can continue with factors and rating values (alternating), and if the list ends in a factor, the curve is extended to the end of the axis with that slope, and if it ends in a rating value (i.e.\ an odd number of numbers in the list), then the last slope is just automatically assumed to be 0. There we go: an easy way to define a segmented curve of line pieces, which is also quite easy to compile into a (JS) function.\,:) (13:00) .\,.\,Hm, alternatively, one could of course also exchange to slope numbers for numbers representing the value at the end of the given line segment (with will be at the end of the whole interval if it is not followed by an x-axis value).\,. Perhaps that's even better.\,. (13:03) .\,.\,One could then also consider starting the list with an y value at the initial end of the interval, although this means that the list won't be backwards compatible with having just one number representing the slope.\,. although one could just superimpose that interpretation whenever the list consists only of one number.\,. (13:06)

\ldots (13:54) I have it: I don't think we'll need the contentKeys for the initial version, or rather the users won't need to think about them. I should instead just let the contentKey --- and the initialNum and queryNum --- be decided by the Context of the predicate instead.\,! And then I should first of all divide ``Nouns for predicate definitions'' up into two subcontexts: ``$>$\{s.\}'' and ``$>$\{pl.\}''. For predicates form both both these kind of nouns, I will then choose the standard TermElement contentKey, but let both the queryNum and the initialNum be smaller for singular nouns *(1 in the case of the initialNum) and greater for plural nouns. And for HTML semantic fields, which are supposed to act much like subsections of an article, as if the Info page is a composite article as a whole, I should make a completely different Context to make predicates of that kind. And queryNum should also be small for these, and initialNum should of course also be 1. There we go.\,!\,:) (14:01)

Some other points that I should mention are first of all that I just (just before the little walk that I took) had the idea to use \$l[$n$] instead of \$s[$n$] for the List syntax, saving \$s[$n$] potentially for another interpretation where the def string consist of a list of strings (which are not supposed to be de-referenced in their interpretation, as opposed to for the \$l[$n$] syntax). Let us do that.

Another point is that, even though I have made the Statements Context in initial\_inserts, I will not implement the part of the application for the release version, where users can click on ratings and see a list of users + ratings, although it should be one of the first things that I implement afterwards, preferably before I start implementing more ``user group'' bots, etc. (14:06)

I should also mention, importantly, that I will only implement unions for combSets, not any intersections at all, for the release version. So that removes that Sorting Options setting as well from the (initial) table.\,:) (14:08)

.\,.\,I haven't talked about this in my notes, but I will also make a HTML Context, which should then only be able to contain very simple HTML tags (otherwise the application will not print the text). (14:12)

.\,.\,And I think that these were all the points that I meant to mention for now.\,. no! There is another point, and that is that apart from the regular TermColumns and the Data Term Columns, there should.\,. well, no it \emph{shouldn't} actually be a Column, that was the point. It should instead be a quality of the Interface header, that there is a string search bar meant to take you directly to a String Term, if any one can be found that matches the string. I will then also use this procedure (automatically) for my browser extension, where a newly input URL will make the extension window update itself with a new Column, namely that of the String Term, if a match was found. .\,.\,I guess I should also think a bit more about how to handle non-exact matches, but I'll leave that for a later time. Let me instead just say now, that I imagine that the String context should work splitting the string up into strings of length 254, and then add/look for the series of Contexts where each subsequent Context in the series has the former Context as its Context, and where the def string is the given substring of length $\leq$ 254 prefixed with ``$>$'', and where the series then end in the last substring where ``$>$'' is then \emph{not} prefixed (signifying that the final Term is not understood as a sub-Context). The initial parent Context of this series should then simply be a ``Strings'' Context. .\,.\,Well no, it could also be a sub-Context of ``Strings,'' e.g.\ ``Strings''$\rightarrow$``$>$URLs''. (14:26)

(18:02) The ``Applies to'' tab should also have an expandable submission field at the top.

(19:14) I should also point out that the lookup of a String should be implemented with a special procedure that can look up a whole string at once and give the ID of the final Term. And on another subject, I think I'll actually go away from the $>$ prefix syntax and back to using a ``Context'' Context again. Oh, and another important point: The ``Context'' tab should not only hold predicate fields relating to the Term's Context, but should also hold a description (as a semantic field, i.e.\ changeable) of clarifications about how to interpret Terms derived from Term of the Column, i.e.\ Terms that has the given Term as their Context. But for Terms with the ``Context'' Context Term as their Context (.\,.), these should probably also just have this as their (only) field on their Info page.\,. .\,.\,If so, then ``Context'' Terms will also be special in terms of what tabs there are and what appears in them, just like the ``Users'' Terms, the ``Texts'' Terms, and the ``Binaries'' Terms.\,. (19:22)

%(21:37) And note that "Contexts", or rather "Sub-Contexts", is only meant for the Terms that cannot and/or is not supposed to be interpreted in the context of ther Super-Context themselves. So for Strings, e.g., I should not use the "Subcontexts" Context, since each Term in the series can also very well be interpreted as strings themselves (and in fact the should be).

(16.06.23, 9:58) One of the absolute first things that I should do after completing the first version of the app is to add a ``freshness'' and a ``trending'' bot, and add Comments (a Context and a tab) and not least Posts (a Context) to the site. And I should also either make the HTML be able to include images and small videos from other green-lit sites, and/or make a new type of Predicates for images and videos (similar to the HTML Predicates).

%..(10:02) And I'm also actually considering simply promising out money, via ratings of users signifying the amount, to users that help add content to the site and rate things, and for any open-source developer that helps extend the app on their own time.. ..(Of course those would be money conditioned on whether there will be a surplus to give from (which there very well should be), that goes without saying..)

(10:28) Oh wait, maybe the ``$>$'' syntax is just better\ldots\ \ldots Yeah, it is better.\,. (10:47)

%(12:23) Hm, thinking about how to reimplement computeAveragedSet() + computeCombinedSet().. Maybe an option could be to first transform the rating in place, and then average afterwards.. ..Hm, perhaps that's not such a good idea.. ..(12:31) Oh, maybe I should actually even rethink the bots and the userWeights system slightly.. ..Hm, I'm sorta considering introducing special "user x says" predicates, and I'm also considering using a priority list, then, rather than a userWeight array.. (12:34) .."user $s[0] says that $s[1] applies to $t".. (12:36) ..No, that's way redundant.. (12:38) ..But the app could just use predicate--user pairs and then automatically have the user either first or just after the queryUser in the priority list.. (12:39)

(12:41) I'm considering (see the source comments) using priority lists rather than user weight arrays.\,. .\,.\,(12:48) Yeah, I think I will use priority lists instead, 'cause then if users want to mix several large user groups, they can just add the same predicate several times.\,. or we could in the future also implement a way for users to choose more than one ``default user( group)s.'' (12:50) .\,.\,Hm, and at some point, we should add a switch to the predicate settings such that the specially chosen user (for the given predicate setting) can get higher priority than the (main) ``query user,'' but let me just start by always giving the ``(main) query user'' first priority.\,. (12:53) .\,.\,Hm, or the other way around.\,.\,? (13:02) .\,.\,Hm, or maybe just replace the special priority user \emph{with} the main query user.\,.\,? .\,.\,Yeah, maybe.\,. (13:05) .\,.\,Hm, \emph{if} a should even go away from using the userWeights at all.\,. (13:08) .\,.\,(13:17) Oh, we actually \emph{want} to ratTransFun to be applied \emph{before} the weighted averaging.\,!\,.\,.

%(14:48) Lige kommet hjem fra gåtur. Det går ikke så hurtigt med tænkeriet, som jeg gerne ville have haft det, men jeg har da fået tænkt nogle idéer. Der er dog stadig lige nogle ting, som skal overvejes. Kan være jeg vil prøve at tænke på tasterne her lige om lidt.. 
%(16:34) Ah. I think I almost got it..
(16:48) I have to use user weights.\,. (And then one can just combine that with a priority list by using some $\infty \times n$ type of ``numbers''/cardinals/ordinals at some point.\,.)
%..Hm, jeg har virkeligt ikke nået meget i dag..:\..

(17:44) Okay, I've got it, I think.\,. The SetLists should not care about priorities or anything like that. In fact, because I now want to take the ratTransFuns first thing before combining, doesn't matter how the pred + user pairs are grouped, anyway.\,:) So the SetList CL should actually just use an array of pred--user-ratTransFun--weight (plus some more stuff) tuples. Now, I need to implement a freshness and a trending bot pretty soon after release, but here I can first of all just say that all uprated predicates for sorting should instead be predicates \emph{or} predicate--user pairs.\,. Hm, something like that, yes.\,. And in terms of the Info page, one could just use a special context for semantic fields that should automatically include the trending and/or freshness predicates.\,. Something like that.\,. There well luckily be time to figure this out; even if we get a false start with some system, it will not be the end of the world to then have to change that system to something else.\,. But anyway, let me note that we should aim for a system in the future (for the application, that is) where each user can select a broad range of ``user groups'' an adjust each one's weight for querying. The each ``user group'' should further not only rate Terms in relation to predicates/relations, but should rate the predicates/relations themselves with a weight, which defines how much the user group's ratings of those predicates/relations should count. This will be important when we get to ``user-driven machine learning (ML)'' as I've often called it, where ``user groups'' can start representing correlation vector. But for any given correlation vector, there will also be a limited rnge of predicates/relations that that vector.\,. ``hits.'' Or in other words, the relationship between a correlation vector and each predicate/relation will vary in strengths, so to speak.\,. (My brain is not on its sharpest level rn, btw, which one might very well be able to tell.\,.) And an honest UD-ML user group should also limit its influence only to the predicates that matters for it, via weights. So therefore the user groups should also rate the predicates/relations themselves with how much they the user groups opinion ought to count in the combined sets. For small weights these should just be rounded down to zero, then, in which case the app can simply remove the user from the pred--user-ratTransFun--weight (plus more) tuple that is passed on to the SetList. (18:05) .\,.\,Yeah, and I think that was it, really; what I needed to say, except perhaps that this future system might then also use special sets of predicates, for which this system should be overwritten. This could for instance be for the ``trending'' predicate, where one might not want to bother about querying each ``ML user group'' for a weight that is expected to be 0 anyway, and where one would probably instead just want to simply query a special user/bot for their rating only. (18:08) %Okay, I give up for today. Hopefully I will be sharper tomorrow, and luckily reimplementing computeCombinedSet() will probably be quite easy now.. (7, 9, 13, of course..)..

%(18.06.23, 22:46) Åh, jeg har havde da nærmest helt glemt mine "simple brugergrupper" (altså dem hvor "tokens" er fordelt)..! Nu har jeg lige tænkt lidt på dem igen, og de kunne da muligvis være \emph{vildt} nyttige..!(!).. ..Tja, i hvert fald til visse ting såsom at fordele tillid, men lad mig da lige tænke over, bare her i løbet den kommende tid, om ikke man kan bruge det på en smart måde til alle mulige andre ting også (hvad jeg før har tænkt/troet, og hvad jeg da lidt stadig tror på umiddelbart).. ...Hm, tja tjo, måske gør det ikke så meget forskel..

%(19.06.23, 18:26) På overfladen ser det ikke ud til, at jeg har nået så meget i dag, men det synes nu på en eller anden måde, at jeg har lidt alligevel; ikke meget, men en ok mængde, især taget i betragtning af manglende søvn.. Nå, men jeg kom egentligt her for at brainstorme lidt over.. eller i hvert fald bare lige nævne, at jeg lige er kommet til at tænke på, at måske bliver "brugergrupper" egentligt ikke.. eller rettere, måske kommer der ikke til at være så mange af dem alt i alt, som altså også er gavnlige, for måske kan man opnå det meste med bare nogle få forskellige BG'er og så bare nogle virkeligt specifikke og varierede prædikater (og relationer).. Har ikke konkluderet noget omkring det, men er altså det, jeg lige har tænkt mig at tænke lidt over.. ..Hm, på den anden side: Det vil tiden jo vise (er der virkeligt grund til at tænke særligt meget over det nu? --- for de vil jo være gavnlige under alle omstændigheder i én eller anden grad..).. ..Ja, de bliver rigtig gavnlige (..sikkert \emph{meget})..

(20.06.23, 10:04) I'm considering going back to using shorts/smallints for ratings again. If I can then only find another way to implement a lexical index semantically\ldots\ \ldots Well, the question is of course, haven't I already kinda done that with my Strings (especially my intended Control server procedure (I think it should be implemented on the Control server rather than as a database proc., but it could also be database proc.\ instead.\,. in fact, that might be better.\,.) that can also give you the (concatenated) String Term immediately for strings of length larger than 255).\,.\,? (10:23) .\,.\,Hm, only problem is auto-completion, isn't it.\,.\,?\,.\,. \ldots (10:52) Oh, I think I might do something else. I think I might create a new basic Data type called Indexes/Indices.\,. .\,.\,Indexes, where one user controls a given Index. .\,.\,!\,.\,.\,:) .\,.\,Oh wait, or an Index could instead be created upon request (from the userbase) with respect to a certain Set (i.e.\ a Predicate Term + a User).\,! .\,.\,And then the database would have to schedule reoccurring events to update the index with all Term titles of Terms above a certain threshold in that Set.\,:) Okay, I'll do that! But it might be a bit advanced, so I have to figure out what I want to do in the meantime, if I want users to be able to search through predicate noun( lexeme)s for the semantic fields on the Info page.\,. (11:00) .\,.\,Hm, well the best option seems to be to just implement the Indexes table and make one (including the scheduled event) specifically for predicates noun lexemes.\,. So yeah, let me just make the app first with out any search bar.\,. well, except the string one.\,. Ah wait, but couldn't that also be an option for an early version of the app, to use the String searches.\,.\,? (Not that it will be a lot of work to make the Indexes, but let me think about it still.\,.) (11:07) .\,.\,Nah, I need to make the Indexes to make it work.\,. .\,.\,I'll then make an Index key query procedure that outputs a table just let a Set output, but where ratVal is then changed for the word string (and where the subject is the given Term that corresponds to the string, in particular the predicate noun lexeme Terms for the specific case that I just mentioned). (11:14)

(21.06.23, 9:46) Hm, maybe it's not actually worth it to have all this syntax stuff for the Terms; not worth the confusion/trouble to learn for new users.\,. Especially since all it does is to disambiguate some Terms that people won't really.\,. go to (i.e.\ not navigate to the Terms' Columns) much anyway. .\,.\,! Yeah, so maybe I should cancel all that.\,.\,? \ldots I'm talking about the prefixes of course; we still need \$s,\$l,\$t and \{\}.\,. .\,.\,Hm, I could remove `/', but it's more difficult to remove the others.\,. .\,.\,Hm, by the way, maybe I'll remove the ``Noun lexemes for predicate definitions'' Context.\,. (10:20) .\,.\,(10:27) Hm, maybe it will be a lot easier to learn if we just introduce a tinyint flag to the Terms table, 'cause then we can present the options easily as a selection menu in the Term submission fields.\,. \ldots Hm, or I could just do that anyway, keeping it like it is now.\,. (10:39) .\,.\,Oh! Can't I make concatenated Strings by using the def terms instead!\,.\,?\,. .\,.\,Yes, of course.\,.\,!\,x) (10:44) .\,.\,And I could also just go back to using that ``Subcontexts'' Context again, if I want to eliminate the other prefixes again, right?\,.\,.

\ldots (11:44) It's actually a kinda hard question. But I think I might remove the \{\} formalism except for Subcontexts in particular.\,. .\,.\,Let me by the way mention something else:

At some point we could make use a predicate to determine what (requests) should be cached in local storage. Each user can then OK this system and choose which user (group) to query about the predicate. And then the app could automatically store various (common) requests in local storage to increase its speed.

(11:49) Okay, I'll make the ``Subcontexts'' Context again, and remove the `/' and the \{\} syntax, except for the Subcontexts which keeps the \{\} syntax. .\,.\,And is that it.\,.\,? Oh, and I'll also add checks to insertOrFindTerm() to make sure that the context and the def.\ term each exists if not null. .\,.\,Oh wait, I should only use the ``Subcontexts'' for the `:'-type Terms (see my current code (initial\_inserts) and my last couple of commits), i.e.\ those that use the \$s,\$l,\$t (and \{\}) syntax, so maybe I should call it something else.\,.\,? (11:56)

.\,.\,Hm, why did I get rid of the Contexts/Categories table in the first place?\,.\,. Well, because it could be nice to just let Categories be regular Terms as well, but let me think about introducing Contexts again.\,. (12:07) .\,.\,Oh, and it gets rid of the type (char) prefix, so that was a good decision.\,. .\,.\,Uh, but I could make Contexts work like Texts and Users such that they share the ID range with all the other Terms.\,. (12:10) .\,.\,Yeah, how about that; then I'll make a ``Contexts'' Term, which users \emph{can} add Terms to, and in fact, they can \emph{only} add Terms that has a Context as its context. Then the only other type of contexts are the Users, Texts and Binaries, for which users can not add Terms directly (only indirectly via the appropriate procs).\,. Hm.\,. (12:15) .\,.\,Oh, and I'll use the \$s,\$l,\$t and \{\} syntax only for Contexts.\,. .\,.\,Hm, this does seem like the right choice.\,. the right way to go.\,. (12:17) .\,.\,Oh, and the users can add Terms with ``Contexts'' itself as the context.\,. well, but I might as well also introduce a special procedure for that.\,. well, perhaps.\,. (12:18)
.\,.\,(But I don't need to add a separate table for Contexts, as they can just be stored in Terms.\,.) (12:25)

\ldots\ I have just changed the database according to these plans, but now I'm wondering if I shouldn't turn ``Contexts'' into ``Subcontexts'' and then allow all Terms as contexts again.\,. (14:41) .\,.\,Hm, why on earth is this so hard to figure out.\,. .\,.\,(Well, I kinda know why, but still.\,.) .\,.\,(Subtle semantic ambiguities and redundancies can just often be quite hard to clear up when it comes to such systems.\,.) .\,.\,(14:48) Well, maybe I actually have cleared it up enough right now; maybe we \emph{should} just use two different Terms e.g.\ for the regular Term ``Music'' and the Context Term ``Music''.\,. .\,.\,Sure.\,. (14:51)

(16:17) Oh, maybe we can get the best of both worlds, if both Context and regular Term Columns have a tab to go to the other, namely where defTermID is toggled between 0/NULL and the parentCxtID/cxtID, and where the cxtID (table column, i.e.) is toggled between the parentCxtID/cxtID and 1.\,.\,!\,! .\,.\,Yes!\,:\texttt{D}\,.\,. (16:23)
.\,.\,Hm, yeah, one could do that, but I shouldn't implement that for the first version, I guess.\,. Hm.\,. (16:30)

.\,.\,Wait, what was wrong with allowing the subcontext--instance ambiguity (now that we no longer need the string syntax, and are only using special syntax when it comes to Contexts).\,.\,?(!).\,. (16:40)


%(23.06.23, 14:07) I've not done anything today, really, other than to think about the algorithms for combining sets and such.. But it turns out that this was important enough since I've just realized that I should avoid.. Well, I should not be sorting and combining large arrays in one algorthm (regardless of whether the app should query for the large sets or not.. well, probably not; the app should actually only even query for a small part of each set to begin with.!..).. So I'm hereby realizing that the efficiency of the combination methods actually won't be important after all..(!..) ..Yeah, this is very good news.. ..Oh, and I also shouldn't worry about letting the SetMangeger keep the various ratVals, again because this data will be quite limited in size now. (14:15) Hm, so I guess I should just make a more flexible implementation of the SetManager, perhaps by using recursion and letting SetMangegers also hold an array of SetManagers, instead of just a setData array (which the "leaf SetMangers" will hold..)..? (14:18) ...Oh, and I can't let ratTransForm deal with missing subjects in a set, like I thought a bit about, since we can't really tell when subjects are missing with this approach.. ..So the combined score/ratVal can only be accumulative, really.. ..Hm, which means I should use an algorithm much like my current one but without letting the missing subjects count, right..? ..Hm, and no need for recursion, so it could be a lot like my currunt alg., before the missingWeight stuff, except that I now also need to seriously consider how to extend combined sets.. (14:36) ..Oh no, maybe I should do something more complicated, perhaps with recursion.. (14:38) ..Hm, or maybe I'm wrong about not needing to query much of any set at the same time; maybe there will be some sets where we, in some situations, want to query a big part of the elements in that set..

(25.06.23, 12:11) Even though I use the ``Applies to'' tab for both Predicates and other Terms, I should actually rename it as ``Instances'' for non-Predicates at some point.\,. .\,.\,Oh, but that actually means that I should probably just cancel that extended interpretation where non-predicate Terms can be used as the pred(\_id) for semantic inputs.\,. .\,.\,probably.\,. (12:15) .\,.\,Hm, or maybe I should instead just start to call the ``Applies to'' tab ``Instances'' instead.\,. .\,.\,Let me do that for now.\,.

(13:14) I've btw also just renamed the ``Subcategories'' tab to just ``Categories'' (letting the sub- be implicit).


(29.06.23, 16:55) I've weirdly run into wall today for some reason. But let me just write about some updates here: I've decided to just take the app in its current version and let that be the first prototype that I publish, why not; I might as well work on it openly. So I'm going to write a readme text about the project, which I will continue tomorrow. I've just bought the opensdb domain name, btw. .\,.\,Uhm, I don't have to much else to say, but I feel like talk about the fact that gathering all the Data Types, e.g.\ Users, with the Term type, it opens up for having non-User Terms in the SemanticInputs as well. This means that we are no longer bound to record all bots in the Users table. And (.\,.\,Oh, I feel really out of it for some reason.\,.) .\,.\,and it means that users can create there own ``user group''/bot Terms and ask the Developers to implement and maintain these, and if the developers then decide to do so, the do not need to create a new User, or a new Term in general, as they can just use the Term at hand. Okay, I can feel that I'm not making much sense.\,. .\,.\,I should just stop for today.\,. .\,.\,Oh, but let me try to write about the following to things. I feel like I need to mention that my ``simple user groups'' probably \emph{will} be quite useful, especially for FoaF-like networks, and for distributing trust in general. \emph{And} it will probably be quite useful also for those ``discussion user groups'' that I've envisioned and talked about before (in relation to my ``Debate site ideas''.\,.).\,. And the second thing: Another useful type of bot/user group will probably be taking an existing user group/bot and deriving another one from it with the same ratings as the first one, but where the subjects (and/or perhaps the relations) that this new user group rates is restricted compared to the first one. This will be useful for cutting out subjects of sets and thus making smaller (proper) subsets of them (which is useful for app efficiency and.\,.).\,. Okay, my brain really doesn't work rn for some reason, but I think I got there. I think I managed to say what I felt like I needed to say (even if it wasn't very well said (or written, rather)).\,. (17:13)

(30.06.23, 10:08) I think I might remove the def\_term field and then use the \$l lists instead. And I also think that I will use a NULL context much more for contexts, making it a rarity that a term has more than one ancestor.\,. .\,.\,Ah, and let me then replace \$s with \$ and \$l[n] with \$[n].\,:)\,.\,. (10:14) .\,.\,Hm, I guess I will make this change, but let me think for a little more.\,. .\,.\,Hm, let me also remove the `:' syntax, by the way.\,. .\,.\,Oh wait, how about using variables instead, with identifiers that can then be used as labels in Term submission fields?!\,:) (10:22) .\,.\,Oh, that would almost be smart, but.\,. oh, but if I use a syntax like.\,. oh, perhaps with a trailing \$ as well.\,.\,?\,:) (10:25) .\,.\,Hm, then why not use $<>$ instead?\,.\,:) (10:26) .\,.\,(10:34) Okay, I need to use this $<>$ syntax for sure, first of all. And now I just thought, maybe I should also make a ``Template context'' Context for all the template Contexts.\,. .\,.\,Sure, and then this will function as the current `:', by the way. (10:36) .\,.\,Hm, I should make a queryUnsafe() method, then.\,. (10:45) \ldots (11:07) Hm, I'm not sure I can remove the def term, 'cause it is handy e.g.\ for the Ratings page.\,. .\,.\,Wait, no, maybe it isn't.\,. .\,.\,No, I can remove it.\,. (11:14)

.\,.\,Hm, let me say that all elements of a list (of the form $<n>$,$<n>$,\ldots) that exceeds the number of placeholders in a template will be appended inside a trailing parentheses in the title, each element (if more than one) separated by a comma. (11:20) .\,.\,Okay, let me start on making these changes (but it's okay if I don't finish it today).

(12:06) Oh, I guess I should also allow strings in the lists, because won't that be important to for searches, particularly in order to make the Indexes work.\,.\,? .\,.\,Hm, and I could actually use \# for IDs, then.\,. .\,.\,And let me use `;' instead of `,'.\,. .\,.\,(12:17) Yeah, let me do this; let me allow strings in the lists.

(13:36) Let me by the way mention that I now intend to go away from using non-Predicates for pred\_ids again (which means that I should probably go back to the ``Instances'' relation, and maybe split the ``Applies to''/``Instances'' tab up into two again.\,.).\,. (13:39)

(19:08) I've had the delightful idea to actually change context\_id to context\_str instead, simply.\,:)

(21:24) I had second thoughts but I actually think I will let context\_id $\to$ context\_str.
\ldots\ (22:56) Or maybe not.\,.

(01.07.23, 11:26) I think I will keep context\_id and just disallow inserts of Terms with Contexts who themselves has Contexts: no more than one ancestor Context, the parent. At some point we might change this, but I don't see why we would need to.

(03.07.23, 18:47) Oh, something else that  think I've forgotten to mention, is that I intend to try to implement a small version of my ``variable documents,'' or whatever I used to call them, which were central to my ``wiki idea,'' pretty soon after having finished the first prototype. I'm then thinking of implementing a kind of ``semantic field'' for text section, where users can upload and uprate small article section in some markup language (possible Markdown, if not HTML). And to this markup language I'm then gonna add a syntax to denote ``variable subsections,'' such that the user, instead of writing the actual subsection/paragraph, instead just states what predicate to query to get the subsection/paragraph. And in a further implementation of this system, it should also be possible for users to adjust extra predicates about the article section, for instance by saying that a ``detailed'' text is preferred by the user (in the given moment), or perhaps the opposite: that a ``brief and concise'' text is preferred. And then the point is that (at some point) the application will then not only query for the best section template matching this extra predicate (if not several extra predicates) but will also then use the same added predicates when choosing what ``variable'' subsections/paragraph to query in order to fill out the section template. If this idea can be implemented sooner rather than later, it will be very useful in showing the users the possibilities of my ``wiki idea'' (that I have often referred to it as before). (18:58)


(15.07.23, 12:36) I'm actually now playing with the idea of adding types back to the system, perhaps the types: Predicate, Category, Context, Object.\,. .\,.\,Hm, and I could perhaps also refer to Contexts more as Templates, if I want to use ASCII characters for type flags as I used to.\,. .\,.\,Hm, but should I then also have the types: Users, Texts and Binaries?\,.\,. .\,.\,Hm, maybe Contexts shouldn't actually be considered Terms.\,. .\,.\,The reason I'm thinking about this now is that I'm also considering making new tabs, something like: ``As an Object,'' ``As a category,'' ``As a predicate,'' ``As a context''.\,. .\,.\,Hm, but yeah, maybe I should add types instead, but then do it as a sort of prefix to the Context, and then indeed not have Contexts as being Terms.\,. (12:47) .\,.\,And let me indeed just use the characters `p,' `c,' `o,' `u,' `t,' `b,' if I do this.\,. .\,.\,But let me think a bit more on it before I commit to restructuring the SDB.\,. (12:51) \ldots (13:11) Okay, I actually think it is the right thing to do.\,. So let me get to it.\,.

(14:16) Hm, maybe Indexes should just be introduced as Objects.\,. I'm considering adding Statements to the list, though.\,. .\,.\,Hm, then again, perhaps no to both.\,. .\,.\,(14:25) Hm, now I'm instead considering just adding `Aggregation algorithms' to the previous list --- which also includes Indexes at this point in time.\,. .\,.\,Yes, so the types will probably be: ``Categories'',  ``Predicates'', ``Objects'',  ``Indexes'',  ``Users'',  ``Texts'',  ``Binaries'',  ``Aggregation algorithms (Bots).'' (14:32)

%Hm, I just pushed accidentally (the "I'm thinking of ..." commit) by clicking the wrong button in my editor (using Atom). I didn't know that it could do that, and now I'm wondering how on earth it does that; how does it have/know my/a token for pushing changes..? ..Oh, well.. (15:11)

(15:28) Hm, shouldn't I actually start calling Terms Entities instead now?\,.\,. .\,.\,I think so.\,. .\,.\,(15:32) Hm no, that doesn't work when Templates aren't Terms, but shouldn't I actually make Templates (Contexts) a part of Terms/Entities once again?\,.\,. .\,.\,Yeah, I should.\,. .\,.\,And I guess I will use `x' for the text type once again, then.\,. .\,.\,And `m' for Templates, I guess.\,. \ldots (15:45) Hm, let me stick to calling them Terms, right.\,.\,? .\,.\,Hm.\,. .\,.\,Yeah, I still like Terms.\,. (15:49) .\,.\,Or.\,. Hm no, maybe Entities \emph{is} actually better.\,. .\,.\,Yeah, it actually is.\,. (15:51)
%Puh, at omdøbe alle "terms" til "entities" er en del arbejde, så lad mig lige tygge på det engang.. Ville også have det fint med en pause.. (15:57)

(16.07.23, 16:32) I have thought a lot today, after having successfully changed the backend and frontend, and now I'm actually considering letting types also be given by an entity, just like the templates (i.e.\ a Type entity (with the type of Type)).\,. Hm.\,. .\,.\,Let me explain, by the way, that the idea is that Types can then be used more than Templates for defining e.g.\ the Column tabs and such, and they can also always be cached because they are not intended to be very many. .\,. .\,.\,Hm, but more than 128, though, probably.\,. .\,.\,(16:45) Hm, I actually really like this idea.\,. It also makes us able to have different types of properties that ``know'' themselves the rough amount of elements that are usually attached to them.\,. oh, and perhaps also even the ratingLo value.\,. .\,.\,Hm.\,. (16:49) \ldots (17:00) No, I'm really not sure; I  could also just do it all with Templates.\,. \ldots Yeah, maybe I should just let types be part of the syntax for the templates after all.\,. (17:02)

(18:10) Okay, I think I finally know what to do. I will gather the Term types into just one type: Term (which includes Predicates, Categories and Objects). The Term type will then be the only type using templates, which I will now rename as `classes.' Classes then consist of a class name and a template, which are separated by a `$|$' in their defining string. Some important class names are then `Predicate' and `Category.' Furthermore, I will also add caching back to DBRequestManager.query() and then just make sure that all class queries are cached in this prototype of the application (disregarding that this might be redundant due to the browser's cache).

(19:33) I have been thinking about the fact (I think) that I ought to actually use sets/categories more, including for properties. And now I just had the thought: Well, why not keep the types as they are now, with Predicates and Categories apart from Terms --- and actually \emph{not} refer to the former two as Terms --- and then make it so that SemanticInputs can take either Predicates \emph{or} Categories for their pred\_id field. Interesting idea.\,!\,.\,. .\,.\,Yes, this is it. This is what I'll do.\,.\,! (19:39)

.\,.\,(19:47) Hm, now I'm even playing with the thought of dropping predicates.\,. .\,.\,Oh, which is actually just similar to back when I wanted all relations and predicates to be formed from noun phrases.\,.

.\,.\,My current names for things makes it hard to use CHAR(1)s, so let me actually just use TIYINT type codes instead.\,.

(17.07.23) I'm actually indeed going to remove predicates and use only categories instead.\,.

(11:19) I'm actually gonna stick to calling it templates. And then I'm gonna remove that whole thing about ``Add field'' to the submissions, as well as appending extra properties at the end of templates. Instead the standard syntax for templates should be ``$<$class name$>$: $<$rest of the template introducing the fields/properties of the class$>$''. The point is to then only use the class name, when defining how Columns or Elements etc.\ should be set up/rendered. So when a user needs an additional field in order to fully define an entity, they can just use a different template that has the same class name, but adds another field (or more) to the rest of the template. And there we go.\,:) (11:27)

(11:53) Oh wait. It will actually be better then to have the class as a separate column.\,. although it will take an extra byte for non-Terms.\,. Hm, but it seems to be better still.\,.
\ldots Then again, if all other def items (or most, anyway) are gotten from IDs in the def sting\ldots 

\ldots (12:19) Ah, but then I should just let types be given by an entity like I mentioned yesterday, right?\,. .\,.\,Yeah, I guess.\,.

(18.07.23, 13:14) I think I will let template entities know their own intended type by letting them hold said type entity (ID) instead of their tmpl\_id (which was just null otherwise).

%(14:28) I need to figure something else out for the Titles, 'cause right now you need to click e.g. on "of" to go the a subcategory from its Title.. Hm, maybe I should just do something with holding down control to go to the def items.. uh, or I could (also) make.. only the.. full template titles link to the def items.. and not the entity itself..

(19:03) I should also allow Type entities to hold a supertype in their tmpl\_id column.

(19.07.23) I actually don't think supertypes will be too useful, at least not in the beginning. So for the time being, I'm not going to allow types to have anything but null in their second (tmpl/cxt) field. I'm nevertheless still going to rename the tmpl\_id column back to cxt\_id for the backend (to account for the fact that it is different at least for the Template entities).

%(21.07.23, 18:51) I dag er godt nok gået langsomt (med at arbejde). Det kan være fordi, jeg ikke har spist nok, så det må jeg hellere lige prøve at gøre, og så håber jeg, det bare er det. Håber ikke, det er fordi, jeg har behov for mere ferie (det føler jeg ikke umiddelbart, men jeg kan dog til gengæld altså mærke, at luften lige er gået lidt af mig igen..).. ..Jeg holder for resten muligvis en halv fridag i morgen, så hvis jeg gør, og hvis det altså ikke bare er det med, at jeg ikke har fået spist nok (til virkeligt at kunne klø på), så kan det være, at det kan give mig noget energi igen..
%(22.07.23, 15:24) I dag har jeg heldigvis bare vildt meget energi (så tager en fuld arbejdsdag).! Jeg har lavet alt hvad angår userDB i dag (der var meget lidt, jeg ikke har commited fra i går (med i mit første commit i dag) *(tror nærmest bare jeg fik erklæret PrioritySetGenerator, og mere nåede jeg ikke rigtigt den langsomme dag --- udover at tænke over, hvad jeg er gået i gang med i dag, dog..)); det går bare derudad.!

%(23.07.23, 16:14) ... :(:'(:( ...

%(25.07.23, 12:37) I woke up around 4--5 and started thinking about turning rat_val into a TINYINT and some more things. It naturally took me a long time to fall back asleep with those thoughts. But I did, and then slept til almost 12. So that's why I'm only starting now.

(25.07.23, 12:40) I've been thinking about turning the rat\_val into a TINYINT, and I've even thought about the fact that I could use larger integers, and then just only use the trailing byte a lot of the time, since the first 0 bytes of those integers should then be compressed together with cat\_id, taking up effectively no extra space.\,. But now I've got the feeling that I should change it from a SMALLINT.\,. .\,.\,No, I probably shouldn't change it, cause the important set queries to optimize are the large ones, and for most of those, it is nice to have more than 256 (128 non-negative) containers to put the rating values into.\,. (12:47) .\,.\,Perhaps.\,. .\,.\,Yeah, I think so.\,. .\,.\,And besides, it is also nice that users can determine the structure of certain sets more carefully than with a 256 resolution (e.g.\ when it comes to semantic properties, but also when it comes to some standard categories, I think.\,.).\,. .\,.\,So the conclusion must actually be that I keep it as a SMALLINT for now.\,. (12:52)

%(28.07.23, 13:37) Det går lidt langsomt i dag, men det hænger nu også meget sammen med, at jeg også går og tænker over, hvilke nogle ting jeg skal føje til min(e) README(s). Men nu har jeg fået arbejdet lidt på mean-botten, og:
(28.07.23, 13:39) Hm, I've run into a problem that seems to maybe cause some big trouble in terms of the efficiency of the aggregation bots (e.g.\ the mean bots), unless I can find something smart to do.\,. The trouble is: How do I record and get the previous rating for each user?\,.\,. Well, I \emph{could} perhaps look at the solution of just simply letting all bots and (what is now) events run immediately for each new user input. But.\,. Hm, well maybe that \emph{would} be a reasonable solution, actually.\,. (?) (13:43)
%..(13:43) Vejret er også så godt i dag, btw. Jeg har nu egentligt ikke savnet sommervejret, for juni var så varm, og det er helt klart bedst, hvis det er mere køligt, når jeg sidder og arbejder. Men nu får jeg da lidt lyst alligevel til at gå ud og nyde det.. Så spørgsmålet er, om jeg ikke skal tage en tænke-gåtur over det her spørgsmål..? (13:45)

%(15:01) Det er faktisk godt, at jeg lige har taget --- og tager --- noget tid for at tænke over det. For det første er der også den mulighed, at jeg bare tilføjer et index og changed_at igen til RecentInputs. Men i virkeligheden var de smartere bare at opdatere alle bots for hvert nyt input, hvis ikke det var fordi, at jeg jo også godt kunne tænke mig at lægge op til, at brugere (inkl. tredjeparter) skal kunne implementere bots også. Men dertil kan man så også sige, at hvis de skal det, så skal de nok alligevel have en speciel aftale med openSDB for at få lov til at uploade og opdatere så stort et volumen af ratings. Og så kan openSDB jo lige så got bare oprette botten selv i princippet, right?.. Så er der så lige den ting, at en +index og +changed_at til RecentInputs også kunne være gavnligt for at sikre imod at brugere troller ved midlertidigt at give en forkert rating for så at annullere denne inden at nogen vagthunde kan nå at se det. Men måske kunne man så sige, at \emph{hvis} dette bliver et problem, så kunne man så se på (eventuelt) at oprette et sådant RecentInputs igen --- nå ja, for spørgsmålet er så nemlig i øvrigt også, om ikke RecentInputs ligefrem skal udkommenteres i den første version af databasen.. Så ja, det er altså dertil, jeg er nået i mine tanker nu.. (15:09) ..Hm, men bliver det ikke bare det, der er svaret: Hvis RecentInputs på et tidspunkt bliver nødvendigt, hvad end det er for tredjeparters bots's skyld, eller hvis det er for at folk ikke kan drille med at skifte ratings kortvarigt, så kan man jo bare tilføje det da. Og så kan jeg altså starte uden, hvor alle bots så bare updaterer sig for hvert nyt rating input.

(15:14) I think I actually will use that solution, i.e.\ to just let all the bots and (what was) events run immediately for every new input, and I think that I might even out-comment RecentInputs from the database, then. The reasoning is that, if RecentInputs again becomes useful at some point, either to better allow for third-party bots, and/or to prevent users from being able to troll by changing ratings back and forth quickly (which might be important in some special cases, e.g.\ when it comes to ratings of code safety), then RecentInputs can just be added once again --- also with an index like the secondary one of SemanticInputs and with the changed\_at column again, which should then also be the last column of that index. I think this is what I'll do.\,. (15:19)

%(15:40) Hm, det er åbenbart i dag, hvis man skal nyde dette solskinsvejr, for i morgen bliver det vist (kraftig) regn igen...

%(29.07.23, 9:46) Hm, der er så også lige det, at man jo gerne vil sigte mod en distribueret database, og så kunne en RecentInputs/RecordedInputs tabel måske også være gavnlig...

%(30.07.23, 10:32) In the bath here in the morning (I slept until 10 for some reason), I...
(30.07.23, 10:33) I have just realized that because the inst\_id column of SemanticInputs will likely contain two or more leading bytes that are zero-filled, if the last byte of the SMALLINT rat\_val is zero-filled, it should just get compressed along with the zero-filled bytes of the inst\_id, at least most of the time, I think. I still want users to be able to make precise ratings in some cases, for example because I still want my idea about rating entities on a list by moving them around implemented at some point, but when they are just rating via a rating bar, I the app should just round off so that the last byte is zero.

%(12:10) Har af en eller anden mærkelig grund brug for en lille pause og en gåtur (må bare tage paraply med, for jeg synes allerede det trækker op til regn). ..(12:16) Nå, never mind, nu står det allerede ned i stænger. ... (13:51) Nu pause og gåtur! (Solen skinner ligenu.)

%(31.07.23, 11:57) Mit internet er nede, så det besværliggør arbejdet med front-ended (navnligt med at teste det). Derfor har jeg bare besluttet mig for i stedet.. hold da op, sikke det regner nu..!.. ..(12:01) i stedet at skrive på READMEs'ne i stedet. Efter en smule tænketid er jeg så gået i gang med at skrive et nyt draft, hvor jeg faktisk endda omskriver introduktionen. Så det er jeg i gang med, og nu søgte jeg så lge på, hvad man kalder en "instans af en semantisk ontologi," hvis man skal være præcis og altså ikke kalde det en ontologi. En "semantisk model?" Det søgte jeg på, og nu har jeg så lige fundet en wikipedia side om "Semantic data model (SDM)".. Så ja, nu er jeg da lidt spændt på at læse om, hvad det går ud på, og hvor meget det mon ligner mit... (12:05) ..Ah, det er vist bare en "model" ligesom UML er en "model".. I think.. (12:08) ..Ja, pyh ha.. (12:10) 

%(13:38) Jeg har skrevet det her indtil videre:
	%## Introduction to the project
	%
	%openSDB is an open source Semantic Database (SDB).
	%By 'semantic' we refer to the fact that entities in the database can be linked
	%via (user-provided) relations that can carry any meaning, just as in the case
	%of the [Semantic Web](https://www.wikipedia.org/wiki/Semantic_Web).
	%
	%In fact, this project seeks to revitalize the idea of the Semantic Web, but
	%with a different approach than the conventional one. Instead of trying to
	%extend the World Wide Web itself, this project instead aims to launch an open
	%source [Web 2.0](https://www.wikipedia.org/wiki/Web_2.0) site that utilizes
	%semantic data structures, not just as part of its data processing, but where
	%the users are actively engaged in building these structures.
	%
	%The point of this is to make it way easier for the average user of the web to
	%take part in building semantic data structures than it is in the conventional
	%Semantic Web, where contributing to the data structure requires users to
	%write special [RDF triples](https://www.wikipedia.org/wiki/Semantic_triple).
	%These are fairly complicated HTML entities that web developers then have to
	%add as metadata to their web pages. So not only does the conventional approach
	%require its users to have specialized knowledge in RDF triples, it also
	%requires them to have access to editing web pages!
	%It is thus not particularly hard to see why the Semantic Web never really took
	%off with this approach: It never managed to become very accessible for users
	%in terms of participating actively in it.
	%
	%openSDB first and foremost seeks to do exactly that: make the Semantic Web[^1]
	%much more accessible to all users of the web.
	%Its approach is to instead start out as a Web 2.0 site, running on top of a
	%Semantic Database (SDB), and try to make an interface for this database
	%(in the form of a web application) that is very easy and intuitive to use.
	%
	%[^1]: Although a more appropriate term in our case might be 'Semantic
	%Net(work),' since our approach do not directly extend the World Wide Web
	%itself.
	%
	%The danger of this approach, if not dealt with appropriately, is that, as one
	%might point out, it risks exchanging more accessibility for more centralization
	%as well, since a Web 2.0 site might have ownership over its source code, and it
	%might also be unwilling to share its data structures (the non-sensitive parts).
	%This centralization would very much be in contradiction with the original
	%visions of the Semantic Web.
	%
	%However, openSDB seeks to prevent such centralization first of all being
	%completely open source, second, by allowing any other parties to copy all its
	%non-sensitive data, and third, by committing itself to working towards a
	%distributed and decentralized database. This means that other parties will be
	%able to back up the application and the database, and to host their own version
	%of the system at any point. openSDB encourages other such hosts and wants to
	%work together with them forming a distributed database.[^2]
	%
	%[^2]: This will likely include implementing processes to remap entity IDs such
	%that database nodes (in the distributed database) can keep their respective
	%data structures in sync with other nodes.
	%
	%Thus if openSDB at any point does something that is against the interests of
	%its users, the unsatisfied part of the userbase can then immediately just
	%start up its own copy of the site from a backup.
	%
	%
	%## The massive advantage of making the Semantic Web more accessibly.
	%
	%If openSDB succeeds in making a sizable Web 2.0 site where the users can easily
	%participate in building the semantic structures, it will ...
%Jeg tror, jeg vil holde en lille pause nu (og tænke lidt over, hvad jeg videre skal skrive..)...

%(16:03) Har skrevet lidt mere:
	%## Not just facts, opinions as well!
	%
	%One of the prospects of the Semantic Web is to be able to easily be able to
	%search for specific facts on the internet, such as "who was the successor of
	%Julius Caesar?" or "what is the air-speed velocity of an unladen swallow?"
	%
	%If openSDB succeeds in making a sizable Web 2.0 site where the users can easily
	%participate in building a semantic structure, it will first of all mean that
	%more such facts can be recorded. There are in principle an infinite amount of
	%fact about our world, and we cannot record them all, but the more users a
	%semantic system has, the more facts can be submitted and validated by this
	%userbase.
	%
	%However, conventional search engines, such as Google's, are already quite good
	%for finding out facts, and it will take a while before a semantic network
	%could start to compete with those. And although AI is still quite unreliable
	%at this point in time, it is not unreasonable to think such technology will
	%make it even easier to search (reliably) for facts in the near future.
	%
	%But the vision of openSDB actually extends the vision of the Semantic Web to
	%include not only searching for facts, but to search for *opinions* as well,
	%and especially the averaged opinions of the userbase, or a particular parts of
	%it.
	%
	%This opens up a myriad of new possibilities and use cases. *...*
	%
	%*...*
	%
	%Extending the visions of the Semantic Web to include opinions instead of just
	%facts obviously does not make much sense if the userbase is limited to people
	%with special access to edit web pages, and with special knowledge of how to
	%write RDF triples, because then you would only get the opinions of those people.
	%
	%So in order to achieve this, we have to first do what openSDB seeks to do and
	%make a semantic system that is accessible to all and easy to use.
%

%(01.08.23, 15:48) Jeg har ikke fået lavet meget andet i dag end dispositionsarbejde: Jeg føler mig mærkeligt flad, når jeg prøver at skrive..:\ Nå, jeg vil prøve at give det endnu et skud nu, for nu synes jeg efterhånden (til gengæld), at jeg har fået godt styr på disp'en.. ..Og hvis det ikke går, så må jeg jo bare prøve at få kodet lidt (nok bare i blinde, hvorfor ikke..).. ...(16:20) Ej, jeg kan bare slet ikke tage mig sammen.. Det er mærkeligt, for jeg synes, jeg har sovet godt i nat, men det føles nu ikke sådan..

%(02.08.23, 16:51) Har holdt en slags pause fra kl. tolv i dag til nu. Vil prøve at se, om jeg kan få skrevet lidt mere i dag. (Internettet er btw ikke kommet tilbage endnu.)

%(04.08.23, 13:56) Jeg er lidt ked af det i dag, så det er ikke sikkert, at jeg når at få skrevet så meget...

%(00:07) Holy shit, jeg fik lige den vildeste idé (måske)..: Hvad hvis man begynder at bruge AI til at modtage tale inputs og.. Okay, ved ikke, om det er en vild idé, men jeg må jo tænke over den.. Men ja: modtage taleinputs og så bruge det til at konstruere semantisk input ud fra dette.. Jo! det er en vild ting: Det er en vild fremtidsudsigt. .. ..Hm, måske, ja.. ..Tja, joh, ja.. ..Det biver måske svært at gøre ordentligt anonymt, men hvis man kan det, så kunne man måse virekligt øge flux-(*)kvaliteten af bruger dataen... (00:13) ..
%(05.08.23, 11:51) Ja, hvis det kan gøres på en god anonym måde, så kunne dette blive ret revulotionerende på et tidspunkt, for det kunne betyde et meget højere indflux a semantisk data til det system, der nu end kommer til at stå for at bearbejde den data (forhåbentligt det nye semantiske web, som jeg jo prøver at sætte gang i).

%(06.08.23, 10:29) Jeg ved ikke hvorfor, men jeg er ikke særligt oplagt på at genoptage kodningen igen her til formiddag (har først lige sat mig, btw).. Jeg tror lige jeg tager det stille og roligt og prøver at summe lidt over, hvor jeg står først.. ... (11:26) Ah, jeg ved hvilken secton, jeg bør tilføje til README'en.:)...

%(16:22) Efter at jeg fik skrevet den sektion har jeg nu ikke lavet så meget: kun ændret contact_info.md og debugged SubmissionFields.js (outID -> entID).. Jeg tror bare, at i dag bliver en fridag i høj grad (på når den sektion, jeg fik skrevet der), og så går jeg bare ordentligt i gang med det sidste kodearbejde (som jeg har tilbage før jeg kan gøre beta-versionen/prototypen live (hvor lang tid det end vil tage mig i sig selv)) fra i morgen af.

%(08.08.23, 20:43) Non-related: I've just seen a video and read a bit about the Stein's paradox, but it seems quite weird. I think I might understand it, though: My question is: Is it true that if two people, "you" and "I", let's say, play a game where a point is sampled in 3D space from a 3-dimensional gaussian, either with a new random true mean value each round or with the same, that shouldn't matter (right?), and I continously pick the normal estimator as my guess and you continuously pick the Stein estimator. If the game is this: if I get closer to the true mean with my guess, then I win a bit of money from you, and you you get closer, you win a bit of money from me, then will I not with most likelihood have taken all your money at the end of the day, if we keep on playing? You will go home without money, but you will not be sad because you know that you had the "best" estimator.;) Is that not what would happen? And if I understand the thing correctly, to be fair, \emph{if} we instead played a game where the money owed in each round would be proportional to the differnce in the square of distance of our guesses to the true value, then you would win at the end of the day, right? Maybe I'm wrong, but that's how I'm currently understanding this "paradox" at the moment (and I don't care to investigate it further). (20:53) ..(20:59) It does still seem somewhat paradoxical/weird if "you" would win the second game, but I cannot beleive that "you" would win the first, absolutely not.

%(09.08.23, 10:35) Jeg er en lille smule syg i dag. Jeg havde tænkt mig at gå i gang med at få de rigtige SetCombiners i gang den individuelle bruger. Og nu tænker jeg så også lige lidt over, om jeg mon skal fjerne CSS-delen fra min ContentLoader klasse, om ikke andet måske midlertidigt..?

%(12:43) Jeg får en lidt mærkelig fejl nu, hvor setArr = [undefined, undefined, ...] i PrioritySetCombiner for min nye SimpleCategorySetGenerator.. Tror lige jeg holder en lille pause før, jeg går videre.. ...Okay, det er ikke en mærkelig fejl: Jeg har bare aldrig debugged mine SetCombiners, på nær at RatingMaxSetCombiner har virket fint tilsyneladende.. (13:30) ..Åh, jeg havde bare glemt et "return val;" i en map()-funtion..

%(10.08.23, 12:36) Jeg har lige skrevet første felt (forklaringen) til min AKA Startup Growth-ansøgning (lige akkurat 995 anslag). Jeg føler mig forresten slet ikke syg i dag, allerede. Snotter en lille smule og nyser lidt stadig, men den tunge følelse (af at være fuld af snot i hovedet) er der ikke. Elsker virkeligt (7, 9, 13), at min krop generelt (næsten altid) er så hurtig til at komme sig over forkølelser.:)

%(19:31) About Stein's paradox, "I" would also win the second game, obviously.. I'm wondering if this is perhaps something to do with these mathematicians integrating x before they integrate \theta, and that this particular order of integration means that they get the wrong answer.. But let me actually look more into, exactly what the theorem is saying (and why it doesn't conflict with my game examples, which it can't..)... ..Oh, and let me just mention: Integrating over x before \theta might create an artificial assumpton that \theta is always "small" compared to (the norm of) the x's in the space, which therefore might make bias that the Stein estimator adds give a better result: because there is an artificial bias introduced in the calculations as well. This is just a thought that I just had (and I've only just started thinking about this topic again (since last) a few minutes ago); I need to look more into the subject to see if it actually could make sense. (19:39) ..(19:44) Hm, it seems that the theorem actually exactly does state essentially that "you" would win the second game of my examples.. ..(19:46) Hm, and maybe I actually could believe that that might be true (and that the mathematicians are technically right (which would also be a crazy sensation if they weren't, of course)).. ..Yeah, 'cause although it still seems somewhat paradoxical to me that "you" win the second game, the idea that I just mentioned cannot change the outcome of the calculation: It would be okay to integrate over x first in that calculation (I'm pretty sure..).. (19:50) ..No, wait! No, it wouldn't! Not if \theta changes for each game, which is much more realistic if the game is supposed to mimic what empirical scientists (including data scientists) have to deal with. (19:52) ..And actually in any case, the first of my two games would also be what an empirical scientist would have to go for in terms of estimators: A scientist should go for an estimator, that is likely to beat other estimators in terms of which ones is likely to be closest. ..Well, unless there is a reason why you want to square the distance, but typically the "failure" a scientist makes would be measured linearily in terms of how far the guess is away from the true value, not quadratically. ..Although of course there might exist cases, where it is better to measure the failure quadratically, but it should by no means be considered a go-to standard for general cases.. (19:58) ..Oh, wow..! I actually kinda believe that I'm right about that thing about the mistake of integrating over x before \theta (and not the other way araound)..!! (20:02) Because if the calculation is true, it tells that "you" win the second game of my two examples for a any constant \theta. But it does not tell us (I'm pretty sure) that "you" would win for a randomly sampled \theta.. Hm, although that is of course not really possible, namely to sample a \theta uniformly from all of \mathbb{R}^3, and now that I think about this fact (since I was just about to mention it parenthetically only), I can see why it might actually make sense to integrate over x first after all... (20:06) ..Hm, or maybe not.. (20:07) ..Well, the fact that the order might matter \emph{would} be a very important critisism of the estimator, and might even show why frequentists (although I must admit that this reading has made me realize that I do not fully understand what the term means exactly) are just someone who tries to escape reality, but only ends up reaching wrong and confusing results in doing so.. ..Of course, since it seems that I do not fully kow what the term actually refers to, there might be okay interpretations of frequentism, but I do feel like I have a bone to pick with a lot of frequentist: You can't just close your eyes and ears to the fact that not knowing the universal prior for things matters in some instances, and that you therefore have to actively consider this fact and if it matters for your dataset (or if you have enough data that prior does not matter (which is exactly what a frequentist might miss! (unless I misunderstand the term completely)))! And the fact that I know have stumbled upon this result, where it seems that frequentists are actively using a biased estimator, when it gives them worse results in reality.. well, let me not go that far yet: I don't know any of this. I just know that I really can't see why "you" would win the second game, if we allow ourselves to look at the space of all \theta's (i.e. the "true mean") at once (and play the game at all points in \theta space at once.. well or in a grid, let's say, such that this set of points is countable.. sampling just one x for each of these \theta's).. (20:22)
%(21:08) Anyway, I think that (some) mathematicians are probably already aware of this, even if some data scientists are indeed creating an unecessary bais in their statistics (which it sounded like from one comment I read on the YouTube video that made me aware of the paradox..), so I don't think I will try to look more into it at this point..
%(21:37) Oh, wait! I couldn't help just thinking a bit more about it, and maybe I am wrong..!.. ..Hm, or maybe not, but it might be the case that the calculation if we integrate first over \theta by integrating over a ball and then letting R go to infinity actually gives "you" an advantage, since it might be the case that "you" win more than "you" lose on average by letting "your" guesses be biased, namely since "your" bias is strongest.. hm, when the sample is on the other side of the true mean.. hm.. ..(It's still all very fishy no matter what; the fact that the order of integration matters means that we are not telling ourselves the full story...) ..Hm, 'cause couldn't you, even if the just mentioned calculation would indeed still favor "you," couldn't you just make a third calculation, where you integrate over all of \theta space first, and then move on to integrate over x, and not (x - \theta)! but just x, integrated as a ball with increasing R (so an improper integral) from the origo of \theta-space, and then the calculation would favor "me," right..? To explain this further, we are thus looking at the contributions to all thetas in the infinite grid at once, and then we start aggregating the winnings and losses for all games where x lies within a certain R from origo, and when you then let this ball grow to complete the calculation, "I" would remain the "winner" of the game as R (integrating over x, not (x - \theata)) goes to infinity. Right?.. (21:56) ..(21:59) Oh, or maybe this would just get us the same result as when intgrating over (x - \theata) first?.. Anyway, I'm to tired to think more about it, and I probably won't return to the problem any time soon either ('casue it wouldn't really matter much to me, even if I \emph{am} on to something (I mean, it would matter to me in the sense that it could be quite cool to have found that kind of thing out by myself this quickly, but it wouldn't matter a bit to my current life and goals..)).. ..Oh wait, integrating over x, not (x - \theata), is actually a completely unreasonable thing to do, so it doesn't matter anyway. (22:07) ..Okay, I can feel that I am actually kind of curious to know more about the paradox, so I might actually think more about it "any time soon" after all, if/when I get some free time like now where I don't feel like it makes sense to think about my actual work more for the day.. (22:11)
%*(11.08.23, 16:58) As I said, I won't invest any energy into this subject for now, unless I'm sure that I'm done for the day anyway, but let me just mention now, that it could perhaps be very interesting to see what happens if we regularize ('cause I'm assuming that the integral in the calculation is improper one) the integral by introducing a gaussian probability function for \theta when we play the game, and then letting the variance of that gaussian tend to \infty. ..Hm, but maybe that would still give the conventional result.. Oh well, I will not think more about this now. (17:04) ..(17:18) Yeah, one will probably still get the conventional result, so maybe that result is just simply.. right...
%*(18:57) Okay, I can feel that I won't get anymore done today, so I've just thought a bit more about it, and it's actually quite clear and simple. The problem \emph{is} that these frequentists integrate over all x for a given contant \theta, instead of integrating over all \theta for a given x, which is much more natural given that the theory is supposed to answar, what should we guess that \theta is if we are a scientist who has just measured a given x. And when you integrate over theta for a fixed x, you see that "you" would lose more money on average in both games, also the second one. Of course integrating over an unnormalizable distribution might seem a bit weird, but that's the nature of the question; you cannot close your eyes and ears to the fact that the scientist, who has just measured x, \emph{has} to now consider how to guess at a \theta over the space of all \mathbb{R}^3. But if we decide that we are only interested to know what happens in the boundary where the \theta prior tends to a uniform distribution, then the only reasonable thing to do is to regularize the integral by taking a normalizable distribution for \theta and let it tend towards a uniform distrubution, either by having a ball where R \to \infty, or by having a Gaussian where the variance tends to infinity. And if you do that, "I" will win the second game (as well as the first) of my two examples above. The best estimator will be the more intuitive one, not Stein's. But I'm actually quite sure that mathematicians are aware of this, but I don't know why they would insist on spouting confusing and misleading theories, actually leading real data scientists (or so it seems from some comment I read *(where I person said that they used Stein's estimator very frequently when modeling, or something to that effect..)) to introduce a wrong bias into there analysis! In real life! Tsk tsk tsk.. ..:) (19:09)
%*..(19:13) (I didn't watch the YouTube video to the end, btw, only as far as the 2D example. But I did read a comment saying something like: Paradoxes like these is why I prefer a Bayesean approach, which makes me think that the video perhaps talked about the fact that the approaches are different (like the wikipedia article about the subject says)..)
%*...(19:35) Oh wow, its actually quite interesting, I don't think a Monte Carlo simulation would tell you the truth either, 'cause if you sampled from very large but bounded set of \theta's, the difference of the two estimators would just be very small on average. And in this sense, we can perhaps actually think of Stein's estimator "exploiting" the fact that the \theta-space and the x space will (typically) be set to the same (having the same dimensions).. Hm.. ..Yeah, and you can't really do anything else when you Monte Carlo, so that's probably it..!.. Stein's estimator probably "exploits" the fact that its difference from the intuitive one gets smaller the smaller the chance is that we land on the edge of the space, where the contributions that makes Stein's estimator win come from (as I see it..)..!..:D (19:42)
%*(19:50) Wait, but is there then actually a reason behind this appraoch (of looking at a fixed \theta and integrate over x) in real life after all..!..? ..I don't think I will think about this now, but it's definitely something that I should. For maybe there could actually be a reasoning behind choosing that approach after all...
%*(12.08.23, 21:00) Yes, there could be an idea behind it, and with a Bayesean approach, you can calculate exactly why, when and how much it makes sense to introduce a bias (and you can calculate the optimal bias, quite easily). This other approach, which I guess is the approach of (formal) frequentism, only hides the fact that it actually assumes a non-uniform prior for \theta when choosing a particular biased estimator. (21:04)

%*(9:06, 09.12.23) If I have a habit of subtracting 10^{100} from all quantities before I present them as a data set, and I give you three data points from three different and independent quantities that I have shifted by -10^100, all three of them. Then a frequentist naively following what their theory tells them *(even if they knew what I was doing!) would say that by adding a small amount to all these numbers, it would result in a lower squared error on average. But if I presented them the unshifted data instead, they would tell me that \emph{subtracting} a small (but significantly larger) value to all these would lower the squared error on average. These are contradictory statements (about the real world) and therefore this theory cannot be true, i.e. in the sense of providing only true statements about the real world.



%% Startup Growth ansøgning:
%
%%(Beskrivelse af din/jeres startup. F.eks. produkter/ydelser, kunder/marked, det unikke ved forretningsidéen – hvilke behov dækker det og/eller problem løser det.)
%
%Startuppen udvikler og vedligeholder en Web 2.0-hjemmeside bygget over en 'Semantisk Database,' som er en yderst fleksibel form for database, der bl.a. gør det muligt for brugerne at uploade meget alsidigt og nuanceret data om, hvad de mener om de forskellige entiteter/ressourcer på siden.
%
%Denne nuancerede data gør, at søge- og feed-algoritmer i princippet kan gøres langt bedre end, hvad der ellers normalt er muligt, hvilket gør at siden muligvis kan udkonkurrere andre Web 2.0-sider!
%
%Samtidigt har systemet ikke det samme behov for at prøve at trække så meget data ud af brugerne som muligt, men behøver kun det data, som aktivt og frivilligt gives fra brugerne. Systemet kan derved også anses for mere etisk.
%
%At brugerdataen gives aktivt og frivilligt af brugerne (som kan være fuldt anonyme), gør at denne data kan gøres offentligt tilgængelig.
%
%"Kunderne," foruden brugerne, vil derfor være sponsorer i form a virksomheder, der gerne vil have adgang til al denne nuancerede data.
%
%
%
%%(Hvordan er konkurrencesituationen?)
%
%Idéen er helt ny, og der er ikke nogen eksisterende konkurrenter, der prøver at gøre det samme.
%
%Dog skal hjemmesiden selvfølgelig konkurrere med eksisterende Web 2.0-sider i form af at kunne tiltrække brugere, det er klart.
%
%
%
%%(Hvad er planerne for vækst i løbet af det næste år?)
%
%Dette afhænger meget af, hvor mange sponsorer og hvor store sponsorater, vi kan tiltrække.
%
%Investeringsomkostningerne er dog ret små sammenlignet med, hvilken gevinst det vil være for sponsorerende virksomheder, hvis de via projektet kan opnå gratis adgang til en masse brugerdata om deres produkter og servicer, og at de dermed ikke længere skal betale i dyre domme for denne data.
%
%Dermed er det ikke utænkeligt at startuppen kan tiltrække store nok sponsorater til, at vi kan blive en hel håndfuld af ansatte, der arbejder på at videreudvikle, vedligeholde og gøre reklame for hjemmesiden.
%
%Og da startuppen har et internationalt potentiale, så kan vi muligvis udvikle os til en endnu større virksomhed på sigt.
%
%
%
%%(Hvad forventer du/I at få ud af at deltage i Startup Growth?)
%
%Nu har jeg arbejdet i lang tid selvstændigt på projektet, så på alle mulige måder vil det blive godt at få andre øjne på det. Og særligt vil det være godt at få fagkyndige øjne, der kan hjælpe mig med alle de ting, som jeg ikke selv har særligt meget forstand på endnu.
%
%Dette handler om praktiske ting såsom at få opstartet selve virksomheden, og også særligt ting såsom hvordan jeg kommer i kontakt med eventuelle sponsorer og får "solgt" min idé til dem.
%
%Jeg tror, der er rigtigt mange ting, I kan hjælpe mig med, og jeg tror virkeligt, at jeg har brug for denne hjælp.
%
%
%
%%(Beskriv kort dig selv eller dit team.)
%
%Indtil videre er jeg kun ene mand på projektet, men jeg håber på at kunne tiltrække flere, der kunne være interesserede i at være med i det!
%
%Jeg er en engageret ung mand med en stor passion for videnskab og teknologi, og en stor lyst til at prøve at gøre verden et bedre sted. 
%
%Jeg er uddannet først i fysik, med specialisering i teoretisk kvantefysik, og har sidenhen uddannet mig i datalogi også.
%
%I årene efter min datalogiuddannelse har jeg bl.a. arbejdet på et stort hængeparti fra fysik, samt en hel masse andre projekter, hvilke tilsammen så har ledt mig imod dette projekt og denne drøm om at vække den gamle vision om det 'Semantiske Web' til live igen, hvilket nemlig er, hvad jeg mener at kunne gøre med projektet (og mere til).
%
%
%
%%(Beskriv hvorfor du/I skal have en plads hos Startup Growth)
%
%Først og fremmest bør jeg få en plads på Startup Growth, fordi min startup muligvis har et kæmpe stort, internationalt potentiale, hvis bare jeg kan få det kørt godt i gang.
%
%Derudover er det også bare et kanonspændende projekt i det hele taget: Tænk hvis det kan gå hen og ligefrem udkonkurrere gængse Web 2.0-sider, og dermed ændre fundamentalt på, hvordan vi bruger webbet!
%
%Og jeg har i den grad brug for skub for at komme godt i gang med den næste fase om at lancere projektet, og det håber jeg meget, at I har lyst til at give mig!



%(17:39) I actually think that I will leave the "sorting menu" for later, perhaps after I have made the prototype live. And my plan is then just to make some room for IDs in Entities after the last insert of initial_inserts, which I can then use if I need more fundamental inserts, that should preferably be part of initial_inserts. ..And if all goes wrong, then I can just change initial inserts and not care at all about if I create any gabs.. ..Yeah, I should be able to do so..

%(20:40) I think I will jut let the interface use only one Column at a time in the initial version (before I add the possibility to use more than one Column at a time again (i.e. 1--3)).

%(12.08.23, 10:45) Hm, why don't I just make the interface scroll left and right for the initial version (instead of making a more neat system where you can cycle through the Columns)..? I think I might just do that.. ... Nå, nu endte jeg faktisk med at fosøge at lave det, og det har jeg så gjort. Og det gik faktisk ret hurtigt, endda på trods af at det skulle debugges en del. Så nu mangler jeg faktisk nærmest bare Tutorialen..!.. (14:40)


(14.08.23, 11:50) I'm close to being done with the prototype, it seems. I'll write the rest of the tutorial today (probably), and perhaps I will even start renting a server and try to install it (or I'll do that tomorrow if not). I have I point about the e-mails, that I want to write here, in a minute..

(12:00) I thought about adding an option to tell the site/database/back end to save your password. But I can always ask the users later, when there actually are a reason to submit your e-mail for being able to change forgotten passwords. So in the meantime, I will just keep the sign-up page as it is now. But the important point is this: If a user has not submitted their e-mail for being able to change forgotten passwords, then the database should actually save a \textbf{hash of the e-mail} rather than the plaintext e-mail. But I will only implement this later, because I still need to hold on to the e-mails until I(/we) implement the system that sends a confirmation request e-mail to the users to confirm the address. So for now, I will keep things the way they are.

(15.08.23, 10:49) I'm not currently informing the users that the time for rating something will be recorded, and instead of doing this, I've decided that I will simply erase the timestamps of RecordedInputs before sharing them, replacing them with $(1, 2, 3, 4, \ldots)$ instead.

I also just thought about the browser extension, and whether you could actually implement that on the website. But I don't think we are allowed to inject JS into iframes from other domains, so I guess that wouldn't work. But an idea that might work, if we want users to search among SDB entities using Google, is to include a Google search field on the page (like you see in a lot of places), and then look for related entities of the URL hits that you get there. I don't know if we could even proxy that search so that Google can't see which IP address the individual searches originate from.\,.(?) Something to think about, but of course I won't do this now.

%(16:30) Puh, holdt en pause og gik mig lige en god tur, "imens det var godt vejr," men nu er det godt nok blevet varmt..


(22.08.23, 19:23) Woah!! I just searched for React, which somebody mentioned to me. It seems almost exactly like a much-developed version of my ContentLoaders!! .\,.\,Interesting..!.. Hm, I don't know how to feel about this.\,. .\,.\,I guess it's bad in some way, 'cause it might mean that I ought/need refactor my code as React.\,. .\,.\,But nice in a lot of other ways, for sure.\,.\,:) (Including for me: It means that I might very well get to work with a similar flow as I do now in my career---without having to first try to spread the idea.\,.\,:))

.\,.\,Oh, and if it really is like that, it means that it will probably be a lot easier to do a lot of things, namely of one can just import a lot of solutions.\,:) (19:31)

.\,.\,Oh, this might also cement the fact that it is best for me to gain some experience from working now: I should probably try hard to get a job where I can use React (and apparently Next.js builds on top of React, even, so also that, I guess). .\,.Hm (ha).\,. .\,.\,I.\,. .\,.\,This is yet another time where something like this happens to me.\,. .\,.\,Something like this truly has happened to me more times than I can count.\,. (19:40) .\,.\,I\,.\,. .\,.\,It's a funny thing.\,. I need to think about all this in the coming days (let it simmer in my head).\,.

.\,.\,I feel so lost for words, but yeah.\,. It's just funny.\,. (19:45) (that this always happens.)

(23.08.23, 10:04) Okay, React does actually seem to be server-side (which explains the neat syntax), so it's not exactly the same.\,. \ldots (10:54) No, it can also render client-side.\,.


(24.08.23) As I've written in a todo in ContentLoader.js, I will refactor the front-end code as React instead. And this ought to just be the next thing that I'll do. Then afterwards I can resume the next tasks such as making the SetDisplays sortable and start laying the groundwork in order to build the browser extension (that can search the SDB for the URL that the user has visited), etc. (10:47)

(24.08.28) openSDB actually clashes somewhat with some other names, especially a Linux distribution (I think). So I should maybe change it, but on the other hand, this particular name isn't too important, since it is only one node.\,. Well, maybe I \emph{should} change it anyway.\,.

%(29.08.23, 14:05) I've read enough about React now, and I think I'm ready to refactor my front-end code now..

%(30.08.23, 13:28) Har brugt en del tid i dag på at overveje, hvordan jeg ungår re-renders, noget som jeg kan se bliver besvaret i https://react.dev/learn/preserving-and-resetting-state. Så hvis jeg lige havde læst den ordentligt noget før, eller havde fundet den noget før i dag, så ville jeg nok have sparet en del tid.. ..Har i øvrigt også fået VSC op at køre i dag, for Atom understøttede ikke rigtigt JSX. Og heldigvis har jeg fundet Atoms syntax-highlighting theme i VSC (der var nogle ret svage kontraster (og vattede farver) i standarden..!..), så det er jo dejligt..:)

%(01.09.23, 19:10) Har lige holdt en kodepause og sendt nogle ansøgninger i stedet, men nu kan jeg mærke, at jeg er fr træt. Men næste punkt er CSS og så at prøve at køre og debugge det! Men kan godt være, at det først bliver på søndag (skal afsted til Fyn kl. 11 i morgen).

(01.09.23, 19:11) I'm considering making thumbs up and down next to the rating bar/ stars and then make it give 0xFFFF for thumbs up and 0x0001 for thumbs down. The simple mean bots will then just include these values as is, but at some point we can make it a convention that these values means exactly that: thumbs up and thumbs down. And then more advanced bots can ``choose'' the actual values that respectively 0xFFFF and 0x0001 will be transformed into (such that 0xFFFE will actually typically be the highest rating you can give in practice i.e.\ because 0xFFFF will be automatically lowered by the bots).




\section{Some comments etc.}
(18:10.23, 11:37)
I have a few comments about my Sematic Database project.

First of all, let me mention that I intend to write a much shorter version of the READ-ME.md, where I pitch the idea starting from: Hey, why don't we make a browser extension with ratings and comments across the whole web, and where comments can be sorted after subject, and where ratings are arbitrarily nuanced (with predicates, much like tags) and rated on a scale. And then those ratings should also be able to be used for searching among things, and that could be done on a dedicated website (or several, but that point is for a longer pitch, not this short one) where users can then search for things via categories---and subcategories!---and predicates. (I will keep my current README, but that will then just become the longer version of the pitch.) (11:43)

.\,.\,I also want to mention that although I have put that idea in the background in my project for now, I still believe that it could be a good idea if users can adjust the precision of their ratings, namely by adjusting the amount of stars (down to just thumbs-up--thumbs-down if they want) that the ratings have. Ad since we are not using the last byte of the short (i.e.\ the two-byte short integer/word), this could easily just be encoded in this byte.\,:) *(Oh, and it might also be beneficial to have the user first click positive or negative rating, and then give them the stars only then, such that fewer stars will be needed, which \emph{might} create a better user experience---it is worth considering at least.)

.\,.\,I should also mention, that my current ``applies to \ldots'' statement titles should be changed. ``Belongs to \ldots'' would be a much better choice right off the bat. But I actually also want to have it, at some point, so that adjective predicates (i.e.\ from the standard adjective-predicate template) will be rendered (as statement titles) as just the adjective in question.



\subsection{Selling the idea to existing open source communities}

(02.02.24, 10:52) I am absolutely convinced that my Semantic Network Project will lead to the future of the web, and the idea \emph{must} also be ``sellable,'' in particular also to the various open source communities like the Linux community and Mozilla. The point is this: You have already shown, Linux and Mozilla, that open source project can very well compete with commercial solutions. Linux definitely competes with e.g.\ Windows---and I think that it is even quite a bit better! And Firefox definitely also competes with Chrome and Edge (it is my preferred browser)! So why couldn't open source also compete with web sites/platforms like YouTube and Facebook, etc.?? (And especially Reddit.\,.) `Well,' you might say, `a website requires servers and maintenance etc.' Yes, they do, but so what? If the users are happy to use the service, they will provide enough money to maintain the service. And if your service also helps other organizations/companies (like my Semantic Network Project!), then your absolutely golden: the service maintenance will be paid for! But hold on, should open source then try to compete with all existing websites at once, or which website should we choose to compete with first? Well! I know exactly what website we should begin with! Enter the concepts of a `Semantic Database' (SDB) and the concept of a `User-Programmable Application' (UPA)!

The great thing about an SDB is that you don't need to change the backend and add new relations to your database whenever you want to develop a new part of the web app. You have to do that with a relational database. If you for instance want to add a like button to your resources, you have to add new relations to contain the associated data. A relational database has its advantages. But one of the big advantage of an SDB is that you don't have to do this! The database is so flexible that you can just use the core of it for pretty much anything that you want.\footnote{The only time that you would need to write SQL (not counting the times that you upgrade the SDB solution itself, if you happen to be both a developer and a user of the SDB solution) is if you want to write the so-called `Aggregation Bots,' but these can also be implemented outside of the backend, and even by third parties.}
With an SDB, the users themselves can create whatever data structures they desire!\footnote{To fully make this point understandable, I should preferably have developed my prototype (openSDB) just a little bit further.}
%But of course, if you want to implement something like a like button, say, then you also need to change the frontend code, and this is also typically the job of the developers as well. %..Hm, lad mig lige tænke lidt inden jeg fortsætter, for open source kan jo allerede meget i sig selv, uden UPA.. (11:28) ...(11:50) Jo, lad mig bare fortsætte denne pointe. ..Ah, men lad mig lige starte på en anden måde..
This means that application can evolve quite a lot in how it can be used in different ways even without any actions required from the developers. This saves a lot of work from the developers, which means that the services are easier to pay for (by the users and donors).

But it gets even better! Introducing he concept of an `UPA,' which is that users can also upload scripts, (including React modules), HTML snippets, and CSS style sheets to the site! These will of course not be approved automatically,\footnote{Except if someone at some point were to complete my `safe JS subset' language, or a language like it.} but will be approved by the developers, requiring some work by them. However! Here the developers can safe a lot of work by out-sourcing the code validation to the users! This can be done by having a `safe script' rating, which the users can then rate. (This is almost trivial to implement.) And by utilizing something which I often refer to as `user groups' (implemented via a so-called `Aggregation bot' which then aggregates ratings of users), the developers can implement a user ranking based on how much they trust the users decisions of when a script is safe and not. This technology can even be furthered by implementing code annotations with attached ratings such that users can even rate specific snippets of a script for safety, which means that the next users to read through it can get an overview of which parts are the most tested/analyzed ones and which part are in greatest need for testing and/or analyzing. And with this, the developers then only need to read through the scripts that has risen to the surface in this process\footnote{Oh, by the way, users can also rate how interested they are in new script, meaning that the interesting scripts will get more attention by the user community.} a few times before accepting it for users to then be able to add to the site, i.e.\ as a kind of (so-called) `add-on' (similarly to how a `browser extension' works to change the contents of a site). Each user can then simply choose which extensions to use, a bit similarly to how open source projects can fork in general, but where the the process of forking back and forth a now just way more flexible, and can be decided by the individual users!

Not only does all this help reduce the cost of maintenance, which help justify the open source model, but it does something even more important as well. It answers the question posed in the beginning of this text of `what website to start with.' Well, if you start with this website, then it can branch and develop into all other websites! For instance, it could develop such that open-source `Facebook' is just under one tab in the site header, and YouTube, Reddit Wikipedia, etc., is under other tabs! So by starting with this website for this proposed open source website project, we get all possible websites for the price of one!

And what is more, because there are in fact more, the SDB website that I have in mind will also fill out a hole in the market that isn't discovered yet! I thus strongly believe that even without all the points above, and even without being an open source site, the `semantic website' that I have in mind would be a great commercial idea, had I wanted to make it a private enterprise. I really believe that the things that the site will afford will be greatly appreciated by the users, even without this whole deal of being open source, and about being a UPA. This is what truly makes this idea so golden: You don't even have to convince the users to join alone on being an `open source alternative to existing commercial sites,' and on being a flexible UPA, \emph{once} it has gathered enough interest. The website will also be able to attract users simply on the ground on filling out a hole in the market, providing the users with affordances/abilities that the didn't know they needed. If this sounds interesting, see my README.md introduction to the site on github.com/mjdamgaard/Semantic-Network-Project. (There is also a longer version (not well-edited, though) of that README which mentions more points about being open source etc.) %(12:42)

So there we go, this is an absolutely great idea---immensely great, I would say! Now, there is also another important point about how to ensure that the users can always trust the companies/organizations not to be corrupted over time. But I have described this in several other places (here in this `23-xx note collection.tex' document, possibly in my `main.text'/`2021 notes' document also, and in my READMEs in the GitHub repo of the project), so let me not repeat this here.

*\textit{The next paragraph is not so important; feel free to skip it:}

.\,.\,Oh, except that I should actually mention an important point.\,. .\,.\,Yeah okay so the outline of the idea is that the organizations/companies whose supplies the web services to run the website should all allow for any competitor/collaborator/third party to copy all their data and set up a copy of the site. This allows for a whole network of service providers where if one `node' in this network all of a sudden becomes corrupt (e.g.\ by not adhering to this rule), then the users can just immediately switch to and use some of the other `nodes.' Now, the new point that I wanted to mention is this: When this ``copying'' happens, it should be a public process that all users can see (perhaps getting notifications about it, even). The users have then agreed to this from the start, as part of using the services in the first place. And (now comes the point), if a user wants to have some data deleted about them,\footnote{Anonymity is greatly advised for the Semantic Network Project for the accounts/profiles that the users use in every-day matters, but a user might for instance accidentally reveal there identity even so.} then they just have to send this request to all nodes who has copied the data in question. (However, this is only in principle; in reality, the network will work together such that a user only needs to put in the request in one place, and then it will be sent to all other relevant nodes in the network (and confirmations of the deletion will also be sent back by each node).) Since all these nodes are required by law (as far as I know) to then delete the relevant data, this whole distributedness of the Semantic Network should thus not be a hindrance in practice for the users to get data deleted.

.\,.\,Okay, this was all I wanted to write here, I guess. If I think of something else that I've forgotten, then I will just append it here. (13:14)



(14:10, 16.02.24) There is actually another point which is quite important to mention in relation to the UPA idea. And that is that users will have to uprate the scripts, style sheets, and modules before they can use them.\footnote{
	By the way, if a user logs into another computer, they will be prompted again, in serious tones, to ensure that they trust the various scripts etc.\ that they have are using (going through each one of them). This will make it a lot harder for people to convince people online to log into their own account and accept their scripts, since they users will then have to click through several warnings in that process. By the way, all the scripts etc.\ will also by checked by a parser/language checker for a supposedly safe subset of the given language, and these extra precautions are thus only there to ensure that this parser/language checker does not need to immediately be absolute 100 \% devoid of exploits on day one.
}
And this means that it will be quite easy to figure out which script-etc.\ creators have contributed a lot to the community. So when we also get the donation system that I have in mind (see my other notes, e.g.\ my `READE\_longer\_version.md' document) into the picture. It means that people will with all likelihood start donating serious money to these creators. (And the site can also run adds as something which the users can opt in to, where the money will then go to the `user groups' that the user chooses.) Think of how much money is involved on sites such as YouTube for the perspective of the creators. With this open source UPA idea, we can get an open source site where the open source creators can be rewarded with similar sums of money! (14:27)




\section{New context templates}

(04.03.24) I think I might change the template syntax, such that the full title is written first, followed by the shortened title, where some numbered placeholders are used to refer back to the template placeholders, in order of appearance. And then I'll do something else about the capitalization problem. I will recommend uncapitalized titles as standard. And the application should then capitalize on its own. However, when the first letter should not be capitalized, I will introduce a syntax (I'm thinking something like \texttt{\_} %, \texttt{\_\{...\}},
and
\texttt{\textasciicircum}, %and \texttt{\textasciicircum\{...\}},
escaped by \texttt{\_\_} and \texttt{\textasciicircum\textasciicircum}) to change which letter are and which are not capitalized during capitalization.

By the way, if it at some point becomes obsolete with the shortened titles, opting to only use up-rated shortening schemes instead, then one can just start identifying the old templates with shorten-title instructions with the equivalent ones without those shorten-title instructions at the end of the template. (18:33)

(10:35, 05.03.24) No, I will instead just make it so that some codes can be added to the template, after yet another (probably `$|$'-)separator, after the short-title template. These codes can then for instance say `don't capitalize (if not capital by default) the first letter *(first \emph{word}, rather, as it could be a placeholder, in which case the capitalization is done recursively) of the full title,' `don't capitalize the first letter of the short title,' capitalize all letters of the first word of the full title,' etc. (And again, if this becomes obsolete, the contexts can then just be identified with their simpler versions without these codes, joining their IDs as one.)

(06.03.24, 9:55) No, never mind about the trailing codes for the templates. The most important thing is just that title/defining item can avoid capitalization, which can just be done with a leading `\_'. We can also use a leading `\texttt{\textasciicircum}' to say that all letters of the following word needs to be capitalized upon capitalization, but in practice, this is only really relevant for abbreviations, such as PDF (and XKCD), and in those cases, there is really no reason why they shouldn't just be capital always. But we can choose to include it. Now, I also think it might be useful to be able to use a leading `\_' for templates, but then again, in reality this should be more up to the app rather than the entities, i.e.\ whether the full or short titles should be capitalized, and when. So there we are. I still intend to remove my `\{\}' syntax in place of having the full and the shortened title separated by `$|$'. And in regards to this, one could even use several separators to write even shorter titles (in place of using nested \{\}'s)!\,. I think this could be useful e.g.\ for entities like the `Good Movies' entity, which by the way soon will become the `Good movies' entity, since the def-item `Movies' will no longer be capitalized, as it is not the first word of the title. The template could then be change to.\,. `$<$Adjective$>$ $<$Category$>$$|$\_$|$@1', hm, where the `\_' between the separators could then signify `repeat the last thing,' in this case the full title. And the ultrashort title at the end then uses a numbered placeholder, `@1' to pull over the `$<$Adjective$>$' def-item from the full title (such numbered placeholders will always refer back to the full title). One could also maybe write `$<$Adjective$>$ $<$Category$>$$|$\_$|$\_@1' if we want to use the leading-`\_' syntax to tell that the adjective should not be capitalized for the ultrashort title. Yeah, I think that's actually a good idea.\,. (10:14) .\,.(Oh, and the reason I sandwich in the `\_' is by the way because I want repeated special symbols, and in `$||$' or `\_\_', to escape the special meaning and become e.g.\ `$|$' or `\_' when rendered.)






\section{p-models/-ontologies}

I haven't written too much about my p-model idea, despite how important I think it is. But in very simple terms, it is about linking statements in terms of how correlated their truths are: `If one statement turns out to be true, what is the likelihood, that the other is then true?' So I should make sure to work on adding this when I (or hopefully `I' will be a `we') start to work on the discussion parts of the comment sections. (10:44, 05.03.24)



\section{New thoughts (21.03.24)}

(12:34) I feel inspired to continue working on my semantic network system (openSDB/the Semantic Network Project). I have my new templates, described above, that I want to implement. And I've also had some new ideas today about maybe actually including `predicates' again in the SDB, \emph{side by side} with the `categories.' But I should think some more on that. I've also re-convinced myself of how important it is for me to get to the point where I have a nice looking and easy-to-use browser extension, and with a website underneath that is also somewhat alright to look at, and where all the main things are implemented, especially searching/sorting categories. And yesterday I also thought about a great point that will attract a large amount of users, after the initial ones, and that is the following.

Users should be able to create a.\,. `subject'.\,. Hm, name to be declared.\,. .\,.\,a subject of interest, and then up-rate statements for the subject. Other users can then take the tour and go through each of the most relevant (as many as they want) statements, and rate how much they agree to it. The service providers can then agree to make statistics over this subject, deriving correlation vectors *(you know those from standard linear algebra ML) from this data subset (of ratings related to the `subject'), and then rate each user (once the site has taken off, we can make so that the users have to OK this first) that has made ratings related to the subject (and/or has taken the `tour,' as I just called it.\,.). And with just a relatively small amount of users participating, this can already lead to something very useful (due to the very high \emph{quality} of the semantic data), such that the users will be able to find a good `user group' for them regarding this `subject.' This can then easily lead to much, much improved recommendations, search results, comments, etc., compared to what the existing web has to offer otherwise. So this is how we go from a small community to a very large one: by attracting a large number of users based on the fact that they can get so good recommendations---and meet other users with similar tastes as themselves online---and with not very many users and very much data required in order for these recommendations to start being better than what the existing web offers. (12:55) *(!\,:))

(12:59) Hm, and as I said, I'm considering adding predicates (not replacing categories) to the fundamental system. The idea is that, 1, it makes it more intuitive if predicates can be formulated as predicates, I think, and 2, the predicates are not meant to be used as categories anyway! For I am dropping using the `$<$Adjective$>$ $<$Category$>$' template anyway, in favor of `entities that are $<$Adjective$>$.' But this category, as said, is not really useful as a category in it self. It is only useful when combined with another category. So I actually intend, now, to make a special type of category, formed from exactly one `category' and one `predicate,' and then make a bot that rates this category automatically. (And the service providers are then free to decide, which and how many of these compound categories its bot will rate (and bot ratings can always be deleted, e.g.\ if a compound category is to be discontinued).) (13:07) .\,.\,I always did intend for things to be like this at some point, but maybe I should do it from the start, especially if I also decide to make `predicates' special in the fundamental SDB, as I'm considering.\,. (13:09)

\ldots (13:42) Hm, maybe I'm slowly landing on indeed introducing `predicates,' but without altering the function of the `categories' in the fundamental system at all. And `predicates' could then just get a separate SemanticInputs table (maybe renamed to CategoryRatings and PredicateRatings), which works like the original one, but with the PK removed and the SK made into the PK.\,. .\,.\,(such that you e.g.\ cannot look up all `fun' entities, but you can only look up how `fun' a given entity is). .\,.\,I have also been considering adding an `is relevant' rating directly to PredicateRatings as well, but maybe not.\,. (13:48) .\,.\,Hm, it could definitely do some good (in terms of potential speedups in the future), but is it worth it---'cause it also creates a redundancy, since `Relevant predicates' should also be a properties category.\,. .\,.\,Hm, and I guess you could also make a bot that just attaches the (compressed) actual rating to the least significant byte in the short (integer) of the `Relevant predicates' ratings.\,. (13:52) .\,.\,Yeah, that's how we will make that speedup in the future. Okay, so this might indeed be the plan, namely to simply introduce a PredicateRatings, that only has a PK which can be used to look up individual ratings (not lists of ratings).\,. .\,.\,Hm, but how about just overloading the semantics such that a predicate entity in the `cat\_id' column just is automatically interpreted as the category of all `entities that are $<$predicate$>$'.\,. .\,.\,Right, 'cause I could actually imagine cases where a `entities that are $<$predicate$>$' category could be useful.\,. .\,.\,Okay, this seems like the right call.\,. .\,.\,Hm, but what about plural vs.\ singular predicates; should I make templates that define both?\,.\,. (14:05) .\,.\,Oh wait, couldn't we just.\,. hm, maybe not.\,. We \emph{could} just make a category template based on a predicate, and then just make the short title read like a predicate (i.e.\ a verb phrase), but this complicates all other titles a lot, so no. It's much better to introduce a `Predicate' type. And I think I will just let that type behave like almost like a category in its own column.\,. Hm, or maybe not, on second thought.\,. (14:13) .\,.\,Well, yes and no: I think I might actually still call it `subcategories' and `supercategories' even for predicates. Now back to the singular/plural matter, I think I might actually do this.\,. .\,.\,(14:22) Hm, I think I will just do this with an `is/are' (or `takes/take,' `has/have,' etc.) slash syntax, and then just for now disregard the potential for cases where several words could replace several words, as this will probably almost never happen. I've btw also thought of a RegExp-like approach, writing replacement codes for the plural version at the end of the template, but again: the slash syntax will probably be good enough for almost all cases.\,. (14:25)

\ldots\ (16:49) No! I will not introduce `predicates,' or make SemanticInputs take predicate entities. I have a much better solution. The point is: We decide what `categories' are. And `Funny,' for instance, can also be a category.\,! Note that since the F is capitalized, it can be interpreted as a proper noun: the category `Funny.' And that's it, we will recommend more than just normal nouns as category titles: Capitalized adjectives and verbs are also recommended! And this should \emph{not} even require a clarifying template context. For instance, `Category $\blacktriangleright$ Funny' is a perfect valid (recommended) entity. Furthermore, `Category $\blacktriangleright$ Has good acting' is also a valid (recommended) category. (And `Has' here always has to be rendered as capitalized, as it is always understood as a category.) But categories beginning with `Is' is not really recommended, unless the somewhat (unlikely) help disambiguate the whole thing. It is often better to then simply write the following adjective or noun alone (e.g.\ as in `Funny' and `Iconic movie' rather than `Is funny' and `Is an iconic movie'). (17:04)

This means that I will actually go back to using manual capitalization for each entity, since now the entities always have to be capitalized once again. And what's more, I will even go back to (or rather, not go away from) using the `\{\}' syntax, instead of the `$|$' syntax that I recently proposed above. The reason for this is simply that it is actually a good syntax: It's easier to write and is less verbose. (17:09)

.\,.\,Oh, and about the ``compound categories'' which I talked about earlier today, I will keep them, but calling them `aggregate categories' instead. And their syntax should simply just use code, not NL. More precisely, they should simply use plus signs between the categories.


(24.03.24, 18:10) I have a lot of things to write.\,:) I'm not sure I will get to them all this evening, 'cause I need to brainstorm over the most recent parts of it. First of all, I just want to quickly pat myself on the back again over realizing that adjectives and verbs can be categories as well. It really makes sense. And since last time, I have even realized that in a way, a category titled `Funny' is more semantically precise than a category named `Movies.' And it seems quite trivial in hindsight, 'cause a category are really just a title that you put on a metaphorical box of things/concepts, which makes it exactly equal to how we define `tags.' Categories \emph{are} just tags, and tags are categories. Anyway, so it doesn't even limit the semantical precision of the system, bootstrapping its own semantics, when we make this change, and the change is so handy as well. Okay, I got to move on.

I have some other really great news. And a big part of it basically boils down to the fact, that I thing the website (plus browser extension) can become really useful (enough to attract he first user community) even if it only really revolves around `external links' as the only property that is really used by the website / the users. This makes me think that I am \emph{much} closer to being able to complete a useful version of the website (on my own, even!) than I thought before! But let me get back to this more later, 'cause I really need to brainstorm about these latest ideas, which I just got on an afternoon(/evening) walk that I was just on.

I got the idea that I can probably actually merge the `Type' type and the `Category' type into simply `Category.' This will mean that instead of the first entity being `Type $\blacktriangleright$ Type,' it will be `Category $\blacktriangleright$ Category' instead. (I think that part of the reason why I didn't see and/or want this before is because I really wanted plural nouns for categories.\,. I think, maybe.\,.) Anyway, so instead of having a Type called `Movie' and a Category called `Movies,' we now remove this redundancy and simply use the Category `Movie.'

And then I've also gotten an idea on top of this: Maybe we should merge the type field and the context field of the Entities table into one.\,!\,.\,. My idea is then that when a Category is the.\,. Well, I think we should call the merged field `type,' by the way.\,. So when a Category is the Type, the interpretation is that the defining string should be.\,. Wait, no, let me think.\,. (18:33) .\,.\,(18:42) Hm, we can always make it the standard entity query to.\,. Hm, or maybe not, but we could still use a query type where all parent contexts are given at once (and maybe I should call it `context' rather than `type' if I merge them). But maybe this is not relevant, so let me think.\,. \ldots (19:07) Hm, one could make it so that the sequence of contexts are interpreted as supercategories, each one being a subcategory of the former, and then you could simply merge `Templates' with `Categories' as well, saying that a template is just a category with meta semantics, more precisely with semantic about the form and the intended interpretation of the defining strings of its members.\,. .\,.\,(Making the `$<>$' syntax part of the fundamental interpretation of the defining strings: If it is there, the entity in question should be interpreted as a Template, and otherwise the `$<$' and `$>$' need to be escaped.\,.) Hm, maybe I will run into a previous problem here again of determining whether the context is a supercategory or a parent category. Hm.\,. .\,.\,Hm, unless we just say that parent category contexts simply always need to be followed by a template defStr, and otherwise they are supercategories.\,. Doesn't sound too bad, actually, but I'll think some more on it.\,. (19:20) .\,.\,This actually sounds like a really good idea!\,.\,. 'Cause we hardly need non-category entities, or non-meta entities in general, with no template.\,! .\,.\,I think I might make this change.\,. (19:23)

(25.03.24, 11:29) Okay, I'm definitely on to something good, especially in regards to merging types and categories, and also removing the type field. But I should stick to the principle of using as little/few context(s) as possible. And in that regard, I might even go further than before and say that templates can contain the type as well.\,.

(12:00) It by the way makes sense, that I get these thought now, 'cause after having realized that the site can work well with only external links in the beginning, it doesn't feel as sensible to make all that effort to allow for.\,. entities that are not either `categories' or `subjects' (as in `topics'). In the beginning there will thus not really be much use for having types. (I am currently considering whether we should distinguish `subjects' from `categories' at least.\,.) .\,.\,Oh, of course we also have the `User' and the `Text' types, e.g.\,. (12:05) .\,.\,Hm, and what about Properties?\,.\,. .\,.\,Well yeah, of course we still need types, but they could then maybe still just be a part of the templates, or they could of course be the contexts of the templates.\,.

\ldots (12:39) Hm, maybe I should keep the type field.\,. .\,.\,Or should types just be `semantic'?\,.\,. (12:43) .\,.\,(Making use of a Type property.\,.) .\,.\,Yes, I think so. But now I also got another interesting idea: How about attaching a type to predicates, such that you could construct e.g.\ `Funny as a Movie'.\,. (12:51) .\,.\,WWII is a `Good' subject of history, but it is not necessarily a `Good' thing, as an example.\,. (12:53) .\,.\,This is actually so interesting, 'cause it can also be a help for the Aggregate/Aggregation bots/categories as well.\,.\,!\,.\,. .\,.\,So yeah, how about (often) ambiguous types, such that each entities might have several types, which are each `semantically' up-rated for the given entity (for a `Type' property), and where predicates/(ranked) categories have a common opportunity to be given an `as a' type? .\,. (13:00) .\,.\,Hm, but I guess the pragmatic thing is to then just make a template for these `as a' predicates.\,. Sure.\,. .\,.\,Wait, or shouldn't just be required?\,.\,. .\,.\,Oh, and maybe this could also separate `Predicates' from `Categories,' namely by saying that.\,. well, I guess categories might also benefit from the `as a' clarification.\,. (13:06) .\,.\,But yeah, this `as a' idea might actually be one of the most important ideas in this latest round, and that's saying quite a bit, I think---at least that's what I want: to `say quite a bit' about how this might be a very important idea.\,. (13:09) .\,.\,Because it really embraces ambiguity of entities in full, which I actually think is very important for the usability (while the semantics of the actual statements about the entities still needs to be somewhat precise (although not at all completely precise either)).\,. (13:12) %..I'm still typing quite slowly on this keyboard, despite having had it for over a year now---it has gotten a little bit better, but only a little..
.\,.\,(13:17) Oh wait, maybe Categories, including Properties, could include the type themselves, whereas Predicates.\,. does the same, never mind.\,. .\,.\,Ah, and yet, Categories/Properties do not need a template, necess.\,. oh, that might actually also be useful for them, never mind still.\,.

(13:26) Ooh, maybe the.\,. various types for an entity could be the first tabs in the app column.\,!\,.\,. .\,.\,Yes!\,.\,.

.\,.\,But we also don't want maximal ambiguity, which is why one can definitely still make good use of the templates to disambiguate entities (and making them get both a short and a full title). (13:34)

.\,.\,(A `Homonyms' tab could by the way also be useful.\,.) .\,.\,`\{Similar words\} and homo-nymns'.\,. .\,.\,`Homonyms and \{Similar words\}'.\,. .\,.\,Hm, `Homonyms and \{similar words\}', and then I should actually go back to automatic capitalization of the first letter when appropriate.\,. Hm, but what about e.g.\ iPad?\,.\,. .\,.\,Hm, maybe I'll just use an underscore to say `never capitalize,' I think I will.\,. (13:46)

.\,.\,So a pretty much typeless version of the system, where types are instead just specified in the categories/predicates.\,. .\,.\,And where Entities are thus not really specific semantic entities (after all), but are instead just `words'.\,.

\ldots (14:14) Okay, I think I might go as far as to add a type\_id field to SemanticInputs, and then just add it in the beginning *(just after the user\_id) of the.\,. primary index.\,. .\,.\,and of the secondary index, such that it will generally be compressed into almost nothing (I think). .\,.\,Oh, and a type\_id of 0 just means, as a `word'/`subject'/`category,' essentially.\,. .\,.\,I think.\,. (14:20) .\,.\,Hm, or maybe it isn't needed. But I'll perhaps keep this option open, why not?\,.\,. (14:25) I also just realized that this also makes it easier to decide the right tab to start on, when you have the variable types, cause then you just open the.\,. well, the relevant type tab.\,. .\,.\,Oh, back to the previous subject: You need the 0 type to rate the `Types' property, so yeah, it needs to be included.\,:) (14:29) .\,.\, So a type of 0 basically means `as all/any of its possible types together.'\,:) .\,.\,`as a general word (in the SDB)'.\,.\,:) .\,.\,Oh, and that can be the default tab if no specific type is relevant in the context (e.g.\ if users has just come from a word search, or has typed the ID into the URL field or some other entity search).

.\,.\,Okay, but do we really need whole templates, then, to disambiguate, or can we actually not just use the defStr alone, together with the `\{\}' syntax.\,?(!) (14:38) .\,.\,And the `\#$<id>$' syntax as well.\,.\,!\,.\,. .\,.\,Hm, then an Entity would simply consist of a defStr, which I might then rename to simple `title' for simplicity (and then make it implicit that this title can potentially be a coded one (i.e.\ with the mentioned syntax)).\,. I think this might be a good idea.\,.(!) (14:44)

\ldots (14:55) Wait, no, maybe the types are actually all we need in terms of disambiguation!\,.\,. .\,.\,Yeah.\,.\,!\,! .\,.\,Hm, or maybe not, but I could be close to something.\,. .\,.\,(15:00) Hm, I could consider using two levels of type specifications (and I am): One to select between homonyms and word functions (e.g.\ `as a name'), and one to select between `as a subject,' `as a person,' `as an actor,' etc.\,. hm, and now I'm also considering having an arbitrary amount of types, although that kinda brings me back to having to use the templates and/or contexts in general, right?\,.\,. Let me see.\,. .\,.\,Hm, I need to also have things like Properties in mind.\,. (15:08) .\,.\,Hm yeah, so maybe keeping the context field and the Templates is the right way.\,. .\,.\,Oh, absolutely: I also need the Templates for e.g.\ URLs and such. So no, the Entities will consist of a defStr and a context.\,. (15:13)
.\,.\,Wait, but wouldn't it be better, if we could just.\,. Hm, either make defStr able to be longer, or sort of hide the chopping up of the word somehow.\,. Hm.\,. .\,.\,Hm, I could do that. And how about going back to just letting `as a' be a (very fundamental) template.\,.\,? (15:19) .\,.\,Oh, but the point is: Maybe it's better that the type is connected to the predicate/category in SemanticInputs, rather than the instances.\,. .\,.\,Hm, but yeah, then we still need to be able to disambiguate the instances that need further disambiguation, hence why we need the contexts. .\,.\,And these contexts should preferable all be templates, actually (for disambiguating) (I think.\,.).\,.

.\,.\,Hm, now there's a pull between letting the type sit at the category/predicate, or simply using templates all the way to determine/disambiguate the type.\,. .\,.\,Oh wait, maybe there is a good way to do both! Maybe one could just wrap an entity in as many type specifications as one wants. And then the SDB just automatically orders them.\,. or maybe that's a bad idea, to order them, but still.\,. (15:29) Maybe I'm still on to something here. The idea is then that the category might get a type in SemanticInputs, but the instances might also be wrapped in an additional type to disambiguate them further. And when you then go to one such instance, you just first select the tab of the wrapper type, and then subsequently (but immediately and automatically) select the tab of the category/predicate type. .\,.\,!\,!\,.\,. (15:32)

.\,.\,Oh, the idea of using `as a' in general is actually really just so good.\,.\,! What a great and fortunate idea this was.\,.(!) (15:36)

.\,.\,And I think the idea with which I ended the last paragraph before the previous one is the right way to go.\,. (15:37) But let me take a walk and think some more\ldots

(15:46) Okay (before I go out), two quick things: No, I think that the initial disambiguation in terms of similar words/homonymns should be done by the entity itself as an initial thing. But (second thing) maybe we don't need templates for it, and maybe we don't even need templates for URLs, 'cause we could just make defStr/title longer (in terms of maximum), while the database can still just compress them.\,. at least if we then make the PK the actual string and not the (then subsequent) entID.\,. the regular (`table compression') way.\,.\,:)\,\ldots (15:51)

\ldots\ (18:40) Okay, I should actually move away from capitalization entirely.\,! For now that we ought to think of the Entities more as words, it makes sense to not capitalize them (for the EntityTitles).\,!\,:) And then my plan, I think, is the following. Entities are defined by a single defStr, and no longer have a context field, or a type field. But templates are still supported. Template instances are just made by starting the defStr with an entity id of the given template entity. I don't intend to use a template for normal disambiguation, such as in e.g.\ `rock (music).' Simply writing out `rock (music)' as the whole defStr is better. I will also increase the maximum defStr length, at least in the interface of the SDB. And then in the implementation, one might keep a table of common defStr prefixes, such that one might be able to.\,. chop it up.\,. I'll need to think more about this part. But another important thing is then to introduce Indexes, just like the table in create\_sdb.sql is now, but of course with only a defStr field. Both template entities and template instance entities can also be a part of such Indexes. And for these, you also simply search for them verbatim. So when searching for a template instance, one could then potentially first search verbatim for the template defStr, then take the obtained id and prepend it to a search for the defStr of the template instance (i.e.\ by searching in these `Indexes'). (18:51) .\,.\,(Or one could also write `rock (music genre),' btw.\,.)

(22:33) Hm, about capitalization, I could also use an idea of adding a trailing code to the Entities, either appended to the defStr or as a separate field, which determines the capitalization. This might nemlig %*(I wish English had this adverb.)
be needed anyway, I think, if searching is otherwise complicated by having capital letters in the mix, and not having only small letters.\,.

(26.03.24, 11:13) I need to think more about the Indexes and the defStr length. If I can plan a good implementation that hides the limit that (My)SQL has, then I will probably go forward with an initial max length, and then think about extending it in the future.\,. .\,.\,Hm, alternatively, one could make another defStr syntax for concatenating defining strings, but then the users.\,. hm, or could it be hidden in the interface?\,.\,. .\,.\,Well, this could be my future implementation plan, anyway, and then I should just reserve some syntax for it.\,. (11:19) .\,.\,Oh, and regardless of whether it should be hidden under the SDB interface or be visible to the users, I need to reserve this syntax all the same. .\,.\,And even if I find another solution, it doesn't hurt to reserve some syntax for concatenation templates, surely.\,:) Okay, so this is what I will do.\,. .\,.\,The obvious contender is of course just to use a string of `\#$<id>$'s, but then I should probably use a colon separator for the Templates, which does also kind of feel right to have: It does not feel completely right to just use a string of `\#$<id>$'s for the regular Templates, and let the.\,. function be treated on the same footing as the inputs.\,. well, it works for functional programming languages, so it could work. Hm, but I could also simply change the leading `\#' for the regular templates to another symbol, e.g.\ `@'.\,. (11:26) .\,.\,Yes, I will do this, since it also neatly keeps the room open for using the `\#$<id>$' syntax in the defining strings of the regular entities as well. (11:34) .\,.\,Hm, let me actually try to think of a better term to replace `defining string'.\,. .\,.\,`word'?\,.\,. .\,.\,`string'?\,.\,. .\,.\,Hm, I'll get back to this, and just use defStr for now.\,.

.\,.\,I'll also just keep the `\{\}' syntax for the regular, non-template-instance entities, why not?\,. (11:40) .\,.\,(But I don't plan on advertising it, really, or using it myself---only for templates.) .\,.\,So the special characters will simply be `\{', `\}', `\#', and `@'.\,. (11:44) .\,.\,And they should be escaped by `\textbackslash', which is then also a special character, escaped with itself as well. .\,.\,Oh, but, importantly, `@' should only be escaped if it appears as the (otherwise) first character of the defStr. .\,.\,Hm, but wouldn't it be cleaner, if we only used this code for the templates, and then only had the rule that leading `@'s need to be escaped for the regular, non-template-or-template-instance entities?\,.\,. (11:50) .\,.\,Hm, and leading `\#'s as well.\,. .\,.\,Wait, I also forgot about `$<$' and `$>$'.\,. .\,.\,which I am actually now considering changing somewhat, but let me see.\,. .\,.\,Having special characters is no problem, 'cause I will just make a radio button options to choose between `WYSIWYG' and `code' when submitting new entities. (12:03) *(And there should be the same options when searching for entities.) .\,.\,But back to thinking about the `$<$$>$' syntax.\,. .\,.\,Ah, I should replace that with a simple placeholder sign, such that the placeholder title (which was formerly written inside `$<>$') can instead just put before the given placeholder with a colon after the placeholder title (if one wants; all things are possible). The point is then that this allows the author to decide whether the placeholder title / property title is included in the short EntityTitle, or if it only appears in the full title, i.e.\ by using the `\{\}' syntax. (12:09) .\,.\,Good, so this might.\,. oh, but I still need to determine the syntax for the template placeholders.\,. \ldots (12:24) Ah, I can just use either `@' or `\%' (I think the former 'cause it's more visible on its own), and then this only need to be a special character in the context of a template alone. Regular entities still don't have to escape any other than the leading `@' (I think I will go with that.\,.). .\,.\,And WYSIWYG does by the way not need to be an option when writing templates; here you need to code. (12:29)

(12:42) Hm, I think I'm almost ready with this new version of the system. I hope it won't take forever to implement up through all the layers of the stack.\,. But I guess I should try to think about whether I am missing something, or if I'm good to go.\,. .\,.\,Hm, you could say that there are mostly somewhat superficial changes (that nevertheless makes searching much easier, and makes a huge difference all in all), and that the only major change is that the type of the entities are now kept more ambiguous until one makes a statement about them.\,. .\,.\,Yeah, and then there's top-level type tabs, which will cause significant changes to the app as well, but I'm ready for it.\,. (It is probably gonna be a lot of work, but I have the time, now that nobody seems to care about my theorem, ``fortunately'' enough.\,;)\,:))

\ldots\ (15:15) I will indeed just let the capitalization code be appended as part of the defStr. And I think I'll then keep `$|$' as a special character as well, used to separate the capitalization code from the initial string. And potentially, in the future, one could also imagine adding further codes to e.g.\ determine how to bend the words in other cases, and specifically (for English) the plural case. Of course, an introduction of this possibility will then make us want to edit old entities to add new codes to them, but at that point, we will likely have the (combined) resources to do so, no sweat.\,.\,:) (15:20) .\,.\,And for the capitalization codes, I think we should just use something like a comma-separated list of integers, denoting the words whose first letter should always be capitalized, and then we can also in rare cases have ``floating point numbers,'' where the integer before the dot is the word number, and the integer after dot is the letter number (used e.g.\ to capitalize P in `iPad'). And if the first word has no code to it.\,. Oh, and 1.0 could also be used to say, don't capitalize the first word, essentially. 'Cause as I was about to say, if the first word has no cap.\ code to it, then one can assume that one should capitalize the first letter of the first word if appropriate for the context. (15:29) .\,.\,But I will still try to work with entities that are not capitalized except for proper nouns, I think. *(Hm, and a dot with nothing after it could mean `capitalize all letters.')

.\,.\,Okay, let me try to get going with the restructuring of the system.\,:)\,\ldots

(16:08) Oh, I could perhaps simply call the defStr `definition' instead (and then use simply `def' as the abbreviation rather than `defStr'). Great!

(17:04) Oh, apparently the standard maximum length for VARCHARs in indexes are very low in MySQL anyway. So I'll just stick to VARCHAR(255). And then I'll implement a query proc that takes a potentially large string and outputs the IDs of all the entities of the chopped up (in lengths of up to 255 bytes, rounded down if the last character otherwise makes it exceed 255 bytes) string that can be found. And then it is the app's job to turn this into a new query for the entity of the concatenated string. (And note that it is possible to nest concatenations, 'cause when a string containing `\#$<$id$>$'s is inserted, these will in turn also be treated as placeholders, and will be further replaced (and so on) before the final render.)

(17:33) Hm, maybe it's a bad idea to have the trailing capitalization code. Maybe we should just add lower-case versions of all entities, use these in the Indexes, at least for the common natural-language-based entities, and then just make it so that whenever you go to an entity column, there is an automatic search for the `Duplicates' property (for some bot, which the user can change to another if they want), and if one exceeds some high enough rating value, the app will automatically redirect to that entity instead.\,. (17:38)

(18:06) Oh, I haven't really thought about how to implement User entities and Text entities, etc.\,!\,.\,. .\,.\,(18:13) Hm, why not actually just use separate IDs for users, texts, and binaries? And then I could just introduce other syntax similar to the `\#$<$id$>$' syntax to refer to these in Entities.\,.\,! .\,.\,Hm, I could perhaps then simply use e.g.\ `u\#123' to refer to User 123 and `t\#123' to refer to Text 123, while still omitting the `e' for Entity references, referring e.g.\ to Entity 123 by `\#123', still. (18:23) .\,.\,Oh, or maybe I'll then replace `\#' with `@' and move the `u' and `t,' e.g., to the other side of the `@,' thus writing e.g.\ `@u123' instead.\,. (18:25) .\,.\,(And write e.g.\ `@123' for Entity 123.\,.)

.\,.\,(18:30) Hm, maybe we don't even really need to be able to search for strings longer then 255 bytes. For when searching for a longer string, the given Index will probably always turn up just a few of the closest matches, where these index keys then ends on either an entity or a text reference. The app can then expand these, and the user can then choose between them---or the app can recognize which one the user is after. Great.\,!\,:) (18:34)

.\,.\,Ah, this is really great.\,. So nice, this new thing of just using (internal) references of different types.\,.\,!\,:)\,.\,. .\,.\,(And when you want to speak about these users and/or texts, etc., you then just do exactly the same thing as you do for any external references: You make a template (typically) for this kind of thing, and then insert the identification, in this case the internal references (/ placeholders), in that template.)

.\,.\,(18:41) Uh, and then I could maybe use `\%e', `\%u', `\%t', etc., for the template placeholders.\,.\,!\,.\,.
.\,.\,(18:44) Hm, and maybe I could use something like `@t123(\ldots, \ldots, \ldots)' for the templates, although I am not sure that templates should be have their own internal type, like Users and Texts do.\,. .\,.\,Hm, and I would rather just stick to the string of references, without any delimiters, which then just means that you have to always insert input by reference for the templates.\,. .\,.\,Hm, maybe Templates could be their own thing, though, i.e.\ be apart from the Entities and get their own type.\,. Oh, I cannot use `t' two times, by the way.\,. .\,.\,Hm, but I could use P instead, for `temPlate' or `Pattern'.\,. (18:51) .\,.\,Hm, it kinda does make good sense to also give templates their own `type,' then, since they are so meta.\,. .\,.\,On the other hand, we would like to be able to search for them via Indexes as well.\,. .\,.\,You could of course introduce Template Indexes, but.\,. .\,.\,But then again, why go to all this trouble, when there is no real benefit to it?\,. .\,. (18:57) .\,.\,I'll probably still use the `@t123@\ldots @\ldots @\ldots\ \ldots' syntax, but the `@t123' reference is then just simply looked for in the Entities table, i.e.\ at the same entity that is also pointed to by `@123'. .\,.\,Oops, I mean `@p123'.\,. .\,.\,And why not just call it a `pattern,' then. It works just as well as `template'.\,. (19:04) .\,.\,Hm, or I could call them `formats,' alternatively.\,. .\,.\,Yes, I actually like that better, 'cause I like `@f123' better than `@p123'.\,. .\,.\,I like that it looks a bit like a function (`f' for `function'). .\,.\,`Format' it is. (19:13) .\,.\,Or `format string,' if one likes. .\,.\,Oh, it's called `formatted string' in C in full.\,. .\,.\,Oh well, it still becomes just `format' when being brief. %..(And they are also called 'format strings' as well.)

(27.03.24, 10:51) I shouldn't actually call it a Type.\,! Instead it should be a `context category,' which can then be shortened to simply `context' or `cxt,' now that I don't use that otherwise. And for the EntityTitles, which should now also get the cxt (context category) as a property, one could print them as e.g.\ `Movies / The Lord of the Rings' or `Persons / Viggo Mortensen' (or e.g.\ `Actors / Viggo Mortensen,' if you chose that context). And at the top of the AppColumn, you can then choose a tab or a dropdown menu to see all the most relevant context categories for the given Entity (e.g.\ `Viggo Mortensen' or `The Lord of the Rings'). (And when showing the ratings in a given column, you then don't have to repeat the context category. That can just be implicitly implied.)

.\,.\,Hm, should I call it `cxtCat' and `predCat,' then.\,.\,? (11:00) \ldots (11:12) Oh, maybe I should actually move over to using Predicates instead of Categories, 'cause maybe it will now be fine to just use a predicate template (or `format') to say that an instance `belongs to $<$category$>$'.\,. .\,.\,Hm no, categories still just makes everything much easier grammatically.\,. \ldots (12:01) I might start calling it `tags' instead! .\,. .\,.\,Hm, I have also just been wondering about using a variant of the `$\in$' symbol, and I really liked U+22F2, since it makes sense associating that with a rating as well, I think. But I'm annoyed that LaTeX doesn't support it. But now that I'm thinking about calling it `tags,' one could also very well use.\,. $\Lleftarrow$.\,. Yes, it works.\,. Hm, the idea is that it also has the association that the tag to the right is stuck on the instance to the left, while also looking a little bit like a `member of' sign.\,. Hm.\,. .\,.\,Well, there are plenty of options, anyway, and it's not for certain that we will need it.\,. Hm, but it does seem like a good idea. .\,.\,Hm, or simply $\Leftarrow$.\,. .\,.\,Hm, I might like $\Lleftarrow$ a little better than that.\,. .\,.\,Yeah.\,. .\,.\,Back to `tags' vs `categories,' it \emph{is} a bit more intuitive to use the word `tag' for my categories, so I think I'll indeed do that.\,:) But one can also still refer to them as `categories,' especially when also taking about the resulting entity lists.\,. (12:23) .\,.\,Yeah, I'll use both: `tags'/categories.' .\,.\,But I'll try to use `tag' as much as possible, I think.\,. (12:29) .\,.\,Oh, but back to the possible abbreviation, it is actually also quite nice that `$\Leftarrow$' has a natural association with `$=$'.\,. .\,.\,But I'll think more about this some other time.\,. .\,.\,(This is also something which others should preferable look at, before we take the decision (and even then it should preferable be something that can be changed.\,. Oh, I could assign a special character encoding to this sign, and then you can just always change the appearance afterwards.\,.\,!).) That was actually a good idea, i.e.\ making it a special character encoding.\,. (12:37) .\,.\,Well, or one could also just use a standard template, and then one could get the app to render the template instances differently in certain circumstances.\,. (12:38) .\,.\,Anyway, let me move on now.\,.

.\,.\,Hm, tags and categories, and each category is also itself a tag, where the tagged entities are then rated according to how important/useful they are as a member of that category. Couldn't this be a fundamental statement about the semantics of the system?\,.\,. (12:50) .\,.\,Or should I make a `is a useful/important member of $<$category$>$' template? Hm, this reminds me, I think I should go back to still using this `$<>$' syntax as the template/format placeholders, instead of `\%u' etc., oh, and then I could maybe just reserve `$<$u$>$' etc.\ as special placeholders for users etc.\,.\,! (12:54) .\,.\,Good idea. But we should then still not let the name/title inside these placeholders be important to the semantics, like I did before. The full semantics should be understandable just from reading.\,. Oh wait, maybe the placeholder name/title should just be the context category!\,.\,. (I have actually had this thought before, very recently, I think.\,.) That way, when you click on it, you are transported to the right column! Oh, so this is actually a must.\,\texttt{:D} (12:59) And then it could actually still be permissible to make templates where the context category matters---at least somewhat---to the semantics.\,. (13:00) .\,.\,Great things.\,.\,:)

\ldots (13:17) Oh, and note that it now works well to just write the word `category,' instead of e.g.\ `@2,' since `category' will now be the full SK of the Entity.\,:) .\,.\,Oh, but shouldn't it be `categories' instead.\,. Hm, it's really hard to avoid this tug between using singular and plural nouns, but maybe using `tags' rather than `categories' could actually help here.\,.\,!\,.\,. Let me see, we could also have subtags and supertags, couldn't we.\,.\,? .\,.\,Or I could still call it subcategories and supercategories, i.e.\ `of the given tag,' hm.\,. .\,.\,Hm yeah, that actually seems to work.\,!\,.\,. (13:24) .\,.\,Oh, but what about Properties, can I.\,. no, it doesn't work so well for those, does it?\,.\,. (13:26) .\,.\,(13:27) Hm, maybe it's better to just write e.g.\ `$<$categories$>$' instead.\,. .\,.\,Ah, wait! Isn't `category/movie' almost as good as `categories/movies'?\,.\,. Hm.\,. (13:30) .\,.\,But again, what about Properties.\,.\,? (13:33) .\,.\,Hm, think property, but formulated as a tag.\,. (13:35)
.\,.\,Well, that works, doesn't it. You can define a property tag by: `$<$property$>$ of $<$e$>$'.\,.\,!\,.\,. .\,.\,So maybe by being consistent about calling it `tags,' we can finally get to just use singular nouns pretty much all over.\,.\,!\,.\,. (13:40)

.\,.\,Hm, and I'll probably write `category: movie,' then, instead of `category/movie'.\,. (13:42)

.\,.\,(13:46) Hm, now that Entities are no longer the only entities in the SDB (if we didn't include the semantic inputs), I probably ought to change their name as well. And I could maybe call them `words' now instead.\,.
%Hm, I just thought a bit about my timestamp notation for some reason. The rule can be said to be: If there are dots between a timestamp and a new sentence, then the timestamp belongs to the (end of) the previous sentence.. *More precisely, it binds to the left, unless the is a sentence to the right of it without leading dots between it and the timestamp.
.\,.\,Oh, but that's not only a bit confusing to a lot of people, it is also downright incorrect, I believe. Hm, I could go back the lexItems, but I'd rather not, no.\,. .\,.\,`Strings' is another contender.\,. .\,.\,Hm, and maybe `entities' is actually also still a decent contender, although it could be better.\,. .\,.\,Maybe I should actually stick to entities, if nothing better comes up (but I have thought of what the options are before.\,.). But I think I'll take a walk now, and think about all this\ldots (13:56)

\ldots\ (15:58) I think I will call the entity string `code' instead. This \emph{code} is then translated to another (HTML) string (which has a little bit of freedom to vary across implementations and applications, as long as the semantics of that rendered string does not change) before being read and interpreted by the (human) users. And, more importantly, now it makes perfect sense to go back to calling the `context (category)' `type' again. And I've also figured out what to call the Entities. I will call them objects, but only when their type is also decided (with the option of the 0-type as well). The objects therefore has two IDs (of what was formerly called Entities) as their key, and are actually not stored in a separate table: These objects only appear in the semantic inputs. Hm, so what to call the former `Entities' table, by the way, before I continue?\,.\,. (16:06) .\,.\,Well, `ObjectCodes' seems like the appropriate choice, doesn't it?\,. (16:07) .\,.\,Sure.\,. .\,.\,Or `Codes' might also be a good option.\,. Okay, let me continue. So an object consists of a type and a code. Both of these are then (typically) referred to by IDs (BIGINTs), where the type of the type object is then automatically taken to be the (0, `type') object. In other words, it is of the type `type.' And if we then dissect the fields of SemanticInputs, we first of all have the user\_id, where the type is interpreted to be the special, reserved `u' (user) type, which tells the app to query in the Users table in the database for further data (or go query for the object with a fundamental user template, if one wants to see semantic data about the given user). Next we have the obj\_type\_id, as I intend to call it, which is what I called inst\_type before (in the latest commit). This is of course interpreted as a `type,' meaning that if the user would go from the, not `EntList, but \emph{ObjectList}, and to the obj\_type of that list, the should be directed to the column of the (`type', obj\_type\_id) object. Next up we have the, not `cat\_id,' but `tag\_id,' which is an object that is then interpreted as of the type `tag.' So `type' and `tag' will be some of the most fundamental types, together with the 0-type. The 0-type, by the way, is when you interpret the rendered code as the label/lexical item/string of characters themselves (i.e.\ once the @-placeholders have been inserted, and/or when the the template has been assembled, if we're talking a template instance object). Then we reach the specifying data for the object itself on the list, which is of course the rat\_val, with the same interpretation as before (I've re-described this in the latest commit), and finally, the obj\_code\_id. (16:25, 27.03.24) .\,.\,And the object with this given rating value on the list is then of course the (obj\_type\_id, obj\_code\_id) object. (16:26)

.\,.\,By the way, I should also mention that e.g.\ `$<$@2$>$' is a valid template placeholder as well: you can reference the type within the `$<>$' by both its ID, like here, or with its object code, like in `$<$tag$>$.' And of course, when you write `$<$tag$>$,' this is the same as writing `$<$@$n>$,' where $n$ is the ID of the (`type', `tag') object (and you could replace `tag' here with any other type).

.\,.\,Hm, I can call it the 0-type, but when it comes to rendering it, it could maybe fittingly get the `\$' symbol.\,. (16:32) .\,.\,Oh yeah, and I also need to reserve a type symbol for it anyway, similar to the reserved `u,' so yes, let me reserve `\$' for it. (16:35)

.\,.\,Oh, but there is more to consider: How to interpret (and specify) the types of inserted object references.\,. well, I guess they should have two keys then, these placeholders.\,. Oh, and I should also be careful.\,. .\,.\,with object codes that are pure integers, but let me see.\,. .\,.\,Hm, but I definitely want the option as well to just insert/substitute the code directly.\,. Hm.\,. (16:40) .\,.\,Hm, let me go back to using `\#$n$' for direct code substitution, such as in e.g.\ `$<$@2$>$' *(which then becomes `$<$\#2$>$' instead) within the code of a template. Then I just need to figure out what to do for the.\,. substitution of object links.\,. .\,.\,Hm, I want something like `@u.$n$' (and `@tag.$n$' etc.).\,. (16:46) .\,.\,Hm, and that works without making `.' a special character in most contexts, since it is only when it appears in this form, right after a string of letters preceded by an `@'.\,. .\,.\,And since we always need the dot.\,. we can also include syntax like e.g.\ `@\#2.123' (instead of e.g. `@tag.123', if `tag' has the code ID 2).\,. But I just realized, I need to find a way to end this syntax; I need some sort of stop delimiter.\,. (16:51) .\,.\,Hm, why not use a syntax of writing e.g.\ `@tag[123]' and `@\#2[123]' instead.\,:) Nice. And then I should just remember to not allow `\#' at the beginning of types.\,. Hm, and how do I enforce this restriction on the codes of the types?\,.\,. (16:54) .\,.\,Should I maybe just put parenth.\,. Ah, or I could use single quotation marks!\,.\,. .\,.\,No, I could also simply say that using `$[$' and `\#' in type codes is to be avoided, since it will make it impossible to then use placeholders the use the SK, i.e.\ the code, instead of the type object's ID (i.e.\ with the `\#$n$' syntax). (17:00) .\,.\,(Well, using `\#' in the start of a type's code will certainly cause trouble (and using `$[$' will in general).)
.\,.\,And of course, using (`type', `u') or (`type', `\$') will also not work, unless you reference them by their code ID, since these will also be interpreted differently if you use the `@$code$[123]' syntax rather than the `@\#$n$[123]' syntax. (But of course, no one would want to do this either in practice; it's just a good thing to consider what the potential danger could be (and there is none, really, with this syntax, as far as I can see).) (17:07)
.\,.\,Oh, but why not then also simply say that using type codes consisting of pure integers makes no sense, and therefore, let us drop the `\#' for these template placeholders for compactness, why not?\,.\,:) (17:09) .\,.\,So the syntax that I might go with is using e.g.\ `@$code$[123]' and `@$n$[123],' where $code$ is then simply required not to be weird in order to work.\,:) (17:11)

.\,.\,For the `\#$n$' substitutions (and here we of course keep the `\#'), I also think that this should be rendered as a link, actually.\,. well, maybe.\,. .\,.\,Hm, ooh, or maybe it could just be an inserted bookmark, or what to call it, as a prefix to the substitute, where this prefix is then a link to the (`\$', $code$) object, where $code$ is what $n$ (which is a code ID) points to.\,.\,:)\,.\,. (17:16) .\,.\,Yeah, a little, unimposing, possibly raised (like a superscript, but in front of the thing.\,. a ``pre-superscript''.\,.) symbol with a link to the (`\$', $n$) object (or I could write `the (0, $n$) object' here, equivalently).\,:) (17:19)

(20:08) I think I will actually use that idea of adding a trailing code for capital letters. And this can also be used for things like URLs as well, that should be fine.\,:)

(28.03.24, 10:47) I should also let users type the.\,. Oh, let me start by saying, I think I will call it the `object string' rather than `object code.' And to continue the last thought, I should also let users type the object string into the placeholder syntax between the square brackets as well. But in order to not have two objects with different strings leading to the exact same HTML, I think I will automatically convert to the object string ID.\,. Hm, or let me call it the `string ID' for short, and maybe I'll then also simply call the table Strings.\,. .\,.\,Yeah. .\,.\,I will automatically convert to the string ID for any placeholder. So users can write e.g.\ `@movie[The Lord of the Rings],' but it will be converted to `@$n$[$m$],' where $n,m$ are the two string IDs. (10:55)

.\,.\,Hm, sorta unrelated note: Let me also prohibit some characters like newline and tabular (if I don't do this already.\,.). These can then always be included at a later time if need be.\,.

(12:05) Okay, I also have to consider the option of making an Objects table to allow for object keys of just a single ID rather than two.\,. .\,.\,No, that just makes things more complicated, I think.\,. (12:07)

.\,.\,(12:09) Oh, I just realized, the `\#123' syntax also needs an stop delimiter. So let me just use the syntax `@[123]' instead for direct string substitutions. .\,.\,Hm, and this could be different from `@0[123]', could it not?\,.\,. .\,.\,Hm, I'm not sure, 'cause users could also use.\,. single quote delimiters, hm, except that the string could start or end with such quotation marks.\,. .\,.\,Sure, let there be a difference: One is rendered with just that pre-superscript I wrote about above, and the other (`@0[123]') is rendered as a clickable link. (12:15)

.\,.\,(12:19) Hm, it might actually be quite nice if an object could have a whole sequence of types, each one being more specific than the last, i.e. One could probably define a fundamental template (format string) for this, as I've probably thought before, but let me see.\,. .\,.\,Yeah, that's it. So how should that go?\,.\,. (12:22) .\,.\,(12:22) Hm, how about a comma separated list, simply? .\,.\,Yeah, so the template would simply be `$<$type$>$, $<$type$>$'.\,. .\,.\,And then you ought to keep choosing the last of these placeholders, if you want to make long type sequences. In other words, you would always chose a non-template-instance type for the first input in the template (format string). .\,.\,That sounds good, and then I just have to ``tutor'' the users that this is how to do it.\,. Well, or giving/setting examples could actually also be good enough, but I \emph{should} also include it in the tutorial. (12:29) .\,.\,I'm happy with this idea---I've had so many happy ideas lately, and this is yet another one (even though it is a simple one, but it means a lot knowing/realizing that this can be done).\,:)

(12:49) Hm, should I or shouldn't I make an `object' type, maybe with the reserved letter 'o,' instead of using the 0-type/`\$'-type.\,.\,? .\,.\,Hm, but `\$' was the reserved letter.\,. .\,.\,Hm, guess I haven't thought enough about placeholders for general objects, where the type might still matter for the semantics, such as the template `$<$property$>$ of $<$object$>$'.\,. (13:03) .\,.\,Hm, but since the references specifies the types anyway, the type of the placeholders are actually kinda redundant, except of course that they help guide the users of how to use the template. And I guess I also should consider, whether type restrictions for templates could be beneficial in some way.\,. .\,.\,(13:11) Hm, I don't really think so. But let me think about whether to remove the placeholder name/title again---or to make it so that the inputs then doesn't have to specify type.\,. Hm, I think that might be a good option, and then for `$<$object$>$,' the \emph{do} have to specify the type.\,. .\,.\,Hm, since they are now always converted to integers anyway, I actually don't need the reserved letters, do I? It can just be e.g.\ `user' and `bot' etc., right?\,.\,. (13:17) .\,.\,Oh wait, no! The point is that the reserved letters \emph{shouldn't} be converted to an integer, since these are not custom types that.\,. wait.\,. (13:21) .\,.\,I was about to say something like `assign to custom objects,' but they can't do that now, anyway, since the users only create the strings now (and rate the object--tags, and upload texts and potentially binaries).\,. .\,.\,Hm, so I guess I should just let the first String be `object'.\,. .\,.\,Hm, and when it is `object'---or rather 1, since this is what it will be converted to---then the users are allowed to specify the type of the given format string input, and if it is anything else, I have to then choose whether they can overwrite this or not.\,. .\,.\,Hm, no they can't. (13:28) .\,.\,And they by the way can't have `@[123]'-like references as format string inputs; there needs to be something between the `@' and the square brackets. The `@[123]' syntax is only when there is a substitution that happens before anything else is processed/translated about the string. Hm, and this means that you could technically build a template out of a concatenated string, or a substituted string in general, but of course we only make one substitution per string, and this substitution never happens across the boundaries of any previous substitution (e.g.\ `\#[123]45' will not yield the same as `\#[12345],' if 123 just so happend to be the ID of the string `123'). (13:36) .\,.\,Oh oops, I mean `@[123]45,' not `\#[123]45'.\,. (I no longer use `\#' for anything, I believe.) .\,.\,Hm, but maybe I \emph{should} go back to using `\#' for these macros, in order to better tell them apart. Yeah, I should, actually. And that also means, by the way, that I can now shorten any general object reference to just.\,. Well, I can write `' everywhere instead of `0' when it comes to the placeholders and the references (if I want to.\,.).\,. (13:42) .\,.\,Oh, and that actually solves another problem I had, 'cause we would still need to use the `@[123]'-like references for inputs for typed placeholders, and therefore it's really nice that the general, untyped `object' references now also looks like `@[123]'.\,:) (13:45) .\,.\,Hm, oh, but I'm actually making the `object' string the one with ID 1, not 0. So all in all, you could say that the special `object' references always just have the `1' turned into `' before being uploaded. (13:48)

.\,.\,Oh wait, no, reserved letters for the fundamental types is actually a good idea for several reasons. (13:56) Hm, and since they don't have to be actual type objects in the database---except for `type' and `tag' which are also fundamental.\,. wait, no, what am I talking about, I need these types to be.\,. no!\,.\,. yes! I need them all, in fact, to be actual type objects. So what to do.\,. .\,.\,(14:01) Hm maybe `object' is actually not th best choice of word.\,. .\,.\,Hm, how about calling it `semantic object,' `semantic type,' and `semantic tag' instead.\,. (14:04) .\,.\,No, I just need to find a better word for `object,' or at least I think I do.\,. (14:05) .\,.\,Hm, `thing' might be appropriate (and intuitive.\,.).\,.
.\,.\,Hm, but I don't like `thing string' and `thing type'.\,. (14:07) .\,.\,Hm, but I could maybe call it `semantic object' up in the app, but still call types and tags just that.\,. (14:09) .\,.\,Hm, sure I could, but do I actually even need a type name for the untyped.\,. Hm, that kinda answers it, doesn't it: We think/speak of the untyped objects as exactly that, and I go back to using 0 as the null type ID for such objects.\,. (14:11) .\,.\,And users could maybe write `$<$any$>$'---if not simply `$<$$>$'---if they want an untyped placeholder. Right, this seems right.\,. (14:13) .\,.\,So 0 is the (null) ID that is replaced with `' before uploading strings with placeholders or references, not 1.\,.

(14:30) Oh, I should still reserve some letter and/or words for the internal entity types, such as for users, e.g. Let me chose the letter `u' for `users of this network' (which I now think I will call the type string). And I'll chose f for `format string'. .\,.\,Yeah, and so on.\,.\,:) (14:33)
\ldots (14:47) Maybe I'll actually just call it `templates' once again, but specify it as `string templates.' Then I could change the reserved letter `f' to `t,' and change the reserved letter `t' for texts to `x'.\,.

(14:57) Hm, an alternative option could be to let `thing,' or perhaps better `any,' with string ID 1, be the `untyped type,' so to speak (the `general type,' i.e.).\,. .\,.\,And I can still refer to it in more technical contexts as `(semantic) objects,' even if I choose `thing' as the general type in the application layer.\,. (15:01) .\,.\,And then I'll still replace `1' with `' for the template placeholders and the references, before upload.\,. .\,.\,Yeah, I like this.\,. I like it quite a lot.\,. (15:04)

(15:11) Hm, would it make sense to make two kinds of Strings tables; one for case-insensitive strings, containing only lower letters, and one with case-sensitive strings?\,.\,!\,.\,. %I'm actually dizzy rn, I need a break.. (15:13)

%..I'm still feeling dizzy, but:
(15:17) I should also reconsider if templates are actually really worth the effort, now.\,. \ldots (15:49) Hm, they probably are, since we'll need them for things like comments, etc.\,. \ldots But instead of using the `$<$type$>$, $<$type$>$' template, I might just work with strings directly of that syntax, and the same goes for the `$<$property$>$ of $<$thing$>$' template.\,. (16:04) .\,.\,Hm, come to think of it, I might not \emph{need} the templates for comments, etc., either, since I could just define and use these templates in the JS code.\,. And users could in principle also define their own templates, but then be responsible themselves for adhering to these.\,. .\,.\,(16:12) I could always just postpone introducing/implementing these templates.\,. Hm.\,. .\,.\,Hm, there is also the fact that having templates creates a redundancy, and I don't have any HTML in mind currently to distinguish a template instance from its equivalent counterpart. So yeah, I'll throw templates in the paper bin, at least for now.\,. (16:16) .\,.\,And I am making room for more fundamental types (similar to `user' and `aggregation bot' etc.) in initial\_inserts.sql, so I can always just introduce the templates again, at some point, if it turns out that they will be useful (and then I should make it so that template instances also get a ``pre-superscript'' link to the template object in their HTML when rendered). (16:19)

(16:21) But yeah, I should also find out about that idea of potentially having several Strings tables\ldots

\ldots\ (18:31) First of all, I wouldn't need to introduce another table if we ever (for some reason) where to implement strings that can be searched case-sensitively. (Note that we can also search case-sensitively with the trailing capitalization code, but then this is just the least significant information in the search.) For one could then just start allowing strings with capital letters in Strings. But no, it's a good idea as it is now, to just have this lower-case Strings table with trailing cap.\ code---and accent code, potentially, for languages with accents that matter. But I need to choose a better format for these codes than what I had, and on the walk that I've just come back from, I figured out the following format/syntax.

The capitalization--accent codes start with an integer, if the on should skip that many letters before coming to the first letter that needs changing. And note that we are only counting letters, not other symbols! Then comes a code for how the next letter(s) should be changed, e.g.\ `c' for `capitalization,' followed, potentially, by.\,. Hm, let me see, actually.\,. .\,.\,Right, yes, followed either by an integer followed by `l' (for `lower case'), or followed by simply `l' directly, if only one letter is to be changed. .\,.\,Oh, or followed by the end of the string; we don't need to write the final `l' of this code. For the `l' is a code for `lower case letters,' and this can also either be followed by a number of integers, or.\,. No, this doesn't work. Let's see.\,. (18:43) .\,.\,(18:44) Okay, we just have alternating numbers and codes (consisting of no numbers). We can start with a number, in which case this is essentially interpreted as starting with `l$n$', where `l' stands for `lower case,' but more precisely just means `no change.' A `c' means `capitalize.' So for instance, `example of a not very useful entity|1c1l1c1l1c1l1'.\,. Hm, maybe I should `n' instead of `l' for `no change,' shouldn't I, to avoid this mess. Okay, I'll do that. So  `example of a not very useful entity$|$c1n1c1n1c1n1c1n1c1n1c1n1c1n1c1n1c1n1c1n1c1n1c1n1c1n1c1n1c1' is rendered as `ExAmPlE oF a NoT vErY uSeFuL eNtItY.' .\,.\,And it's a good thing that this is \emph{not} something that the users have to code. Rather, it's coded automatically for them. And about accents, I want implement this until it becomes relevant, but the idea is then that one can add more symbol instead of or directly after the `c' to then code one or more accents. (ANd it's natural to use the symbol that are related to these accents. For instance, a tilde, as in `ñ,' might be encoded with a `$\sim$,' and the two dots in e.g.\ `ä' might be encoded by `..'.) (19:02)
.\,.\,And note that `$|$' is also gonna be a special character, i.e.\ one that needs escaping, otherwise.

.\,.\,I have considered adding a code for pluralization, but it just becomes way too complicated. I think users should just become used to searching for tags, that are singular and uncapitalized, instead of searching for categories. And let me therefore wave goodbye to this idea of rendering categories with plural nouns (for some).\,. (19:06)
%..Ha, what is wrong with me today, I just got dizzy again..

(21:26) I \emph{will} include templates, complete with the `\{\}' syntax and all. This is precisely done so that very specific things can be referenced, in a way where it is easy to achieve consistency as well as semantic precision, without having to worry much about the length of the boilerplate of the template. And these templates should be rendered a bit differently: There should be a link to the template itself, probably a pre-(super)script, like I've talked about, and there could also be an expand button in case the template includes the `\{\}' syntax. (21:26)

Furthermore, we will not be needing the sequences of types, like I've talked about. Each type in such a sequence should be self-contained anyway, so the last type in the sequence will hold all the information about the context/type anyway. So no types of the form `$<$type$>$, $<$type$>$,' I don't think. (Users \emph{can} of course make these, but I don't think it will be useful.) (21:32)
\ldots (22:11) Oh, but it could be useful for rendering/specifying the layout of the application column.\,. .\,.\,(22:18) Hm, there's something to think about here: Is it okay to.\,. or to what degree should the type specify what object we are talking about.\,.\,? .\,.\,(22:20) Hm, maybe one could make wrappers for objects, with the same syntax as the templates, but intended for only a specific use.\,. And then you could uprate all relevant specification wrappers for a given object.\,. .\,.\,Hm, I could be on to something here.\,. (22:22) .\,.\,(22:29) That didn't make sense, with the wrappers, but of course, it might be important to have a tab with the various versions of the word. But there's a danger that it will run amok, then, so we also need to be careful not to overspecify.\,. Hm.\,. .\,.\,Nah, it's fine.\,. If there are different things that the same word/title can refer to, the the users will be quick enough to notice this, so we shouldn't be too worried about loosing votes/ratings for under-specified objects, I think.\,. (22:33) .\,.\,Ooh, especially since we could just notify the raters, that they have previously rated an object, that is now deemed to be to ambiguous to rate, and asking them which of the version their ratings should be carried over to. (22:35) \ldots (22:50) And a way to measure this is to note when if a given object falls below some threshold in terms of its rating as the given type (e.g.\ `The Lord of the Rings' no longer being considered a `movie' if there becomes (or are) several movies called that).\,. .\,.\,Hm, so the type specifies the context, not the object/thing itself.\,. And so we shouldn't use e.g.\ (`movie', `The Lord of the Rings') and (`book', `The Lord of the Rings'), but rather make sure to specify book vs.\ movie in the object string?\,.\,. (22:56) .\,.\,No, that's not true; the object string just have to be pretty unambiguous when in the context of the given type.\,. .\,.\,Hm, but why not specify the object in the type string, then?\,.\,. (22:59) .\,.\,Hm, I guess because that doesn't work so well when you want to search for an object. Okay, there it is. So it's better to specify the object via the object string. And the type does not need to be specified beyond what.\,. hm, beyond what is a useful category of things.\,. Okay, I should think more about this.\,. .\,.\,Hm, for instance, `action movie' will be a useful type, surely, but if you rate an action movie as `good,' you naturally also want to rate it `good' as a movie.\,. .\,.\,Oh, but maybe you just always rate according to the outermost type---and then you actually do make big use of types defined by sequences of other (atomic) types.\,. (23:05) .\,.\,Hm, or maybe `action movie' is just \emph{not} very useful as a type when it comes to tags.\,. well, except for ``aggregation categories''.\,. Hm.\,. .\,.\,Yeah, so the useful types are only those who help specify tags, and also the layout of an app column. .\,.\,Well, no, other types are useful as well, but only in order to limit search results for optimized categories.\,. well, and also since they can be used as categories themselves. .\,.\,Hm, so I should have two tags, at least, about being a valid type for an untyped object. One tags says that the type `is a useful type for specifying tag semantics,' and one says simply `the object belongs to the given type.' Maybe there could also be more.\,. oh, something like `useful type for specifying the app column layout,' maybe.\,. (23:14) .\,.\,Hm, ah, but maybe I \emph{will} use type sequences, then, and make it so that the rating appearing in a given column automatically is given the type (context) of the.\,. outermost type, which then ought to be specific enough that the the vast majority of tags will have well-understood semantics in the context of that type.\,. (23:18) .\,.\,Sure. And tags that doesn't have that, well, they just need to specify themselves more, then. (23:19) .\,.\,Oh wait, this actually also means that these compound types (i.e.\ sequences) are \emph{not} needed after all. The column just always has this ``outermost type,'' and the column can then have tabs for any of its up-rated subtypes, where the sub-tabs (and the layout in general) can be determined by the given subtype tap that you have clicked on.\,. Hm, a bit complicated, but I think I'm on the right track.\,. (23:24)

(23:33) Hm, maybe I won't actually implement the templates.\,. For why do users need this help to make consistent names of objects?\,.\,. I'm not sure they do. And in terms of comments, the app constructs these automatically, anyway, so that's actually not an important example.\,. .\,.\,And again, ratings can be moved over if/when ambiguities appear.\,. (23:38) .\,.\,And when not using templates, it makes it easier to search for the objects.\,. (23:40) .\,.\,Oh, but I could still include the templates, but just make it so that they are exploded *(no, `instantiated' is a more fitting term.\,. .\,.\,or maybe better: `filled out'.\,.) \emph{before} the object string is uploaded (such that it bears no trace of coming from a template, other than its form, of course). (23:43) .\,.\,But I can then still make the same submission fields for these templates, where each input gets its own input field. (23:46)

(23:56) Maybe I should start using `category' again as a term for all type tags that are not ``main types''.\,. And then I could use the term `type' only for the ``main types''.\,.

(29.03.24, 10:28) We can do better than that `c1n1\ldots' encoding for the cap.\ code. The code could start with the first letter (lower case, always) that needs changing (capitalization and/or accenting), followed by the number of identical letters that you had to skip over to get to it. And for any of the subsequent letters that needs changing, you just do the same but where the number tells you how many identical letters to skip after the last position. If you had to skip 0 such letters, you write no number after the letter, i.e.\ instead of writing `0.' Now, if the letter only needs capitalization, you simply move on to the next letter. For instance, our example from before *(`ExAmPlE oF a NoT vErY uSeFuL eNtItY') would turn into `example of a not very useful entity$|$eapefnteysflniy'. And ``ExAmPlE of a NoT vEry uSeFuL eNtItY' would become `example of a not very useful entity$|$eapentesf1lniy1'. And then for accents, you append a single non-letter, non-number symbol after the `[a-z]([1-9][0-9]*)?' part, which determines the accent, followed potentially by the copyright symbol (I think), if the accented letter should also be capitalized. Note that I would now prefer that it is a single symbol to encode the accenting, since this makes the encoding/translation one-to-one (bijective). So `..' is not advised for making `ä' after all. (10:46) .\,.\,Ah, but `:' could be.\,:) (10:46)

Now on to some more important things. First of all, I'll probably stick to the idea of only using templates in the application layer to help make the submission fields. (And users can also up-rate templates for a given type.) But should we worry, that everything.\,. Wait, let me first say that I have also had the idea to get rid of the `\{\}' syntax, but still include a syntax to add expandable information to the object string. I could maybe just use the `$|$' delimiter, and then you just have to write `$|$$|$' if you want to go directly to the cap.\ code.\,. Hm, it's an option. But yeah, there we are. Hm, let's refer to it as a `subtitle,' why not?\,.\,.

Now, should we worry, that everything is precise.\,. that every object string is precise from the beginning?\,. No, I don't think so. It's nice to use the templates, especially now that they are actually completely searchable, since they are filled out before upload, and since the no longer use the `\{\}' syntax, on only have the specifying information last. But if an entity.\,. Hm, let me actually pause for a bit and say that, as they are now, templates should actually really be encouraged.\,. I should make it the standard option to choose from a list of templates when wanting to submit a new ent.\,. no, I mean a new object string. .\,.\,And I should really encourage using that `subtitle'/information appendix. For it will be really nice, if we can avoid having to set up the quite complicated system for recognizing duplicates and transferring rates from old objects to their more precise versions. Now, as I was getting at, this \emph{is} possible to do. We can use a `better duplicate$|$ (less ambiguous)' property. And if a certain mean rating exceeds some threshold, we could signal a bot (or several bots) to then recalculate the mean of all relevant tags (for the given type (that said property is rated in relation to as a tag)) where all ratings of the old object is then moved to the duplicate, except whenever the given user has a newer rating for the same tag for the `better duplicate' object. Another bot can then also at the same time submit a down-rating of the old object belonging to the given type. So all in all, it is possible to handle, but as one might be able to imagine, this will require a lot of effort, actually, not just to program the bots, which \emph{is} a complicated matter in (and of) itself, but also to then make the other bots around them use these bots as well, and to make the users take an active part in all this.\,. Yeah.\,. Complicated, for sure, but I believe that it's possible. But the thing is, however, it's probably way too complicated for the first version of the app, so it's actually (after all) so important that we are able to use the templates from the very beginning, and encourage users very much to use them as well, \emph{without} this hindering the user experience of searching for objects, and being able to see short versions of the object strings rendered, without the information appendix. (11:17)

.\,.\,Hm, by the way, it's nice that when we make sure that we always insert links (i.e.\ object references) into the templates (the app is responsible for ensuring this), it means that all the properties of the information appendix/subtitle can be typed, without it making the full title longer, when rendered. And if you are unsure of what property a certain value represents, e.g.\ if you are uncertain of the role of `Peter Jackson' in `The Lord of the Rings: The Fellowship of the Ring$|$, 2001, Peter Jackson', then you can just click---or maybe just hover, even better---on `Peter Jackson' to see the type that this link carries, since it will be rendered as a link (since instead of `Peter Jackson,' the object string would actually have a (typed) object reference).\,. Hm, oh, but according to what I thought about last night, `director' might not be a useful type.\,. Hm, is there anyway to.\,. Well, yes, we could make it so that columns where the object type does not have other layout date attached to it, looks in the property of `supercategories' in order to find a type which does have layout data attached to it.\,. Oh wait, no, you could also simply.\,. Hm.\,. (11:29) .\,.\,Before I forget it, let me also.\,. Hm, no, maybe not.\,. I was about to propose using `;' instead of `$|$' for the specifying appendix, but maybe not.\,. (11:31) .\,.\,Back to the other thought, the thing is, we could of course always just get to the (`director', `Peter Jackson') column, and then navigate to (`person', `Peter Jackson') from there. But.\,. (11:32) .\,.\,But nothing. You get to the `director'-typed column, and if this type is not yet implemented very thoroughly in terms of column layout, then you simply navigate to the (`person', `Peter Jackson') column from there (e.g.). And this is always possible, since you can at least always go via the (`thing', `Peter Jackson') column. (11:40) Hm, or could we say `anything' rather than.\,. no.\,. `Thing' is better.\,. Wait, or is it? You can also ask: it this object `anything?' And that would be the same as asking, is.\,. oh, wait, or we could use `something' instead.\,. Hm.\,. (11:42) .\,.\,Yeah, that's \emph{much} better.\,.

(12:08) Hm, since templates now have a different role, I guess it doesn't really make much sense to convert the type strings into string IDs.\,. No, probably not, so let me not do that. But I will of course still convert for the object references. (12:10)

\ldots\ (14:21) Hm, maybe the appendix delimiter should not actually be a symbol, but should come as a trailing code as well. This will nemlig make searching easier/better.\,. .\,.\,Let's introduce the adverb `nemly' to English.\,. .\,.\,Hm, should it then come before or after the cap.\ code?\,.\,. *(capitalization--accent code.) .\,.\,Hm, I guess it should actually come after, since this makes it least significant in the searches.\,. (14:25) .\,.\,No, that doesn't matter.\,. (14.27) .\,.\,Well, it could actually matter a little bit, so let me just say that it comes last (of these three parts of the string). (14:28) .\,.\,Oh, I forgot to say: and an empty string for this last part just means that there is no appendix.
.\,.\,(14:35) Hm, it could only matter if we.\,. No, never mind, it could matter a little bit: To prioritize a hit where the cap.\,. hm, or maybe it doesn't.\,. .\,.\,No it won't matter a bit, and I actually prefer to write the appendix start position first, before the cap.--accent code.\,. (14:39) .\,.\,'Cause you can always expand a bit on the specifics of your object, but the.\,. CA code is only used when there are proper nouns involved.

(16:41) Hm, let me call it an `object definition' rather than simply an `object string.' (An `object definition' \emph{is} a string, but so are the `object type.')

(17:05) Hm, maybe I will use `any' rather than `something' for template placeholders, where the user themselves are supposed to determine the type. This is then opposed to when `something' is \emph{supposed} to be the type given for the template.\,.

(18:58) I will of course just start out with having a single Index, governed by a bot, that user can search in. And I should then also create a FULLTEXT index on the str column of.\,. Oh wait, but can I do that if.\,. Well, if I only have one single idx\_id in the whole StringIndexKeys table, then yes, I certainly \emph{can} create a FULLTEXT index for the str column of that StringIndex.\,. .\,.\,(19:08) Yeah, and if we'll need more, we can create separate tables for it.\,.

(30.03.24, 11:55) I've realized that now that the Entities table are called Strings instead, I should definitely go back to calling what I have now been calling `objects' `entities' instead. We then have `typed entities'/`semantic entities' which consist of a type and a definition, both being entities themselves---the first with the type of `type' and the second one being untyped. And then we have the `untyped entities' which consist only of a string (and has an ID).

How ambiguous should we allow entity definitions to be?\,. Well, it depend: For tags/cat-egories etc., it perfectly fine to not be very specific. For instance, we shouldn't need to specify the `funny' tag any more than that. And the same goes for property tags, type/category tags, etc. But when it comes to entities that defines things of the ``real world,'' be it fictional things or non-fictional---in other words, the fundamental entities that we wish to rate with this system (never mind the fact that it can also be useful to rate the tags themselves)---their definitions should generally be very precise, enough that we know exactly what thing is beig rated. However, as an example, we might have specified `WWII' very precisely (in this case, hardly any specification is needed, 'cause there is only one WWII), but we still need an extra specification in the form of the entity's type in order to be able to interpret the tags correctly. We might for instance say the `WWII' is `good' as a `history subject,' but not thereby also saying that `WWII' is `good' as a `war.' So the type is generally meant to give this last touch of specification/context in order to make the semantic statement more precise. (12:09)

(12:50) It's actually quite important for the concept as a whole that users can rate anonymously \emph{while} also having some way of proving that they are not bots/spammers. And I guess the way to go \emph{would} be to persuade most users to make a public profile, which possibly does not upload anything. Users can of course use their public profiles, but they don't have to. In these public profiles, they define enough information about themselves that people either from their place of origin or their work, or so on, can identify them. And they also state how many profiles they have, as well as perhaps the degree of overlap in the statements that are rated by these profiles.\,. perhaps.\,. Hm, and the point is then to use some sort of game where several users from different locations around the world can link up and maybe anonymously post their non-public profiles to a pool of profiles.\,. Well, it should actually be large parts of the user community that does this at once (and it's just done automatically be a program, which means that users can hire/get third parties to do this for them, of course where these third parties then promises not to record any data from it). And when you have this large pool, you can.\,. hm, you should check that there are no collisions, but that means the groups can't be so large.\,. Hm.\,. .\,.\,Hm, let me get back to this, and then continue another thought, 'casue once you have a vast network of public users, then you can also make.\,. Friend of a Friend.\,. Hm, or would this work when you don't.\,. No. No, you have to make a public profile in order for your ratings to be taken seriously---\emph{after} a certain point, that is; this will not be necessary in the early stages of the network. But yeah, a fully public Friend of a Friend network, where each public profile state their number of non-public profiles.\,. .\,.\,And back to the cryptography game, how should this go again?\,.\,. (13:06) .\,.\,(16:08) Ooh, maybe if you first encrypt the non-public profiles' (NPP) IDs.\,. .\,.\,Then you can check for collisions. And if one happens, you can abort the procedure and ask users to reveal ``their hand'' in the game (which I have described somewhere before, perhaps in the out-commented notes below from 2022.\,.), which then makes it possible to identify the culprits. But even though all participants then have their submissions known, only they hold the key to decrypt their submission to reveal the \emph{actual} profile ID. So nothing is revealed about the participant, other than whether they followed to rules of the game or not. They culprits are then removed from the game, and their associated public profiles can now also be marked (unless it is actually the third party responsible that can be seen to be the culprit.\,. anyway.\,.). The game can then repeat, and hopefully it will then soon yield a pool of encrypted NPP IDs with no collision. (And you somehow have to make it so that.\,. Hm, let me postpone these thoughts for a bit.\,.) Then you play another game where the participant get to anonymously add decryption keys to a pool, and here it doesn't matter if you get collisions, or get more than you desire, 'cause they will only work (once) if they are right. Then you decrypt all the NPPs to get a pool of exactly the right number of NPPs mathcing the group. (That the number is exactly correct is required for the first part of the ``game'' to be excepted.) Most of the users then throws out the information that is used to unravel this whole game, i.e.\ ``their hand'' as I called it before. And even if some users (with malicious intend) does not throw out their ``hand''/data as they should (using a hacked version of the recommended program), they will not be able to unravel the game without the other users' data. Now, how do we ensure that the encryption of the NPPs are injective (one-to-one, basically)?\,.\,. .\,.\,The problem is we shouldn't, so what to do instead.\,.\,? (13:25) .\,.\,Hm, my legs need to be walked, so let me think about it outside (I bet I can figure it out)\ldots\ (13:28)
.\,.\,(13:35) Hm, it's not collisions that we need to prevent but that there are too many NPP IDs in the pool\ldots

\ldots\ (15:26) I recalled that in my idea from 2022 (I think), the the participants of the protocol uses it to share encryption keys first, and then publicly states that some of the keys was created by them, by which they will be thrown out. And everyone then has to do this until they only have the right amount of keys left in the pool that they should. No one knows who the remaining keys belong to, except the creators themselves. And if the protocol fails, it will be unraveled to find the culprits, and if it succeeds, the users throw their data away. Now, the important thing is then this: The the users can then afterwards verify their non-public profiles by uploading a cipher that can be decrypted with one of the keys \emph{via} the given non-public profile itself. So that's it. I won't repeat the protocol for creating that pool, nor for ``unraveling'' it here. See my (out-commented) notes from 2022 (I think). I'm pretty confident (although not 100\,\% sure, of course) that the idea there will work, maybe with only some few adjustments needed, who knows?\,. .\,. (15:35)

(15:36) And an alternative to all this, which might work for some, is of course to find a third party that one trusts *(and which the broader community also generally trusts) to govern all one's non-public profiles.\,.

(16:26) Oh, maybe for the sake of templates, it would be a good idea to go back to using `$|$' as a symbol within the string, or use another one, instead of having a trailing code for its position. So yeah, I guess I'll go back to that. .\,.\,And let me just use `$|$', indeed.\,.

(17:05) Hm, I should consider whether it is possible to make the subtitles/appendices ``semantic'' instead, and thus dividing the entity definition into two parts.\,. .\,.\,Well, couldn't we just make the entities consist of (type, name, specifying appendix)?\,.\,. (17:07) .\,.\,And just like each app column should have an `(other) types' tab, there should then also just be an `(other) specifications' tab.\,. (17:09) .\,.\,Hm, and then maybe I should also expand SemanticInputs thus. And when we at some point need to deal with duplicate specifications, this would then just be to ``tell'' a bot to merge any two `rated lists' where the specs are deemed as duplicates (for the entity in question), keeping the newest of the two ratings (if we have implemented RecordedInputs at that point) of a user has rated both.\,. (17:13) .\,.\,Not bad at all (it seems).\,. (17:14) .\,.\,Of course, this makes the entity references even longer (and they could be changed by using commas to also specify the specification *(within the square brackets)), but it might be worth it.\,. (17:16) .\,.\,Hm, and the specification is optional, just like using the `$|$' was optional prior to this potential change.\,.

.\,.\,(17:20) Hm, this might make me put templates completely out of commission again.\,. .\,.\,Yeah, 'cause the whole point is, that this allows us to be much more relaxed about the specifications (i.e.\ `subtitles'/`appendices'), and just write some that is `sufficient enough' in the beginning. This is because dealing with duplicates will now be something that can be implemented *(much more easily and) not long after the network takes off, I believe.\,. (17:24)

.\,.\,(17:29) Oh, but the `ent\_spec\_id' column would then have to be next to `ent\_def\_id', i.e.\ not being part of the PK, and that would expand the data. So I need to then instead make a new table, where these `specified entities' can get their own ID.\,. (This also means that the entity references will not grow (really) after all.\,.) .\,.\,Well, I guess this is what I must do, then.\,. (17:33) .\,.\,Hm, so a typed/semantic entity's definition is then either a `string/simple entity' or a `specified entity'.\,. .\,.\,Something like that.\,. (17:35)

.\,.\,(17:37) Okay, so this change is actually a must, now that I've thought about it. Since all it does is to put a clearer line between the buzzword/keyword part of an entity's name and its specifying part, which then makes it much easier to deal with duplicates, once we get to that point (and therefore means that we can be much more relaxed, luckily). (17:39)

.\,.\,In fact, maybe we can even be \emph{so} relaxed that we'll rarely need the specification part in the beginning of the website/network.\,.\,!\,.\,. (17:44) .\,.\,Hm, it seems like it.\,. .\,.\,Oh, and the thing about notifying the users if they have rated an entity which now either gets further specified (by creating or changing the specification), we shouldn't even really need that: We can just expect that the users in general talked about the same thing, nemely the thing that the entity is now being further specified as. (17:49)

.\,.\,Hm, is there any sense in letting SpecifiedEntities do double work and also serve as a way to implement concatenated strings?\,.\,. (17:52) .\,.\,Hm, but then, why on earth not just make a table of ConcatenatedStrings?\,.\,. (17:54) .\,.\,(also, that is.) \ldots(18:09) Yeah, I should make a ConcatenatedStrings table, and then drop the `\#123' syntax.\,. .\,.\,The StringIndexKeys table could then get a TINYINT column denoting which table the stringID.\,. oh wait, never mind about this part.\,. \ldots (18:25) Hm, maybe ConcatenatedStrings isn't so easy to work with (so I'm might consider going back to the `\#123' syntax, but let's see).\,. .\,.\,Hm, yeah, maybe it's better to use the `\#123' syntax.\,. .\,.\,Hm, or maybe ConcatenatedStrings is not so hard after all, and maybe it's better.\,. 

\ldots Oh wait, I probably need to have (Atomic)Strings, ConcatenatedStrings, and SpecifiedTitles all share the same ID space. So maybe, just maybe, it \emph{is} better to go back to using syntax for this.\,. Hm yeah, and using syntax instead should not make dealing with duplicates harder.\,. (18:56) .\,.\,And I could just make it so that only one instance of `\#$n$' can appear in a string (without being interpreted verbatim), and only in the beginning (such that `\#' is the first character). (18:58) .\,.\,Oh, and it can also appear as exactly the last part of the string, in which case it is interpreted as the specification!\,:) (19:00) .\,.\,Good.\,:) .\,.\,Oh, unless the syntax for specified titles should instead by `\#$n$\#$n$'.\,. .\,.\,That's probably better, isn't it?\,.\,. .\,.\,Yeah, let me say that.\,. (19:03)

(19:21) Oh, but what about entity references? Then they ought to be converted as well under a duplicate removal / specification.\,. .\,.\,And this could of course cause trouble in terms of the restricted string lengths and for concatenated strings.\,. .\,.\,(19:24) Oh, unless we just make an automatic redirect for the column of a discontinued entity. And such a ``redirect'' could even be made very seamlessly, since it could essentially just be a matter of searching which `specification tab' to open.\,:) (19:26) .\,.\,Phew, good.\,.\,:)

(31.03.24, 12:19) I think I will make it so that concatenated strings ought to end in `\#$n$', where $n$ is the ID of the first string.\,. .\,.\,Hm, at least for nested concatenations.\,. The idea is that the app can then fetch that immediately, and perhaps more importantly, when searching for strings, you don't get false hits of strings where there is supposed to be more to it (where the string doesn't refer to anything without its tail). .\,.\,Hm, and for single concatenations, it could then just end in `\#' (with the following $n$ being implicitly the same as the first). This then makes `\#' a special character always, like `@', bit that's also okay. Now, it would perhaps be nice, if we could find some way to chop concatenated strings up.\,. Oh wait, maybe compression on the Index table (i.e.\ StringIndexKeys) does help here, let me see.\,. (12:26) .\,.\,It does, since this table only has a PK. Of course, there is also the Strings table, but.\,. .\,.\,Hm, where it is the primary index that doesn't compress so well.\,. .\,.\,Yeah, but whatever. It's not a big problem. I'll just go ahead with this greedy algorithm for concatenation, i.e.\ where the heads (in each step) are always made as large as they can be. (12:33)

.\,.\,I was also going to mention that I think `\#$n$:$m$ is better for the specified titles, but now I'm thinking that maybe it would be nicer to just write out the appendix directly.\,. .\,.\,Hm, this is only a possibility due to that new idea of ending with.\,. Yeah, but that gets way too complicated when the appendices/specifications are concatenated themselves, so no, let me stick to `\#$n$:$m$' and only that for specified titles. This makes `:' a special character that needs escaping, but only if it comes directly after `\textasciicircum \#$n$', where `\textasciicircum' here is taken to denote the start of the string, not the symbol `\textasciicircum'. (12:40) .\,.\,And then `\#$n$\#$m$' as a full string will typically be referring to a concatenated string, starting with `\#$m$', and where the last string referred to by `\#$n$' couldn't fit the \#$m$' at the end of it, hence needing another nesting to complete it. (12:44)

.\,.\,(12:46) And let me also double down on thinking that it's totally fine, in the very early days of the network, to move users rates over from one entity to another, more specified entity without further ado, as long as we are not talking untyped/`something'-typed ratings, but are talking ratings where a specific type (such as e.g.\ `movie') is given. Then later on, we can be more careful to account for the fact that the network needs to function in a completely decentralized way, and where no party thus should take such liberties (anymore). Luckily, at that point, it will be easy enough to figure something else out, such as simply notifying the users and ask them to OK the transfer for example. (12:52) *[(14:04) Oh wait, we probably don't even need to transfer rates!\,.\,. It will not be so hard to simply tell a bot, when dealing with a certain specified entity to also look for similar rates for the unspecified entity, when the specification is the highest rated one.\,. Well.\,. Hm, it's harder when an entity is only \emph{further} specified.\,. So never mind, I guess.\,.]

.\,.\,Hm, that reminded me: I also need to think a bit more about untyped/`something'-typed lists (for instance property lists).\,. .\,.\,Oh, but the point, I guess, is just: never let the type determine what \emph{thing} we are talking about, only the \emph{function} of that thing in the context of the statements. For instance, `WWII' is always referring to \emph{the} war, and the type is not going to change that, but if we take e.g.\ `history subject' as the type, it then simply refers to \emph{the} war as a history subject. The type only qualifies the `as a' part, where the following type then does not change the \emph{thing} itself that we are talking about it, only in what context we are talking about it. More precisely, the types only specifies the tags/statements, not the thing itself. (13:00)

(13:42) Hm, maybe templates are still worth while to have (just as guidelines still, though).\,. But I'll see.\,.

(15:11) Hm, I'm reconsidering removing the `1's; it doesn't really seem worth it.\,. .\,.\,Since the ``null type'' is an actual type now (i.e.\ `something'), let us write the `1'.\,.

(19:00) Oh, I also need and end delimiter after the numbers of the head reference in the concatenated strings.\,.

(01.04.24, 13:18) About the end delimiter, let us just use a `.'.

I'm thinking of changing the system again. I think types are a bit too much trouble in comparison to what they achieve, so I think it might be better to just make some compound tags, maybe with a special syntax, and then just use those instead.\,.

.\,.\,I have also had some thought about postponing the types of the entity references for all custom, non-special types, but this might of course not be necessary at all, especially now that I might give types a lesser role.\,.

.\,.\,Hm, but it does kinda seem like the compound tag idea might be the way to go.\,. (13:24)

.\,.\,Hm, so in principle, all I'm changing now would/could just be that we introduce a syntax for making compound tags (i.e.\ tags that also tell the type of the instances), and then change SemanticInputs back, removing the ent\_type\_id column.\,. .\,.\,Hm.\,.

.\,.\,Hm, or maybe it makes sense to keep it like this, I' not sure.\,. (13:34)
.\,.\,But maybe typed references should just be for the special types, such as e.g.\ `user'/`u'.\,. (13:37) .\,.\,This might be a good idea, yes, and then an app column is also generally defined just by the entID; any additional type prop would just be auxiliary data.\,. (13:42) .\,.\,(13:42) The types would still be important for the system/network, but each entity will just have their relevant types queried for semantically.\,. .\,.\,(like I intended anyway.\,.)

.\,.\,Hm, I also considered using the SK for the non-special entity references, to make them more searchable.\,. .\,.\,(rather than using the ID *(so using the definition string instead).\,.) .\,.\,Hm, this would not work very well for specified entities, though.\,. (13:49) .\,.\,(13:55) No, there's no sense in that: If you are looking for a specific entity (a tag or some other kind), you are looking for that thing specifically. So no, I don't think I should use the SK for references.\,.

.\,.\,(14:02) Back to the question of compound tags vs.\ using the ent\_type\_id column, there is also the option of not using any special syntax for these compound tags, and then just.\,. .\,.\,Hm, maybe just use it for the aggregate (filtered) categories.\,. (14:04) .\,.\,Hm, or maybe the special syntax should just be `as a' or `as an', and if a tag includes this, followed by a reference/link (which are now untyped), then it is just automatically interpreted as a tag to be filtered by the various bots, meaning that they will only rate entities for that tag, if those entities are rates high enough as having the given type.\,. (14:13)
.\,.\,Hm, but it would be much more preferable with a single syntax for it, though.\,. .\,.\,A parenthesis could do the trick, but.\,. .\,.\,Hm, how about using `::'.\,. .\,.\,That could actually work quite well, where we then simply read `::' out loud as `as a/an'.\,. (14:22) .\,.\,`$<$entity$>$ fits $<$tag$>$ :: (as a/an) $<$type$>$'.\,. .\,.\,Hm, $\in$ could also be an option, but it probably won't save any bytes at all, and.\,. (14:26) .\,.\,(14:31) And it can also be read as `having the type,' which justifies the choice since it fits its meaning from Haskell.\,. .\,.\,(even though the syntax does not match that of Haskell at all for such tags, but that's okay.\,.)

.\,.\,(14:33) So `::' followed by a reference/link tells the bots to filter the given tag, and it also tells the application to suggest other types in the place of what comes after `::' to the user (and if there is no `::', the application can suggest types all the same).\,. (14:35)

.\,.\,For untyped references, which are now the only references possible for the non-special types, at least in the first version of the system/network/app as I imagine it now, I will let the syntax be like `@123.' instead of `@[123]'/`@1[123]'. For typed references, it will be like e.g.\ `@u123.' (we will stick to using only one symbol as long as we only have the special types for the typed references), where the type signifier is of course never a number (and never ends in one). (14:41)

.\,.\,Oh wait, going back to `::', we shouldn't even need to tell/program anything special to/for the bots, then.\,. So why not just let the users take care of defining tags that are semantically precise enough to also include the `as a' clause if necessary for the semantics?\,.\,. (14:45) \ldots (15:12) Never mind, it does make sense to tell/program the bots to filter these tags. And I actually also think I like using this special, brief syntax for `as a/an' clauses (and I think the users will find it useful as well). (15:13)

\ldots\ (18:16) I think I will embrace syntax like `::' even more, also letting property tags by constructed via syntax, especially. I'm thinking of using `-$>$' for property, and then perhaps also using `:' potentially after a property to denote that we are only interested in instances of the type coming after the `:'. This is much like `::', but not completely, since `::' also changes (specifies) the semantics of the tag, whereas `:' is purely there for practical reasons, namely to instruct the bots to filter the property tag.\,. (18:20) .\,.\,The first part of a property tag, before the `-$>$', should be a link/reference, but maybe the other parts shouldn't.\,. (18:21) .\,.\,Oh, and non-property type tags can also use the `:' syntax, namely if the type *(before the `:') is a subset of the type that comes after the `:'.\,. .\,.\,By the way, let me mention that that `::' syntax \emph{does} work a lot like in Haskell, namely if you thing of the tags as a kind of class (in programming terms).\,. (18:24) .\,.\,Oh, and I also might use `;' instead of `:', then, for the specified titles.\,.

.\,.\,Some of this can then be translated when rendered, if the user wants it, which might especially be a good idea in the beginning. However, the verbatim string should also be visible. When submitting entities, there should also be special forms to submit these kinds, where the user can then also see the verbatim string, and can also choose to write it verbatim. (18:31)

.\,.\,Let me also point out something else: `has good acting::movie' is not as good as `good acting::movie': Always try to make the tags as simple and easily searchable as possible. (18:33)

.\,.\,(18:41) Hm, I guess the other parts of the property tags should also be references/links as well.\,.
.\,.\,Hm, and then when you type in a property entity `verbatim,' it should actually \emph{not} be verbatim, not completely, as one should still be able to type in `@' and then continue to type in a link, where one chooses from some of the suggested entities, if any, and then when hitting enter, the link is inserted into the text field at/before the cursor position, replacing the `@' as well, seemingly.\,. (18:48)

(19:14) Oh, but I guess the superset type/supertype written after `:' should actually instead just be a semantic property of that tag. So if the users wants the bots to generally filter the instances of a tag by a certain (super-)type, they should just up-rate such a super-type/super-tag for that tag. .\,.\,Yeah.\,:) .\,.\,Hm, and what about the `as a' symbol, `::'? I guess this is different, since it also has another use, which is specifying the semantics of the tag. And then the bots might as well use it also, if that is helpful, why not?\,. (19:19)

(02.04.24, 12:47) I have slept poorly, but slept until late, so I got my sleep in the end. And in the middle of the night, I got the following good idea. I will give templates, or rather `formats,' a return, and then instead of using the `\{\}' syntax, I will let user write first a shortened format, followed (after a `$|$') by a longer, more specific version of the format. And (\emph{pause for effect}) I will use this to make (and allow users to make) the abbreviated syntax like the whole tag and property syntax I came up with yesterday.\,! (12:52) What a great idea.\,. .\,.\,Furthermore, for the formats, I will use a `\%$n$' syntax for the placeholders, and simple repeat these in both the abbreviated and the specific (parts of the) format. I will then recommend using language where the placeholders are always preceded by `the $<$type$>$', namely since this removes the problem of inflection. And for the form generated from a given template, I should then parse the first (function-identifier-valid) word before each placeholder, and put them as the label of the given field (in order of the placeholder numbers) in the submission form. (12:57)

In regards to my `::' syntax from yesterday, I think there should also generally be a `::' (`as a') clause before the `-$>$' in the property tag, such that the possessor has its type defined, i.e. (12:59) The order of the various part of such a syntax now does not matter too much, since the user will see the format above the form (be it a search (and/)or a submission form). For instance, it is okay that the property tags are written as e.g.\ `WWII::war-$>$end', even though the `war' part is postponed as the third placeholder input, such that you can search for the two others first (searching for `WWII' first, then `end'). (13:03)

I have by the way considering using `=$>$' rather than `fits' (in reverse, if you will). In that way `x =$>$ y' means that y is a quality of x, and `x -$>$ y' means that y is a property of x. (13:05)

And lastly, as I thought about in the bath this.\,. midday, when it comes to the specified titles---first of all, I will keep these, since I think that it is nice to be able to have this expandable subtitle. And in terms of dealing with duplicates, the users then simply up-rates a property tag `$<$entity$>$::$<$type$>$-$>$better duplicate,' first of all. The `$<$type$>$' part here is important, since you obviously don't want to move all votes/rates for the entity---for instance you don't want to move the rates for `$<$entity$>$::$<$type$>$-$>$better duplicate.' Now, when this tag has a high enough rating, and with enough users having voted. The app can indeed just notify all users who has rated $<$entity$>$ with tags where $<$entity$>$ (which could be `WWII' for example) was specified as a (`::') $<$type$>$ (e.g.\ `war'). And the notification can simply be `will you let you rates be automatically transferred to the `better duplicate' entity after the userbase has voted and decided (with enough margin, and enough votes) on which entity is the best replacement.' .\,.\,Oh, maybe the property tag should be.\,. hm, not a property tag, and be something like `needs specification/changing::$<$type$>$'.\,. Hm, but that's not completely right, since the semantics is understood with the entity being `as a' SDB entity, so what to do instead.\,.\,? .\,.\,Hm, could be simply: `needs specification/changing::SDB entity'.\,. .\,.\,Hm, and then the rate transfer should then simply concern all custom types at once, i.e.\ for all tags with an `::$<$type$>$' in them, where the type is not `SDB entity'.\,. .\,.\,Hm, that could work. So all in all, let us not be too worried about having underspecified entities in the early days of the SDB, nor about using consistent ways of specifying entities of various types, since this can all be mended without too much trouble later on.\,:) (13:23)

(14:09) I should also mention, references are ended by either `.', `@' (or `\#' for concatenated strings) or by the end of string. If a reference is succeeded by `@' (or `\#') or end-of-string, the dot should always be omitted. *(No.\,. (15:13))

(14:16) Hm, I'm now considering whether to just require that the syntax matches the `order of importance' as we might call it.\,. .\,.\,Or I could remap it in the specifying format.\,. .\,.\,(14:22) Or require that the syntax matches the order of importance.\,. .\,.\,Hm, I think so.\,. And then I will just use `$<$$>$' instead of `\%$n$'.\,. .\,.\,No, I'll use `\%e', where `e' stand for `entity.' (14:25) .\,.\,And the specifying format then gets to use `\%$n$' still, which makes to possible for it to explain it using a different order.

(14:40) Hm, but in regards to the `\%e::\%e-$>$\%e' syntax, maybe this order of importance (selecting the type before the property) is just as good as when selecting the property before the type.\,.

(15:12) Hm, maybe it's easier if references just always end in `.'. Yeah, I think it is.\,.
.\,.\,But maybe we can omit the `@' for format inputs.\,. .\,.\,Except that.\,. Oh no, the type is defined by the format, so yeah, we could do that. (15:15)

(16:03) Oh, I should probably use another delimiter for the formats rather than `$|$', since I'm using that for the capitalization--accent code as well.\,.
.\,.\,(16:06) Hm, but I could also go back to just using `$|$' as well for the subtitle/appendix/specification, and then there will just be two `$|$'s.\,. .\,.\,I think that might be better, and it also fits nicely with the format specification also being a specification, and one where it could also be nice if it were expandable. Yeah, so I think I'll do that.\,:) (16:09)

\ldots\ (18:32) I've had a couple of more good ideas. I'm not completely done thinking. But let me start by saying that I was considering using RegEx's for the search field where the app could continuously match the typed in query with the RegExp's, and if there is a match, it could make some relevant suggestions. In particular this could be used for the templates. Here the user might then type in a string that matches the rendered template string, and the app could then convert it and suggest going to a template column to finish the query there (or it could all happen in place). But I think that this idea is actually not necessary (and not useful enough to implement). Let me think some more about what else I have in mind, however.\,. (18:37)

\ldots Let me write something else first. I think we should use `::' (`as a') specifications only when necessary.\,:) So if you have a tag that you want to submit and rate for a certain entity, think about the other (up-rated) types of that entity, and think if it is necessary to specify the type among those, or if it can be understood implicitly without the specification, or if it has the same semantics anyway for all the types among these that the tag \emph{can} be understood implicitly in the context of. That was an ugly sentence, but I hope it makes sense. *(Oh, and the same goes for properties: Think if the type of the owner of the property has to be made implicit for the semantics to be clear, and otherwise just use the `\%e -$>$ \%e' format.)

And there's also always the `entity definition' type, which is a type that applies to all entities, and allow users to make meta statements about the entity, such as e.g.\ whether it has a better duplicate, etc. (This is similar to what I called the `null type' before.) Then if we go back to the question of dealing with duplicates, etc., the rates that are transferred automatically, if the user accepts it, should then simply be all tags where there is \emph{not} an explicit `:: entity definition' (`as an entity definition') declaration.\,:) (18:59) All other tags should have their instances of the relevant kind (if any) mapped to the relevant `better duplicates.'

.\,.\,(19:03) I have made a user--statement format of the (abbreviated) form `user who thinks \%e', but I think I will make it into a statement property instead: `$<$statement$>$ -$>$ user who thinks this is true.' For I think it is a good idea, as I've said before, I'm sure, to use the property construction as much as possible.\,. (19:06)

%This realization of not having to be strict at all about using types is really so important, I think.:) Just because types are often important for specifying the semaantics---in a very handy and easy way---doesn't mean that they are \emph{always} important to use.:) (19:10)

%(20:03) I have some more things to say, but also still some things to think about as well, and I was hit by tiredness, so maybe it'll first be tomorrow..

(22:33) Ah, we can just do something similar as with the duplicates: For property tags where the type isn't specified---or is/becomes underspecified---we can also just let it be up to some process involving user votes, which type should be chosen. In general, we shouldn't fear not being to strict about specifying the semantics of various things, as long as we think that other users will know in what way we meant, as such things can always be mended later on, when going from the early stages of the network to the more advanced stages. (22:37)
.\,.\,In a way, what's most important is that the early stages shows the way, so to speak, and leads to the following stages; it's not actually very important that we take great care in ensuring that the votes/rates from the early userbase it kept intact at all cost. (22:39)

(22:43) Maybe the order of the inputs in the formats won't matter very much\ldots

(23:06) Hm, wouldn't it make more sense to just make another SK for SemanticInputs rather than to use the statement\_user\_rater\_bot?\,.\,. .\,.\,That would also make the list include bots, but that's probably for the better overall, I think.\,.

(23:52) Maybe we can assume that most things have \emph{one} type that is naturally assumed (as the context in statements) without any further specification. And for this `main type' of an entity, we don't need the `as a' clause; for all others, we do.\,. (23:53) .\,.\,Yes, that's it.\,.\,:)

%(03.04.24, 12:26) Slept somewhat poorly. Went to bed very late and woke quite early. But snoozed and then lay wake for a long time, and then I had some good ideas about the tag syntaxes.

(03.04.24, 12:28) I've had some good ideas about the tag syntax. I will actually write it all of the property tag format using English words instead of special symbols. But I \emph{will} actually keep `::' for the general `fits $<$tag$>$ as a $<$type$>$' format. .\,.\,Hm, yeah, I think so.\,.(:)) (12:31) .\,.\,Sure.\,:) And the good thing is, it users can always expand and see what it means specifically, so they don't even have to memorize it. Now, for the property format, I think I will use `$<$property$>$ of $<$entity$>$ the $<$type$>$' instead.\,:) And again, the last part is only necessary to use if $<$type$>$ is anything other than the so-called main type of the entity, i.e.\ the one that is naturally assumed when speaking about it in most sentences. This so-called main type is then just a semantic property, specifically it is the type that is highest rates as the type property of the given entity---the entity definition. So let be more precise, for a given $<$entity$>$, the tag in question will be `type of $<$entity$>$ the entity definition'.\,. No wait, it seems that just using `type of $<$entity$>$' here would be fine.\,. no.\,. I should just call the meta type `entity' instead, rather than `entity definition'.\,:) (12:46)

I also had another idea% in the bath after getting up
, which is that when clicking on the text field of the search bar in the app, the first suggestions to immediately appear, before anything has been typed yet, should be the list of highest rated (as being useful) formats. The user can then select one (or make a search containing `\%e'-placeholders and then select one), whereafter they are lead to the template search(/submission) form field.

Now, there are many things we can do for the search field, including the mentioned thing about using RegEx matching, and so on. But I actually think that the first version of the app should just aim, apart from the thing mentioned in the previous paragraph, %..okay my typing speed right now really costs some time, actually.. :\
to search directly for the entity definitions. Then at some later point, it would be nice to also be able to type `@'---without a backslash first---and then do a sub-search essentially, where the search results while typing are temporarily exchanged for giving result searching just on what is typed after the `@'. When the link is then selected, it is inserted and the search continues for the whole string. This could be nice, but I will not implement it for the standard search bar in the first version of the app. The thing is, it will probably be much more common to use format for any such construction, by which the user should select that format first instead, anyway. And in regards to searching for e.g.\ properties and such, there are also the (good) options of doing what I call (and have been calling) a `semantic search' instead. (12:59)

For the template *(format) search/submission forms, however, there should also be search results shown while typing, and these should of course be for the individual text fields only. (And at least for the first version of the app, this should be enough). There is, however, the matter of searching directly on entity IDs, and of searching for.\,. oh no, searching for special types (like `user'/`u') is no further problem, 'cause this is always given by the format itself. .\,.\,And I guess when wanting to type in the ID instead of the entDef (the SK), we should just make it so that searches on straight numbers will give as the first suggestion, the entity with that number as the ID, before giving suggestions from searching on the given number as (the start of) an entity definition. (13:06)

So there we are.\,:) I also thought that maybe it would be a good idea to separate the bot and the user types, and then give SemanticInputs an extra tinyint to specify either `u' or `a' (for `aggregation bot', as to not be confused with `binary'), but then I recalled that aggregation bots don't have to be internal/native. They can be controlled by third parties as well, and simply appear as `users' in the system. (13:09)

About the statement\_user\_rater\_bot, I think.\,. Well, let me actually just think a bit more.\,. .\,.\,(13:12) Hm, I think I might indeed turn it into.\,. well, except that maybe one would want to have such sets but filtered in some way, perhaps by excluding dead user profiles (I think that might be a technical term for it, i.e.\ `dead,' but I'm not sure) for instance.\,. And it shouldn't really demand more space if we only use the statement\_user\_rater\_bot, should it?\,.\,. .\,.\,Hm, I'll keep the statement\_user\_rater\_bot for the reason given here (about the potential use of filtered lists of such users), so let us just keep in mind that we can also always just make another secondary index (another SK). (13:18)

And to round off, let me just repeat and underline how great it is to just have it like this where the users don't have to specify the type when it's the naturally assumed one, and where bots can just automatically make the aggregation categories.\,. oh, I feel like I had an idea last night in bed about this.\,. Let me think for a bit.\,. (13:20) \ldots (13:35) Hm, let me see, I think that such bots should look at the all the decently rated tags for any given type, taking all the types one at a time that is up-rated for filtering against. And then for each such type--tag pair, they should rate the `\%e :: \%e' version of that tag, where they first of all exclude all instances, that are not rated decently as being of the given type. And.\,. Hm.\,. .\,.\,And for each of the remaining entities, they first look at whether the `naturally assumed' type of that entity is the one in question. If it is, then the bot takes the rating directly from the tag.\,. Oh, but I \emph{am} missing something here, and I do feel like this is what the idea from last night was about.\,. .\,.\,Hm, if we for instance think of the types `film director' and `person,' then some entity might.\,. well the point is, the naturally assumed type might depend on the tag in question.\,.\,. (13:45) .\,.\,Okay this requires some thinking\ldots\ (13:46) %Luckily, I think I'm up for it; I don't feel tired at all (and actually haven't since I got those ideas in bed)... ..(13:50) Oh, I was about to write "..But isn't it trivial...", but it isn't. We uprate all the appropriate tags for a given type, but the problem is when a tag needs no type specification in most cases, but in some cases, they do. Hm, I might therefore just suggest that the users always specify the type, just in case, but I'm not sure... (13:52)
.\,.\,(13:54) Ooh, maybe we should think more about the `naturally assumed' type given a tag with no context of the entity, rather than the naturally assumed type of a given entity in the context of a tag.\,. Hm, and I guess this essentially leads to `always specify the type,' don't it.\,.\,? (13:57) \ldots (14:12) I guess the key might just be to always define the tags fully, using the (expandable) subtitle/appendix, preferably.\,.

\ldots\ (15:04) Okay, I have it now, finally. First of all, the `::' tags should not be meant for users to rate---and preferably not even to look for themselves---but should be meant for the bots to use only. So we should actually remove the specification from that format; no sense in specifying something that users in general are not really meant to use. When a user has `filter by $<$type$>$' for their ListGenerator search, the app can then see if it is possible to utilize such `$<$tag$>$ :: $<$type$>$' tags, where $<$tag$>$ is a relevant one for the given search. And instead of the bots just automatically creating these filtered lists for all relevant tags of a given type, the users instead up-rate exactly the relevant tags for a given type, where the tag can be used in a much wider sense as well. For instance, their is not much sense in filtering `action movies' by `movies' (since this can only ever reduce a little bit of spam, which shouldn't actually be a problem, since the userbase needs to actively down-rate spam (and down-rate the spammers)), but it makes sense to filter e.g.\ `entertaining' or `good' by `movies.' So that's how to do that.\,!\,:) And what's more, as I wrote at the end of the last paragraph, just before my walk here, the key \emph{is} to just to make a specification appendix/subtitle to all tags that isn't clearly understood on its own for the most part, but where said specification might often enough be helpful. And in general, one can probably say that it is good to specify most of the tags that are either abbreviated verbs or adjectives, more so than those that are just type nouns, essentially, such as `action movie.' .\,.\,So as a rule of thumb, specify all tags that either starts with `is' (with no `a'/`an' afterwords) or `has', or more likely, can have `is' (with no `a'/`an' afterwords) or `has' inserted before it. .\,.\,Well, that could be a rule of thumb, but I guess in general, just follow what seems natural: `which things can enough be helpful to have been specified, and which things really don't need it?' *(A better formulation of the rule of thumb, perhaps: `if you can put `is a(n)' in front of the tag without changing the meaning, then you may not need to specify, but otherwise it might very well be a good idea (I think.\,.).\,. (16:05))
As for properties, I will \emph{not} use the `$<$property$>$ of $<$entity$>$ the $<$type$>$' format, but only just the `$<$property$>$ of $<$entity$>$' format. And if this such be specified further, the users can specify the `property' entity here. Hm, and how to do that, actually.\,.\,? (15:24) .\,.\,Hm, by beginning the specification with `the property $<$property$>$\ldots'. For instance `movies directed$|$the property.\,.'.\,. Hm, or maybe it could by like `movies directed$|$as a film director'.\,. Hm.\,. .\,.\,Yeah, I guess that's fine, and I guess it's fine in general to just let it be up to the context of whether the specification is interpreted as a standalone sentence/lexical item, or if it is interpreted, like here, as continuing where the title left off. (15:32) .\,.\,One could.\,. Ah: If there's an ambiguity, one could.\,. use a capital letter, but maybe one might just want to rewrite the thing instead. Okay. moving on. Back to the properties: Sure, it is a good idea to specify the semantics of otherwise somewhat ambiguous properties, but it actually won't matter very much if users don't specify their properties. The point is, they are first of all rarely used for filtering/sorting EntLists (entity lists), and if they are, the user can just find the right property for the given thing that they are interested in. In terms of up-rating properties for what's essentially the `information page' of an entity column, sure, it might in principle happen that some entity has a property shown whose ranking was rated on the basis of different semantics than those it naturally has for the specific entity in question (of the column) (long sentence, but it should make sense), but what does that really matter?\,. Not much at all. So yes, it might be a good practice to specify properties, but it's not really needed, and one has to also weigh in the fact that using simply entities also has some benefits, since its more intuitive to look for the simple entities, rather than looking through the recommended specific ones.\,. (15:41) :)

So there we are!\,:)

I also have some other things that I need to mention. I talked about making the `users who thinks $<$statement$>$' into a property (and have done this), but I actually now think that `users who thinks $<$statement$>$' is a better choice. Hm, wasn't there more I needed to say?\,.\,. .\,.\,Oh well, I'll think of it if there was.\,:)

Ah, I really think that I'm landing/have landed now on something good.\,:) It's always such a long creative process when I need to make big changes like this, and of course, I might not be done yet: It so often feels like I'm done, and then they same day or the next, I realize that some other big changes (further ones and/or changes back to something previous) are needed. But it really does seem like I'm about to land / have landed on something good now.\,.\,:) (15:48)

.\,.\,Oh, I could mention that I think that when the users type in `$|$' in the search field, it might make them jump to the specification. This could be true both in the early and the later versions of the app. And in the early version, this will simply implemented by \emph{not} scaping the `$|$' character automatically---unless the user has chosen the verbatim option, which is handy e.g.\ for searching on URLs. (Note that the concatenated string syntax is always under the hood, however, so ``verbatim'' really means `verbatim, except for concatenated string syntax.') (15:59)

(16:40) Hm, I'm actually just gonna let the specification always be a continuation, and then you can just make a period or a colon, etc., if you want to begin a new sentence, e.g. This means that I will also make it so that spaces are written explicitly, meaning that many specifications will begin by a whitespace.

(17:05) And remember: It's (much) easier to go from an intuitive system over to a more efficient one, based on the first, rather than the other way around.\,:) So with that in mind, don't worry too much about efficiency of the early version.\,:) (Talking to myself.) Not that I \emph{think} that I will change the system---I actually don't---but it's still a comforting thing to remind oneself of.

(18:28) Hm, it almost seems that the entity references won't be necessary, and maybe not used much. But I'm not sure if I dare remove them.\,. .\,.\,(18:30) Hm, that would maybe be in order to actually prevent users from using them, forcing them to use the templates instead, which is probably best. For instance, it might be tempting to define a relational tag on one's own by writing it intuitively, but it might be much better to reformulate it as a property-of-entity tag, and thus use the property template (format) instead.\,. (18:33) .\,.\,And I can always add it later on.\,. at least if I still keep `@' as a special character for the whole string, not just the beginning of it (where it can represent the beginning of a format closure).\,. So I'll basically keep room for these inline entity references, but having them as `not implemented yet,' essentially, except without a clear promise that they will be implemented.\,. Hm, on the other hand, it would be nice only having to escape special characters at the beginning of a string, wouldn't it?.\,. Hm, but maybe not enough that I want to throw away the possibility to implement and include inline entity references (links).\,. (18:37) .\,.\,Oh, and `$|$' is also a special character throughout anyway.\,.

(19:03) I have until now forgotten about formats over entities with specifications, but I guess we can just escape `$|$' (once) in the format.\,. Wait, does this even make sense; the specification will just be exactly that of the template, after the placeholders have been substituted (but the cap.--accent code it interpreted before said substitution).\,. Hm.\,. .\,.\,Yeah, that's it, so I have already implemented formats where the specification is part of the format; it always is. (19:07)

.\,.\,(19:08) Let me repeat: I'm very happy with all these new changes (as a whole). It's for instance so nice that e.g.\ `movie' as both a `type' and a `tag' (formerly known as a `category') can share the same `subcategories' tab.\,:) And there's so many other nice things about these changes.\,:)

(22.17) The ability to specify properties is actually so important. It means that we can for example make properties like `early life$|$\ldots' etc., where the dots here then specifies that to property instances are of the type `article section'.\,!\,:)

%(23:31) Hm, one will probably not be able to log in / be logged in with the browser extension, while on other sites, as this poses a security risk, it seems. But I guess since everyone can query as a given user, we only need it for rating and submtting things. And for that, there can just be a link to the website itself.. Hm, although if I made a browser extension like feature on the website, where the user browses the web in an iframe.. Hm, let me see about something.. ..Hm, I don't think I can get the address bar in the iframe, but this maybe doesn't matter too much.. well, it matters some.. (23:38) ..Oh wait, no, we're free to just change the top url to anything we like, right.. Right?.. ..Oh, of course not, as a StackOverflow answer points out.. (23:41) ..Hm, but my site could just redirect to the page with the given URL if it receives the relevant reformatted version of the URL (with my domain in front). So this could all work; you could in principle make a browser extension via a website, I think. But do I want to?.. Hm, maybe.. (23:43) ..And there could also be a button to copy the real URL (of the iframe site) to clipboard.. (23:45) ..Ah, but not being able to use the address bar or one's bookmarks, and in general having to always go via my site.. Well, one could of course change one's bookmarks, but no. This is way to complicated, enough that it defeats the purpose of the browser extension, rather than just navigating to my site when you want to see data aboout a specific URL. (23:48) ..Oh wait, I forgot I could just use an iframe for the browser extension for loading a window from my domain, where the user can then be logged in. This was also my plan to begin with. So never mind all this: it could be possible to make a browser extension where the user can be logged in. (23:51)

(04.04.24, 14:13) Hm, since the specification part of a format is meant to be come the specification of the.\,. Oh, I'll stop myself there, 'cause there is actually just one answer. Yeas, the formats should only appear as the whole entity string (which means that I can and should get rid of the trailing dot for sure), and if you want to substitute it in the middle of a string, will then you just substitute the format instance entity that has the format closure as its whole definition.\,:) .\,.\,Hm, since templates will be the most common use of `@' references, and also to balance things out, wouldn't it be much better to use `@123' instead of `@f123' for templates, and then use `@e123' for entity references. I think so. (14:21) .\,.\,Hm, and this also means that `template' is just as good a name as `format string,' if not better.\,. .\,.\,Yeah, let me go with `template' instead, like I used to. (14:30)

\ldots\ (17:17) I quick note: When users submit any entity, they should immediately get the options to selects its main types and then up-rate both that the entity fits the tag and that the tag first the `type of $<$entity$>$' property tag.

Now, more importantly, I actually have to rethink the concatenated strings, and I've landed on the following, I think: There shouldn't have to be any support in the backend layer for searching for longer strings than of length 255. Not apart from being able to search for hits for strings that matches on the 255 bytes, and then maybe to let the application check the first couple of hits to see if the tail of the hit matches the tail of the query. .\,.\,Oh, but this obviously does not include the backend layer, so never mind. .\,.\,Hm, more to the point, I think I will implement longer strings for entities by simply letting an entity hold both a string a nullable text id, where the string is the first up to 255 bytes of the full text, and the text is, not the remaining text, but the full text itself, meaning that it starts by repeating the string. .\,.\,So there we are.\,. (17:28) .\,.\,(Note that this means that the entity's SK can be obtaining from knowing the textID and the text itself, the latter of which can be obtained from knowing the textID alone.\,.) .\,.\,Oh, but the text should simply be null if it is smaller than 255 bytes, and therefore contained fully in the string.\,. .\,.\,Hm, but I could also implement this in the app.\ layer alone, namely by using a trailing `\#$n$', where $n$ is the textID.\,. .\,.\,Hm, and if we instead let $n$ be a regular entity ID, then we are back to getting the opportunity to implement completely searchable entity strings, if we want to.\,. (17:35) .\,.\,Well, not \emph{completely} searchable, actually; only in the sense that each substring can be searched for.\,. .\,.\,Unless we implement it as a doubly linked list (with both leading and trailing `\#$n$'s).\,. (17:40) .\,.\,Hm, so should I just do that, and thus keep concatenated string up in the application layer (not counting initial\_inserts.sql, of course)?\,.\,. .\,.\,Hm, there is also the option of doing both things, I guess.\,. .\,.\,Oh, and if I choose to still implement it via syntax, I might also let the backend interface provide one query procedure for the purpose of getting all the parts of the concatenated string immediately, or rather up to some maximal number ($\sim$10--20).\,.
.\,.\,Hm, using syntax would actually be more efficient for the most part, at least if I stick to wanting the text to repeat the string.\,. (17:49) .\,.\,Oh, and if I use texts, I can't prevent identical entity duplicates, which is something I think is really important (only semantic duplicates are allowed (where their defs are different but their meaning the same)). So that settles it: I'll use this systax for concatenation, where I make it a doubly linked list, and where you are supposed to reference the head, not any parts of its tail. And let me actually set aside a fixed number of bytes to each `\#$n$' link, such that the maximal number of bytes that any string in the list can contain is fixed, and never depends on any of the $n$'s. (17:55) .\,.\,Hm, and this means that the tail end does not need an end delimiter, and the head does not need a start delimiter. Instead I should just make `\#' a special character always, I guess.\,. .\,.\,Sure. (17:58) .\,.\,Hm, with BIGINTs, I lose 21 bytes this way for the head and the tail end, and 42 bytes for all the middle parts, which is fair enough, I think.\,. .\,.\,No, 22 and 44, since I.\,. No, I need only and end delimiter for the leading link, so I could get away with 22, 43, 43, \ldots, 43, 21 *(no, the other way around), but is it perhaps better to round up?\,.\,. (18:04) .\,.\,Hm, I'm not gonna use hexadecimals, I think, since MySQL does not support conversions at all(!) as well as it thinks it does.\,. .\,.\,And it doesn't matter enough that we should worry about it. I don't know why, but I think I'll round up to 22, 44, \ldots, 44, 22.\,. (18:08) .\,.\,No, 22, 43, \ldots, 43, 22.\,. .\,.\,Oh, maybe I should pad the.\,. hm, no.\,. .\,.\,(18:17) Oh, because I round up the first 21 to 22, it actually means that one can also (perhaps later) implement concatenated strings using a text as the entire tail, namely by using (e.g.) a `\#t$n$' syntax instead. And this will work since `\#' is a special character that always needs escaping if it is not part of a (concatenation) code. (18:20) .\,.\,By the way, note that while the concatenated strings are implemented in the application layer, this implementation should still be almost completely hidden from the users: They should just essentially see the entities as having a higher limit than just 255 bytes, as if the backend simply supported that directly. (18:24) .\,.\,(18:25) Oh, wait, how can we implement linked lists when we don't control what IDs the submitted entities will get!?.\,. .\,.\,Hm, we can't.\,. .\,.\,Hm, so maybe I'll either need to use texts as the full tail, or the full text, repeating the head as well, or I should let the backend support inputting/submitting concatenated strings.\,. (18:29)
.\,.\,What to do.\,.\,? \ldots (18:47) Oh, the doubly linked lists actually doesn't help to make it more searchable.\,. Hm.\,. .\,.\,Hm, I guess it would work to use the idea I was gonna implement before I had the ideas of this paragraph.\,. Hm, why was it again that that way of doing it would not work.\,.\,? .\,.\,Yeah, why??.\,. (18:52) .\,.\,Oh, it works only when you know (almost) the whole string; if you only know e.g.\ the first part *(less than the 255 bytes.\,.), then you can't use that to search for the rest, that's why.\,. (18:55) .\,.\,Wait, that's not true, is it.\,. .\,.\,Oh, you could let the head and all other parts that is not the tail end end with `\#', without a number behind it, thus telling the application to look further for the search results. (18:58) .\,.\,Yes, and this actually makes the concatenated strings `completely searchable', i.e.\ basically as good as if the backend (entity SK) index allowed for any number of bytes.\,:) .\,.\,Yeah, essentially.\,:) (19:01)
.\,.\,Hm, and since the concatenated string you would want to render are always the tail ends, which begins with `\#', I'm now back to having that `\#' need only be special when it is the first character.\,. (19:05) \ldots\ (20:25) Oh no, it should always be a special character.

(05.04.24, 9:57) I should allow for using entity references as the type ``declarations'' of templates. In particular, I might use this to specify `property' further in the property (`$x$ of $y$') template, namely by writing `@e41'---well, I guess I should insert `property' earlier---instead of `property.' And then I will specify `property' further. This seems like an actual good use of `@e$n$' references (outside of template inputs).

I think my expandable EntityTitles could work, especially if there's a linkLevel prop/ state that decides what recursion level gets links. And then linkLevel could change when you toggle the expandable titles. But let me just implement it at first like I did before, where you simply have to click the link and go to the column to see the full title, and where the ``linkLevel'' is then 2. (10:06) *[(11:33) Or maybe I will implement it, and just make all links toggleable, only.\,.]

By the way, when implementing different languages, unless a translation algorithm can simply be used, it would probably be best to just try to relate each entity to a translated version, and then let the app automatically look up and replace the title of the entity, but make it so that users are still rating the original, English entities. In terms of translating the property (`$x$ of $y$') template, if I haven't mentioned it before (I might have), if the `$x$ of $y$' construction is not so easy in that language, maybe even if this is simply do to (possessive) inflection, I would recommend using a special `$x$ $<$- $y$' syntax instead, and just get used to that. (10:13)

(10:36) Oh, what about compound words for the template types; I probably can't just parse the word in front via whitespaces.\,.\,? .\,.\,Hm, how about using underscores instead?\,.\,. Oh, or one could also just use entity references.\,. (10:39) .\,.\,Oh, or I could just parse from the end of `the '.\,:) (10:40) .\,.\,Yes, let me just do that.\,.

(19:17) I should also mention: Note that tags can also break out of the standard semantics for what the rating scale means, and importantly, they can specify it more precisely. For instance, a `durable' tag might define (via the specification) how the rating should roughly translate to a time (e.g.\ `this item is durable for roughly three years,' where three here is then deduced from the rating).

(19:25) In regards to my whole `UPA idea,' why don't I just start by making a category of user submitted code suggestions, both for CSS and JS/React. These can then be explained in real text and shown haw to implement via code snippets. So if a can just find a code snippet React component online (like listings in LaTeX), and prepare the whole code suggestion format, then we can already get a taste of the overall idea, even though we it won't exactly be a UPA yet with just this. .\,.\,:)

(21:23) Hm, maybe the `as a' clause \emph{is} actually quite important, since in a way, all ratings are relative, and therefore it's best to always be able to compare to others when you rate.\,. So maybe I should focus more on trying to make it so that entities can be rated while viewed in a list, moving them up and down (I probably won't implement dragging entities, but maybe just make it so that one can copy--paste, kinda, or at least make it so that the list is updated immediately after---perhaps even before submitting a rate).\,. Hm, some food for thought.\,. (21:27) .\,.\,Yeah, good thing I (re-)realized this: It is quite important for the system to work well for the users to be able to rate entities on a list. And these list should in general be carefully selected for each *(predicate) tag where the spectrum is important (unlike e.g.\ most property or type tags), which is why the `as a' clause might be quite important after all (and filtering by bots less so, by the way.\,.).\,. (21:32) .\,.\,Oh, it could be nice if, especially for larger lists, we could pick out some good examples for the whole spectrum of the list, preferably prioritizing the most famous examples, and then show a given selected entity on this list, together with these example ones.\,.\,!\,.\,. (21:35) .\,.\,And by `we,' I mean the user community. .\,.\,Hm, this would mean creating a tag property of `part of a representative selection of some of the more well-known instances of this tag'.\,. (21:37) .\,.\,Perhaps with just `representative instance' as the short title of this property.\,. .\,.\,(Although I will probably try to avoid using the term `instance,' since I probably have special connotations for that word.) .\,.\,(And it doesn't fit for `tags' as well as for `categories'.\,.) .\,.\,Hm, and then the best thing would be to have bots copy the ratings of these representatives over to a.\,. Well, or just to have a bot that only rates representatives---hey, that'll actually be pretty easy after all.\,. (21:43) .\,.\,And then I just need for a ListCombiner (ListGenerator) to combine this list with one or a few selected entities, which also shouldn't be much trouble. .\,.\,Great.\,. (21:46) .\,.\,Oh, or even better---at least at some point---we'll just get a bot to make the representative list automatically, simply by selecting from as much of the spectrum as possible and also prioritizing entities which are rates highly as being `well-known'.\,. Yeah, good possibilities. And in the beginning, why not just make a bot that selects at random from the whole spectrum, and then we can always upgrade the same bot later to prioritize `well-known'/famous' entities.\,:) (21:50) .\,.\,That's actually great.\,.\,:) .\,.\,really great.\,. (21:53)

(06.04.24, 11:36) Okay, I'm not going to make the `as a' clause special. But we should just in general be careful not to use too wide-ranging tags. For instance, `funny$|$ as a movie' is generally better to use for a movie than `funny$|$ as a piece of media.' I will by the way divide the `Ratings' tab into types, such that the tab includes several EntityLists under/above one another, one for each of the most relevant types to the entity (if there is more than one (that exceeds the rating threshold)). (11:40)

(11:48) I think I will also make it possible for template specifications to introduce new placeholders, not just use the ones from the (short) title. I also have to consider the fact, that I should probably make `\%' a special character as well.\,. Oh no, maybe just.\,. hm, make `\%' followed by a number disallowed in specifications, as it will be replaced.\,. Hm.\,. .\,.\,Let's just make it a special character throughout, why not?\,.\,. .\,.\,And I should by the way also make sure to prevent single backslashes that does not escape a special character. (11:54)
\ldots (12:43) Ah, the ``excuse'' for making `\%' a special char could actually be that it is not actually rewritten as the EntityTitle of the entity that it refers to, but it is simply rendered as itself, only as a link (to the same entity as the link before it that it references). .\,.\,Hm, but shouldn't I use `@$n$' instead for this syntax. It doesn't clash with the template syntax, as they never make sense to have at the beginning of a def. (12:49) .\,.\,Okay, I'll do that, and I might then make `\%' only a special character in the context of templates, where it is then escaped, not by `\textbackslash', but by writing a double `\%\%' instead. (12:52)

%... (15:49) Havde en skøn løbetur. Og fik en ny idé:
\ldots\ (15:49) I had a good idea: I should also make a template for constructing tag types, and then we should also up-rate types for tags---and tags for types. In other words, tags should have semantically defined types, as I like to call it. Then bots can for each popular enough type take all the `relevant' enough tags for that type, make.\,. Hm, wait.\,. .\,.\,Oh, so maybe we don't really need this so much, since the `relevant tags (for this type)' property can just be understood to mean that these tags are also relevant to have bots filter by said type. .\,.\,Yeah, so we only need the `relevant tags' property, not necessarily the reversal, which is to have tag types.\,. (16:03)

(16:35) Hm, maybe I just want to repeat the EntityTitles for the `\%$n$'-back-references.\,.

(17:34) Hm, I just had the thought that maybe I could also make an input procedure for submitting/inputting template instances, and then I could go back to saying the templates are exploded/converted/filled out before being saved (but where it's still easy to insert template instances already in the backend layer).\,. .\,.\,Of course, it cost a bit extra space (but the space that Entities table requires is not really at an order where it matters much), but apart from that little thing, what would be the downside of doing this? And on the plus side, at makes these instances more searchable.\,. (17:39) .\,.\,At least it makes it a bit more searchable, although you still have to make a sub-search for each reference---well, unless I then go back to allowing for.\,. inserting strings (not references) directly into the template, but wait, I just had an idea, also: What about making the reference/links a trailing code instead, such that you control the title of the input entity and give it a reference underneath, so to speak, similarly to how links are made in HTML and in markdown, but where the link code is instead postponed as a trailing code.\,.\,!\,.\,.(?) And when you submit via a template, you can then either insert a non-link string, or a string with links in it, which are then moved back to the end of the entity def when this finally constructed.\,. (17:45) .\,.\,And again, we shouldn't worry about the extra space that the Entities will then require, and we also certainly shouldn't care about exceeding 255 bytes, since this method will prevent more subsequent queries (querying for references and template inputs) than it will cause (querying for the tail of the concatenated string).\,. (17:49) .\,.\,Oh, and I should make a query procedure for querying many substrings of a concatenated string at once, anyway.\,.

.\,.\,Hm, it seems that trailing link code and templates that are expanded/filled-in upon submission straight away in the backend, before being finally stored as Entities, would indeed be a good idea.\,.

%(17:55) Det var en god løbetur, og lang: 10 km (bare i roligt tempo)! Men har så ikke haft så meget energi her efter den, så jeg er virkeligt glad for, at jeg så endte med at få de her idéer i stedet (når nu jeg ikke får kodet rigtigt).:) ..Og ja, tilsyneladende nogle virkeligt vigtige idéer..!

.\,.\,Hm, maybe I should make the template insert procedure in PHP, rather than in SQL, though?\,.\,. (17:59) .\,.\,Nah, 'cause it's best if I can run it in the initial\_inserts program(s).\,. .\,.\,Hm, but maybe I should just copy--paste instead for making ``template instances,'' and then I can implement the template instance maker in JS instead.\,.

(18:20) Let me use the same kind of technique as for the cap.\ code to define where a link starts and ends. .\,.\,But where the symbol is then any UTF-8 symbol, not just (lowercase) letters. .\,.\,Oh, and by the way, I should make check for no non-lowercase letter in the PHP program.\,. Oh, I wonder how MySQL treats non-english letters like e.g.\ Æ, Ø, and Å. I should look into that (and make sure to choose the right character set/collation).\,. *(Oh right, I use the utf8mb4\_bin, so it should just treat all different characters as such.\,. .\,.\,Oh, but that means that I have to know all letter characters, if I want to make it searchable in other languages.\,.\,:\textbackslash.\,. (18:51) .\,.\,Ah, PHP has mb\_strtolower to the rescue.\,.\,:) (18:53) \ldots (19:35) Oh, and even better, MySQL has LOWER().)

.\,.\,Oh, if we include all symbol, then I can't use the numbers.\,. Oh, I can, if I just always write always write.\,. No.\,. But I can think of something else.\,. .\,.\,Oh, for instance, I could give the numbers an end delimiter (and since it is only one symbol always, we don't need a start delimiter (and it wouldn't work if we did)). So that's a possibility.\,. .\,.\,Yeah, so we could have e.g.\ a syntax like `hello world!!!$|$w.!2.123.' which would give us a link *(to entity 123, but I guess we should also have a type identifier first (like `e' or `u'), actually.\,.) located on `world!!!'.\,. Oh, but then I need to only treat the special characters.\,. as special characters before the second `$|$', but no, I can't do that either, since I need `$|$'.\,. Well, no, not necessarily. But I guess it's better to just convert from e.g.\ `\textbackslash$|$' to `$|$' before the link code is interpreted.\,. (18:37) .\,.\,Right, which means that both the link code and the cap.\ code \emph{can} actually use the special characters, namely if we just un-escape them before interpreting these codes. (18:39) .\,.\,(And if there are escaped before submission, i.e.)
.\,.\,`hello world!!!$|$e123.h.o.e124.w.!2.'.\,. (18:43) .\,.\,Let's separate the links with `;' rather than `.' to make it more clear: `hello world!!!$|$e123.h.o;e124.w.!2;'.\,. \ldots (where I have omitted the specification, including the extra `$|$' needed, as well as the cap.\ code if we decide to let that come before.\,.) (19:00)

(19:25) Hm, I might just use numbers for specifying positions instead for the links.\,. .\,.\,Something like `hello world!!!$|$e123.0.4;e124.6.13;', for instance.\,.

(19:29) Oh, I by the way also had the idea to use `anything' once again, rather than `entities' (or `something') as the everything type. For `anything' can be interpreted exactly the same as `something'.\,.

(19:48) Hm, would it make sense to drop---or delay implementing---templates, and then just let users do the copy pasting. And then I.\,. ``just'' have to make the thing where you can insert links by typing `@' (with out a backslash in front), and then start typing the title of the entity to insert, where the search results then temporarily is about the link that you are currently typing in.\,.\,? .\,.\,Hm, and this feature can then be used both for searching and for submitting.\,. (19:53) .\,.\,(And when it comes to searching, you then just don't \emph{have} to use this feature to search for entities with a link inserted, as you can also just start typing in the (short) title of that entity directly, without typing in the `@' first. .\,.\,i.e.\ now that I'll use trailing codes for making the links.) .\,.\,Hm, but even though you type in `@', this character is not actually used for it, then, which means that it doesn't have to be a special character anymore.\,. (19:59)

.\,.\,I think this is what I'll do.\,. (20:00)

(22:22) The nice thing about not using templates, in particular for properties, is that each property tag can then be given a specification that is tailored specifically to the property tag, and not just be given an instance of the property template's specification, which only defines the property tags' syntax broadly.\,.\,:)

(00:53) I could also use the `@'s, but just postpone the rest of the links to the trailing code (so that the trailing code would be e.g.\ `e123e124u123').\,.

(07.04.24, 11:24) I can make a kinda intermediate language for the app where we use `@', but no, in the database we should rather use the syntax like `e123.0.4;e124.6.13;', although I actually just had the thought of just using a syntax like `e123e124' instead, and then I could say that the link is just located the first place where the short title is repeated.\,. Well, or I could even also make skip codes to be absolutely precise.\,. Sure.\,. So this way, I'll then \emph{not} allow links that where the rendered text content of the link differs from the short title of the entity referenced, just like I had it before. And then I could maybe just make sure that the syntax is open for future modification (backward compatible) such that the links does get the ability to have a different text than the short title of the entity exactly.\,. (11:29) .\,.\,And that's actually trivial since the `e123e124\ldots' syntax is already open thus, as it expects one of the special type letters as the first symbol. So if you want to break out, just use a different symbol as the first character of the code. (11:32) .\,.\,And for the rare skipping of the first few matches of the short title (which might happen if the short title for instance is just a single letter or two long), just append a dot and another number after `e$n$', writing `e$n$.$m$' instead (but where the last part is optional), where $m$ is of course the number of occurrences to skip, just like for the cap.\ code. (11:35)

(11:36) And about templates, I do need them still, since how else are we going to uprate `relevant properties,' for instance?\,. .\,.\,But we could perhaps uprate single-input templates rather than properties.\,. \ldots I think I like this idea.\,. The alternative is to have properties that specify themselves as properties, but that doesn't seem as good.\,. (11:50) .\,.\,So property entities will now actually be a class of template entities.\,.

(12:01) Hm, maybe I should turn the first `$|$' into a trailing code as well instead.\,. .\,.\,Sure.\,. .\,.\,And let me just use the symbol-followed-by-skip-number syntax for this as well, as this is more compressed, and can be done by eye, which I find nice as well.\,. (12:04) .\,.\,Hm, and since the spec will often start with some punctuation, let's say that the chosen position is just before the given symbol.\,.

(12:10) Ooh, the fact the properties are now templates (as I think I've landed on) also means that we are no longer completely tied to `of' as the proposition.\,. although it will probably still be best with a convention of using `$<$property$>$ of $<$entity$>$' as the short titles of properties as much as possible.\,. (12:12)

.\,.\,(12:15) Hm, let me put the specification delimiter code last, preceded by the cap.\ code, preceded by the link code, preceded by the full title. This then fits the order of when the changes of these codes should be applied, from right to left, i.e.\,. .\,.\,Oh, that's not true, the link insertions should be done before the cap.\ code, now that.\,. they are written as text within the full title.\,. Hm, but what about when the short titles have capital letters in them.\,. oh, maybe I \emph{should} then let the capitalization be carried out before the link insertion, and require that the capitalization matches the capitalized (and accented, by the way) short title of the referenced entity.\,!\,.\,. (12:23) .\,.\,Of course, this could also be an opportunity to finally let the referee dictate the capitalization of the referenced entity.\,. (12:25) Hm.\,. .\,.\,Hm, and I should also still keep in mind that if I go back to using positions by links, this will make the referee be able to control inflection as well.\,. .\,.\,(finally.\,.) (12:28) .\,.\,Hm, but it doesn't work very well in regards to the properties being templates and all, which is important.\,. (12:29) .\,.\,No, let me stick to only implementing only these `e123e124\ldots' kinds of link insertions for the first version of the app, and let me indeed just say that the capitalization has to match as well.\,. (12:33) .\,.\,Or should it.\,.\,? (12:34) .\,.\,Yeah, actually, let me say that it should.\,. .\,.\,Hm, so yeah, let that be the order of the trailing codes.\,. .\,.\,the full title, the link code, the cap.\ code, and the spec.\ delimiter code last.\,. (12:38) .\,.\,Hm, or maybe I will reverse the order, such that are instead just carried out left to right.\,. (12:42) .\,.\,Yeah, that's nicer.\,. .\,.\,Oh, there will also often be a whitespace at the start of the spec.\,. Oh well, I guess that's also fine.\,. (12:44)

(12:54) Yeah, and I should also make an IL, so to speak, of these entity defs, which is easier to use for editing new entities, where the specification delimiter is a symbol/code inserted at its place, where links are also inserted at there place (e.g.\ using a `@$n$.' syntax), and where the capitalization is WYSIWYG.\,.

(13:00) Ooh, I just realized, having the full titles written out also opens up for FULLTEXT searches.\,!\,.\,. Of course, it won't work \emph{as} well for long titles that needs to be divided up and saved as a concatenated string, but thats fine: If you have some important buzzwords, they should come before the 255 bytes mark anyway, shouldn't they?\,.\,;)\,:)

\ldots\ (15:05) For the templates, I should use a delimiter, `$|$', for denoting where the specification starts, like how I did before (for the actual, stored entity def). I will also use the `\%e'--`\%u' syntax for template placeholders, and then use a `\%[$label$]' syntax for regular entity inputs that are then not labeled just as `entity $n$', but as $label$. In terms of the back-referencing placeholders, I don't think I will implement these for the first version of the app, when if they are ever implemented, they can use a `\%$n$' syntax, where $n\in\{1,\ldots, 9\}$, and potentially use a `\%[$n$]' syntax for larger $n$.\,. Hm, but that means that I would ought to disallow number labels for the first version of the app as well.\,. .\,.\,Yeah, nah, even \emph{if} we ever implement these, we will surely never need more than 9. (And if we ever do, we can just find another syntax that works.\,. ah, for instance simply by using another kind of brackets instead of the square ones. So no worries.) (15:14)

.\,.\,If there are links in a template, they are just implemented the same way, and then the app just has to.\,. combine the trailing codes.\,. Hm.\,. .\,.\,Hm, that will not be totally easy to program, but I guess it's worth it, so yeah, I guess so.\,. (15:17) .\,.\,Hm, but why not just also let the spec delimiter be defined the same way as well, then?.\,. .\,.\,Hm, I think I will let it be so, and then all of the three trailing codes then just have to be combined, from the inputs and the template itself, when submitting a template instance.\,. (15:20)

About the tag types, it could actually be useful if one for instance wanted to have bots filter e.g.\ property tags by a type. So yeah, maybe tag types could be useful at some point.\,. (15:21)

.\,.\,(15:25) Oh, the concatenated string don't have to end in the head ID, do they?\,. They just need to end not in `\#'. And then you always reference the head entity when you reference a concatenated string entity.\,.

%...(15:44) It's too good weather to be indoor and code. I'm going out again. It is actually too warm in here; my hands are sweaty.x) ..Time to use my curtains against the sun again..^^

\ldots\ (18:08) I \emph{will} remove the trailing spec.\ delimiter code and use `$|$' instead as the delimiter instead for templates---and for entity submissions in general. And I'll do the following for submission field. There should first of all be a field with the type, which is not part of the entity submission itself, but results in som immediate upratings of the entity as having that type (coming from the user). .\,.\,Hm, and the user should also see the relevant rating bars afterwards such that they can potentially adjust these uprates (if they want them to not be 10/10).\,. Then there's the main field, for which there are two options, determined by radio buttons: The field can be the entity definition straight up, or it can be a template. If the user chooses `template' as the option, only then will the app query the database for matches while the user is typing in the entity. Whenever the user makes a well-formed placeholder, using `\%$char$' or `\%[$label$]' syntax, there will appear a new field underneath, where the user can then type in an entity to search for.\,. Hm, and maybe there should also be radio buttons for each of the input fields to say whether the entity should be inserted as a link or not---and if the latter option is chosen, the app should not query the database for matches.\,. .\,.\,And that's it. .\,.\,And maybe the user should be forced to choose an existing template, or submit a new one. When templates include links, they template instances will inherit the same links. But if templates are the only way to make entities with links, then this requires template templates, i.e.\ in order to make the templates that include links in the first place. But this is possible; you just have to use double `\%\%' for the will-be placeholders, such that they are not interpreted as such in the template template, only in the (template) instances of said template. This is of course a bit complicated, but luckily, templates with links in them won't really be needed much---and I might even delay implementing them, meaning that submission ia them might fail in the very first version of the app.\,.

Now, this will mean that only `$|$' and `\#' are special characters in the stored format (in terms of the so-called full title). And in the app, the users will not see `\#' as a special character, since concatenation is hidden under the interface. So they'll only see `$|$' as a special character, unless we also count `\%', which is special only in the process of making a template instance. I will therefore just use double characters for all these instances, `\#', `$|$', and `\%' as well, as the way to escape these characters. So users will thus only have to write `$|$$|$' instead of `$|$', unless they use it to point where the spec.\ delimiter should be. And they'll sometimes have to write `\%\%' instead of `\%', but only for templates, i.e.\ whenever `\%' should not be interpreted as part of a placeholder.

When it comes to the trailing link code, I then have to be careful with the syntax that I'm planning on using, since it has to be clear whether the codes works before `$|$$|$' is turned into `$|$' or after. And here I will say: always \emph{before}. In other words, `$|$$|$' should only be turned into `$|$' as the very last thing before it is rendered and shown to the user. (18:32)

.\,.\,This multipurpose submission field can then be used t submit all kinds of entities, which is why it is the only submission field I will implement for the first version of the app.\,.\,:) (18:35)

.\,.\,And for searches, I will only implement direct Entity SK lookups for the first version of the app. So no full-text search, and also no typing in `@' to then get a sub-search for an entity. .\,.\,:) (18:39) .\,.\,And no use of Indexes for the first version.\,.

(22:06) Wait, there's something wrong with my idea for concatenated strings, let's see.\,. .\,.\,Hm, I guess we just \emph{do} need to reference the tail end instead.\,. .\,.\,And I could then make it end in a reference back to the head, but no, let me just implement a query proc that returns all the (up to 10--20) substrings at once.\,.

.\,.\,(22:17) I could remove the `\#' at the end of each substring, but no, it stays. And let me mention that when we implement searching on long, concatenated strings, we should then simply make the strings that end in `\#'---although the users should see in ellipsis instead of this `\#' (followed by a `expand down' button/symbol)---expandable, such that when clicking on them, the app then start querying for more possible continuations.\,. Oh, and this means that we don't need.\,. Oh, never mind, a query procedure to immediately get all (or a lot of) the substrings will still probably be useful for the EntityTitles. (22:22) .\,.\,Oh, and that query proc.\ also goes the other way around than when you search for concatenated entities (where you, in this latter case, start from the head and go towards the tail end).\,.

(08.04.24, 9:12) Oh, let me actually use backslashes to escape special characters still, especially since it won't do that you can't have empty trailing codes.

(11:31) Hm, I need to figure out exactly what to do when links are not of the `e' type.\,. .\,.\,Hm, would is make sense to reintroduce the `@'-references only for the non-regular entity types, such as the user type and the text type (`u' and `t').\,.\,? .\,.\,Hm, and when searching for entities, the users will then just use this syntax directly; only the search matches will have the this syntax translated to a link to the given non-regular entity.\,. Hm.\,. (11:39) .\,.\,Yeah, I think so.\,.

(11:41) Oh, is there any sense in letting this format with all the trailing codes and such be something that's implemented only for the Indexes, and then use a format like one of my earlier ones for the Entities themselves?\,.\,. .\,.\,Then me might want to give the IndexKeys table an ent\_id, but then again, we don't necessarily need to, since the entity SK might still be derivable from the given format.\,. Hm.\,. (11:45) .\,.\,Hm, this might actually be useful, yes.\,.\,!\,.\,. Hm.\,. (11:47) .\,.\,(11:49) Oh, and if I do include the ent\_id, then the capitalization code might not even need to be, 'cause I can then just convert to lower case (and non-accented) for the Index.\,.\,!\,.\,. (11:51) .\,.\,I would then let the specPos be defined by a `$|$' once again, just like how the users would write it when submitting an entity.\,. .\,.\,And I could back to references of the form `@$c$$n$.', where $c = \mathrm e$ is then the only type of reference that gets converted in the Indexes.\,. .\,.\,Hm, this does really make a lot of things a lot simpler.\,. (11:59) .\,.\,It would actually mean that I don't need trailing codes at all; not for the Entities and not for the IndexKeys.\,. .\,.\,(12:04) Oh, maybe I should call it IndexEntries instead.\,. .\,.\,Ooh, or I could also call the table IndexedEntities instead. (12:07)

.\,.\,(12:17) Hm, with this, I'm back to only expecting one instance of an unescaped `$|$'.\,. .\,.\,By the way, this doesn't change anything about the concatenated string; not for the entities nor for the indexes.\,. .\,.\,It also means that I no longer rely on implementing templates, at least not if I then go back to expecting the users the use the entity IDs, which, I guess, I couldn't get around anyway since they need to use them for the user and text (etc.) types, regardless.\,. (12:21) .\,.\,Hm, so should I implement templates.\,. well I certainly need them for the properties still.\,. wait, do I, let's see.\,. .\,.\,Hm, well, no, but I \emph{want} to use templates for properties now.\,. (12:23) .\,.\,So yeah, let me still implement template submissions, namely as a tab in the columns of template-types entities, but for the main submission column, the users can just get one input field, where they write the entity in, well, actually the exact syntax as it is stored in the Entities table.\,. (12:26) .\,.\,Hm, it's also nice that the app will then still function (and I can test it / try it out) without needing for the search field to be implemented.\,. .\,.\,Pretty great.\,.(!\,.\,.) (12:31) .\,.\,(Oh, but it would be quite easy to implement an index that just includes all entities, since all I need to do is really just to use LOWER()---and perhaps use a function to de-accent as well, if there is one at hand.\,.)

.\,.\,Hm, we can keep the same syntax for the templates as I had in mind *(and wrote about) before this realization (that we don't need trailing codes after all when we have the indexes).\,. (12:36)

\ldots (12:49) Oh, but there's also the option now of including template closures, i.e.\ entities of the form `@$n$.$m$\ldots', like I had before.\,. .\,.\,Hm, and maybe it would make sense to have properties be singular nouns again, with specifications that specifies how the are interpreted when appearing in a `$<$property$>$ of $<$entity$>$' clause.\,. (12:54) .\,.\,Yeah, but let me take a walk and think about it\ldots\ 
.\,.\,(12:57) Hm, I think I will go back to doing all that\ldots

\ldots\ Let me disallow numbers for placeholder labels, and then use the `\%$n$', $n=1,\ldots, 9$, and `\%[$n$]', $n\in \mathbb{N}$, syntaxes for back-referencing placeholders.\,. Maybe.\,. (15:38) *(And I might allow references as labels.\,.)

.\,.\,(15:48) Hm, maybe I will go back to a convention of capitalizing things where the `short title' is understood more as a title, rather than as a predicate. So basically almost all nouns, except something like `good acting,' where there's an implicit `has' before this title.\,.

.\,.\,Hm, about the labels, maybe I will also go back to how I parsed the labels from the specification instead.

.\,.\,I should by the way start calling it the `full definition' rather than the `full title'.\,. (16:00)

.\,.\,But yeah, maybe I shouldn't convert the `\%$n$' (and `\%[$n$]') back-references. They can just be stored that way.\,. Sure.\,. (16:04) .\,.\,Ah, I should give each link in an EntityTitle a className with the number $n$ contained in it, such that I can simply render to backreferences as numbers, perhaps like `($n$)', and when hovering over `($n$)', or the original reference further back in the full definition, then both (or rather all) these links with the same className (containing $n$) will get underlined!\,:) (16:08) .\,.\,Nice.\,.\,!

\ldots Hm, should I just capitalize everything, even adjectives and verbs?\,.\,. (16:38)
\ldots I'm a bit torn, but I might indeed do that: capitalize all entity titles.\,. (17:22)

(09.04.24, 9:38) I've thought a bit more about what it is that will bring users to using the SDB; the website and the browser extension. And being able to quickly see a lot of ratings for a given thing that you're browsing is of course one thing. And being able to easily find discussions and critique about the thing is another. But the thing that will really attract users is still the fact that we can make so much better Machine Learning algorithms based on this high-quality semantic data, so that users (anonymously) quickly can find where they are in a parameter space, just answering a few ``questions'' (or rather rating a few things), which can then be used to make so much more precise predictions of what they will like compared to existing technologies. However, this will only be the case once the system gets going a bit. So this grand thing will only be what attracts users if I can somehow make them excited about the promise (and if I can in particular attract other open source programmers). Now, if my mathematical discovery becomes big news, this may be possible, but even so, it will not be an easy task to get so many on board. Of course, I also have my general argument for why the open source community should get working on a Web 3.0 where the users are completely in charge. .\,.\,But still, it will not be an easy task.\,. (9:48) Hm, let me think a bit more about the angle of simply being able to see a lot of diverse ratings immediately for the things that you browse.\,. .\,.\,Hm, perhaps paired with just a simply algorithm to boost users that have an overall high `trust'/`agreeable' score.\,. .\,.\,Hm, and maybe I could also get the ML going at a somewhat early stage, let's see.\,. (9:52)

.\,.\,(9:59) But maybe focusing on the idea of a \emph{user}-driven Web 3.0, where algorithms are also a lot, lot better, due to semantic data, despite them being a lot less intrusive: They will not need to \emph{sniff} for data in order to be useful; the semantic data that the users actively volunteer themselves will be more than enough. (10:02) .\,.

.\,.\,But let me still think some more about what the chances are (and about the possibilities) that I can make an app that is able to attract a small userbase.\,.

.\,.\,Hm, maybe getting those user-to-user ratings at an early stage could actually be key.\,. (10:07) .\,.\,Especially if I also promise to make bots to save these user groups, i.e.\ such that the users are never in risk of losing their individual trust/likedness, nor the user group as a whole that they have built collectively.\,. (10:10) .\,.\,Yeah, this could really be it.\,.\,!\,.\,. (10:11)

.\,.\,Get `user groups' (I have a lot of specific (implicit) connotations when I use this term (see my earlier notes about it)) going as soon as possible!\,.\,.
.\,.\,(10:19) So I should make bots at some fitting intervals to save the user trust/likedness global scores.\,. Well, or maybe each new bots of these are actually based on the previous user group, such that popular users' votes count more in determining the new popular users. And I never have to delete these bots, since they won't require a lot of data *(and requires no maintenance, really, since their job is just to rate the users one time *(well, they might actually as well be active until some deadline, until another bot takes over.\,.)). I could even make their opposites as well, if I wanted to.\,. (but maybe not.\,.) This will prevent spam at an early stage, and more importantly, it will give users good incentive to be actively helping the system by rating things and other users---and commenting/discussing etc. And at a very early stage, I should then also make ML statistics on the user community and publish the a lot of the correlation vectors, together with a bot for each one that up-rates each user in terms of how they fit that correlation vector. .\,.\,These can then further more be combined with the trust/likedness scores to already give some very useful and interesting usergroups, which will give the users a good idea of the potential of this system, and which will give them even more incentive to rate things and be active, since this now also help define their.\,. belonging.\,. (I'm looking for a different word, but you know what I mean.\,.) to each of these interesting user groups. So maybe this is exactly how the userbase can grow from just a few interested users, to a decent amount of users.\,.\,:)\,.\,. (10:29) .\,.\,(Where the first users to join will then have a lot more to say in terms of helping the user groups evolve from there.\,.\,:)) (10:31)

\ldots (10:45) Yeah, early `user groups' (already from the first version) is what can make the thing grow in the first place; all the extra incentive that this gives, which makes the users \emph{want} to rate things and be active, is really paramount.\,. (10:48)

%(20:18) Jeg har tænkt lidt over det, og jeg tror måske jeg er landet på, at jeg endelig (efter fire år, kan man sige) vil give mig selv fri og så søge arbejde. For selvom jeg godt kunne arbejde videre på min SDB app, og selvom at jeg jo godt tror, at den vil kunne vokse sig stor, når først den kommer frem, så tror jeg ikke rigtigt jeg kan klare det uden nogle medarbejdere/partnere. Så det er nok bedst og komme ud og så forhåbentligt skabe et godt netværk. Så kan jeg stadig arbjede i weeknderne/fridagene, men jeg tror måske endda, jeg vil prøve at sætte mig selv for at opprioritere sociale arrangementer, og andre ting sociale ting, og dermed ingen gang arbjede alle mine fridage. Jeg tror bare jeg vil sigte efter, at jeg ikke slipper det helt af arbejdshukommelsen, og at jeg lige for lavet måske lidt hver uge. Men nok ikke mere end det.. ..Jeg tænker lige over det til i morgen tidlig også, men jeg tror altså mulgivis this is it.. ..Jeg kan også mærke, at der er nogen gange, hvor jeg egentligt burde være frisk på at programmere, men hvor motivationen halter (fordi jeg ikke længere har helt den samme (forestillede) gulerod foran mig, som jeg tænkte/følte, at jeg havde for et år siden). Så på den led er det måske så også fornuftigt nok med lidt luftforandring.. ..Det tror jeg, men jeg tænker lige noget mere over det.. (20:28)

(10.04.24, 10:11) Since we just render all substrings of any concatenated string as an InvalidEntityTitle, except the tail end which is interpreted as the full string, it means that re-mapping entities will be an easy matter, as we are always free to remap all references in entity definitions as well. And about the users accepting that their ratings are re-mapped, this can just be the standard setting, i.e.\ to accept all re-mappings greenlit of the central SDB organization, and then they just toggle off this setting if they want.

So for instance, if we suddenly want to remove templates again and substitute them for their filled-in versions, this will not be hard to do---except that the properties will then rely on having the templates, if we go by my current plan, so all these will need to be changed to templates (now without the special backend functionality) instead, but of course, we would only want to remove the (backend-supported) templates if users were already using (front-end supported) templates instead of the singular-noun-properties for constructing property tags.
.\,.\,Anyway, let me stick to templates with the full implementation (i.e.\ with the `@123.124.\ldots' syntax), and rest assured that we can always change it again, if it turns out that only-frontend-supported templates are better.\,. (10:21)

(10:21) About my thoughts mentioned in the source code comments after the last paragraph of yesterday: Yes, I think I will change lanes now and focus more on getting a (regular) work etc. Then I will puase this project somewhat: I will still work a bit on it in some of my free days, but only that, I think. (10:24)
%(10:24) Det er nemligt vigtigere for mig lige nu, mener jeg, at jeg får noget mere arbejds- og arbejdslivserfaring, for et forhåbentligt større netværk, og også at jeg lige for lidt socialt afrustning (og erfaring).. (10:26)

(15:26) I just continued programming a little bit this afternoon. I haven't considered the fact that because we need the template's definition in order to define the type, it means that the inputs can only be queried for after the template definition is fetched.\,. .\,.\,Hm, a simple fix would be to also include the type specifier in the template closure syntax.\,. (15:30) .\,.\,Another option could be to remove the type specifiers from the templates, and instead use numbers.\,. .\,.\,where repeated numbers is then treated like back-references.\,. Hm, and you could require them to be in order as well.\,. .\,.\,Or I could just use `\%e' always.\,. .\,.\,Hm, or I could just repeat the type character in the template closure, as I said.\,. (15:34) .\,.\,Maybe I'll do this, and then also check that the two declarations of the types match.\,. .\,.\,Hm, maybe except for `\%e' exactly, as this could be an inclusive placeholder.\,. Yeah.\,. (15:36)

(15:58) Oh wait, I actually haven't thought this thing of reintroducing fundamental types through. I need to either go back to then either include these types in SemanticInputs as well, or go back to letting all entities be included in the Entities table.\,. Hm, and I guess I could do the latter by sort of using some fundamental templates for entities of the special types; some that doesn't follow the rules of the regular templates, but who are rendered via special React components (not TemplateTitle).\,. (16:02) .\,.\,Hm, but maybe it's more pragmatic to add types to SemanticInputs.\,. (16:05)
.\,.\,(16:08) Oh, this is actually a kinda deep/big question; it actually makes me think of going back to using types again, and in particular the way I had in mind before where an entity can have multiple types, and where the full key to a column therefore consist both of a (nullable) type and the entity ID.\,. Hm, wild that it takes me so long to figure this out.\,. (16:11)

(16:20) .\,.\,Maybe the easiest thing would actually just be to make special template-closure-like syntax for making user and text, etc., entities, and then that's the only way that you can reference these: by referencing the entity with that special syntax. And then all other references will just always be references to the Entities table, including the inputs/placeholders of the templates.\,. .\,.\,(16:26) Hm, now that the def is close to WYSIWYG, and doesn't include the trailing codes, it makes sense to once again end all concatenated strings in a reference to the head substring. And that means that all concatenated string entities will have exactly two unescaped `\#'s in their def. So for template closures and special entity closures, I could just let these start with `\#' instead of `@'. And for all the non-template closures.\,. which are not really closures, actually, since they only contain one ID.\,. the `\#' could just be followed by a (special) type specifier first, instead of directly by a number. I think I might do this.\,. And note that then I can.\,. Oh no, I still cannot split the UserAndBots table just with this.\,. (16:31) .\,.\,Whatever, it's fine to just have an overloaded table like that; the extra one or two bytes per user is really not something to be concerned about.\,. (16:33)

.\,.\,`u\#123' makes more sense than `\#u123'.\,. (16:35)

(11.04.24, 12:51) Okay, I have a problem in the fact that template entities themselves (not talking about their instances) will have `invalid entity titles' as I have it now. (I'm ``procrastinating'' today by programming.) Maybe I should just render non-substituted placeholders and non-active back-references in a special way.\,. (12:55)

\ldots Hm, I can render the placeholder in a special way, but.\,. Hm, maybe it's better to.\,. Oh, maybe I could turn the `\%[1-9]' back-references into an active kind of back-reference, using `@', for template instances.\,. .\,.\,Hm, maybe with a /@n[1-9]/ syntax.\,. (13:16) .\,.\,Sure.\,. Unless I want to remove templates, but I think not.\,. .\,.\,No let me do this.\,. (13:18)

\ldots (13:46) It seems that it might be a very good idea to make sure that my new syntax and all that works well, before I move on to a new phase of my life: Think about if I had paused the programming completely (which might happen if I find (more regular) work and it takes up all my energy) before yesterday and not found all these bugs and problems: That would have made fixing it when I eventually got back a whole lot harder.\,. .\,.\,('Cause if I know my self correctly, I tend to start rethinking everything when I look at an old project with fresh eyes (and this is not what I need right now).\,.)

\ldots\ (16:05) If we at some point want to change Entities to divide it into two columns, the title and the specification, then we can also just do that, as long as either the app--control-server interface doesn't change or at least that the application user interface doesn't change. But alternatively, we could also just supply the control layer and/or the database layer with extra procedures that only returns the title part of the def, e.g. ('Cause right now you need to fetch the whole entity definition, even if you just need the title.) So no worries, if we want to be able to fetch only the title part of the definition, we can just implement an extra proc for this. (16:10)

.\,.\,(16:10) And going back to the question of whether to unpack the templates before storing, here we can also just make a proc that gets all the relevant defs at once. (And there's also always the option of remapping the syntax and use my idea for the trailing link code instead.) (16:12) .\,.\,There's even the option to make this remapping one-to-one by introducing a `was formerly a template instance' syntax.\,. wait, or one could just introduce an `is a template instance' instead, which future Entities might also use. So yeah, all in all, no worries.\,:) (16:15)



(16.04.24, 10:02) I have various things to write about and think more about. And now I just re-realized an idea, which I think I've had before. the idea is that users might want to be able to up-rate all the things/point about a certain thing that make this thing good. And also, under another tab, the things/points that make it bad. These are then up-rated according to importance, I think, and there might thus be a separate rating for how much they affect the `goodness' of the thing. But maybe it can also be done with one rating. Let me think some more.\,. \ldots Maybe the users could add and uprate these points as texts, and then for each text, there could be a property of relevant ratings.\,. And what to call these texts?\,.\,. .\,.\,`Points of praise,' maybe, and then the opposite could be `points of constructive criticism'.\,. .\,.\,Yeah, and I would wants these tabs anyway for thing-entities.\,. .\,.\,So these `points of praise/criticism'-type entities could then have a property, and tab, of `related ratings$|$ for a @[point of praise/criticism], i.e.\ ratings about the thing(s) that the @n1 points out'.\,. (10:34)
\ldots And maybe we don't need the importance rating: maybe the praises/criticisms need only be rated according to the `goodness'/`badness' that they cause.\,. (10:49) .\,.\,(10:55) Hm, maybe a way to do it would be to first have two tabs, one for praise and one for (constructive) criticism, and then rate these properties just for the goodness/badness they cause. Then the next step could be to also introduce a third, mixed tab where all points of praise/critique are rated according to importance rather then `goodness/badness that they cause,' but where the `goodness/badness that they cause' rating can also be fetched and shown for each element in this entity list. (10:58) And what the user community then decides to do / invents from there is up to them.\,:) .\,.
.\,.\,Hm, but I guess all these praise/criticism entities might as well get the supertype `tag' as well.\,. (11:02) .\,.\,No, 'cause the statement is really: `point of praise $x$ causes the entity $y$ to be good'.\,. Hm.\,. (11:04) .\,.\,Hm, which \emph{could} be reformulated as: `(is) good because of point $x$'.\,. (11:05) .\,.\,Hm, that's actually not a bad idea, i.e.\ to use such praise/criticism tag template, and it would also gives a good way to make the praises/criticisms ordered after importance in their respective tabs after all.\,. Hm, nice (it seems).\,. (11:08) .\,.\,Yeah, this is for sure what we ought to do.\,:) (11:09)

.\,.\,Hm, I think this little piece of technology will actually be so important for the app (thinking about the early browser extension especially).\,.\,:) (11:14)

%(11:32) Øv. Det er virkelig en flot bygning, der står i flammer nu.:(

(15:05) I ought to continue this subject in the next section as well, but I'm thinking that thing-entities should have a `points of praise' tab, a `point of constructive criticism' tab, a comment tab (for the normal positive engagement that you tend to see), a corrections tab, and a discussions tab. About discussions.\,. Oh no, I should write those points below.\,. .\,.\,I think that this system will provide a very good user experience of being able to review and discuss what makes various things good and bad, as well as other things. And especially if a make a bot that continuously calculates `user groups' via ML (dealing with correlations), such that the first users can immediately start to be grouped with the users that are most like them.

(15:13) I also have something else that I want to point out, concerning the monetary aspect of the idea. Since this system will very soon start to become a very important way for users to review products/services, media, and more, there will be a giant interest from companies to boost the visibility of their products etc. Now, commercials and biased search results are generally not something that users want. However, if the users can see how much this helps the community monetarily, they might still be willing to accept (as preferences/settings) that the sponsoring companies' products etc.\ have their visibility boosted. For if it is seen by the individual user as an alternative to donating money themselves, it they might very well be on board with that after all. This creates a giant vector for getting monetary towards the contributing `users' (including all open source programmers and inventors, of course). (15:20) The other vectors that I had in mind, i.e.\ attracting sponsors based on increased brand recognition for them, and because it supports a pool of user data about their products, these are still there. But they are probably not nearly as big as allowing companies to get their products boosted in terms of visibility (except for users who has turned this off, perhaps because they are donors themselves). So there we are, a potentially \emph{giant} source of income/funding for the project.\,.\,:) (15:23)

(15:37) I/we should also consider allowing tags where the semantics can depend on the user, i.e.\ such that the tag can.\,. Well, the statement, rather. Okay, maybe not, but I should think some more about this, still.\,.
\ldots (16:22) It could be done with a `tag that I, the rating user, would put on myself' tag (i.e.\ a tag for tags, where the rating tells you how much the user thinks that they fit the given user tag).\,. .\,.\,Or we could say: `predicate that fits me, the rating user'.\,.

.\,.\,Let me also mention: As part of the early app, the users should also already be able to up-rate statements as good ones for determining what type of user the ones that rates these statements are.\,. Hm, we could by the way also do the thing from the last paragraph with rating-user-referencing statements instead, uprated for the tag `True'.\,. Nah, the other idea is better. But it is worth considering this possible redundancy, i.e.\ if we utilize a `true$|$ statement' tag.\,. (16:32) .\,.\,Ah, well, if users just always up-rate tag--instance pairs, when they uprate these `good-for-type-determining statements,' they can just uprate a (`true', $<$text-based statement$>$) pair. (16:39)
.\,.\,(There should then of course be a bot that finds correlation vectors looking at only these statements (with a high enough `good for user-type-determining' score).)

(17.04.24, 9:03) About the praises/criticisms, these should also generally be spoiler-free as well (for movies, books, etc.). At some point we can then make another tab, or a switch to toggle within the initially spoiler-free tab, which then shows the praises/criticisms / review points \emph{with} spoilers.

(10:52) I'm considering a slight ``pivot'' in the sense that I might (with these latest thoughts, including those of the section below as well) try to focus the early app more on ratings, reviews, and discussions---and especially in the browser extension---more than about the `user-driven search/feed algorithm' part.\,. .\,.\,Well, I also need a lot of the other stuff to make it all work well, so I'll also have to implement a lot of that as well. But I could make do with ListGenerators that aren't were complicated, at least.\,. (11:00) .\,.\,But in terms of explaining/``selling'' the idea.\,. .\,.\,Yeah, I can focus more on just the browser extension part (with ratings, reviews (praises/criticisms), and discussions) .\,. (11:02)

(11:46) Hm, I'm looking at the definition of `Subcategory of Entities,' and now I'm thinking, perhaps the documentation should be in the form of (not searchable) texts instead. And come to think of it, we actually \emph{don't} want the documentation to be part of the search.\,. Hm, and maybe the exact `appendix'/`specification' should rather be determined when.\,. submitting an entry to an index.\,. Yeah, so such entries could be submitted instead.\,. .\,.\,(11:57) Hm, I have to make it more simple and clear somehow, I think, how the semantics of the various entities (especially tags and properties/relations).\,.

.\,.\,Hm, I think all tags should have documentations.\,. Then there is an initial documentation, but what the users will see, is whatever is rated highest as the `updated version' of that tag.\,. (12:06)
.\,.\,Hm, and the same could also be quite useful for ``thing entities.'' There could thus be an initial ``documentation'' (specification, rather), but the users will normally see the updated version instead, if there is one.\,. (12:08) .\,.\,For tags, the documentation will given to the template, not the tag instance, though.\,. Hm, but I guess any template instance could just have two documentations: one for the template, and potentially one that's more specific for the instance.\,. (12:10) .\,.\,And what about searchable specifications, should we then just make it so that a searchable string is uprated for each entity, and then the top-rated one can be used for the Index(es)? That could be an idea.\,. (12:12) .\,.\,So each entity just consist of a short title, potentially a template documentation (if being an instance of a template), and then.\,. \emph{potentially} also an individual specification as well.\,. And then users uprate the most fitting searchable string for each entity, which can then be used for the Indexes.\,. Hm, this sounds good.\,. (12:16)

\ldots\ (14:38) I've had several thought, and now I just had some wild additional ones about maybe letting all the defining properties of the entities, including even the title, be semantic.\,.(!\,.\,.) .\,.\,I've had such ideas before, once, but now they actually kinda makes sense again. But let's see.\,. .\,.\,And then you could just uprate the \emph{most} defining / the \emph{defining} ones, which will then be shown under the title and the ID in the Entity column.\,. .\,.\,(This of course requires an assisting bot that uprates what the creator chooses as the defining properties, and which is then generally given much weight.\,.) .\,.\,(14:45) Hm, I could let properties have a special type and/or make a special SemanticInputs table for them.\,.

%..Det er lidt vildt, men der er nu et eller andet ved de her seneste tanker, der tiltaler mig..

.\,.\,It is also easier to just uprate for instance one list of actors, instead of having to creating and maintaining a list by uprating each actor individually.\,. (14:52)

.\,.\,And with this, types can be both defining and semantic properties at the same time.\,.\,!\,.\,. (14:59)

.\,.\,Hm, so there's a fundamental tag of defining.\,. No, a fundamental property of properties.\,. (15:01) .\,.\,And a new entity--property--(rating--)instance SematicInputs table.\,. .\,.\,One which does not need to be optimized for fetching lists of entities (i.e.\ property instances), 'cause this table is meant for quite-constant property instances, which even for lists (like e.g. `actors') are defined only via single entities.\,. (15:07) .\,.\,These `properties' are thus meant only for factual data, or for data that defines entities (for instance such as tags, which are invented by the users, but which nevertheless need some fundamental properties to be settled before they get their intended meaning).\,. (15:11) .\,.\,Oh, which means that the (somewhat) fundamental `properties' relation, should actually be implemented as a normal tag, right?\,.\,. Unless we change it to `defining properties,' meaning that it can be a small list.\,. Yeah, we should probably do that.\,.

\ldots But general properties should be implemented more like the normal (in terms of what has been normal until now) SemanticInputs.\,. (15:26)

.\,.\,(15:32) Well, maybe never mind about the thing of saying that the properties have to be singular. For instance, having multiple types could be a good thing.\,. .\,.\,Well, but you could also make and uprate a (short) list of the types.\,. Hm.\,. .\,.\,And if I make a special List type of entities.\,. (15:34) .\,.\,(So that when a property value is a List, it is always interpreted as meaning that the elements of the list are the property values.\,.)

.\,.\,(15:40) I could also just add an importance rating directly to the Properties (or what we should call it) table.\,. That actually sounds smarter.\,.

.\,.\,(15:45) Maybe be I should just make yet another table such that I have two `Properties' tables: one for the one-to-one properties (including List entities), and one for the one-to-many properties.\,. .\,.\,Nah, I should probably implement the latter via tags, still.\,. (15:49) .\,.\,Yeah.\,. (15:49) .\,.\,And then the documentations of such tags will be a property of theirs. Note also that the `category title' of a tag could be a property as well, which will mean that we can get plural nouns for categories after all.\,. (15:52)

\ldots (16:17) Yeah, so this new Properties table is just for semantic facts and definitions. And the rest is then done in the same way as before, but where the documentation, and everything else, is now automatically updatable with this system. The factual/defining properties does not have a documentation themselves, however, but are just nouns (plural or singular depending on whether one expects a List entity or not).\,. Hm, and their names/titles actually does not need to exist outside of the Properties table.\,. (16:22) .\,.\,A List entity can just be implemented via a TEXT containing a comma-separated list of integers (IDs).\,. .\,.\,Oh, and let's actually not make it an Entity, but let us just make it something that is only used for the DefiningProperties.\,. .\,.\,Oh wait, all property values should just be texts (which are able to include references), so never mind about the List entities; these are just implemented via the Texts/Strings that are the fundamental building blocks of Entities (since they are what is used for all property values (including e.g.\ the title of the entity)). (16:32) .\,.\,`Defining properties' is a good word for it.\,. .\,.\,Oh, and then we could call the normal `properties'.\,. (I wish English said `call $x$ \emph{for} $y$, instead of just `call $x$ $y$'.\,.) .\,.\,call them `relational properties' instead.\,. (16:37) .\,.\,Oh, or even better: `subjective properties'.\,. (16:38) .\,.\,Or simply `ratable properties'.\,. .\,.\,One of those three options, I guess (if not just all at once).\,. (16:40) .\,.\,And simply `qualities' might also be a potential alternative.\,. (16:43)

\ldots\ (18:27) Okay, I can't get rid of the Entity defs if I also want to keep the possibility to search for an entity via its template, such as in e.g.\ my tag--instance statement template.\,. So maybe the def could be as it is now, and thus define the title of the entity, at least until a potential updated version of the title comes along.\,.
.\,.\,So the initial definition doesn't have to be \emph{completely} defining. It just needs to serve as a starting point for the definition, as well as a secondary key for the entity, which can be useful in some instances.\,. (18:37)

.\,.\,This might mean that I can go pretty much back to where I was in terms of the database implementation, I think (maybe), except that I might actually keep the thing about making at least one other SemanticInputs table, namely a entity--property--property-value one.\,. (18:43)

\ldots (18:55) The creating user should choose a title property along with the definition, which can, however, also be generated automatically from the definition.\,.

(19:59) Hm, or maybe it's easier to stick with tags only. In that case, the only change might then just be that Entity definitions, by this new convention, do not have to be very specifying, and that you instead treat the `semantic properties' as part of the definition.\,. .\,.\,Hm, then again, maybe a properties table for the factual/defining properties would be good.\,. I need to think more about this.\,.

\ldots (20:28) Hm, I think I will change it, i.e.\ such that we fundamentally have tag--instance statements as well as owner--property--value statements. I'll then make two tables for this, and for the factual/defining properties, we can just use.\,. .\,.\,Hm, never mind, all properties are entities, and can therefore always be documented at some point. And since the def is still always supposed to contain an initial title (written before the `$|$' still, actually), this means that we can bootstrap the whole thing, whithout having to define the `title' property of the `title' entity via itself, for instance. (20:34) .\,.\,So that might be the only new changes: Two types of fundamental statements instead of only the tag--instance one, and no longer with a convention that an entity's definition has to be completely defining: Any entity can be further defined `semantically' via its properties. (20:36) .\,.\,(Oh, and I will also cut a bit in the def syntax: Back-references will for instance no longer be needed.\,.)

.\,.\,Hm, I could perhaps also make.\,. .\,.\,Hm, I don't know.\,. .\,.\,Uh, maybe I could go back to an old thing of having a special, fundamental kind of template for property tags, and then always unpack these as the owner--property pair before storing in SemanticInputs, i.e.\ meaning that the tags of this special type cannot be used directly in SemanticInputs.\,. Hm.\,. .\,.\,Oh, or I could also just implement special database procs (query and input procs) where the owner--property pair is used instead of the tag, even though SemanticInputs then still only allows for tags.\,! That could be an idea!\,.\,. (20:49) .\,.\,Great.\,.

.\,.\,I should also keep the idea of using List entities sometimes instead of rating a whole list of factual properties one element at a time.\,.

\ldots (21:15) Instead of making a property tag template, let us just use a special syntax for it instead, and why not `@$<$\emph{owner ID}$>$\texttt{->}@$<$\emph{property (name) ID}$>$'?\,. .\,.\,e.g.\ like `\texttt{@123->@124}'. .\,.\,Or just `\texttt{@123->124}'.\,. (21:21) .\,.\,Or `\texttt{@123>124}'.\,. \,.\,Or `\texttt{@123/124}', alternatively.\,.

(18.04.24, 8:32) The syntax for the definition could be like `short title$|$type:type,tag$|$
prop2:something$|$\ldots', oh wait, or I might actually make it standard to use IDs (integers) for the property values, and then use quotation marks when wanting to type the thing in directly.\,. .\,.\,Oh, never mind, it should always just be IDs.\,. (8:38) .\,.\,Hm, and maybe it should also be IDs before the colon?\,.\,. .\,.\,But that would mean that e.g.\ the `type' entity cannot be specified further (or any other of the early entities) in their definition.\,. .\,.\,Hm, so let me actually allow non-ID words, both for properties and for values.\,. Hm, or maybe the parts of this $|$-(vbar-)separated list should just be free, but if any of the parts conform to the `123:124,125,\ldots' syntax, it means that the app knows to automatically uprate these properties as well for the created entity.\,. (8:44) .\,.\,Hm, or let us just make it `@123.:@124.,@125.,\ldots' instead.\,. .\,.\,And let us actually not prioritize implementing this functionality; users can just go to the newly created entity and uprate, first types for it, and subsequently other properties.\,. .\,.\,I should also store the year and month that the entity is created, since this allows the users to interpret the definitions according to the conventions of the given time.\,. (8:51) .\,.\,But yeah, let us start with a convention of writing definitions like `short title$|$type: type, tag$|$prop2: something$|$\ldots' .\,.\,Hm, without the spaces.\,. .\,.\,So: `short title$|$type:type,tag$|$prop2:something$|$\ldots'.\,. .\,.\,And one is then more than free to insert entity references (like `@123.') anywhere here instead of any word.

.\,.\,In terms of list entities, these could be implemented with a syntax like `@123,124,125, \ldots', which would then be rendered as an unordered list (and you could even also implement ordered lists, perhaps by using `;' as the separator instead). But let us actually not implement this for the early app, and instead just uprate each element individually for any one-to-many property.\,. (8:59)

.\,.\,Hm, maybe documentations can also be context-dependent.\,. This would then allow for the same ambiguity that I talked about liking when I removed the the type field/column for Entities.\,. (9:36)

.\,.\,Hm, maybe this is more complicated, than what I had before: Maybe the definition should just be sufficiently defining on its own for the Entities.\,. .\,.\,Hm, it's hard to say.\,. .\,.\,Hm, but I can just still parse the short title from the def always in the early app. That would make it a lot easier, yes. Let me say that.\,. (9:46) .\,.\,And let me also keep the same syntax where there's only one (expected) `$|$' (at most), and where the definition without the `$|$' is then interpreted as the full definition.\,.

\ldots Oh, we could actually just make a list (instance list) query proc where the secondary key, i.e.\ the def, is given instead of the ID. This allows this to be used for other tag templates as well, not just the property tag template.\,:) (10:06)

.\,.\,I will still make the special syntax for the property tags, rather than defining a template like I used to; that idea is really good, I think.\,:)

.\,.\,So maybe I should keep the definition syntax the same as it is now, even with the back-references, as long as I just either write them out or insert a `($n$)' after the original, referenced link.\,. (10:13) .\,.\,And then we'll just say that these definitions, including the (short) title, are not as set in stone, but if users uprate replacements for them highly enough, the app will show these replacements to the users (depending on their preferences) instead. (10:19)

(11:22) Maybe, I will remove the `@n[1-9]' back-references, but not the `\%[1-9]' back-reference placeholders for the templates, which are then just replaced with the given entity reference (like `@123.') instead.

(11:55) Hm, or maybe I actually will just use the property tag template, like I have done, instead of defining a special syntax for property tags.\,.

(12:00) Hm, maybe it would be a god idea to make a sharper line between tag entities and non-tag entities.\,. .\,.\,Hm, this made me consider introducing fundamental types again, but where these then are \emph{not} meant for the custom types.\,. Hm, or will it work with this high level of ambiguity.\,.\,?\,.\,.
.\,.\,It could also just be a leading character of the definition.\,. .\,.\,Perhaps followed by an initial `$|$' for clarity.\,. (12:06) .\,.\,Hm, 'cause it also doesn't make sense to use non-tag entities, like `LotR' or `WWII' as tags anyway, as it's way better to use more clearly defined properties instead. .\,.\,I should not make a separate `type' type (fundamental type/super-type), though, as this should just be a subtype of the `tag' (super-)type.\,. (12:10) .\,.\,`fundamental type' is better than `supertype'.\,. .\,.\,(12:14) Let me just make it a separate CHAR field/column in the Entities table, which are then just also a part of the secondary key. I will not implement typed tags and/or instance lists, so SemanticInputs need not be changed. But I can make a restriction of not allowing semantic inputs where the tag is not of the `tag' type. .\,.\,For e.g.\ 'user' or `text' entities, their defs will then just be an integer alone; no other surrounding syntax needed.\,. (12:18) .\,.\,I will also let `property' be a fundamental type, then.\,. (12:20) .\,.\,(12:25) Maybe I will call the standard/regular entities for (exactly) `regular entities,' and use the character `r' internally to denote this fundamental type.\,. .\,.\,Well, maybe `standard' is actually more fitting.\,. Sure.\,. .\,.\,(And then I'll just use `s' instead---which can also be thought of as standing for just `something').\,.

\ldots Hm, do I want a fundamental statement type?\,.\,. (12:44)

.\,.\,(12:45) Oh wait, if templates have to be able to.\,. determine the fundamental type.\,. well, I guess that could just be done with an initial character of the template.\,.
.\,.\,Hm, but why go to all this trouble of making it a separate field/column, when it might just as well simply be the first character, always, of the def.\,. .\,.\,Yeah, let me go back to just having the def as the, well, the full \emph{definition} of the entity.\,. (12:49) .\,.\,And let me just still keep the `$|$' as the mandatory second character for clarity's/visibility's sake.\,. (12:53) .\,.\,No, make it a `.' instead.\,. (12:54) .\,.\,Hm, or a `/', actually.\,. (12:56) .\,.\,Hm, but/and couldn't we just use single characters for the fundamental (reserved) types, but then also allow custom types.\,.\,? .\,.\,(13:01) Yes, I think this is a very good idea. It's a very good thing to have the overall type defined first of all in the definition (for better understanding). And since we won't really be searching for entities via their definitions, but via uprated index keys instead, we shouldn't worry about having something coming before the (short) title.\,. So yeah, let's probably do this. We could even also use `:' instead, but then allow for several types, separated by `/'s, such as in e.g.\ `Tag/Type:Entity'.\,. (13:05)

.\,.\,Okay, let me drop using `$|$' to cut out the title from the full definition. Let me then instead write whole sentences for the `specification,' with capitalization, of course, and I think I might then go back to using only lowercase for tags in general.\,. Hm.\,. .\,.\,Yeah, lowercase in general for tags, types, and properties, and all such meta-entities, except of course for proper nouns, and then for the `standard' (/`regular') entities, we might actually choose to capitalize as a standard, I'm not sure.\,. (13:18)

.\,.\,I'll probably just write `tag:' instead of `tag/type:' for all types.\,. .\,.\,And let me just separate the type declaration from the title with a `$|$' instead of a `:'. (13:22)

.\,.\,Great.\,.

\ldots\ (15:42) I will just use a list of integers for the type declarations (and bootstrap the types of the `tag' and `type' entities). I think I will separate them with `/' since this is actually how I intend them to be rendered, which means that I will also propose always having it so that each new type in such lists is always a subtype of the last one. Then when users create new entities, I \emph{will} make it so that these types are uprated by the user automatically. But I will also make the app cut corners and always add the types from the type declaration to the list of types, as well as any potential additional ones which are uprated highly enough as types for the entity. (15:46) .\,.\,Oh, and I \emph{will} thus use `tag/type' as the declared type for my types. And never mind about the reserved letters again, as we'll just use the IDs, as said. (15:47)

.\,.\,By the way, `questions' should also by a standard tab for the `standard' entities, which should then of course lead to (the `question' property of) `answers' as well.\,. (15:49)

(16:43) Hm, now that templates all have `4$|$' in front, we can just make `\%' a special character only for these, and not for any other entity. We can also treat only this first `$|$' as a special character for the templates, and just render all the rest of the template verbatim.\,. well, except for constant references.

(16:54) Hm, now that we don't need the definitions to be searchable, I might think about doing something else for the concatenated strings.\,. Maybe I'll even.\,. Hm, maybe I'll even just add a TEXT to entities.\,. .\,.\,Hm, I wonder if it could make sense to just make a manual check on the TEXT column, then, in order to prevent duplicates.\,. .\,.\,(17:00) But then again, one could just make a standard `documentation'/`full specification' after the specification part of the definition, and then require that this is always a text entity.\,. .\,.\,Hm, one could by the way uses hashes instead of BIGINTs for text IDs, if one really wanted to not have any duplicates.\,. .\,.\,Hm, that might not actually be a completely bad idea, as it also has the added effect of making texts and binaries searchable.\,.\,!\,.\,. (17:06) .\,.\,And I could make an input proc that just inserts/finds the given specification text automatically, as part of inserting the entity.\,:)\,.\,. (17:09)

.\,.\,(And of course, for the Indexes, I can still use the same concatenated strings as I had in mind before (those that are fully searchable).) Hm, this might actually not be a bad idea, about the hashes.\,. Hm, but I can probably make it even better, let's see.\,.
.\,.\,Hm, or maybe no; maybe the full specification / full definition / documentation / specification should just always be a text entity, which are then referenced by its hash (that serves as its primary key).\,. (Note that all texts also has a BIGINT ID as well, which comes when the `@t$<$\emph{hash}$>$' entity is created as part of inserting the text.) .\,.\,Hm, which means that one can actually also just use that ID for the def, instead of using the hash directly.\,.

.\,.\,Hm.\,. Oh, I can still bootstrap the first few entities, simply by adjusting the specification ID afterwards to the correct text entity ID.\,. (17:26)

(17:40) The Texts and Binaries tables can store their hashes, but I might do as https://
dev.mysql.com/doc/refman/8.0/en/optimize-blob.html
says and also do manual comparisons on top of that. And I can then also just use BIGINT UNSIGNED AUTO\_INCRE-MENT for the primary keys / IDs of these tables.\,.

(17:48) And let me just repeat, the specification/documentation, as well as the title and the type declaration, are never set in stone. They should preferable be pretty precise and well-formed, but they can always be ``replaced'' by the users, namely by them uprating replacements highly enough (in which case the app, depending on the individual user's preferences, can fetch and render those instead of the original ones). .\,.\,(And the types in the type declaration is not even meant to be an exhaustive list to begin with, not at all. The users are instead expected to uprate any other types `semantically' for the given entity---and might also at some point in the future be able to downrate the ones from the declaration, although this might also be achieved instead by uprating a replacement for the type declaration.\,.) (17:53)

(18:02) Oh, and let me then remove back-references completely, and let us for templates just use a general specification for all template instances at once, where the specification then uses some variables/pronouns/placeholders instead of back-references. This then means that the semantics of a template instance's specification is only fully understood once you also have the actual title part as a reference for what should be inserted in the place of the pronouns/placeholders. And.\,. Oh, and users could also.\,. No, let us just say that if the specification of a template instance is not enough to fully understand it, then you can.\,. Well, maybe users could uprate amendments to the general specification rather than replacing it in such instances, actually. (\emph{Or} they can always also just vote to replace it outright.\,.) (18:09) .\,.\,But generally it's better, like I do for the properties, to just make the input entities define how they should be interpreted in the context of the given template instead.\,. (18:11)

(19.04.24, 9:27) There are some things left to consider, so I've been thinking this morning. And now I just had a kinda wild idea: What if all factual and/or defining properties are uprated for an entity, not via a property tag for each property, but instead as whole batches of data in the form of XML documents. And when looking up factual data, you just look through all the high-enough-rated XML data documents in order until you find the first match for the property that you are looking for.\,.\,?\,!\,.\,. .\,.\,Well, or you could look through all and take all the property values that you can find, and serve them up as the ``instance list''.\,. Hm.\,.
.\,.\,(9:36) Hm, could there be a good way to combine this method with the one of rating each elements individually, more specifically such that we can combine two such different lists?\,.\,. .\,.\,If we for instance say that the elements from the XML document just automatically adopts the combined rating of the whole XML document as the individual rating.\,.\,? .\,.\,Hm, that sounds like quite a good idea.\,. (9:40)

.\,.\,Hm, maybe I will then use a special syntax for the property tags after all, since this would make `properties' something even more fundamental of the system.\,. (9:43)

.\,.\,Hm, and then we could perhaps just use XML TEXTs for the entity defs, making sure to also store the hash of this TEXT def in the Entities table as well, and to use it in order to check against existing duplicates before inserting any new entity.\,. (9:48) .\,.\,The stored def will then be the original one (by the creating user), and all subsequent ones will just be uprated as `property documents' for the entity. Then the original def will then just automatically start with a high rating.\,. (9:51)

.\,.\,Hm, but the Entities table should also store an original (short) title, which is the first thing that is typically fetched for an entity, and often times the only thing.\,. (9:54)

.\,.\,Hm, if this can be made to work, I might not need templates at all then.\,. (.\,.\,!\,.\,.) (9:56)

\ldots `Property document' will then of course be a reserved property that is not supposed to appear within a property document.\,. (10:14)

.\,.\,(10:19) The fact that the original property document is uprated as such as well of course means that it has to be an entity, which means the the Entities table should just have the ID of the text entity for its prop doc column.\,.

.\,.\,(10:22) Hm, alternatively to storing the short title, the app could also perhaps just query an Index for it instead.\,. Hm.\,. .\,.\,Well, might as well query for the top-rated instance of an instance list (in SemanticInputs), then. And then one could start out by using a bot that just always uprates the original title.\,. .\,.\,And one could then soon migrate to a bot that updates this if another property document with a different (short) title takes the lead (decided by some mean bot).\,. (10:26)

.\,.\,And let us underline: Property documents are meant for factual and/or defining properties only.\,. .\,.\,(Not for the more subjective properties, such as e.g.\ `related entities' or `subcategories,' etc.)

.\,.\,I'm by the way also considering going back to using `\#' instead of `@' for the references.\,. Oh, unless I want two kinds: one that is often expanded, and one that always stays as an ID.\,. Hm, maybe not.\,. (10:33)

(10:42) When people write texts within an XML tag, when they edit a new entity for upload, I.\,. Well, let me actually think, 'cause the typical inputs ought to be a list of entity IDs, right?\,.\,. .\,.\,Hm, and maybe they should be able to escape this when editing and write texts directly, where these will then just be stored separately, and the text content will then be replaced in the stored property document by an entity reference instead.\,. .\,.\,My point about these texts is that apart from redundant whitespace, the text should just be saved as is, with exactly as many newlines as the user types in between the given XML start and end tag. And then we can always decide on a standard format afterwards. Of course, any single newline should just be rendered as a space.\,. wait, no. I don't need that. The editor can just use wraparound, and then we'll let the users write there UTF-8 text almost verbatim, except for some special characters that needs escaping, for instance `$<$' and `$>$'.\,. (10:50) .\,.\,Well, and they can even get to write it completely verbatim if we implement an `add property' button to the form field, and make it so that each property is edited separately, and where the property name and the content for each property is also edited separately.\,. (10:53)
*(Oh, except for the entity references, which should not be verbatim, I think, but should be replaced with a link when the user has typed it in.\,. (12:40) .\,.\,Well, at least at some point when we implement this.\,.)

.\,.\,Hm, maybe I'll use JSON, then, instead of XML.\,. (10:54) .\,.\,Sure, that's easier/better, then.\,. .\,.\,And since we should not have nested tags anyway, JSON will also be at least as readable as XML. I will probably transform the property documents a bit, though, before rendering them for the user, but even if I do, the resulting format would then be more like JSON anyway, i.e.\ with a title for each property, followed by the content. (10:57) .\,.\,Yeah, and I will probably just render the JSON text verbatim for the first version of the app.\,. (10:59)

.\,.\,Hm, I might really make this change.\,. (10:59)

(12:03) I guess this will require text entities to be a separate kind of entity. .\,.\,So we could say that there are `data entities' and `semantic entities,' and also `user/bot entities' if these are not also considered `data entities'.\,. .\,.\,Okay, so I should probably let there be four fundamental types of entities, then: Texts, Binaries, Users (which includes both actual users and bots), and Semantic Entities.\,. (12:06) .\,.\,Hm, the user\_id of SemanticInputs (.\,.\,hm, which could by the way also be called something like RatedInstances/RatedEntities.\,.) will then always be of the User type, the tag\_id will always be of the Semantic type, but the inst\_id would need a CHAR/TINYINT to denote its type.\,. .\,.\,(I could use CHAR, and let the four characters be `t', `b', `u', and `s'.\,.) (12:11) .\,.\,Hm, but it would be smart, if I could let tags define their fundamental type instead. I could still.\,. well, I \emph{might} still store the (fundamental) type character in SemanticInputs, but I \emph{could} also just let this be defined by the tag alone.\,. .\,.\,Hm, let me include the type character, at least for the early version. It's also alright that this technically opens up for the possibility of type-overloaded tags, even though you'd still have to retrieve each instance list separately for each fundamental type. Okay, let me just include it, indeed.\,. (12:17)

.\,.\,Hm, this is a bit bothersome, so couldn't I just collect all these four types into one Entities table?\,.\,.
.\,.\,Hm, I'll do that somehow, yes, and one way to do it might just be to let Entities$\to$SemanticEntities, and then create a new Entities table that just hold a type character and an ID.\,. (And then I could make an Entity query proc that instead of fetching the type and ID, fetches the type and the data of the given.\,. sub-entity-table.\,.) (12:31)
.\,.\,The IDs of all these four sub-tables / helper tables can then be private to the database, not being visible above *(/in) the database (query/input proc) API.\,. (12:35)

\ldots\ (15:15) Okay, I had some more changes/corrections to these recent ideas, but now I also just realized, silly me, I forgot about how important it is that we can search for entities via a secondary key. So let me think about whether the ideas are salvageable or not.\,. .\,.\,(15:18) Hm, maybe if we somehow made `tag' another fundamental, and searchable, type.\,.

.\,.\,I by the way also decided that I would scrap the `property document' property, and then stick to uprating instances individually. And since this is the case anyway, I might go back to the defining the entities via a def, using a syntax like what I had just before these `property document' ideas from today.\,. (15:22)

.\,.\,Hm, but maybe the idea about making a searchable fundamental type for tags especially might also work, let's see.\,. (15:27) .\,.\,Hm, and maybe that's just it: Tags are.\,. Hm no.\,. .\,.\,Hm, how about property tags especially, then?\,.\,. .\,.\,Hm, or just having a WordEntities and SemanticEntities, where WordEntities are considered more abstract and more constant.\,. Hm, `ConstantEntities'.\,. .\,.\,Or AbstractEntities.\,. Hm.\,. (15:31) .\,.\,Hm, `abstract' and `specific' entities.\,. no, maybe not.\,. (15:33)

.\,.\,(15:34) Ooh, how about using the `as a' clauses for property documents / documentations?!\,.\,. .\,.\,So that the properties are made dependent on the type that the title is interpreted as.\,.\,!\,.\,. Hm, but then we're also back to having type-specifying tags and all that.\,. Hm, I should think about all this.\,. I feel like it could work fine with the def-defined entities that I had before the ideas of today, so I should keep that in mind.\,. (15:38) .\,.\,Hm, yeah, maybe I should go back to that.\,.

.\,.\,(15:47) Wait, back up to the `how about property tags especially, then?' idea.\,. .\,.\,Hm, by having a fundamental type that stores the owner entity's ID and the property entity's ID.\,. .\,.\,Oh, this might actually work.\,.\,!\,.\,. (15:51) .\,.\,Ah, or maybe we could even make it more general by going back to having CompoundEntities, where the `function' is then also stored.\,. (15:53) .\,.\,Ah, like templates, except that the input is not substituted in a text: Instead the function simply has a documentation that explains the semantics of the closures.\,. Well, and it should also define the (short) title.\,. (15:55) .\,.\,(15:56) Ooh, and maybe that title template could then simply be a (`semantic') property of the function.\,. .\,.\,Hm, I like this; it seems like a good idea.\,.(!) .\,.\,Hm, for this means that now I could in principle go all in on the JSON definitions, but still have searchable ``template instances'' (which are now actually `function closures/values').\,. (16:00) .\,.\,`Functional/compound entities'.\,.

.\,.\,On my walk a little while ago, I also thought that since JSON strings can also just be strings, we might also still have entities that are just defined by their title alone, without having to specify that the string is a value of the `title' property. And this would help making bootstrapping the semantics easier and more clear.\,. (16:04)

.\,.\,I also thought (since I'm going away from the thing about uprating property documents) that maybe the entity documentations/definitions don't have to be searchable, and maybe this could be the case.\,. .\,.\,Or I could indeed make a fundamental `word' type of entities, that are defined simply by searchable strings, rather than by documents.\,. .\,.\,(16:10) Hm, if I call it `derived entity' I could also group the `word' and the `functional' entities together.\,. .\,.\,Hm, `derived' and `semantic'/`standard' entities.\,. (16:12)
.\,.\,Hm, but I might also make separate types for the `word' and the `functional' entities.\,. .\,.\,Sure, that actually seems like the right thing to do.\,. (16:15)

(17:11) Maybe never mind about the `word' entities.\,. \ldots (18:09) Except they could perhaps be handy for properties, but I'm not completely sure what to do there.\,. .\,.\,Hm, maybe we should just rely on users selecting properties from a list (an instance list, i.e.), or at least until I implement the Indexes as well---which I of course could just make sure to do from the start.\,. .\,.\,Hm, yeah.\,. (18:15) .\,.\,And let me also just give `semantic entities' an (original) `title' column, by the way, instead of having to always define that via the JSON document. Hm, I might also give them a `types' column then, for good measure.\,. .\,.\,And with this, the `property document' column can be essentially nullbable, and I could make a unique index on these three columns.\,. (18:20) .\,.\,Hm, this then actually allows me to also store it as my previous three-part def varchar.\,. (But I could also store it as just three separate columns.\,.) (18:23) .\,.\,Hm, maybe it's cleaner to just use the one `property document' alone.\,.

.\,.\,Hm, if I make the procedure to take a property document and uprate the relevant tag--instance relations a private helper procedure, maybe I can then use it to bootstrap the first required entities a little easier.\,. Oh, well.\,. .\,.\,Oh, that \emph{will} actually be the easiest thing to do, so yes.\,. (18:31)

.\,.\,(18:32) Oh, there is a problem: We cannot have property documents that only use IDs instead of words---unless we for instance make the title its own, automatically understood column. So let me indeed do the thing about making both the type declarations and the title definition (i.e.\ the original ones) their own columns, next to the.\,. `other properties document'.\,. And let me indeed make that unique index, then.\,. (18:35)

.\,.\,Oh, and since the (other) property(ies) document will only consist of IDs, apart from boilerplate syntax, I will not make it JSON after all, since this would mean a lot of redundant `"'s.\,. .\,.\,(18:42) Yeah, let me just store it like `123:124,125.223:224.323:324,325,326', or maybe use newline characters instead of `.' And if we would like to convert it to JSON, then that would be a simple matter. .\,.\,(Just wrap it in `\{\}', insert a `"' after the first `\{' and after each newline, and then also change each `:' to `":[', and insert a `]' before each newline and before the last `\}'.\,.)

.\,.\,Hm, should I then store each prop doc as a stand-alone text entity, then, and store its entity ID in the prop doc column?\,.\,. I guess so.\,. .\,.\,And maybe I'll also keep the data\_hash column for texts and binaries, by the way, at least for now.\,. (18:55)

.\,.\,Oh, shouldn't I also make the `types' and the `title' columns essentially nullable for.\,. Hm, for entities with long titles, but no, maybe I should just change `title' to `short title' instead, and thereby cement that it might not be the full title.\,. .\,.\,Yeah.\,. (18:58)

.\,.\,Hm, let me reconsider having the `word' entities as well, which can be used especially for factual/defining properties.\,. .\,.\,Yeah, maybe I should do that after all.\,. (19:03) .\,.\,And then I might use actual JSON, and allow for non-integer strings as property names.\,. (19:04) .\,.\,Wait no, I can just use the semantic/standard entities where the prop doc is then null (or rather 0).\,. (19:06) .\,.\,Yeah, and then still just try to make it a convention not to use entities with non-null (non-0) prop docs for the factual/defining properties, such as e.g.\ `short title,' `title,' `description,' etc. (19:08) .\,.\,Oh, and I mean no to the thing about introducing `word' entities, not about using actual JSON. I'll still do that, then.\,.

.\,.\,Well, maybe it doesn't need to be a convention after all: Maybe we should just leave that up to the users. But I \emph{will} use such simple (without any `other properties document'/`prop doc') entities for the basic properties such as `short title,' `title,' `description,' etc. 'Cause how else do we bootstrap the semantics?\,.\,:) (19:13)

(20:35) Oh, if I use JSON exactly, then the IDs also have to be wrapped in quotation marks for the property values as well.\,. .\,.\,('Cause otherwise JS interprets it as 32-bit integers.)

(20.04.24, 9:15) Let me just not care about repeated texts for text entities (and likewise for binaries), at least for the early versions of the system.\,.

.\,.\,(9:19) I think `standard entities' is more clear than `semantic entities'.\,.

(9:36) Hm, to make the fundamental type part of the entity key or not to make the fundamental type part of the entity key.\,. .\,.\,(9:39) Hm, and/or to make the data key public or not.\,. .\,.\,About the former, I really don't want to add even a single byte more to SemanticInputs.\,.

.\,.\,Oh, I guess if we just make an overloaded Entities table, that would beat all (I think) of the other options I had in mind, at least in terms of efficiency.\,. And I could of course even overload some of the columns to make it.\,. well, slightly more efficient, but I guess not.\,. (9:47)
.\,.\,Oh, this might not work with the unique/secondary indexes.\,.
.\,.\,Hm, if I made the fun\_id in the FunctionalEntityData table into a string instead, and possible combined it with the input\_list, it could work.\,. .\,.\,Hm, but no need to combine it.\,. .\,.\,Hm, but I will lose too much clarity with this, so no, maybe I should keep the data tables separate.\,. (9:56)

.\,.\,Hm, but then again, what if I simply went back to the def I had before.\,.\,? .\,.\,But instead of an initial type, we just write an initial \emph{fundamental} type (which is \emph{not} the same, as two entities with different fundamental types can have the exact same types in principle---they can even refer to the same thing and thus be duplicates!\,.) in the front, and only continue with the.\,. \emph{semantic} types if `s' is the character.\,. (10:01) .\,.\,Hm, let me maybe call the `fundamental types' `meta types' instead, to make this (important) distinction more clear.\,.
.\,.\,Hm, but this doesn't work for the text or binary types, so no.\,.

.\,.\,Okay, so I'll keep doing what I'm doing now (having a global Entities table with just a (meta) type\_char and a data\_key, which is a foreign key to one of the `data tables').\,. (10:08)

(11:51) Hm, I just added a user\_type column to UsersAndBotData, i.e.\ a CHAR of either `u' or `b', but now I'm thinking, why don't we just use std entities for bots?\,.\,. Hm, and this makes me think.\,. Nah, let's still use the user ID, not the user `data key' in SemanticInputs.\,. .\,.\,(11:57) Hm, and let's keep bots as a user type, since.\,. Ah.\,. Yes, since it's good to have the bot data be controlled by the SDB, not the users. But I could divide them up into two tables now. I'll probably du that.\,. .\,.\,So I guess I'll use `a' for (aggregation) bots like I used to.\,.

(12:41) Oh, maybe the short title should be a constant, unlike any of the other properties.\,. Hm, or else I do need to include `word entities'\ldots

\ldots\ (14:21) Okay, I will indeed introduce the `word entities,' but I think I'll call then `vocabulary entities' instead. And these are supposed to be used for basic, defining/factual properties. For it doesn't make sense to insist of using a property-typed entity for this: We already know that it's a property when it appears as a property name.

Now, I \emph{could} then remove type\_list and sh(ort)\_title from the std entities table, but I might actually keep the short title, as it allows this initial/original short title to be served up after one query request instead of two. And I don't think it's necessary (and it would also be hard) for the functional entities, since functions are generally likely to be cached by the browser most of the time anyway. .\,.\,:)\,.\,. (14:27) .\,.\,(14:30) Ooh, and then we could also say that the short title is only replaced by something else, not if anything is simply rated higher as the short title, but if this is the case \emph{and} the rating value also exceeds some threshold.\,!\,:) (14:32) .\,.\,Great.\,.

Let me also mention that vocabulary entities are not really meant to be further defined (by their properties): There interpretation should be based on the word/title alone. (And if this title is abstract and/or ambiguous, then the semantics of the entity is simply \emph{supposed} to be equally ambiguous.) (14:35) .\,.\,This is not to say that users \emph{can't} add explanatory properties, as well as any other properties of course, but they are only \emph{meant} to add explanatory properties at most, not \emph{defining} ones. .\,.\,This is opposed to the standard entities and the functional entities whose semantics does not have to be nearly as constant (note that the semantics of the vocabulary entities is thus meant to be almost constant, only perhaps changing if the underlying natural language changes) as the vocabulary entities. Users are thus free to specify standard and functional entities further at any point \emph{after} they have been defined, by uprating different properties for them (although the original definition is still kept, and is supposed to always be honored as much as possible, i.e.\ such that specifying a std or functional entity is okay, but changing it is not okay, really).

.\,.\,Okay.\,:) (14:42) .\,.\,Oh, and maybe I should lose the `short,' and instead just use a convention of specifying it \emph{when} we're talking about a full title, and let it be implicitly understood that `title' normally simply refers to the thing that the entity is commonly called. Okay.\,:) (14:45)

(14:50) Hm, I'm considering simply joining StandardEntities and VocabularyEntities, saying that the former is equal to the latter when doc\_id = 0, but maybe not.\,. .\,.\,'Cause the app is not supposed to query at all for a title replacement for vocabulary entities.\,. Hm.\,. (14:53)
.\,.\,But you could also just say that it's not supposed to do so when doc\_id = 0.\,. .\,.\,Hm, I think that it might be a good thing to separate the two things more clearly. For again, vocabulary entities are not supposed to be specified (only explained at most).\,. (14:56)
.\,.\,Hm, and maybe you can also say that vocabulary entities are meant to generally be interpreted as the words themselves, not the thing that they are referring to, unless they are used in relations (commonly property relations, where they are thus used either as.\,. Hm.\,.).\,. Hm, should we then use vocab entities as property values---I guess we have to.\,. Hm.\,. .\,.\,Oh no, we maybe don't \emph{have} to.\,. (15:03) .\,.\,Hm, but maybe vocabulary entities just should generally refer to the thing, rather than the word itself, and when you want to define word entities, you could make them std entities.\,. maybe.\,. Hm.\,. (15:06) .\,.\,Hm, I guess so.\,. .\,.\,(15:09) Oh, how about simply removing VocabularyEntities again, and just make it a convention not to.\,. Yeah, maybe we should generally not specify entities beyond their original definition, but keep them.\,. deliberately vague/ambiguous.\,. Hm, I don't know.\,. (15:11) .\,.\,Yes, actually, I think so. If an entity can refer to a range of things, we keep it that way: General things are kept general (abstract things are kept abstract). Okay, so do I remove the vocab entities.\,. I guess so.\,. .\,.\,Yes.\,. (15:14)

\ldots\ (16:38) Hm, I'd like to make the prop doc a TEXT column rather than an entity ID (ulong) column, but then I do have to make the vocabulary entity / word entity table after all, since these still need to be searchable.\,. .\,.\,Let me do that, and maybe I'll go back to `word entity'.\,.

.\,.\,Hm, maybe I'll start calling them simple entities (instead of word entities) and prop-erty-defined entities, and just `defined entities' for short.\,. (16:48)

(18:47) It might indeed be a good idea to introduce ML bots early on, but another thing that I ought to do as well (perhaps even more so) is to introduce my `simple user groups,' as I believed I called them. These are then implemented first via the users uprating a pair consisting of a user/bot and then a tag, which is meant to have the instance type of `(actual) user' Then if such a pair gets highly enough uprated by all the users (and later on you could implement so that selected user groups are given more power to create new user groups), then the SDB first of all creates a bot that distributes a kind of tokens to the users rated highly enough as instances of the given tag (second element of the mentioned pair), by the given user (first element of the mentioned pair), such that the amount of tokens is at least kinda proportional to the rating. Then I should find a way to define how these users can then transfer said `tokens' to other users.\,. Oh, of course that just has to be another special tag, which is uprated as well along with the pair, making it a triple. And this allows users to take back their tokens, also. Then the bot continuously calculates each users effective amount of `tokens,' either in a way where givers of tokens lose some tokens as well, making the `token' metaphor more fitting, but perhaps even better where the original users of the `group' keeps the same voting power, and just has a constant amount of power that they can distribute to others.\,. well, or maybe the first option---one or the other. I'll figure that out. Okay, and finally, there's then a bot (maybe the same, if one will) that is essentially a `mean bot,' but where the mean/average is weighted according to the `token' distribution (and users with no such `tokens' are ignored by this bot). I think this could be a very good idea, to introduce these `simple user groups,' as I've called them, early on.\,.\,\texttt{:D} (19:02)

.\,.\,(19:05) Ooh, and maybe I'll start by introducing the following simple user group myself, which is the (mean bot, trust, trust) triple, which would thus.\,. Well, it has to then be a fluid one, instead of one where the initial group of users (`moderators' of the group, essentially) is constant. So I guess there could also be `dynamic simple user groups,' where.\,. Hm, where it is also a triple, but where the ``initial'' group of `moderators' are then allowed to vary as well. Ah, and I could also simply put a deadline on when the `moderator group' will stop varying and become constant, which I recall was also what I had in mind last time I thought about these `simple user groups.' So yeah, let's add that to the description: The `moderator group' for a `simple user group' can be allowed to vary, at least until some deadline is met. And about the (mean bot, trust, trust) simple user group, yes, I think that might actually be useful, since it would give a ``trust-squared'' user group. And since I'll set a deadline (which might be postponed if I (/ the community) see(s) fit), its usefulness will increase all the more, since it will make it a good guard against if trolls appear at some point after the early stage.\,.\,:) (19:14) .\,.\,A `trust of trusted users' user group.\,.

.\,.\,(19:18) I think the latter of the two options will create a better dynamic, i.e.\ where it doesn't ``cost'' anything for the moderators to distribute their tokens, and where the moderators thus retain a special status in the group.\,. (But we can of course always also just implement user groups with the former of those two options at some point, if somebody want those kinds of user groups as well.)

.\,.\,Oh, and `trust' is a little too vague: I think it should more precisely be a tag of `I think I respect the inputs of this user---and perhaps I also agree with the inputs on some level---and I think that the future contributions of that user is likely (according to my rating) to be constructive and valuable'.\,. Well, maybe we can just use the last part: `I believe.\,. no, `I think that the contributions from this user have been valuable so far (to the extend that my rating value tells), and I also (to the extend \ldots) believe that the future contributions of this user is likely to be valuable.' Yeah, and we can maybe shorten this down to just speak of the `contributions' overall, and then it's just implicit that it talks about both the future and the past.\,. wait, what am I saying, there's no need to shorten anything down now that tags can have whole ass TEXT descriptions to them, so never mind.\,\texttt{:D}\textasciicircum\textasciicircum\ (19:29)

(21.04.24, 8:59) Hm, would it make sense to make another text type where entity references are meant to be substituted if the SDB ever remaps its IDs (which it might if working together with other SDBs (other `nodes')).\,.\,? .\,.\,Hm, no maybe texts should just never be verbatim, and thus always have to escape the `\#'s (or the `@'s depending on what I go forward with) etc.\,. .\,.\,So whenever a user uploads a texts from a file.\,. they have to choose whether to interpret entity references as such, or to interpret the text verbatim (meaning that all `\#'s get escaped before uploading).\,. (9:04)

.\,.\,Hm, since some programming languages use `\#' for comments, would it make sense to choose `@' instead.\,.(?) .\,.\,Hm, and it also opens the door up for potentially adding more ways to reference a thing, i.e.\ not necessarily be ID. So yeah, maybe I'll use `@' as I've done up until now (i.e.\ the `@123.' syntax).\,. (9:09)

(9:15) Let us actually parse the title from the JSON document (if a user uploads from a file), meaning that the property document should always contain a 'title' entry (automatically understood as the common, perhaps shortened, title, as we recall).

(9:42) Hm, about not wanting to add ``even a single byte to SemanticInputs,'' should I actually turn the rat\_val into a tinyint? I know it want reduce the primary index significantly when compressed, which is why I have been fine with it, but the servers still have to send more bytes between each other and to the client.\,. .\,.\,Hm, but I could technically reduce this by transferring hexadecimals instead. And then you could even let two hexadecimals represent a smallint after padding to the right with `00'.\,. (9:48) .\,.\,And we could also convert the IDs to hexadecimals. MySQL just \emph{really} gave me a hard time when I tried to use hexadecimal, but then again, I only need to do this for selectInstanceList(); everything else can still just use decimals. This creates a somewhat asymmetric API, but so what? There will be a reason for this asymmetry and that is.\,. well.\,. that MySQL is apparently a dork when it comes to using hexadecimals (in certain instances).\,. Hm.\,. .\,.\,It's fine, simply consider the output of selectInstanceList() \emph{compressed} by default. (9:55) .\,.\,Ah no, there's actually a high chance that this will make the app slower, since it'll need for JS to run conversion procedures on all table elements. .\,.\,Hm, I should probably think a bit more about the costs and benefits of making rat\_val either smaller or bigger, and of using hexadecimals as well. But I'll just do this when it suits, no need to hurry.\,. (10:01) .\,.\,Hm, but no, I actually probably don't need to worry quite as much.\,. well, I'll think about it some more.\,. (10:08) .\,.\,(10:15) But yeah, it might very well be the frontend/client processing that's gonna take the most time, so maybe I shouldn't worry so much about.\,. Well, I could still worry somewhat about the speed of selectInstanceList() (but then I certainly should convert to hexadecimals).\,. .\,.\,No, so I should probably keep it like it is now (when I also compress the table, which includes compressing the primary index). (10:20)

(15:51) Hm, I need to think about if I shouldn't make initial\_inserts af PHP program instead, and where I can insert defined entities via JSON files (and not have to deal with CONCAT()'enated strings.\,.). And now I'm also considering whether I shouldn't just add another meta type for `property tags' to serve as nice starting-off point.\,. .\,.\,(15:56) Hm, I think I \emph{will} make this additional meta type as a help, indeed.\,. .\,.\,I guess, let me take a thinking walk to think about all these things, I feel like I need it\ldots\ (15:57)

\ldots\ (17:43) Yes, I will make that extra mate type. It means that the semantics doesn't have to bootstrap itself, but instead I just have a fundamental semantics of how the various meta types are interpreted, and then all other semantics can be derived from that.

(17:49) And I'll definitely implement initial\_inserts in JS instead. I'm thinking of making a function that takes a JSON object in the form of an array of plain objects, and then it should insertOrFind each entities in this array. Eah object will then denote it's own meta type, and will also have a key field, apart from the other fields that the given meta type needs. Also never mind about letting the prop doc / def hold the title also. It shouldn't. So a (property-)defined entity will thus have the JSON-object properties `key' (nullable), `metaType', `title', and `def', where `def' is then supposed to be a plain object itself. I will then make the insert function (in JS) return a Promise which resolves to an object with all the `key's of the JSON object, where the value for each key is then the outID (regardless of whether this was found or inserted).\,:) This means that I can then define the initial inserts in JS modules, and make then export and import these promises to each other, which can then be used for new inserts (orFinds).\,:)

Also, I think I will let the AncillaryBotData tables use the bot\_name, which I will make unique, rather than the bot\_id, since this will allow the bot events/procedures to work independently of what ID the bot is given as an entity.\,:) (18:00)

.\,.\,Oh, and let's of course just hand the JS insert (orFind) function an actual JS object (i.e.\ an array) rather than a JSON string. (18:01)

For inputting ratings, I will probably do something a bit similar (less complicated); that should be easy enough.\,. (18:03)

.\,.\,Great, I'll look forward to implementing all this tomorrow.\,:) .\,.\,And I might get started this evening.\,.

.\,.\,(18:11) Oh, and I didn't say, each objects to be inserted from an array should also be able to use the keys from a previous object. Oh, and I guess you also just hand an ID index object to the function as extra input, if is has to use some previous keys from an earlier call. (Or whatever way will work when I use Promises.\,.) And the way to reference a key should just be with a `@abc123.' syntax, or more precisely /@[a-zA-Z][\textbackslash w\_]$*$\textbackslash ./.

.\,.\,(18:19) Hm, for functional entities, let me just add a.\,. nullable text entity.\,. no, maybe I should just use a syntax where the last input can use a different separator than a comma, and if it does, it means that this last entity (a text entity, unless I'll also allow simple entities for this) will then be concatenated as a string to the input list. This allows arbitrary number of inputs, which might not be very useful, but it's nice to know that it's possible, I think. .\,.\,Yes. (18:23)

.\,.\,Let us just say text entities only for the functional input tails.\,. (18:28) .\,.\,Oh, and to help remapping (and make it possible), we should actually format the list in the text entity differently, making it a list of entity references, like `@123.,@124.,@125.', such that these will be automatically substituted under an ID remapping. (18:31)

(19:02) Besides the def field for the `defined' entities, I will also make an `other props' field for all meta types as well, where the JS funtion then also automatically up-rates these properties for the new entity (but without these properties being stored as part of the `defining properties' in the case of metaType=`d').

(22.04.24, 8:37) I think the (short) `titles' of simple and (property-)defined entities should actually be verbatim, and thus not be able to include links. The full title, on the other hand, which is a semantic property (possibly (and probably) being defined in the def text), can of course include links (i.e.\ `@123.' entity references). When it comes to the title templates for the function entities, I think they should simply have a `title template' property and a `full title template' property. This then also allows them to have another `title' (and `full title') themselves, which is actually a good thing, 'cause it might make more sense the see e.g.\ a comment function referred to as exactly `comment function' rather than something like `\%e, \%e, \%e', or whatever.\,:)

The fact that titles can't include references also means that I am okay to assume that they generally.\,. don't start with `@'.\,. Nah, let me just escape that somehow.\,. well, I should be able to use any kind of string as a property name in JS, so let's just escape it with a backslash. Then for my insertOrFind JS function, all strings are just interpreted as simple entities, unless they begin with an unescaped `@', in which case it is either an entity reference using the ID directly, or, more likely, it is an entity reference using a key instead, which the program then Promises to substitute for an ID.

If wanting to insert a text entity as a property, simply insert and object rather than a string. This object will then be inserted first, just as if it had been in the outer array, but where its key can then be anonymous. (8:50)

.\,.\,Let's perhaps boost the `initial user' ten times for the mean bot(s).\,. *((19:03) Oh, I actually don't need to, 'cause I can just run the same initial inserts several times for different users, I just realized.\,:))

(9:58) Hm, maybe I'll instead make a class with a key--callback store.\,. .\,.\,And when the key has finally gotten its ID, the callbacks can then be run, and maybe the array can be changed to the ID instead, or we could have a key--ID store next to it.\,. .\,.\,And my plan would then be that for texts with several key references, the callbacks are just inserted and waited on one at a time.\,. .\,.\,JS is single-threaded, so we can probably easily make sure that all the pending callbacks are called before changing to the ID, as I'm pretty sure that JS never switches program mid-code (and I've also used this for the queryQueue in the DBRequestManager).\,. .\,.\,Alright.\,. .\,.\,Let me make two stores, instead of overloading the one.\,. (10:06) .\,.\,Oh, but maybe I should still make the result store a key--ID-Promise store.\,. .\,.\,Hm, or I could just overload it, after all.\,. I think I will indeed do that. So if any subsequent insertOrFinds looks up a key and finds and array (of callback), they simply have to add their own callback instead of getting the ID immediately. .\,.\,(10:13) Ah, let's make a class that just always receives a key and a callback.
.\,.\,And let's give it a fusion() method that makes it absorb the underlying (private) idOrCallbackStore of the input to this method, which is another instance of the same class. This way we just import/export the class instances of this class, and never have to access the idOrCallbackStore field publicly. .\,.\,(Or we might call it absorb() or adopt() or something.\,.) .\,.\,`copyFrom()'.\,. .\,.\,Ah, but it's more complicated than that.\,. We should probably make a field that is a list of `absorbed' class instances, where the class then just queries each of these first.\,. Hm, no.\,. .\,.\,Uh, the absorbing class instance, which I think I'll be calling EntityInserter, can just add its own callback to the `absorbed' instance.\,!\,.\,. (10:30) .\,.\,Let me call it `adopt' instead.\,.

.\,.\,(10:39) Hm, let us just make all keys from an adopted.\,. Wait! Why am I doing this. Let me just use one instance in general, and scratch adopt(); it's really not worth it.\,!\,:)\,x)

\ldots\ (14:15) I'm just gonna store all simple entities automatically, with the title as the key, and then I'm just gonna prepend a `@' to all the user-defined keys.
.\,.\,Wait, maybe this should be a separate store.\,. \ldots\ No, let me just indeed append the `@' automatically to all.\,. keys.\,. Hm.\,. .\,.\,Hm, let us say that titles can also be key references instead of verbatim titles, meaning that titles always needs to have any initial `@' escaped (unless it is interpreted as a key to the ID store). (15:22)

(23.04.24, 9:18) I might for simple entities actually make it the standard tap to look for `instances' that the given `word' can refer to. This goes a little bit against the rule of \emph{not} conflicting `meta types' with the actual `types,' but still.\,. I might do it.\,. (Something to consider.\,.) .\,.\,Yeah, and maybe `simple entities' could be the exception to the rule, making them always be neutral/typeless in a sense. And one should note that this would \emph{not} mean that their type is simply `word,' for they are not always interpreted as referring to the word, far from it. Rather `neutral'/`typeless' means that they can refer to multiple things at once. They can for instance always refer to the word itself, but they can also refer to all the things (if there are more than one) that the word can refer to. I'll still consider it some more, but this kinda seems like a decent idea.\,. (9:25) .\,.\,Yeah, I think it's actually a good idea.\,. (9:26)

\ldots (9:47) Wait, this might mean that the `title' field should actually be an ID field for  defined entities'.\,. Hm.\,. .\,.\,Hm, that would actually make sense to do.\,. .\,.\,Hm, and selestEntityInfo() should then of course still output the title string, but I might as well then also make it output the ID, why not.\,. .\,.\,Sure, let me just do that. Okay, I think I will do this.\,:)\,.\,. (9:52) .\,.\,Ah, unless I want to make the field hold a data\_key instead.\,. .\,.\,Hm no, let us just make it hold the entity ID, I think.\,. (9:57)

(10:22) Hm, maybe it's easier if we keep it like it were, and just basically makes the.\,. Well.\,. .\,.\,Makes it conventional to upload a simple entity at the same time as a defined entity?\,.\,. \ldots (10:34) I might just make it store the data\_key instead. I can still look up.\,. wait.\,. .\,.\,Oh, I of course \emph{do} need the secondary index for the Entities table, so let me just in-comment that line.\,. And yeah, then I can still return the title ID if I want to for selestEntityInfo().\,. And do I want to?\,.\,. .\,.\,Probably not, actually.\,. (10:43)

\ldots\ (14:30) Hm, from the app's perspective, it would be slightly easier if\ldots\ .\,.\,Hm, what to do.\,.\,? \ldots (14:46) Hm, let me indeed change insertOrFindDefEntity() such that it takes an ID instead and just checks that this is indeed an ID of a simple entity. And I'll then change nothing else about the back-end.\,. .\,.\,Nah, this creates a weird asymmetry, so let me actually just change title\_data\_key to title\_id after all, and then simply query for and append the title as will for selectEntityInfo() when entity is a `defined' one.\,.

\ldots Now this case of selectEntityInfo() requires three lookups, but that's okay. One can also change the title\_id column back to title\_data\_key at some point in the future if one wants, without changing the API of the SDB.\,. (15:14)

(24.04.24, 8:31) I've had a couple of good ideas this morning. Let me start by a small one: I will call `functional' entities `formal' entities instead (as their main name), and then use `format' generally instead of `template.'

Another idea is that I \emph{will} use the `property documents' property after all, but users don't uprate the properties in a document by uprating the document under some tag. Rather I should implement a thumbs/arrow-up button that uprates all the properties in the document individually all at the same time. There should then also be a button to expand out a list RatingElements of all the relevant properties, such that a user can also give ratings individually (either adjusting some ratings down after having giving all properties a maximal rating by pressing the thumb.\,. or un-pressing it.\,. or before having pressed it). Then for the meta info page, users should first of all see the original/defining data, and then the should also be able to see a list of the most uprated property documents (unless we choose another page for this instead). Oh, and for defined entities, there should also be a button to uprate the original title. And of course, the original property document should also have this thumbs-up button as well (the same as the one for all the other (potential) uprated property documents for the entity).

Another great idea that I've just had is that I will actually let the set of meta types be an open one, and then in particular make it open for file formats! So instead of just having the `binary' type, there could be all kinds of file types, e.g.\ `gif', `jpg', `html', `php', etc.\ etc. This also means that I will make the meta type a VARCHAR(\ldots) instead of a CHAR, and why not just make it a VARCHAR(255) from the beginning (instead of starting low and then increasing on demand).

If the SDB wants to save a file format in a compressed way, this should simply just be reflected by the meta type name, e.g.\ by appending something to the uncompressed format name. *(e.g. `html.zip', but it doesn't have to be existing file ending; it can also be invented names, e.g.\ `json\_no\_whitespace') And the same goes for supersets and subsets of formats: Generally let this be reflected in the meta type name.

Like the `text' and `binary' entities (if I keep the latter.\,.), there should of course always be a UNIQUE data\_hash column for all such file format meta types.\,:) (8:53)

.\,.\,I should also say, I realized that JSON isn't meant for human readability (which is part of what got me thinking about this stuff). So I might just make my own format for the property documents.\,. .\,.\,And the point is, by defining this format as a meta type, we get a very good way of telling the app that it can render it a certain way. So in this case, the app will know that the property documents doesn't need to be rendered more verbatim as the texts they are, and instead they can thus be rendered more fittingly. So I could for instance just have a format like `123:124,125;234:345,12,1356;126:1;', and then the app can render it such that all these IDs are substituted with the appropriate EntityTitles. (9:01)

.\,.\,(9:02) Oh, and I also thought about adding a `relation tag' entity, why not, where instead of a noun, the `property' is replaced by a sentence, minus the leading subject of the sentence and the trailing object of the sentence. This might be handy in some cases, I think. For instance, a `might refer to' relation could be handy for the simple entities (for their main page), couldn't it?\,.\,.

.\,.\,Oh, let me by the way use meta type names like `text/json' instead, more like, what are they called.\,. .\,.\,the `content types' used in HTTP headers.\,. (9:11)
.\,.\,Hm, so I'll for instance let `t' $\to$ `text/plain'.\,. .\,.\,I think so.\,. (9:14)
.\,.\,And for the the non-data meta types like `d' and `p', I'll maybe just keep using the single characters, and at least I won't include any slashes.\,. (9:16) .\,.\,Hm, let's actually not keep the single characters and make them more verbose.\,. (9:17)

.\,.\,Ah, alternatively we could use formats for relation entities, and e.g.\ write `\%s might refer to \%o'.\,. well except that we don't generally have a specific object to insert.\,. (9:21) .\,.\,But we could just insert an ellipsis, then.\,. .\,.\,Hm, maybe I like it better that the subject is just meant to always come first and the object last for this meta type, and then one can always add another relation meta type if there is a desire.\,.

.\,.\,Alternatively, to limit redundancy (i.e.\ having too many choices for have to make a relational tag), we could also just add an `\%s'-placeholder syntax to the properties, where `\%s' can then be replaced by.\,. `this'.\,. Hm.\,. .\,.\,where `this' can then be rendered differently, perhaps by making it a link.\,. .\,.\,Hm, I'm wondering about this `\%s' syntax, but maybe it could just be exactly that.\,. (9:29) .\,.\,Hm, or we could write `[this]' instead, maybe I like that better.\,. .\,.\,It shouldn't be a link, I think.\,. .\,.\,Hm, maybe `[this]' could even just be rendered as is.\,. .\,.\,Sure, at least in the early versions of the app.\,:) (9:32) .\,.\,So this allows us to use the property of `entities that [this] might refer to', instead of using the `might refer to' relation.\,:) .\,.\,Hm, unless the latter (i.e.\ `might refer to') is preferable.\,.\,? (9:34) .\,.\,Hm, if so, we might as well just overload the `properties' by using a convention that they should generally be nouns if a suitable one can be found, and else they can also be these partial sentences, with the subject and the object cut out at the two ends, respectively. I think I might say that.\,. (9:37) .\,.\,Or they can also use `[this]' to refer to the subject (/ owner) entity if the other two options doesn't work so well (somehow.\,.).\,. (9:39)

(9:49) Wait, I should probably just let the text and the binary entities store their content/file type instead, giving these tables an extra column each. .\,.\,And the I could just let it be up to the app to verify that any received data has the correct format.\,.
.\,.\,Okay so these two tables will just get another varchar(255) column as part of their secondary index, and the backend will generally not promise to verify the given format.

(11:01) Okay, about the property docs, I can use a format like `123:124,125;234:345,\ldots' in the backend and the backend--app interface, but I might still want to encode the def in JSON for the frontend insertion files.\,. .\,.\,Yeah. And the JSON should then just encode an object with either a string or an array of strings as.\,. Hm.\,. .\,.\,(11:09) Ah, maybe I could just always carry around a `property document'-like string for all callbacks, together with the outID.\,. And that string will only ever have to be one level deep.\,. .\,.\,Not a bad idea.\,. .\,.\,Hm, or I could rather make a virtual meta type of `property document' to insert.\,. wait, it doesn't have to be a virtual type, since I need this meta type anyway.\,:) (Well, technically it would be a text meta type with a `property document' format.\,. but I guess that's also just as fine.\,.\,:)) (11:15)

\ldots (11:36) Ah, let the text entDefObj's always hold an array of strings to be concatenated, rather than holding the text as a single string (for its `text' property).\,:) .\,.\,Ah, and I can of course just concatenate before I call getSubstitutedText().\,.

.\,.\,I by the way think that I will simply let uprateProperties() always query the database for the property text, then upload. So I don't need to pass those strings along with the outID/entID for the callbacks, as I otherwise talked about. (11:41)

(12:00) Note that the actual HTTP header content type should NEVER be anything other than just text/plaintext or octetstream (or whatever it's called) when we let verification be up to the frontend. *[(19:02) Well, for images and videos to work, we have to set the content-type header, which means that the backend \emph{should} verify the binaries of these formats.]

(15:06) The ``text/plaintexts'' are nt so plain after all, since we convert entity references to links. So I should find another name.\,. Hm, and why not just `text'?\,. .\,.\,Well, I'll think about it.

(15:35) I had a good idea when I was out walking earlier about how to implement the property document findOrInsert(). The idea is to just make a call to findOrInsert() for all properties and property values at once from the beginning, and then just give each individual callback an index as well. I will then also record an array of all the delimiters that there should be in the final prop doc. And when each callback resolves, they add their entID to another array, together with the index. Then this latter array is finally sorted (once it is checked to be of full length) such that the index values match the index in the outer array. And finally all the IDs are then braided together with the delimiter array, given us the final property document.

(19:34) I just considered adding another unique index for SemanticInputs with rat\_val and then user\_id at last, instead of having the statement---user rater bot, but no. It's better to use bots here, since we want to be able to filter users out.

(19:39) Another kind of meta type(s) that we maybe \emph{do} want to implement at some point might be images etc.\ from external sources. These can then be shown by the app as the images themselves (instead of an URL), even though they are stored in the database as URLs.

(20:07) I think I might actually remove the InstListHeader (and therefore also not implement the ListGeneratorColumns) for the early version of the app. And then I will just implement one global menu where users can choose their queryUsers and adjust the weights of these. Then there should also just be an infinity weight, which can be given to oneself, as well as potentially any factual bots such as the statement--user rater bot. (20:10) .\,.\,This means that users won't be able to combine two (or more) tags in a combined search for the first version of the app, but maybe that's okay.\,. .\,.\,Hm, or else I can just make a new kind of search column specifically to combine tags, how about that?\,.\,:) I think this is what I will do.\,. (20:12)







\section{Structured discussions}

(12.04.24, 9:05) I have written about some ideas before of how structured discussion could work, probably in my 2021 notes, if not the 2022 notes. Let me add some new thoughts here, and then also dedicate this section in general to ideas about the whole `structured comments and structured discussions' part of the SDB application idea.

In general, whether we are talking about my `debate/discussion website,' which I have wrote about before, or the comments discussion of the SDB app (note however, that the former might be implemented within the latter), it's a good idea if we can promote Bayesian logic (note that the `ian' suffix often gives associations to a \emph{persuasion}, and thus that Bayesian logic might not be true, but it is: It is a mathematic truth% Of course, there's semmingly the frequentist--bayesian debate, but I have disproved frequentism here in these notes.
) in the decision making process for discussions.
And this is by the way not just for discussion forums on the web, but it might might also be relevant to e.g.\ courts etc.

The idea is that the participants first give their overall opinion of how likely they think a given statement, i.e.\ the overall one that is being discussed, is to be true given only what was known prior to the event and/or the evidence gathering and discussion phases. Then the participants try to list all relevant pieces of evidence that can be used to inform us about the truth/falsity/probability of the statement. One could start with all the existing pieces of evidence when the discussion ``starts,'' but one could also make no sharp distinction between preexisting and future/subsequent data sources. But I think it might be a good idea, when we get to rate the likelihoods of these ``datasets,'' that each individual notes whether the rating was done before or after the data outcome was known to them. So for each ``dataset''/``experiment'' there is both a ``prior'' probability assignment done before the data is known, but also one that is done afterwards. This is important since it is likely that most participants, if they have a stake in the discussion in anyway (including simply a desire to ``win''), would want to change their ``predictions.'' before the data is known. And instead of disallowing this, I think it is better to allow it, and then the community can instead just note which users have a habit of changing their ``prior probabilities'' a lot, and then for the future take their initial and/or their subsequent predictions all the more with a grain of salt (if the shift is often great from before to after, that is). But before I move on, let me try to make the terms less physics-like, and try to make them more realistic. For the ``experiment'' will often not actually be `experiments' done by `scientists,' but will often be something like predictions about what will happen in the future, predictions of what certain involved people might say or do in the future (or have done, if we are talking about the `post-prior probability' assignments, as we might call them), what experts might say about the topic (so we might also treat what experts/scientists might say about the topic as an ``experiment'' as participants of the discussion, and assign (post-)prior probabilities to these). Oh, and you are unfamiliar with the term `prior probability,' look it up quickly, but also know that if I just wrote `probability' instead, it should also make sense.

So we first, as participants, rate the the overall prior probability of the statement being true, as if we knew no particulars about it. I guess we actually have to be specific about what we deem as this overall knowledge, and what is considered ``data''/``experiments.'' But in general we are talking just about `patterns in the past,' essentially. Yeah, `patterns in the past' is the keyword.\,. .\,.\,And the participant's overall beliefs regarding `patterns of the past and present.'

Then we try to come up with good ``experiments,'' which I will try to stop calling it now, and call it `data sources' instead, that could enlighten the question. These can be data sources that have already provided their data (an expert might already have given an opinion, an involved party might already have done/said something, etc.), or they can be sources that is expected to potentially provide data in the future (near or far). Each user then rates the probability of the data turning out one way if the statement of the discussion is true, as well as the probability of the data turning out one way if the statement of the discussion is false. And yeah, note that we should indeed try to make treat the data outcomes as binary.\,. well, unless we want to implement a more complicated system where users assign ``prior'' probability curves to a whole interval/space of outcomes. But if not, then cut the interval/space in half and divide it two outcome groups. And if we do so, it means that we only have to assign two (post-)prior probabilities for each data source. But yeah, a more complicated/sophisticated implementation might also be useful in the future, and here it is a good thing that ``prior'' probabilities can also be assigned after the fact.

Of course the participants can cheat and give dishonest probability assignments, and they can also try to draw previous assignments back by making marginally different post-prior probability assignments, but the user community can just be on guard for this, and down-rate users that behaves in a fishy way.

Now, the great thing is that from here, it's basically all math. Of course, you have to take into account that users can be dishonest, and you also have to settle on conventions for how to use the actual-prior and the post-prior probability assignments by the participants (i.e.\ settle on some weighted mean of these two things), and have t figure out what to do with users who change their probability assignments to much. But after all this, the resulting probability for the statement of the discussion can be obtained mathematically. Oh, and you of course also have to factor in user trust values to begin with. Luckily this does not need to be done in a centralized way. Some users will assign different trust levels to different user groups, which might change the result of the discussion. And that can then just be calculated for their settings particularly, and other users with different trust settings will be able to see a different result (and will also be able to see the results for all the other (popular) user trust settings). (10:03)

(12:20) Oh, I must mention the ``just math'' \emph{can} be quite complicated, though, if there are correlations for the data sources.\,. But still, this process could still greatly improve our decision making.\,:) .\,.\,And online discourse in general, for sure.\,. .\,.\,:)


(15:24, 16.04.24) About the correlation statements, while this in principle could be the only tabs for a statement (as part of a discussion), this would be way to complicated (especially to understand). So the main tabs should still be `arguments for this' and `arguments against this'.\,.

\ldots Maybe I didn't (get to) mention the idea to make it a `correlated statements/proposi-tions' instead, but that's what I've been thinking---besides the fact that it should not take the place of the more natural `arguments for this' and `arguments against this' tab.\,.

(16:52) There's also the fact that for big enough discussions, the correlation between various statements can also be obtained (to some level of precision, not far worse than if the users were to rate this correlations manually) from analyzing the correlations in the predictions of the users (of the probability of each of the proposition in the group of what's been deemed as `correlated statements').\,. .\,.\,(I know that not a lot of what I've been writing here this afternoon will make a lot of sense when reading it: These notes are quite brainstormy.\,.)

(17:06) Oh, I just had a perhaps very good idea about always choosing an antecedent when making a \emph{probabilistic statement}, i.e.\ a statement/proposition that is meant to be rated in terms of probability by the users. And then sometimes, the antecedent can just be `(only) what we know overall about the subjects, without including any facts/details specific to this case' and other times it can be, well, also that, first of all, \emph{and} also another statement/proposition on top, which means that the user then rates the probability of the given consequent statement when it is assumed (without knowing anything else), that the added antecedent is true. (17:11) .\,.\,And thus the users can rate the correlation of two statements/propositions.\,. .\,.\,This is a.\,. \emph{very} good idea.\,. (17:15)

(9:52, 17.04.24) One can probably even think about these `correlated statements' more intuitively as ``data.'' And that might make it more easily understandable, and mean that this can be part of the discussions at a sooner point, perhaps from the beginning, even.\,!\,:)

And about the other tabs for the discussions, apart from a summary tab, where users can supply and uprate comments that tries to summarize all or parts of the discussion, I think there should be a sub-discussions tab, perhaps instead of having the two arguments and counterarguments tabs.\,. .\,.\,I'm thinking along the lines of rating the sub-discussions in terms of importance, first of all, where this `importance' rating is then a combination of how likely the sub-discussion is to be resolved (from the reader's perspective, of course), in a near future at least, and then of course also how important the answer to the sub-discussion is for the parent discussion.\,. Then apart from this `importance' rating (which determines the order of the list in the tab), there could then be separate ratings of `how important an answer to that sub-discussion would be in terms of how determining/guessing the answer to the parent discussion'.\,. Hm.\,. .\,.\,Well, this could also just double as the `importance' rating, meaning that.\,. wait, no.\,. .\,.\,Hm, or maybe yes.\,. .\,.\,Hm yeah, since this is not the ``data'' tab, we should not be worried about determining probability 
correlations or anything like that, so maybe `importance' is simply enough.\,. (10:06) .\,.\,Hm, yeah and you can say, \emph{if} the users are really serious about it, then the ultimate goal of the discussions would actually be to inform the readers in order to better be able to decide on how the ``data'' probability ratings should be given.\,. (10:11) .\,.\,Including what we can fittingly (as opposed to how I have used the term above in this section) call the `prior probability' of the discussed proposition to be true, i.e.\ when not accounting for any of the ``data'' at all. (And note that I use double quotation marks here to remind ourselves that this ``data'' can be much broader than measurements, which is typically associated with the term: It can also be what involved people and/or experts say and do in relation to the subject, and much more---it can be anything, really *(except for what we could call the `background knowledge' of the subject).) (10:16)

.\,.\,Hm, so that could actually be a quite simple discussion system, outside of the ``data'' tab. Then there would just be the summarizing comments tab, and the sub-discussions tab, which are mainly just rated according to importance---oh, and also how likely the users deem the statement of the given sub-discussion (each `discussion' entity is formulated as a statement (text-based, not tag--instance pairs)) to be true, of course.\,. (10.21) .\,.\,But this probability is only meant to.\,. or wait, could this be part of the ``data'' tab as well, or.\,.\,? \ldots (10:48) Ah, we could just use the same probability tag template for this rating, and then \emph{if} the given statement is also uprated as part of the ``data'' statements, then the rating automatically applies there as well.

(11:11) There should also either be a tab with comments about what the `background knowledge' is, or this should otherwise at least then be considered an important part of the job of the summary comments.


















\chapter{Economic ideas}

(12.07.23, 18:39) I just got an idea for a different version, basically, of my SRC idea. The idea is to propose it as a policy instead, much like ``Økonomisk demokrati.'' In this version, the proposal would be to make it so that.\,. Well, basically that firms are required to become like SRCs.\,. Hm, it could maybe then be part of a sales tax that the government is then required to buy the given company's assets for (and the company is required to sell, I guess) and to give those shares to the buyers. Now, the reason why I think this idea is interesting, although it kind of ruins the whole freedom of my SRC idea --- and the fact that it does \emph{not} require policy changes --- is that this version is perhaps easier to understand and discuss as a first step, before moving on to discussing my actual SRC idea. And this might especially be true for people used to thinking about politics, which *(as I see it.\,.) will likely be the majority of the people who is likely to find the ideas interesting to begin with. So maybe proposing the as-policy version of the SRC idea might be a good place to start. I think I might go forward with this idea.\,. (18:50)

(19:41) There shouldn't need to be any laws required in regards to make the companies sell the shares to the state. So it will just be a certain new sales tax, where the state is then required to buy shares for the same amount (and give it to the buyers), which means that the companies basically owe the customers, through the state, a certain percentage of there shares at each interval. And precisely because the costumers are the recipients, and that the shares received is exactly proportional to the money spent by the given customer, it means that the companies can just raise their prices accordingly, such that no party, neither the company, nor the state, nor the customer, has any losses or gains in total by these transactions. (19:49) .\,.\,This is of course opposed to the ``Økonomisk demokrati,'' which, as far as I understand, was supposed to be payed by the employers. And another advantage of this model is that, instead of requiring a lot by each citizen, since they are forced to become investors and figure out where to put the money (.\,.\,which I guess was the case for the ``ØD'' model, but I'm actually not sure after all.\,.), all the customers have to do is to, well, be customers (much like before). .\,.\,Well, and then they have to also give votes, if they want to use the power that this system gives them over time, but they don't \emph{have} to do this, of course. (19:55)

(15.07.23) Hm, maybe I won't go forward with this right now after all.\,. The thing is: In order for the idea (both my original as well as this one) to really work well, we probably need the good discussion websites that I hope my web ideas can bring about first.\,. .\,.\,First of all the ideas need more thorough discussion before we can be sure that they are good ideas (of course with my SRC idea, we could also just try it out and see, but an initial thorough discussion would still be the best way to go). But what's more, the system itself would probably work best if it is accompanied with good discussion and negotiating/voting sites like the ones I imagine.\,. I feel like this is the case, anyway.\,. .\,.\,So I think I will just keep on focusing fully on my website project for the time being.\,.


%(22.08.23, 17:11) Jeg kom hjem fra forlænget weekend i går aftes, og i dag har jeg bare været til A-kasse-møde og først gået og nu løbet en tur. Jeg holder nemlig lige en lille pause med openSDB-projektet (og bare lige venter er ser om der er nogen, der svarer fra den der Semantic Web Interest Group). Jeg fik lige tænkt en tanke på den der løbetur omkring idéen her fra denne sektion, som jeg synes er værd at nævne, så den kommer her.
(22.08.23, 17:14) More on this idea: If the state buys a small portion of the lands assets at frequent intervals and gives.\,. no, lends them to its citizens (such that they get the.\,. %avance, afskrift på dansk.. hm.. ..dividends, tror jeg det hedder!.. *Ja.
.\,. dividends on those assets), then a very good idea would probably be that they cannot sell this kind of stock (that they get from the state this way). They can however trade them for other stock of the same kind, but not via personal trades. Only via a.\,. .\,.\,central kind of exchange instance run by the state, where people can submit trade offers, not to other individuals, but anyone has to be able to take the offer. (And it should also be illegal to make trades where other valuables and/or money is involved in the trade, so that if people find a way to game/hack that system, it is illegal). When a person dies, their stock of this kind is given back to the state and redistributed to all other citizens, at least partly: A state might also decide that relatives of a deceased person can inherit some (or all) of that stock directly. And there we go. A system where the citizens will slowly take over the assets of a land, not at the cost of the previous owners, at least not directly in any way (because they are reimbursed for them), but at their own cost. And while they then have to carry this cost, they also don't lose something of value, since they now get the dividends for the shares that they get this way for the rest of their lives. And if the state says that it can be inherited by relatives, then that stock will keep on benefiting the family once the person is gone. So the average people do not lose anything either. On the contrary, the system helps them gain more and value in the society, creating less inequality. (And this is not contradictory to the previous asset owners not losing money: What they will lose instead is just their dividends---over time---since less and less free stock in the country/world will mean higher stock price per dividend. So the rich people will not loose anything of value immediately (due to the rising price of the ``free stock''), but they will lose future earnings.) %(Ah! There was the word I was looking for!.)
Going back to the average person, for them the system will just mean that there pension plan will be slightly changed in terms of how it works, namely since (as I see it) the system will work pretty much just like an added pension system for these people. This was to drive the point home that, even though all people now have to pay more in taxes, they shouldn't see it as a loss---and in fact, it would be natural to just lower other pension payments in the state at the same time as this system is implemented. (17:43)





\section{Small note about cryptocurrencies}

(25.07.23, 15:15) I have pretty much abandoned all my ideas about blockchains. But I just thought about the fact that maybe it is actually worthwhile to propose a simple proof-of-public-history chain, namely where there is no mining going on: Instead the miners are exchanged for (independent) firms/parties that provides the service of keeping a public ledger over transactions, and also to spy on other such parties and make sure to sound the alarm if all of a sudden the checksums of any given interval of another party's ledger doesn't add up to what is used to. All these parties are also supposed copy all valid transactions from each other, and if one party fails to copy and record (and show in their ledger) a given transaction, that the majority of such parties have, then they can also sound the alarm on that given party. And as payment for these services, the parties can simply take a small fee in the transactions. A user therefore chooses a party/firm to send their transaction to, and can include a payment to that party as well as part of the transaction in order to make them record it. Hm, I guess that it would be handy to also be able to compress the ledger somehow.\,. .\,.\,Yeah, and the parties \emph{can} do this. They can declare a compression publicly, and then give the other parties (and all their users) some time to reject to this compression. And if no parties record and show their rejections, then all users (that trust a majority of these parties to not want to do anything that compromises their trust in the project) can trust that the compression was legal. So there we go. To begin the project, one simply defines an initial PoW chain, and define a curve that ends the mining rewards after a time. And after this time, the miners are supposed to have been replaced by a number of independent parties, that are willing to store and give public access to a ledger, and to make sure keep to the rules in order to accumulate trust among the users, all for the price of requiring some transaction fees for the users that chooses to send their transactions to them. (15:34) .\,.\,This solution is not very different than PoS, except that it does not give power to anyone in particular (as opposed to giving power to the big stakeholders). It is not vulnerable to users beginning to rely to much on it, such that the stakeholders are able to get away with small cheats to the system. For if any of the mentioned.\,. ``public history parties,'' we could call them.\,. if any of those do not comply to the rules, it will hardly cause any bump in the road for the cryptocurrency, since other parties will have recorded the same transactions.\,. Hm, I guess one should think more about a few things, such as the incentive to.\,. Oh, never mind about that particular thing: A transaction can be considered as having gone through once a majority of the parties have recorded the transaction and confirmed that it is valid (including that the money is there to be transferred). After that no other party that cares for their reputation will want to add any transaction that conflicts with the given one, and they will also make sure to record the transaction themselves in order to maintain their reputation of commitment to the rules as well. .\,.\,Hm, what was the other thing that I thought about.\,.\,? (15:47) .\,.\,Well, I can't recall, but I don't think it was that important either.\,. So let me just stop here.\,:) (15:50) .\,.\,(15:51) Oh, it was about the order of transactions, but I've also answered that now as well: The exact order is first of all not important, and one can rely on the parties to be able to agree to an overall order of transactions, sorting out any disagreements that might occur in order to let the transactions through ('cause if a party is behaves in a contrary way, not being very agreeable, it would simply damage their reputation for being a good and helpful actor in the set of PH parties). (15:55)





\chapter{Hopes for the future}

\section{Some hopes for the future in terms of what my ideas can hopefully help bring about}
\label{Some_hopes_in_terms_of_my_ideas}

(16:35, 24.01.23) In terms of my SRC idea, my other economy-related ideas, and my ideas about happiness and local communities.\,. %Oh wait, I have some other stuff that I want to write about my web ideas.. ..Hm, jeg tager lige en kort pause og for samling på de og disse tanker.. ...Oh no, they are actually related to this section.. But.. Hm, let me just mention them in the Web ideas section first.. ..There..
\ldots I really hope that this can lead to a future where people generally are busy with activities/businesses that are much more efficient in adding to their own and other people's happiness and at the same time much more efficient in advancing our technological level. The way I see it, the two things goes hand in hand quite a lot, for in my opinion, the way in which we busy ourselves according to the current societal systems are just very wasteful. Most of these activities deals with bettering the lives of, well, consumers, but I believe that if you look at the calculation in terms of how much the activity of each person actually benefit or total happiness, this activity is generally very inefficient. The big trouble is that our society is geared towards an unspoken, unelected ``philosophy'' that consumption brings happiness, when in reality there are much, much, much more important things to consider, especially in generally wealthy societies. I thus believe that if we really think about it and start planning our lives and societies better (in a decentralized way, btw), we can achieve much more happiness as people for a fraction of the effort. And this means that we can generally spend much more effort into activities that advance our technological level as well, so its really a win--win: If we optimize our activities in terms of bringing more happiness to people, we can then also spend more energy on activities that advances us as a civilization.

Okay, so that was some very broad strokes in terms of describing what my ideas related to these topics might be able to help achieve, without giving any reason why. In terms of my economy-related ideas that aims towards less capitalism, I then believe that these ideas can basically help us get out of said unspoken, unelected ``philosophy;'' help us get away from that direction as a society. 

And then there's the idea, which I haven't written about in a long time, about being able to ``pay workers/contributors backwards'' (what I have often called ``bagudbelønning'' in my Danish notes). I think this could bring about a lot of good in the future, but probably in terms of the web more so than anywhere else. I have just written somewhere above that I hope that the scientific community will generally join and take big part in the semantic web at some point in the future. I then also really hope that this will bring scientists and all other people much closer together, so to speak (i.e.\ working together), with amateurs also being able to take quite a big part in science and knowledge sharing.\,. which they already do a lot, come to think of it. And I hope that a good community around giving donations to helpful contributors, both amateurs as well as professionals (to thus add to their total income), can do a lot of good for the web. Maybe this ``backwards payment'' could even be a big part of getting scientist to join the semantic web in a big way.\,.

And in terms of my happiness ideas, well that goes pretty much without saying: If these ideas can be efficient in bringing happiness to people, this can then save a lot of wasteful and inefficient work/business/activity at bringing consumers happiness, and this saved activity can then be used on other things instead. 

In terms of the ``planning'' of how to change direction as a society, finding what problems to solve, and in terms of finding out what can more efficiently bring people happiness, I think that the semantic (and user-driven!) web can really help with all these things, potentially. One of the reasons for this is of course that I believe that we will be able to discuss matters much better on the semantic web, both in terms of the quality of discussion (because they can be better structured and because more people can be engaged in a single discussion), and also in terms of the quantity of active discussions that we as a civilization will be able to handle at once. But apart from this more trivial point, I also think the future (user-driven) web really can help people find together with other people with similar interests, and can be used much better to find ideas for activities --- and also ideas to structure one's life. Ugly sentence (and I've had a lot of those today) *(I was a bit roasted when I wrote these notes), but I hope it makes sense (at least if one has read my previous notes.\,.). Thus, I think that the ideas regarding ``user groups'' and ``user-driven ML'' will make people able to much better find things that interest them, and to be able to much better find people to be friends with. And as I have written about in my earlier notes, I hope that we will get to a point in the future where it will be normal for people to move together in small or larger communities with others that share similar interests, a similar demeanor, a similar approach to life, and so on, and that people will thus end up living much more in communities with exactly people they want to be around, instead of just living more or less with a random sample of society around them, and then having to look for friends other places. 

Alright, this summarizes the some points of what I hope my ideas can help achieve. I know this section, what I have just written, isn't super well-written and easy to understand (without understanding the ideas mentioned already), but I just had to write these thoughts down, at least for my own sake. So here we are.\,.\,:) (17:58)


(15:38, 26.01.23) Copied from above: ``And just to make clear, there is also another great point, which might not be so easy to ``sell'' since it is hard to argue that things will go according to how I imagine them, but which is really the big underlying reason why I'm so interested in all this. The point is that I believe that this technology can get us to a point where all of science can also be structured in a great semantically linked graph such that is becomes easy to look at all point and counterpoints to a given question, and to look at all existing solutions to a problem (and see arguments for their benefits and drawbacks). The same can also be said for open source programming: I believe we can get to a point where all programming solutions (modular) can be ordered in a great semantically linked graph. I believe that my ``Web 2.1'' ideas here, as we can call them, potentially might be able to bring about such a future, and I really think that this will mean so much for our scientific (and societal) advancement.\,.\,! %(Let me by the way mention here in the comments that I have thought about this today and reconsidered if I still really believe that my Web 2.1 ideas can lead to this, and luckily I have sort of arrived at the point where I think I will double down on that belief. For the way I see it, having a semantic graph over web content can very well become very popular, and this might very well further lead to the scientific --- and open source programming --- community/ties also making use of this technology to structure all scientific knowledge and discussion (each individual scientist (or programmer or amateur) taking part partly of selfish reasons to make their work reach a larger audience). And once such a well-structured graph becomes a reality, I believe this will... Hm, let me actually write this in the rendered text instead.. )
Let me by the way mention that I have thought about this today and reconsidered if I still really believe that my Web 2.1 ideas can lead to this, and luckily I have sort of arrived at the point where I think I will double down on that belief. For the way I see it, having a semantic graph over web content can very well become very popular, and this might very well further lead to the scientific --- and open source programming --- community/ties also making use of this technology to structure all scientific knowledge and discussion (each individual scientist (or programmer or amateur) taking part partly of selfish reasons to make their work reach a larger audience). And once such a well-structured graph becomes a reality, I believe this will greatly increase people's --- scientists/programmers as well as all other people --- ability to look up specific knowledge and to engage in discussions and innovation/solution-finding processes. I thus see that this technology can maybe sort of create a giant online collective intelligence --- not an artificial intelligence, but metaphorically speaking still a big collective brain. These are large words, but I really do think that such technology will give us intellectual powers as a civilization that is many times greater than what we have now. Anyway, I hope so.''


(12:13, 27.01.23) Hm, I think that AI and semantic web technology can potentially both be really instrumental in the development of each other: I believe that the development of A.I.\ can be greatly accelerated by having an open ``predictive model,'' as I have called it (or we could it a predictive knowledge/statement graph.\,.), with a lot of active users, and I also really think that AI could help the the development of such graphs a lot, namely since AIs could help generating a lot of these graphs automatically. I really see the potential of a great ``symbiosis'' in this regard.\,. But let me point out, that AIs will not be able to give us such predictive knowledge/statement graphs on their own, since a big part of these are open and free way for each user to implement various algorithms for distributing trust. Furthermore, while future AIs might get the ability to keep an internal ontology over the (conceptual) world, such an ontology might be very unreadable to humans, unless said internal ontology developed ``in symbiosis'' with a human-readable semantically structured knowledge/statement graph. (12:24)




(02.06.23, 13:07) I thought about my ideas for a ``happiness currency'' (or whatever I used to call it) last night in bed. I believe that my last notes on that subject is actually in the comments somewhere in my 2021--22 notes. I moved away from the idea because I came to the conclusion that me idea that would later become my ``SRC idea'' was much more likely to be able to lead to a similar kind of future, and much quicker as well. I still believe that, but I just thought about how, once we reach that state where power and wealth will be quite broadly distributed, then.\,. Oh well, maybe I'm actually just about to reiterate what was already an earlier conclusion: that there is a small step from the future that SRCs (in my opinion) promises and then to further implementing a system where people's income will be decided by a democratically run system/model that rewards all kinds of behavior that creates happiness for others, both down on the level of the local community that the given person lives together with, and to any group of people above that. And the happiness-creating efforts are then not limited to working hours: If you are active in your community in your free time, this could in principle be rewarded just as much by such a system. So about getting away from that ``philosophy'' that down-prioritizes any free-time work/efforts that a person offers to their fellow people, such a system might help us get away from that. It might boost people's interest in working less hours at their daytime jobs, and then use some of that time to do, what we today would call ``voluntary work.'' Of course it has to be noted, that giving financial rewards to people for making other people around them happy, does have a little bit of an.\,. iery.\,. *(oh, `eery,' of course (13:30)) Hm, I can't find the right spelling for that word, so let me just say: an discomforting ring to it. And it will certainly be important to discuss such concerns thoroughly before implementing such a system.\,. well, at least on a large scale, but of course it could just be tested by small communities first (which is what should be done for all such suggestions (following what I have discussed in earlier notes about testing different societal ideas in small communities)).\,. (13:31) But maybe a system like that could really boost people's engagement in local activities in a good way; without causing much of a feeling of people ``faking it''.\,. .\,.\,I'm not completely sure, but I actually think it could.\,. .\,.\,Yeah, and for some reason I find that thought quite comforting, so that's why (for one thing) I wanted to take some time now to write these notes (this paragraph) about it.\,.(:)) (13:35) .\,.\,Oh, and just to underline, part of my point here is also that that kind of system would not require nearly as much.\,. todo.\,. as what I wrote about in my last notes about the subject (as I remember it). It would thus not require any future promises.\,. Oh, and more to the point: It would not require a \emph{currency} (which my last notes on the subject was about)! It would instead just require a democratic system where some money are pooled together at frequent intervals and then distributed out as a sort of income to people, where good deeds for the society (the local one or the more global ones) are then rewarded with a little extra. And I guess these are the points that are really worth mentioning here, namely that once the SRC future has already become a reality, one does not need a lot, and in particular not a new \emph{currency}, in order to still achieve what my earlier ``happiness currency'' idea sought. (13:43)



%(07.09.23, 18:49) En lille hurtig note, som jeg bare kan give her ude i kommentarerne, er at jeg jo stadig tror rigtig meget på min e-demokrati-app, og tidligere i dag kom jeg så til at tænke på, hvordan, som jeg før sikkert har skrevet et sted, det kunne være rigtig fedt med en grundig model over, hvordan samfundet (f.eks. det danske samfund eller verdenssamfundet, osv.) fungerer. Men så tænkte jeg, at lige netop denne app, der jo på sigt giver en model, kan vi sige, over forskellige grupperinger i samfundet samt deres løfter og holdninger til ting, kan være det perfekte udgangspunkt for sådan en samfundsmodel. På en måde vil den jo allerede føre til en slags samfundsmodel, hvis idéen kommer til at gå så godt som den kan. For så vil alle forhandlinger jo være med udgangspunkt i nogle instanser i samfundet, og hvordan de interagerer med hinanden. Så ja, man kunne faktisk få lige netop en sådan udførlig samfundsmodel herved.. Ja, eller i hvert fald hvis brugerne/grupperne så også i reglen sørger for at prøve at lave en (del-)model over, hvordan de instanser de administrerer / er en del af fungerer under forskellige parametre, hvilket jo kan være en god måde at formulere sine løfter til andre grupper/instanser, som er med i appen. Så ja, \emph{hvis} idéen udlever sit absolut fulde potentiale (og måske lidt mindre endda), så kunne appen altså også lede til netop sådanne (vildt detaljerede) samfundsmodeller. (19:00)
%(08.09.23, 8:47) Ja, så fra en e-demokrati-app kan systemet altså potentielt set udvikle sig til en hel model over alle mulige instanser (inkl. private virksomheder osv.) i samfundets forhandlinger samt stående løfter med hinanden (og muligvis inklusiv fremtidige løfter, der så kan afhænge af parametre).



\section{Some comments etc.}
(18.10.23, 10:38)
Let me just write a few notes here that I've had on my mind.

.\,.\,Okay, maybe this will actually be quite short. About the consumer union idea, I just want to point out that part of the motivation is create an environment where bad costumer experiences are more easily shares with the rest of the consumers as a group, and decisions to take these into account and do something about them will be greater. .\,.\,I feel like this should be unpacked a bit by some examples, but I'll just leave that for the reader to do here.\,.

Another point about the consumer unions, that I've probably mentioned before also, is that it could mean that the consumers could actually work together an help the industry in some ways, namely by ordering product in advance and in general behave more predictably. Of course, a significant level of unpredictability is necessary for consumer happiness, since people have different needs, and people also want e.g.\ their furniture (etc.) to be unique for them. But while everyone want some level of uniqueness to their combination of belongings, a lot of people, I think, could be perfectly happy---perhaps even more happy---with fewer choices when it comes to certain things. If consumers with similar.\,. indifferences would then join together and make big orders together, it might thus both ease their lives and the lives of the manufactures and sellers etc.

Then there's of course the big point about it being easier to be political consumers in a unified group, and a big example here is the consideration for environmental issues. But another example that I've thought about could also be to boost.\,. the wheels of industry locally to the consumer union. So that the consumers become a part of the bigger economic picture and help.\,. not \emph{plan} the economy, but to \emph{help} plan what the industry should aim for.

About another topic, namely e-democracy, I still really think that an E-democracy party like I've written about (maybe in some notes out in the source comments from 2022, I'm not sure.\,.) could become a great (and popular!) thing. And a big point about it that is worth underlining is really the transparency aspect of it. Present-day parties often have a big incentive to keep their fundamental, day-to-day workings---their deals and decision processes---hidden from the public. Not only would an e-democracy party be incentivized to the contrary; to make their decision making processes public, but since the party is comprised of all interest group in society, the ``inner'' dealings would be.\,. well, much more interesting.\,. when it's not just about dealing about what policies to follow between almost like-minded people, but is the very meaningful dealings across groups in society. An e-democracy party could thus make a whole show about their discussions, even one that might be entertaining to watch (for anyone who is interested in society and the questions and need for decision-making that it faces).\,. (Don't expect me to write very elegantly right now, by the way.\,;):)) I'm thinking televised discussions, where interested people can follow along, and where they can dive into any sub-party's own decision-making processes, before and after a debate. But anyway, even if this is a thought that is easier said than done in reality, I'm still sure that an e-democracy party could get a lot of positive attention and trust by publishing all decision-making processes, whether it be the cross-party debates/discussion/dealings or those of the individual sub-parties, which might be done before or after a big debate. Now, from the average person's point of view, they will probably not want to spent any time at all, really, following debates and issues. But all will probably follow something, and enough to get an idea of what representatives they trust on a decent enough level to give them their vote(/voting power). And the good thing is, that if you are skeptical towards the party, then only need to find someone who has the time to look closer at all the published decision-making processes and that you trust enough to feel assured that if something is off when your chosen person takes a closer look at the inner workings of the party, then that person will notify you and others about that. I'm not explaining this very clearly, but the point that I'm trying to re-make (I've made it before), is just that one about how you can see it as a pyramid of trust, where each layer only has to spent enough time an effort into checking that the ones in the layer above them is doing their job satisfactory as that requires, and not any more. That way you can get a structure where the top is completely accountable to the bottom, but where each individual at the bottom don't have the responsibility to keep up to speed about what's happening at the top (since a lot of that responsibility is then handed to the next layer in the pyramid, and so on). And the lower layers will always have some incentive to follow what the upper layers are doing, either simply because of their interest in the workings and governance of society, but since the ``middle layers'' in the ``pyramid'' might very well be employed by the party and/or be the people below them who has, well, essentially hired them to be vigilant on their behalf, there could also very well be an economic benefit to moving up in the layers (not that the party \emph{needs} to have \emph{many} layers; could be only a couple for all I know), which would then incentivize more vigilance (am I using that term correctly?\,.\,. .\,.\,I think so.\,.). (11:26) .\,.\,But yeah, all in all, I think that such an E-democracy party could become massively popular.

.\,.\,I also have a few comments about my Semantic Database idea, but let my write them under the Web ideas chapter.\,. (11:29)











\chapter{Existence theory}


\section{Empathy utilitarianism}

(19.01.23) Jeg tænkte i går (omkring kl.\ et, var det) for sjov på, at man kunne kalde min etiske lovsætning, som jeg har beskrevet i de udkommenterede noter i Chap.\ \ref{notes_from_2022}, for `empatilitarisme.' Og så kom jeg så efterfølgende til at overveje seriøse bud på et navn, og så kom jeg jo hurtigt på, at man kunne kalde det `empatisme.' Umiddelbart et ret flot og passende navn. Nå, men lidt efter fandt jeg så også på, at et oplagt navn jo ellers vil være `empatiutilitarisme.' Jeg har i øvrigt ikke søgt på, om det allerede eksisterer, det kan også godt være. Men hvis ikke denne etik er kendt allerede, så håber jeg altså på, at jeg kan (være med til at) udbrede den. Og så kunne `empatiutilitarisme' (`empathy utilitarianism' på engelsk) altså være et ret passende navn. (12:39)



(26.01.23, 17:53) Princippet om, at ``alt hvad der kan eksistere, eksisterer,'' er vistnok (allerede eksisterende og) kendt under navnet `the principle of plentitude'.\,.

Det virker i øvrigt på den PBS space video (kendte ikke kanalen før), som jeg lige faldt over (hvor jeg lige har hørt om the principle of plentitude), at MUH gør nogle flere antagelser i sin konventionelle udgave, end den egentligt behøver. Men det kan selvfølgelig også bare være kritikernes overfortolkning af det (det virker som en standard ting i filosofi: Kritikere kan altid bare overfortolke et udsagn eller en teori, og kan dermed så nemt finde en måde at erklære sig dybt uenig med det/den.\,.), det ved jeg jo ikke. Men hvis ikke det bare er en overfortolkning, så kan min, mere generelle, udgave af hypotesen altså helt sikkert være gavnlig. Og selv hvis det bare er en overfortolkning, så er jeg stadig ret overbevist om, at jeg kan hjælpe diskussionen på vej en hel del. (Umiddelbart tror jeg også, at de fleste mennesker, selv fagfolk, har en ret specifik forestilling om, hvad matematik er, hvilket jo så gør det let at overfortolke hypotesen, når man så navngiver den `MUH'.\,.) (27.01.23, 12:02) .\,.\,Det skal faktisk også nævnes, at selv hvis den konventionelle udgave har færre antagelser, end at nævnte video antyder, så er det dog stadig helt sikkert, at min teori er meget mere generel end den konventionelle MUH/CUH, for det virker helt klart til, at denne om ikke andet antager hypotesen om, at der ikke er nogen global tid, og (samtidigt) at den regnemæssige kompleksitet af et univers ikke har noget som helst at sige. (Dette er en fornuftig nok hypotese, men man behøver den ikke; man kan sagtens arbejde med en mere generel mængde af muligheder.)

%Hm, lad mig lige endeligt søge på, hvad der er af grene inden for utilitarisme..
(12:47) For at vende tilbage til `empatiutilitarisme,' så har jeg lige søgt på utilitarisme, og det virker til at den eksisterende idé om `preference utilitarianism' på en måde er ret tæt på mine idéer. Dog synes jeg min version med `empatiutilitarisme' er meget mere elegant, og man behøver ikke at tilføje alle de caveats, som præferenceutilitarismen gør. Og tilmed følger der også en god forklaring med til ``empatiutilitarismen,'' hvilket der ikke rigtigt gør for præferenceutilitarismen, ser det ud til. Og hertil skal det siges, at jeg ikke engang synes det er nødvendigt at antage, at vi selv for all intends and purposes kommer til at leve alle mulige liv igen og igen, før at empatiutilitarismen er begrundet; jeg synes også en etisk grundsætning om at man bør leve som om, at man skal leve alle mulige andre liv, giver ogd mening i sig selv, nemlig fordi den bare er ækvivalent med at sige: ``Sæt ikke din egen oplevelse af lykke og smerte --- og andre følelser --- foran andres (når du skal beslutte, hvad er etisk godt og etisk dårligt i princippet).'' 

I øvrigt så er min udgave af utilitarismen (``empatiutilitarisme'') også meget præcis, når det kommer til, hvilke levende væsener, man bør (og ikke bør) begrænse det til, (nemlig fordi man bør antage, at man skal leve deres liv også (så vidt man tror på, at væsnerne kan have en bevidst oplevelse, og så vidt man tror på, at de kan føle diverse følelser)), og hvordan man skal forholde sig til spørgsmålet om, hvad det betyder at noget tilfældigvis fik et vist udfald frem for et andet. Og min teori behøver heller ikke at snakke om, at nogen personer ikke forstår, hvad der er godt for dem, osv., for ``empatiutilitarismen'' fodrer ikke, at individer, der overvejer, hvad der er etisk godt og dårligt, kan blive enige om det --- ja, faktisk så antager min teori ingen gang at der findes noget ultimativt svar på det!\,. Den siger bare, at hvad person, der stiller sig selv spørgsmålet om, hvad der er etisk godt eller dårligt, i princippet skal lede efter svaret ved at forestille sig, at vedkomne skal leve alle mulige liv (og særligt livene af de personer, der er berørt af vedkomnes handlinger (og hvor man jo gerne vil maksimere den samlede lykke (forventet af individet og dennes evne til at leve sig ind i disse andre menneskers sted) ud fra et statistisk synspunkt --- medmindre, i princippet, at man selv forestiller sig, at man i andre menneskers sko heller ikke ville have lyst til at maksimere lykken fra et statistisk synspunkt, men så er vi også virkeligt langt ude.\,.)). (13:10)




\section{An interesting little thing a want to note here *(that is about Physics as well) (22.06.23)}
(18:34) I was just thinking a bit about a video I saw the other day by.\,. 
Sabine Hossenfelder on YouTube. It's a video about entropy, where the main point is: ``Maybe their will be other life forms within a heat-dead universe in the form complex systems, hidden to our eyes. And I thought about afterwards, that it's an interesting almost-counterpoint, or at least comment, to then point out that, well, we actually know that this \emph{will} be true: There \emph{will} actually be complex life forms that, once you apply a certain basis transformation, get the form of being with functioning brains similar to what we know brains to be, whose motion will depend on the rational (and highly intelligent) thinking and decision making that these brains do. You would be able to take your heat-dead universe, look at its quantum state, and then calculate its time-evolution by making said basis change, apply a time-evolution operator with the desired $t$ parameter, during which the mention beings/brains will take rational decision that affects their motion, and then make the reverse basis change and get the right result for the calculation. And what would that basis change be that does this? Well, the basis change defined by a $\psi \to \hat U (-T)\psi$ where $\hat U (-T)$ is a backwards time-evolution operator with a sufficiently large time, $T$.

You could see this both as a sort of counterargument and as a supporting argument, dependent on how you view certain things, but I personally don't find that question very interesting, so just move on to the actual interesting part.

Because the reason why I write this now is that I just thought of something else related to this thing, which is a more interesting than what I've just noted above. The point is to say that we look at any given --- very large --- part of a heat-dead universe. We want to then calculate how our state in this volume, namely a state that we have made spacial cutoffs on, evolves over a given (not very large) time, $t$. Now, we could do what I've just said, provided that the volume is a lot bigger than the $T$ from before times the speed of light, namely since that means that the errors that we get from the boundaries won't propagate far enough into the volume to mess up our calculation. But regardless of how big the volume is, as long as it's just big enough to contain a lot of galaxies like we see in our visible universe, we can also use some other basis changes to achieve the same thing. Since the state is bounded, we can reach a significant volume of all possible configurations in the total configuration space just by using time-evolution operators alone (let alone other kinds of unitary operators), since the bounded universe (part) will be rebirthed from heat deaths a great number of times before it finally reaches the same state that it started in. So we can follow my above thought experiment, not just with the (kind of) $\hat U (-T)$ that I mentioned, but with an unfathomably big number of $\hat U (T)$'s, even if we only use one $T$ for each time order is created/reappears out of chaos. And thus, for each one of these $\hat U (T)$'s, we again have a certain basis change, that transforms our experiment in a heat-dead universe (or any high-entropy universe (with our laws) for that matter) into another problem that has us calculating the motion of intelligent beings/brains instead, whose rational decisions influences that motion. Now \emph{that} is kind of interesting to think about/keep in mind.\,.(!) (19:13) .\,.\,(19:21) It's definitely an important reply to the point/argument presented in that video, anyway.\,:)




\section{Some other notes}

(28.08.23) I have thought a bit about existence in the weekend vacation that I just had. And last evening I got the following idea which I will start off by mentioning: I should make a paper where I just say: Statistically, you can argue that we likely live in a cyclic, i.e. ``Big Crunch''.\,. .\,.\,well, ``Big Bounce'' to be more precise, I guess.\,. cyclic universe. For if you average over all the times that someone asks, will the universe keep expanding or will it crunch and then bounce?, the percentage of answers that say ``it will bounce'' will tend to 100 \%. Then I will follow that up with a section explaining how that means that all life experiences between yours and anyone else, including someone of different gender and even different species! --- and including machines (due to cyborg in-betweens)! Therefore we will not only all live again in the same as well as all slightly altered versions of our lives, but these slight alterations will then lead to alterations upon alterations, and therefore, if you have a somewhat materialistic mindset, it clearly means that we will all live all possible lives there can be in our universe. The last section should then note how this trivializes the qeustion about what the axioms of an ethics system should be: Whether you are an egoist or not, when asking yourself about what the right thing to do is, you should do so by considering what you would want if you had to live the lives of all people on the planet, as well as all people (on or off the planet) in the future that your actions might influence as well.

I should give all this some more thought, but I think I might be able to make a very short paper telling this points (with a main focus on the first point).

.\,.\,Oh, and it's of course not just with a materialistic viewpoint: If you believe in a soul then why should that soul die after your death? It will either find another brain to latch on to an experience that brains thoughts, or it will go back to your god if you believe in such *(or in a ``god'' as a metaphor, not for an actual being, but for the thing that all souls spring from (and return to and become part of)). And even \emph{if} you believe that a soul might die with the brain whose thoughts and feelings it experiences, you can make a similar argument as the one above. The likelihood that when a person/brain ask themselves/itself if there soul will live on and find a new host brain after the death of their current brain, the percentage of yes answers will tend to 100 \% in the multiverse.

So that's the first thing I wanted to mention: That I'm considering writing a paper like that. The next thing is actually also an idea / a thought from last evening, and that is that the multiverse \emph{could} actually consist of purely short experiences without it leading to ``infinite chaos.'' This is because every snapshot experience of a high enough intelligence will easily contain enough sensory inputs in that moment let alone the actual internal thoughts, which will also include a lot of information!, that this information (that defines the snapshot experience precisely) will be much more than what is needed to describe a universe and then a time and a place for where to locate a given brain in that universe in a volume outside of the universe's origo that is big enough that there are a (vast) multitude of brains to choose from! This means that non-chaotic experiences that are part of a combined experience (if you combine all the snapshots) that follows an orderly path might still be much more frequent than those that is built from just a random set of sensory inputs and internal.\,. configurational information. So there we go. I don't personally believe in snapshot experiences, but it is nice to realize that they don't necessarily lead to ``infinite chaos.'' (9:52)

(14:42) I should rather make a little paper about why hardcore materialism doesn't work, giving the example that references that xkcd strip, as well as an argument about a many-world-hypothesis universe that will then lead to infinite chaos for our prior (likelihood). .\,. .\,.\,Yeah. And I want to then end that paper with a list of examples of other hypotheses for existence that is still quite straight-forward and does not require magical-like or mystical assumptions (necessarily).

But after this paper, it does not really make much sense to make the Big Bounce one, since some of those hypotheses will be able to have.\,. ``Big Rip'' universes.\,.

(29.08.23, 8:30) I've thought some more about the topic. I guess I need to think more about it still.\,. I feel like I have some things to mention, but let me just wait until they are more clear to me.\,. (And it might turn out to be nothing new, btw.) But I should say that I can't really say that hardcore materialism doesn't work at this point.\,. What I will do now is to try not to think about the topics in my ``working hours'' and then focus back on my SDB project (where I'll start refactoring as React today). Existence thoughts (including what I could potentially write about) should then be delegated to ``free time.'' (8:37)

(13:26) I just took a midday walk. I think I \emph{can} actually conclude something very nice, and with a not very complicated analysis at all!\,:) The point is: Of course vacuum pair productions can lead to what might look like a new Big Bang in principle, only with a crazy low probability. But such a probability is incredibly large when measured against infinity, so such pseudo Big Bangs will happen an infinite amount of times in any given large enough volume of space. (And even though Wikipedia states so, I think it is a myth that the Big Rip hypothesis actually includes ripping apart galaxies, planets and atoms---although all these will evaporate given enough time.) But that will mean that we will be infinitely more likely to live in a time just after such a pseudo Big Bang rather than the initial one, given an assumption that, 1, we live in a Big Rip universe, and 2, are prior likelihood should only be calculated from that universe.\,. Well, before I even make this point, the initial point is: Whatever the case, we will be reborn in the future, even if we have a soul that only remains in this universe, and who can't travel faster than light to look for a new brain after death (of its brain). But then if you wonder why it looks like an initial Big Bang when you look out at our universe, and you think about the mentioned infinite prior for it actually being a pseudo Big Bang instead, you can just simply conclude instead that we likely live in a Big Bounce universe, or a limited but expanding universe where the Big Bang keeps happening on the edge of the expanding light cone of a universe where your soul is also able to travel much faster than light to look for a new brain after death, or else that souls are simply able to travel across universes in the (or a local part of the) multiverse, and that even if your soul started out in a Big Rip universe where time started simultaneously in every point (and is not continously starting on all point at the edge of a light cone), you are likely in one of the other, more brain populated (in the long run) universes now. (13:44) So even if you fear that your soul is, albeit immortal, bound to this universe, fear not (death); it will still find another brain at some point---and probably quite fast, even if you are the last human to live before the heat death! (13:46) .\,.\,(And if you don't believe in a specific soul that is separate from other souls in the universe, and that experiences aren't differentiated by a ``who'' that experiences it (but is just experienced ``by the multiverse'' in a sense), then Bob's your uncle anyway: you will live forever in all versions of your life, including all versions in between you and all other possible lives in our universe.) (13:50)

.\,.\,And if you believe in mortal souls, you've got to consider the fact that this means that souls can be created and destroyed.\,. Well, maybe not.\,. but if you believe so, it means that a soul can in principle be destroyed and then remade. But how is that different from having a soul be destroyed and then another one made? How is ``destroy then make'' different than ``destroy then remake?'' If there is a difference, it would be that a soul has some internal variables and/or atoms that makes it it. But where do these then go when a soul is destroyed? If they remain in the multiverse somehow, surely that must mean that the new soul that is made (not remade) will include some of those atoms and/or variables. And wouldn't that mean that the new soul created after yours is destroyed would contain parts of your soul? And doesn't that also alleviate the your fear of this happening? (I'm asking that tiny group of people on earth, if any, who believe that a souls exists \emph{but} are at the same time mortal!) Okay, that is about the time I want to spend on this very niche group of hypotheses (and I think I did a god job.\,:)). (14:00)

(14:24) Okay, there are also some other things that are worth considering, for instance whether or not time is subjective.\,. I'll think a bit more about such things.\,.

(14:55) Oh, I should also mention an important point from yesterday, and that is that it would take way less information to describe an experience by starting in some random point in space an then have a mechanism/function to search for a viable brain rather than defining the brain precisely. And that must mean, given the assumption (not at all without basis) that less-information experiences are more frequent in the multiverse, that your soul is very likely to find a brain near itself after death. So even with that little point, you now only need to fear the heat death if you fear death (and fear the few hypotheses where death might be seen as a bad thing in itself). (And if you do fear the heat death, see my point from a little earlier (just above), as they might help with that.) (15:01) .\,.\,Oh, and you could fear that your soul has a sudden expiration time, but come on, who would actually fear that.\,.\,?\,. (15:02)

(01.09.23, 12:30) ``Hardcore materialism'' can work, I guess, 'cause you can for instance assume that the multiverse has some fundamental laws for when ``it'' experiences what a Brain computes. (I personally believe that there can be several of such laws, though, which makes me think that different ``consciousness laws'' can exist for different universes in an ``object-oriented'' multiverse hypothesis.) This could also be consistent with the hypothesis that existence comes about be the multiverse / the fundamental logic ``figures things out about itself.'' And the fact that this would suggest that computations take ``time,'' it fits well with the materialistic hypothesis, because I believe that materialism cannot really work otherwise as a hypothesis: Each universe must have a restricted amount of ``computation power,'' so to speak, for materialism to work. For otherwise we could have Big Bounce universes with the Many-World Hypothesis in them, which would mean, first of all, that these will create much more conscious experiences than ``more normal'' universes, and furthermore, I believe that these would actually yield ``infinite chaos'' in terms of their average experience in them. It would follow (due to the high ``weight'' of a Big Bounce--Many-World universe) that the non-Many-World universes does not influence the total prior much and the multiverse would thus get an ``infinite chaos'' prior for conscious experiences when looking at all universes that looks like our own. (This is especially true since a Many-World universe would probably require \emph{less} information than a non-Many World one!) So if I'm right about a Big Bounce--Many-World universe leading to infinite chaos---which I think because after a finite number of bounces, the so-called ``time arrow'' (when there is no ``measurement mechanism'' to uphold it) will start to get erased, which can only mean total chaos as I see it---then materialism has to include, it seems, some hypothesis about it as well that means that universes have ``restricted computational powers.'' For if the have that, then the (Big Bounce--)Many-World universes would not necessarily ``weigh out'' the other universes in terms of the (consciousness) prior. (12:50)

.\,.\,(12:53) Oh, and note quickly that even though the Many-World Hypothesis also has the inherent problem of why wave functions with higher amplitudes are more likely (proportional to the amplitude squared) to occur, i.e.\ why don't every split of the wave function not just produce a 50/50 \% chance of being one or the other?, this is not really very important for this discussion, since one \emph{can} (I'm sure) find some solution to this (i.e.\ find a hypothesis that includes the Many-World one which does not have this problem). %Btw: Since you need such complicated assumptions to patch the hypothesis, it means that it is no longer more pure than a hypothesis where "measurements" happen quite physically in the universe, I just wanted to mention that little point (here in the comments), not that it has anything at all to do with the discussion (just a quick little jab at the Many-World hypothesis). (12:59)

(04.09.23, 13:21) In my discussion above, I forgot the fact that universes can also be created continuously. We could thus have a local multiverse where universes like ours are created continuously and then stops after some time. That can also give a reasonable prior where most experiences can be set in the time (on average) just after the original Big Bang.

%(For some reason I've been taking a thinking day, instead of continuing working on the SDB project. I will most likely get back with some more thoughts from today: I feel like I've had some very good thoughts today, but there is something I have to think more about.. ..So I'll probably get back to writing about all that (maybe there won't be too much to note, but we'll see) later today, or in the evening. (13:28))
%(06.09.23, 9:43) Met up with someone the day before yesterday (fore-yesterday.. foreday.. ..foreday and "overmorrow" could be nice choices..) for a walk and ended up spending the rest of the day with them and others. Then yesterday I took a whole thinking (and walking outside) day as well, partly because my kitchen stank because of a (removed) burned down lamp (and it was also very good weather..).

(06.09.23, 9:49) I should first of all mention, if I haven't done before (which I think I might not have.\,.), that my argument about likely being one of the very long-lived souls if there are such unfortunately isn't as water tight after all: You can easily make some assumptions about how to calculate the prior that ruins this result.\,.

And apart from the other very good hypothesis, there still is this one hypothesis that haunts the group of possibilities (that I can think of and which sounds good to me), and that is where, not just the concept of sensing an experience exists in the multiverse, but also the concept of a Subject that senses experiences. (And this would be in the ``all things exists, 'cause what else should things do other than that?\,.'' group of hypothesis (not the ``the fundamental logic finds out things about itself'' hypothesis).)

Now, if we think about such Subjects/souls, I cannot see why the soul would also carry a memory and some mechanism to produce thought (or ability to think in other words) with them, when the brain already has that. The only reasonable thing, the way I see it, is therefore to assume that ``souls'' are pure things without memories, thoughts and personalities themselves, but are simply what we could call ``Sensors'' in the universe; they \emph{sense} whatever the given Brain senses, including the thoughts (i.e.\ it senses the experience of having thoughts). You can almost view it as just a ``media player for experiences,'' in a sense.

If we assume this (troublesome) hypothesis, then the nice message that ``we are all a part of the same; our consciousnesses not fundamentally separate (and therefore we will all live all versions of ourselves and all others)'' doesn't necessarily follow. It \emph{might} very well be true still: Just because you have separate ``media players,'' i.e.\ Sensors, doesn't mean that they aren't interchangeable. But you might interpret them as not interchangeable, and I haven't found any arguments against this particular hypothesis.

.\,.\,Well, I'm still looking a bit into it (but I must get back to the other work soon).\,. But otherwise, the next thing is to go into the matters of, what is the likelihood from there that a given soul/Sensor will still live forever and experience all kinds of things. I think you can actually quite easily conclude that it very likely sticks around after the brain's death and finds a new brain. So in any Big Bounce universe or.\,. let's call it a universe with ``light cone time,'' we would get the same nice conclusion. They same applies if our laws of physics allows any single lepton or photon to cause lasting pair productions in empty space, even with the most minuscule (but finite probability). I, by the way, think that this is true, but it's hard for me to say for sure, 'cause it also depends on the physics of the wave function collapse. But if you could prove/derive that such pair productions can happen for a single particle in vacuum.\,. (10:25) .\,.\,And I know that most physicists would say ``no'' due to ``energy and momentum conservation'' but you \emph{can} have a series of transitions that ends up conserving quantum mechanical energy and momentum (energy and momentum conservation is a nice rule of thumb, but if you are treating it the same way as you are classical energy and momentum conservation, you are not understanding quantum mechanics fully).\,. (10:29) .\,.\,(10:33) If you could derive that, you would get the same nice message. But maybe you can't. And whether you can or not, at the end of the day, the true answer still relies on the physics of the wave function collapse, which we don't know. (And I'm assuming that wave function collapses are real and physical, since I don't believe in the Many-World Hypothesis.)

There is also another another kind of universe that we could live in which gives the same good result of us living forever and in all versions of the possible lives in the universe, and that is if the Big Bang is just an exploding black hole from a larger universe beforehand. Theorists of general relativity tend to take the singularities and material passing the event horizon seriously, even though it can only happen in a toy theory where you allow yourself the continuously shift the parameters of your manifold such that you ``follow the observer.'' I know I'm not competent enough in GR to state this, but I really believe that the actual (mathematical) theory can't just deal with such an event in reality; I bet that you can't define a manifold where a physical object ever crosses the event horizon, when you apply Einstein's equation to get the EOM (of the manifold plus the matter). And even if you can, we are still taking about something that takes place more after \emph{more than an infinite} amount of time in the future, so how can you just state that ``things crossing the event horizon is a reality'' with a straight face?! If you do, you are forgetting what a physical theory is in the first place: It's something to describe what we observe, not a gospel blueprint of the universe and how it works. Anyway, this is besides the point, because even though that GR \emph{might} allow such things, we know that GR (with all likelihood) need to be altered in a theory of everything when having to make it compatible with quantum mechanics. And quantum mechanics is hard to escape: If you have to combine a classical theory and a quantum mechanical one, it is all but expected that the result will also be a quantum mechanical theory. Now, in quantum mechanics you cannot have something like a black hole that is a low-energy state that is also one-way, inescapable. No, if black holes can be made to follow the laws of quantum mechanics, the will \emph{not} be one way. With all likelihood, they will instead be some low-energy states that \emph{almost} behave exactly like the classical black hole, but only almost! For even though matter might be compressed and almost-trapped near the event horizon for an extraordinary amount of time, due to energy (and information) conservation, at some point the inward movement closer and closer to the ``event horizon'' (which by the way won't be a sphere but a ball of compressed matter that is everywhere almost at the threshold of reaching the ``event horizon'' (which is then just an upper bound on the compression)) will transition into an outward movement, as the low-energy state.\,. casts out (I'm forgetting the word that start with `ex-') a big part of the matter again, due to the fact that it had too much energy to remain in the low-energy state. (11:03)
This theory can also explain Hubble's law without having an expanding space, since the Doppler shift can simply be due to time moving faster and faster again, at our visible universe escapes the black hole.\,. Oh, and I guess that doesn't explain the background radiation, but that could also simply be the radiation from the ``outside'' universe that was there before the black hole started expanding, i.e.\ all the light of the previous universe that has not yet been captured by a black hole (or maybe has in the long-ago past but has since then been ex.\,. He, I cannot remember the word.\,. has not since then been.\,. expulsed! (.\,.\,I think that was the word I was looking for, but maybe there is another.\,.) has not since then been expulsed by another black hole). This theory can mean that we live in a non-expanding universe, which then further means that such black-hole implosion--explosions will happen forever and ever in that universe (and has probably happens an uncountable amount of times already, if we live in one now). Thus you would also get the same result with that kind of universe. (11:14)

.\,.\,(11:21) Oh, and by the way, isn't it a bit weird that the entire universe was compressed to a small point, but matter didn't collect in black holes? How did the laws of gravity---i.e. the rest of GR!---only come into being after matter was far enough apart to not cause ``event horizons'' everywhere? I find that part of the theory questionable.\,.

*(11.01.24) Never mind about these theories about originating from an earlier black hole; I'm sure cosmologists have thought of this hypothesis and would have talked more about it if it was a possibility.\,. (17:17)

.\,.\,But to get back to the topic of existence, all in all, even though souls/Sensors/Subjects might exist not be interchangeable at the same time, the Subject/Sensor that experiences your life now will at least likely keep on living until the heat death followed be a Big Rip that stops any recreation of the universe from happening. But there is still a good change, that we do not live in such a Big Rip universe, which means that we will live all possible lives forever, even with such an hypothesis.

And you happen to be a Subject/Sensor of an early alive-but-mortal universe, then you still know that there will exists Big Bounce universes with exact copies of yourself, with the same exact live as you from birth to death, and who \emph{will} live forever like that, which might also be comforting, even if you fear that hypothesis. (11:34)

.\,.\,Hm, but isn't it also kind of weird to begin with to have these Sensors in the multiverse, that are not interchangeable.\,. Well.\,. Maybe, maybe not.\,.

.\,.\,But let me underline that you could also just see these Sensors as giving life to an experience, and that ``you'' are the experience itself more than the Sensor. .\,.

.\,.\,I'm by the way still thinking about whether I could make a neat little paper. I could either just propose one or both of my favorite hypothesis, namely as an alternative to materialism, which most atheists sadly.\,. well, not so much materialism, but they seem to believe that it's just ``lights out'' after you are dead, but you could instead make a good argument that we might live forever.\,. Oh, that's the point I should make: We might very well live forever. Not we \emph{will}, but it \emph{might} be the case that we will live forever as all possible lives. And that is a good message as well: It does not need to be confirmed. Okay, so maybe I \emph{should} actually write a small paper where I point this out.\,. (11:47)

.\,.\,Hm, or maybe not, I'm not completely sure.\,. (11:52)

(11:59) Let me mention a(n important) point that I thought of yesterday: If Sensors are described and governed by the fundamental logic, the mechanism that allows a Sensor to sense is also governed by the fundamental logic, and the experiences that are sensed are also continuously governed by the fundamental logic. The fundamental logic handles everything, what is sensed and how each sub-experience feels for the Sensor. So isn't the Sensor then just an arm of the fundamental logic. Well it \emph{is} that, and doesn't that mean, that the experience is really experienced by the fundamental logic after all? I believe so (but I wish I could just bolster that argument a tad more).\,. (12:05) .\,.\,It also just seems intuitively right, and even though I know that that's not something you should really go by, I think we all have the thought that we are in a sense not alone with our thoughts. The fundamental substance/entity that makes things exists shares our thought, and are just as much a part of us as whatever the rest of us is, assuming that we are not just that underlying thing completely (which I believe that we are). (12:08)

%(12:47) No, I'm satisfied with where I'm at right now with this topic. I will not think more about writing a paper on it for now.

(08.09.23, 8:51) If souls have some information about them that makes them different from others, i.e.\ a kind of ``soul atoms,'' then if everything that can exist exists, there will just be a different universe where the same soul experiences different things. But one might still hypothesize, that souls do not differ but are nevertheless not interchangeable, unfortunately. But since that is kind of a weird statement, some might not like that that hypothesis for that reason.

Continuing on the previous paragraph before this above one that I just wrote, let me try to underline/bolster that argument.\,. (8:59) .\,.\,(9:09) Well, essentially it boils down to this: If a feeling/experience of a soul/Sensor/Subject is governed by a more fundamental logic, and it thus springs from that in reality, how can it then not be just as much a part of the fundamental logic as any other existing feeling/experience?\,.\,. .\,.\,How can one claim that the experience can spring from the soul/Sensor alone, when everything about the soul/Sensor springs from something more fundamental. And in that way, how can anything really spring from anything \emph{but} the most fundamental logic of the multiverse?\,.

So that's really what my thoughts boil down to.\,. .\,.\,I think that these thoughts are especially reasonable when it comes to hypotheses where each thing/universe in the multiverse has a starting point, and then the rest is derived/calculated from there. For what should calculate them then other than the fundamental logic, so to speak?\,.\,. (Hm, note that I'm brainstorming a bit here.\,.) (9:18) .\,.\,This is as opposed to hypotheses where everything is just known from the very start and all things/universes just exist with their entire temporal dimension mapped out from the beginning. .\,.\,Hm.\,. (9:21) .\,.\,Hm, but that doesn't really change much for the ``everything must spring from the source of everything, ultimately, and therefore our feelings/experiences must be a part of the fundamental thing/logic/entity in the multiverse'' argument.\,. (9:26)

Okay, I'm actually really satisfied with this, like I have said before (two days ago). And as a last point, even if you think that there is a real change that souls/Sensors are not interchangeable, then what does it really matter anyway? If we ask the question from an objective standpoint, looking at it from the multiverse's point of view, is it good or is it bad, then, that souls are not interchangeable. And there the answer must just be: it's neither or. And if that is the objective truth, where care about some subjective version of the same question?\,. And to take it more down to earth: If other souls live in what could have been your place after you are dead, why not just be happy for those souls?\,. (9:32) I actually think that a great majority of people might feel the same way as I do on this point.
%%
%\\\\
%%
%(Now, about the paper, I am actually sort of considering a very short paper, that basically just says: The multiverse must have a great symmetry to it; whenever a specific choice is made over another, the converse must just be true in a different part of the multiverse. And let me propose a couple of multiverse hypotheses, namely one where the multiverse is ``thought up/derived'' from the fundamental logic, and.\,. Oh, I should mention first that conscious experiences must exist (we know that). So what the fundamental logic derives also includes experiences, and by calculating each experience, the fundamental logic might essentially feel those experiences as it calculates and understands them. Another one could be that all things just exists---including universes with a time attached to it---for what else is there for things to do, other than to exist, that is?\,. This then includes things which includes experiences (which we know are something that can and does exist). Hm, but then I should also talk about the problems with plain materialism, right.\,.\,? Okay, maybe this is actually the long version of the paper that I'm giving a resumè for here.\,. The very short version could just be: There must be a great symmetry to it all, yarder yarder, and therefore there must also exist e.g.\ universes like ours that Big-Bounces. So even if our universe will heat die and then never recover from that due to a ``Big Rip'' of some kind, there will just be other universes where being will live on forever (and I could mention that with some assumptions about how to construct the prior, this would mean that we would already likely \emph{live} in a Big Bounce universe right now!). And this is then where I'll point out that this means that there will live all kinds of versions of ourselves, and that's not all, even all kind of lives in between you and anyone else will at some point be lived, even though it might be very infrequently. So in that sense, all our lives are just part of a great spectrum of lives, that will all be lived forever and ever. So no need to worry about the heat death and/or the Big Rip. (And maybe I should also mention that physical wave function collapses + Big Bounce means that each bounce will be like a new, fresh Big Bang, despite the law of entropy.) .\,.\,But I'll probably not do that just yet, anyway.\,. I will, however, think a bit about it.\,. (9:56) .\,.\,Oh, and I would also like to tie ``Empathy Utilitarianism'' on at the end, which makes the project larger, and thus probably not something that I can just do---'cause it will probably take a long time to formulate it so that it doesn't sound quite as long-haired.\,. So I'll probably forget the thoughts about writing a paper about the topic for now, actually.\,. (10:00))


%(10.09.23, 10:37) Apropos physics, I had the thought last night that if space expands, whouldn't stars orbits in a galaxy be drawn further and further out? Wouldn't an expanding space thus not also expand galaxies over time? Shouldn't we therefore be able to look out and back in time and see that galaxies tend to be more compressed the earlier we see them (i.e. farther away from us)? A quite interesting question, if I may say so myself..!


%(15.09.23, 9:22) I watched a YouTube video from "Kurtzgesagt" yesterday about "being the dream of the universe." The video turned out to be about the thing about how all, even completely unlikely events occur in a "dead" universe as long as there will be matter left (with a non-vanishing density) in that "dead" universe, and that statistically this leads to the sorta paradoxical conclusion that we are all most likely floating brains in a dead universe. First of all let me say that I'm generally impressed with the video. I think it's very cool that this topic is brought up by such a channel (not that I really know much of it; I have probably seen one or two videos of them beforehand, not really more than that). And they did a very good job of it. Cool.
%Now, a counterpoint to the hypothesis (of us being floating brains) is this: We are likely not the only universe in existence: Why on earth would we be that? And among all the universes (at least that are sort of like ours), there will likely be some that has some mechanism for which something that looks like the Big Bang can happen again and again. (I've mentioned a lot of other hypotheses that will lead to this, but the obvious candidates are Big Bounce universes, which might appear exactly like ours do just after the/a Big Bang, with an expanding space, but where that expansion then turs again at some point.) And even if those types of universes are very infrequent, say like one in a million, they would still end up domination the others statistically in terms of how many brains they have over a long period. Therefore, we are most likely actually living in such a universe ourselves right now.
%This hypothesis is then in fact even bolstered by that very same "paradox" from before, for if the opposite hypothesis, namely that there are only Big Rip universes, is true, well then we \emph{are} likely floating brains for all we know---or it could be that it will still be more likely that whole star systems form, but in that case it would be incredible unlikely that when we look out, we see other star systems, let alone galaxeis, let alone this Big Bang-like universe around us (then it would probably even be more likely, that the light we see coming from outer space is just randomly organized to produce what we are seeing). Well, in fact, if this is not the case, we then \emph{do} live in a universe that has a mechanism where Big Bang-like universes can be created again (with much higher likelihood than floating brains), which contradicts the hypothesis that this does not exist in the multiverse. This means then that we can actually rule out said hypothesis: There \emph{must} be universes where Big Bang-like universes can keep on forming repeatedly with higher probablities higher than floating brains. For else, we \emph{are} floating brains right now. But that means that anything we see is completely random: The cup on my desk right now might just as well turn into a rabbit in a moment than it might stay a cup. So anyone wh is in favor of the pure Big Rip universes hypothesis will have to deem the reverse hypothesis to have a lower (prior) likelihood of occuring, than what they actually deem that whatever object the lay their eyes on can actually turn into a rabbit at any moment, and will likely do so.. Okay, well I guess that a Matrix (the movie (and book)) -like simulation chamber could appear out of nothing, i.e. where the brain is then hooked up to a simulation, in which case that simulation might very well have some laws to it.. ..Yeah, but anyway: We still likely live in a repeating (some way or another) universe.
%Now, I also want to talk about something else about the video, which is not really very cool, and that is that event-horizon--Hawking-radiation bullshit.. ..I mean, let us think about it. In a universe old enough so that some galaxies will move away from us faster than the speed of light due to the expansion alone, yes there will then be an event horizon. In fact, at any point in time, the event horizons from observers exactly on the sphere where things move away with the speed of light (due to the expansion alone) will sweep past us (in every directions), each at exactly the speed of light. Now.. OF COURSE this will not mean that pair-produced vacuum particles will all of a sudden be ripped apart and pushed forward at the speed of light just on the edges of the (invisible) event horizons that passes through us. And it is a bit disappointing that non of the physisict that has entertained this (bullshit, sorry to say it) hypothesis has been able to try this simple line of reasoning before sending the hypothesis on to the public/jounalist (like Kurtzgesagt). That is embarrassing. But I guess maybe there is a kind of selection principle involved at least, where the reasonable physisists that are able to see that kind of reason, and therefore not go on and spout a lot of weird stuff to journalist, well they are not the ones that the journalists get to hear (and maybe the jounalists also play their own role in this selection principle).. So yeah, not too cool..
%And to something a bit urelated.. well it is related somehow, 'casue I thought about it---oh 2 seconds.. (10:03) ...(10:28) and I'm back---I thought about it in the shower this morning, thinking about this topic, but I can't remember what the thread was. Anyway, the thing is: I do actually beleive in a physical wave function collapse, but it might only happen at quite large scales, perhaps such that gravity comes into play (so that if we build a planet-sized quantum computer, there is a chance that collapses will happen, and in that case we would then be able to observed it with such a computer).. ..Okay, I think I've caught the thread: I had an intersting thought about the fact that, \emph{if} the universe is completely quantum mechanical---which would be the most elegant thing for it to be, but on the other hand, I personly don't mind if GR and QM can't be joined together quite as seamlessly, since I don't mind at all the thought of collapsing wave functions (which then means that the space can then know where objects are in space (roughly) and thus know how to bend around them)---if that is the case, and the now quantum-mechanical manifold we live on is also albe to expand and shrink (which it seems to be), then wouldn't it make sense that there is a higher energy associated with more space, and that the expansion that we observe is thus actually part of a process where the photon energy is converted (elongating the wave lengths of the photons) into more space. I know that this idea is not new, but in the light of a unified GR and QM, it just seems like something that is quite likely, doesn't it?.. I think so..
%Okay, that was all.. almost all that I wnated to mention here: I also wanted to mention one more thing, and that is that, if we assume that we don't have a Many-World universe, and if we do in fact see large quantum computers work without any detectable wave function collapse, then we could in principle simulate a true AI on a quantum computer, making it go though $2^n$ thought processes at once. But with said assumption, it would mean that we should only count that as one thought process in when looking at it e.g. from a utilitarian perspective (where one might want to meassure total happiness (and the true AI might tell us that it is happy thinking about certain things, or whatever)). For with that assumption, the "soul" of the true AI must choose \emph{one} path to go by, and the 2^n - 1 other thought will then not be lived by that particular "soul." I thought this was an interesting thought, interesting enough to also mention it here. (10:47)


\subsection{Continuation}

(09.12.23, 9:36) I was considering writing a small paper about this topic before, but I came to a halt, as can be seen in the source comments above. However, now I'm actually considering writing a small paper again. This time I'm thinking about letting the proposal of ``maybe the universes simply have different laws for how consciousness/conscious experiences appears, sorta ``next to'' the laws of their physics.'' And I could start out be talking about how the concept of experiences something consciously probably can't be fully explained/understood with the (``mortal''/intra-universal) logic that is available to us---similar to how we probably can't (even) explain how the experience of seeing something blue differs from that of seeing something yellow. But, I could go on, the fundamental logic underneath all existence \emph{would} obviously include these concepts. Now, a compelling hypothesis (related to MUH/CUH) is that there is a perfect symmetry when it comes to the set of all things that exist. For what would be able to cause any asymmetry? Only the fundamental logic of everything would be able to hold the reason why there would be an (arbitrary! (i.e. with no reason for being there)) asymmetry, but then the fundamental logic of everything would include an asymmetry.. Yeah, this get's a little long-haired, but I believe that I can formulate this point briefly and concisely. And then, since the fundamental logic includes the concept of what conscious experiences mean, there is nothing from preventing the universes in existence to simply contain / spring out of laws about when conscious thoughts/experiences appear within them. And therefore there doesn't need to be an overall law for when something becomes sentient in the entire existence. This law could simply be universe-dependent instead.

I think this could make for a neat little paper, and then I'm also considering including a section or two about my point that with an infinite (or at least virtually infinite) number possible universes, and therefore an infinite \emph{actual} number of universes, if this hypothesis of a grand symmetry of everything is true, then there is an infinite possible lives between your and any other sapient being. And with any kind of hypothesis where the ``I'' in ``I experience something,'' i.e. the subject of an experience, is either something that is spread out and/or is something that is part of grander whole, then each individual can therefore effectively say to themselves, that they will live all possible lives in the grand multiverse (and possibly an infinite number of times as well). And this gives a very nice theory of ethics, don't you think: Try to maximize happiness and content as if you would live out each possible live in the universe (with frequencies matching the probabilities of thing occurring, by the way). For given that these hypotheses are true, you effectively will. (10:06)


(10:00, 21.12.23) No, let me do something even simpler than this. Let me write a paper, where I briefly talk about the potential symmetry of the multiverse (the entirety of existence), and mention CUH, but then quickly get to talking about what such as infinite multiverse might mean, and how this might affect the moral question, at least for a (broad) set of.\,. sets of assumptions (sets of sets, i.e.). I could call the paper \emph{Symmetry of the multiverse and empathy utilitarianism}.\,. .\,.\,And the main point of the paper should then simply focus around that realization that having infinite universes (or even if our own universe is infinite) means that there is lives that follow all possible paths in between one person and any other. .\,.\,Let me give this potential paper some more thought\ldots

\ldots (10:19) Hm, I wonder if there is enough meat on that paper, then.\,. .\,.\,I would probably need to dive some more into the symmetry hypothesis.\,. .\,.\,And maybe I \emph{should} also talk about the possibility for separate consciousness laws.\,.

(11:22) Maybe I should make a summery of a list of hypotheses which a lot of people might find reasonable, and then conclude by talking about empathy utilitarianism.\,.


(23.12.23, 14:57) Or maybe I should focus more on my points about consciousness.\,.

%Jeg overvejer lidt (og tænker lige at brainstorme lidt), at man måske kunne nævne A Bunch of Rocks, xkcd, og så nævne paradokset med, jamen hvad hvis man går det to gange? Hvad hvis man gør det to gange, men over lapper i tid? Hvad hvis man gør de to gange samtidigt? Hvad hvis man flytter rundt på bunker af sand i stedet? ..Og inden da kunne jeg nævne, at jamen, vores hjerner er jo også bare, ikke sten, men atomer, som flyttes rundt på.. (15:01) ..Hm, og jeg kan så se to løsninger: Man kunne enten simpelthen have bevidstheds\emph{love}, ved siden af de fysiske love, så at sige, tilknyttet et hvert univers. Og ellers kunne det også være, at på et fundemantalt plan, jamen så det der eksisterer i det samlede multivers, det er simpelthen bare bevidstheder. Så med andre ord er dr \emph{kun} bevidsthedslove---og 'oplevelseslove' skulle man så næsten også sige---for hvert univers, og de "fysiske love" kommer så bare i kraft af, at bevidsthederne skal have noget at opleve. (Og her burde man så næsten også nævne, eller have nævnt, at der jo nok sagtens kunne være et princip, der favoriserer mindre information i de individuelle universers beskrivelser, dog..) ..Ja, så måske bør man netop først snakke lidt om, at multiverset jo kunne være ret symmetrisk og omfavnende, og at dette så ikke leder til komplet kaos---i hvert fald ikke nødvendigvis---fordi man så kunne have en højere frekvens, fra individets perspektiv, af universer med relativ lav information. (15:08) ..Ja, så lad mig faktisk stadig prøve at indlede med den pointe (og refere så til MUH/CUH)..

%(12:40, 28.12.23) Jeg har været lidt frem og tilbage, for jeg synes lidt det er et problem, at der enten ikke virker til at være nok kød på det, hvis jeg udelader nogle ting, men at det til gengæld bliver for langhåret, hvis jeg prøver at inkludere dem.
%Men nu har jeg faktisk muligvis en god idé til, hvordan man kunne opbygge en rimelig simpel artikel, som kommer med nogle interessante pointer uden at blive for langhåret..
%Denne opbygning handler så stadig om kort at nævne lidt om, at den samlede eksistens nok er ret bred, og så vil jeg nævne det med kontinuumet af livs-stier allerede her. Og så vil jeg nævne, at så med en materialistisk antagelse, så er dette jo allerede en meget behagelig og glædelig anskuelse.. Jeg vil for øvrigt sørge for at fokusere en del på antagelsen om en monoteistisk, og særligt den kristne, gud, og dette vil jeg så også behandle kort i denne første sektion også.. Nå, og så vil jeg så fortsætte med en sektion om bevidsthed, hvor jeg starter med A Bunch of Rocks -eksemplet, og alle dens udvidelser, og så kommer med pointen om, at det ikke gør noget, at bevidsthed ikke kan defineres ud fra.. rene.. principper, for hvis der er arbitrære valg, så må de alle sammen nok bare gælde i forskellige universer. Og man kan så sige det samme om antagelsen, hvor der er en skabergud: Så kan denne jo bare tage nogle forskellige valg for forskellige universer, hvis det er, altså om hvad "sjælene" skal hægte sig på (af hjerner). Herefter kunne man snakke om, at "sjæle" jo nok ikke er aktører, men bare er nogen der \emph{oplever} ting, og at dette om ikke andet kan eftervises, når man for (deterministiske!) maskiner, der kan gøre sig de samme tanker (også ekstentielle!) tannker som vi kan (for så kan man se at vores hjerner godt kan være deterministiske og ikke behøver en sjæl til at give input til den for at give den den karakter, vi kender).. Men det vil jeg springe over.. I stedet tænker jeg, at tredje sektion så bare skal handle om, at selv hvis sjæle eksisterer, og hvad end de er atomare eller sammensatte af mindre dele---og hvad en de udspringer af en skaber-gud eller ej!---så kommer man altså ret nemt frem til, at.. "vi alle er ét," så at sige.. Og så kan jeg herefter slutte af med en sektion, der lige understreger den etik, dette klart leder op til (selv for "egoister"), nemlig: "Empati-utilitarismen." (12:54)

%(29.12.23, 11:49) Jeg overvejer også at nævne i første sektion, at sandsynligheden for at bo i et Big Bounce-univers går mod 1 med visse antagelser, interessant nok.


%(04.01.24, 15:56) Jeg var egentligt kommet frem til en ny disposition her efter nytår. Den gik på først at snakke kort om, at det samlede multivers nok er rimeligt bredt, og særligt bredt nok til at indeholde Big Bounce-universer og andre universer, som varer/lever for evigt. Derfor er der ingen grund til at frygte vores eget univers' død, ville jeg så nok konkludere denne første sektion med. Så ville jeg snakke om, at en dt grundlæggende multivers jo nok faktisk burde være \emph{fuldstændigt} bredt: "Alt hvad der kan eksisterer, eksisterer." Men så kan man så spørge: "hvad kan eksistere," og det er det jo så ikke et klart svar på. Derfor er denne hypotese ikke nødvendigvis i modstrid med tanken om, at der skal være en skaber-Gud, enten for hvert enkelte univers i eksistens, eller for den sags skyld for det samlede hele. ..Hm, og hvordan ville jeg så fortsætte derfra, var det ikke noget med at snakke om bevidsthed (noget a la mit A Bunch of Rocks-eksempel (som jeg dog nok ville ændre til at tale om to neurale netværk med samme ydre sanseinput, som man så langsomt sætter sammen i tid og sted og kobler til hinanden, først svagt og så mere og mere, til det sidst bliver til en og samme hejrne))..? ..Jo, og så pointere, at "alt eksisterer"-hypotesen så ikke har noget problemer med denne arbitr..ærhed..aritet... ..Og så ville jeg også sige det tilsvarnede om forkellen på at se farven rød som rød eller se den som blå.. ..Så ville jeg vist snakke om det her med, at vi alle er forbundne af et kontinuum af mulige livs stier, og at man på den måde kan sige, at vi alle skal leve alle liv for evigt. ..Og så ville jeg vist gerne dykke længere ned og se på: jamen, er dette en gyldig fortolkning med alle de forskellige muligheder ift., om der er en Gud (eller flere) eller ej, og om der er en sjæl for hver oplevelse eller ej.. Hm.. (16:09) .. ..(16:13) Ja, jo, pointen var, at hvis vi ikke har en unik sjæl hver især, jamen så holder fortolkningen, men hvis vi har en sjæl, der gør forskel i kosmos på, om det f.eks. er min sjæl, der sidder i min hjerne, og din i din, eller om man bytter rundt på disse sjæle, jamen så må hver sjæl have nogle kvaliteter, der gør den distinkte. ..Hm, og disse sjæle må komme et sted fra.. Hm, eller hvad.. ..Hvordan var det nu.. ..Hm, man kunne måske have sjæle uden gud, men mon ikke de fleste.. Eller om ikke andet: De fleste, der tror på en sjæl, vil nok mene, at denne sjæl enten med det samme (eller næsten) hopper videre til en ny hjerne, eller at den vil returnere til en højere enhed, nemlig til det samlede kosmos eller Gud. Hvis kosmos/multiverses så varer ved evigt, så..---Ah, jeg manglede forresten at nævne ovenfor, at en Gud jo også nok ville skabe mere end ét meget specifikt unvivers (som dør efter en kort tid); hvis Gud hvilede på syvendedagen, jamen hvad fortog han så så næste dag af arbejde udover at skabe en ny verden, selvfølgelig; hvilket arbejde ville ellers kunne måle sig med at skabe vores verden. Og en evig skaber-Gud ville vel ikke dovne den efter sin hviledag, men ville forsætte med samme energi som i den forgange uge. Nå men for at vende tilbage: Hvis kosmos/multiverses så varer ved evigt, så vil hver sjæl så sendes tilbage til en hjerne igen. Hvis hver sjæl er atomar, så for vi så den samme fortolkning igen, med at vi skal leve alle liv for evigt, og hvis sjæle er kompositte, jamen så kan det være, at de skilles ad og samles anderledes, inden de sendes tilbage igen i live, men hvis muliverses varer evigt, jamen så vil kosmos på et tidspunkt samle en tilsvarende sjæl igen, og så for vi samme fortolkning endnu engang. Så det er jo dejligt at tænke på. Og så kunne man spørge, jamen hvad hvis der også er en oplevelse forbundet med at blive en del af det store hele (kosmos/gud) imellem at ens sjæl finder tilbage til en hjerne? Jo, altså enten er der ikke nogen oplevelse forbundet med det, og så er det jo fint. Men hvis der er, så må man sige, at givet at vi her i livet føler noget af den allerstørste lykke, når vi føler os forbundet til andre, og til et større hele, så er det meget svært at forestille sig, at oplevelsen af at blive en del af det store hele (kosmos/Gud) ikke vil være positivt, hvis ikke ligefrem virkeligt lykkelig. (16:30) Og med det sagt, så kunne jeg så nævne "empati-utilitarismen," og her ville jeg så i øvrigt også gerne nævne denne pointe: Empati-utilitarismen siger ikke bare, at man skal være god mod andre mennesker, men den siger jo også modsat, at man ikke skal ofre sig for meget for andre mennesker, for de skal jo også leve ens eget liv i ligeså høj grad som, at du skal leve deres. Derfor er ekstrem selvopofrelse også dårligt, altså hvis det samlet set skaber mere ulykke end lykke. Og det samme kan man i øvrigt også sige med at blive ulykkelig på nadres vegne ved at have medfølelse med dem: Medfølelse er generelt godt, men husk at de andre også skal leve igennem den smerte, som deres egen smerte indirekte forvolder dig. Jeg synes selv, dette kunne være en meget god pointe, som det ville være godt for nogen at huske. Nå, og havde jeg så mere?.. Nej, det var vist det.
%
%(16:36) Men som sagt så tror jeg altså ikke, jeg vil skrive artikel over dette alligevel.. I går og i dag har jeg læst lidt Tegmark og lidt andet også, bl.a. lidt Paul Davies, The Goldilocks Enigma. Og her for noget tid siden kom jeg hjem fra en god gåtur (i sneen), hvor jeg i første omgang kom frem til, at jeg ikke ville skrive den artikel alligevel (men måske bare ville opsummere den her, hvad jeg så har gjort nu), og senere kom jeg så på, at jeg måske alligevel vil skrive en anden en, hvor jeg i stedet for at sigte mod "vi skal leve alle liv" og "empati-ultilitarismen" i stedet bare redegører for "alt eksisterer"-hypotesen, som er lidt anderledes en Tegmarks, umiddelbart, og så særligt fokusrer på den gren af den, hvor vi ligesom alle er "udregningerne" fra den Grundlæggende Logik som en slags stor \emph{forstående} kraft.. Hm.. (16:42)

%(05.01.24, 11:39) Okay, jeg vil prøve at skrive denne artikel, og jeg går i gang nu her...


%(10.01.24, 11:22) Jeg tænkte lidt i sengen her til morges (jeg sover ret længe her for tiden (efter nytår)---og bliver også træt rigtig tidligt) over, om det nu også løser problemet med uendeligt kaos, hvis man gør 'oplevelser' til, hvad der er genstand for eksistens. Og jo, måske er der en vej, hvis man lægger vægt på '\emph{singulær} kohærent oplevelse,' men det lyder nu lidt arbitrært, synes jeg nu, og hvad værre er, jeg er ingen gang sikker på, at det vil løse problemet alligevel. Men dette er faktisk ret spændende, for det får mig jo så bare pludselig til at tro meget mere på lige præcis den her antagelse om, at multiverses ligesom deduceres (og udregnes (ét eller bare endeligt mange skridt ad gangen)) af the Logic of Everything (LoE).:) Og det føles bare virkeligt dejligt, at være blevet endnu mere sporet ind på den hypotese.:) Der er også stadig den mulighed om, at gentandene for eksistens er 'intelligente væsner' (eller, lidt tilsvarende, (rimeligt) 'fundamentale logikker' selv), hvilket jo også løser problemet på samme måde, fordi vi så igen kan få en løbende udregning af alting (alle sandheder, og specielt alle sandheder om 'oplevelser'). Dette kan jo jo enten nævne i et af det sidste afsnit eller i et appendix. (11:34)









\chapter{Physics}

(12.09.23, 10:28) I already have a few physics-related notes in the Existence chapter above (including out in the source code comments), but now I have an update on my quest of showing self-adjointness of certain unbounded operators, so this deserves it own section/chapter.

%(10:32) Jeg har fået læst en lille smule op på mine noter om aftenen og prøvet så småt at sætte tankerne lidt ind i problemet igen (for jeg sidder alligevel for tiden og slapper meget af om aftenen med logiske puslespil---Linux har en hel pakke, bl.a. "Galaxies," "Palisade" og "Black box" (som faktisk ikke er strengt taget logisk, men som er meget sjov alligevel med de rigtige indstillinger (e.g. 18, 18, 18 *(20, 20, 22)))---samtidigt med at jeg hører musik, og tanken var så: Hvorfor ikke læse op på dette problem og så slappe af ved at prøve at løse det i stedet?.), og i går på vej til tandlægen kom jeg så på, at bare bør sørge for at foholdet mellem halens norm-størrelse og størrelsen på den del-vektor, den kvæler, bør gå hastigt mod nul, nemlig for at løse det problem, som jeg kan huske jeg lidt gik i stå i, da jeg gik i stå sidst i problemmet (og i fysikken i det hele taget). Det problem handler om, at A^- jo også stadig vil opererer på de lavere k i \psi(k_1, k_2, ...), og for halers haler vil de "nedre haler" altså skabe store vektorer, potentielt set. Men hvis halerne bare bliver hastigt mindre og mindre pr. niveau, så vil de, som jeg kan se, godt kunne bare, at de "nedre haler" producerer vektorer i det samlede billede, for disse kan så også bare gøres (hastigt) mindre og mindre for hver \psi_{2n (+ 1)}. (10:45)
%Og i går aftes fik jeg så lige kigget lidt på eq. (3.88) i qed.tex/pdf, ikke fordi min hjerne var til særligt meget der---pudsigt nok, for jeg havde ikke brugt den så forfærdeligt meget, ellers (mest bare til at tænke over, hvordan jeg skal om-implementere SetDisplays nu her i dag, hvilket dog også kræver lidt..)---men jeg fik lige akkurat overbevist mig selv om, at, ja, når vi har en \phi_n, der kvæler et "forbudt område" under sig, så kan gøre det sådan, at vi kan vælge en lille \psi_{n+1}, der stadig giver et ret stort \Braket{\phi_n | A^- \psi_{n+1}}. (For man skal nemlig give store *(nej små) hale-områder til sådanne næsten-basisvektorer, der har nedad-produktioner til et "forbudt område" under sig.) Og pointen er så for det første, at selv hvis \phi_n "snyder" og kvæler produktioner til området, der støtter \psi_{n+1}, hvad det nemlig egentligt ikke må umiddelbart for "V," for der er nemlig i det forbudte område over \phi_n, at vi har placeret \psi_{n+1}, jamen så vil dette (store) bidrag til \Braket{\phi | A \psi} stadig bestå, for her vil tredje led i første ligning i formular (3.88) nemlig altid udligne andet led eksakt, og så videre for hvert tilsvarende par i denne række. Men! Hvis phi har et \phi_{n+2}, der kvæler produktioner til \psi_{n+1}-området, så vil vi faktisk kunne forøge \Braket{\phi | A \psi} endnu mere (som jeg kan se det), for så vil vi nemlig kunne gøre samme trick og tilføje vektorer til \psi_{n+3}, der tilføjer til \Braket{\phi_{n+2} | A^- \psi_{n+3}}'s bidrag til \Braket{\phi | A \psi}, som \phi så igen ikke har nogen chance for at udligne fra \Braket{\phi | A \psi} igen. Og hermed mener jeg altså så, at man kan opnå, at hvis \Braket{\phi | A \psi} skal være bundet, så må \phi altså nødvendigvis også skulle lade sine "forbudte områder" være på et tidspunkt, og nok til at man så kan omdanne \phi til en sum af vektorer, der lader sine "forbudte områder" være helt, hver især, og som stadig har et endeligt billede "under A," hvilket pr. definition gør den til en del af mit Dom(A). (11:04)
%Det skal også lige siges, og dette var vist en idé fra i forgårs, at jeg nu holder mere af at bruge sfæriske skaller i stedet for kulger til "V." Disse skaller skal så have en skaltykkelse, der vokser proportionelt med raduis (hvilket vil sige med |\Delta k|), men hvor skallen er relativt tynd ift. radius, således at vi bare kan regne med en fast faktor på 1/\sqrt{k}, når vi tænker på problemet.
%Og ellers vil jeg bare lige sige, at jeg stadig skal læse mit gamle løsningsforslag igennem, for jeg er faktisk kun nået til først på side 133, nu hvor jeg har læst i mine gamle noter om dette problem. Men jeg er altså rimeligt fortrøstningsfuld over for, at jeg har en løsning, 7, 9, 13.. Det ville jo være lidt vildt.. Det ville også betyde, at jeg ville kunne tilføje "har bevist en (vigtig) matematisk sætning" til listen over ting, jeg har opnået, hvilket faktisk ville være ret stort for mig.. Nå, men hvis det virkeligt er så nemt, og jeg tror, som jeg har skrevet før, faktisk ikke problemet er løst, for jeg har kun set matematiske papers, der laver et cutoff, for at kunne håndtere sådanne formler og gøre dem til selvadjungerede operatorer, så \emph{bør} jeg faktisk bruge noget af min tid på at skrive en artikel om det. For i modsætning til mange af mine andre ting, så kunne jeg forestille mig, at dette ville være en ting, der faktisk kunne udbrede sig ret hurtigt.. ..Måske.:) (11:13)
%*(11:30) Nå ja, og jeg kan altså så forresten ikke se, hvorfor jeg skulle behøve at vise Dom(A^*) \subset Dom(B) direkte nu..:)

(11:13) I've just written some notes (in Danish) out in the source code comments about the update. I think I'm gonna leave it at this for now, and then get back here when I want to continue more thoroughly on the problem.\,.

(20:31) Hm, about ``Task 2'' / showing that eq.\ (124) in my QED paper holds, won't almost eigenvectors in $\mathbf{H}_{CL}$ be sent into almost eigenvectors as well in $\mathbf{H}_{red}(j)$ when $j$ is let tend to infinity?\,.\,. .\,.\,Well, I would think so, and if they do, don't that show the equation.\,.\,? .\,.\,Yes, it does.\,.\,!\,.\,. (20:38)
%(21:05) Ja, for billedet af en(hver) næsten-egenvektor (samt enhver anden vektor) må konvergere punktvist, når cuutoff'et sendes mod uendeligt. Så når cutoff'et sendes mod uendeligt kan vi tage en vilkårligt stor del af parameterrummet (altså Fock-k-rummet) og se at både vektorens billede konvergerer mod kontinuumsgrænsens billede i dette område, og da vektoren altså også selv konvergerer mod kontinuum-modparten, så vil vektoren minus dens billede divideret med en faktor konvergere til en forsvindende vektor, når vi lader området og cutoffet gå mod uendeligt.. Okay, jeg føler ikke, at jeg fik gjort begrundelsen meget klarere her, men hovedpointen er bare, at billede konvergerer punktvist, når man lader cutoffet blive større og større, og derfor er det rimeligt nemt at se, at approksimationen af næsten-egenvektoren selv må konvergere til en næsten-egenvektor, når cutoff'et løftes.. (21:14)


%(13.09.23, 12:54) Fantastiske nyheder! Jeg er lige kommet hjem fra en lille gåtur, som jeg gik med målet om at finde ud af, hvordan jeg helt præcist skal lave min (nye) InstanceSetDisplay. Det fik fandt jeg så endeligt ud af her ret tidligt på turen (og skal have implementeret det nu her efter, jeg får skrevet dette her), og så begyndte jeg jo at tænke lidt over fysikken igen. Jeg startede nemlig dagen med lige at catche op på, hvad problematikken omkring Dirac-havet i kontinuumsgrænsen var. Og midt på turen slog det mig så! Hvem siger, at 0-impuls-bølgefunktionen skal være invariant (i praksis) under Lorentz-transformationer?! ..Hov, lad mig forresten skrive dette i den renderede tekst:
(13.09.23, 12:59) I have great news! I thought about ``Task 5'' (about the Dirac sea) just now on a little walk, and I realized: Who says that we have to have a solution to the empty vacuum that is invariant (physically) under Lorentz transforms?! Sure, we need to show this if we want this solution to be our \emph{vacuum} solution, but who says that the 0-momentum part of the wave function have to be vacuum-like?! Why can't this state just be part of the physical state of the universe?! For when you think about it, the universe already seems, from where we stand at least, to have a preference towards a certain inertial system, namely the one we arive at if we take the mean momentum (I guess when accounting for the expending space also) of all the galaxies we observe. But this does not makes us say that the universe isn't Lorentz-covariant.\,! And similarly, if we find that the 0-momentum state has a skewness to it, that makes it seem to point to one inertial system over others---for instance if it is (close to) the ground state in that inertial system but not in any others---we would also not say that our universe isn't Lorentz-covariant then! The 0-momentum state would in that case just not be an actual \emph{vacuum} state; you wouldn't quite be able to call it that. It would be a \emph{physical} state instead, carrying actual information about the current state of the universe.

And with that.\,. Oh, first I should then also say, that if I can indeed show self-adjointness of Dirac-like Hamiltonians without the vacuum-perturbing terms, I'm actually pretty confident (7, 9, 13) that I can also show that the Dirac Hamiltonian \emph{with} the vacuum-perturbing terms are self-adjoint.\,! It wouldn't surprise me if I could, at least.\,:) For in order to do this, we could just remove all the 0-momentum k-states in the reduced Fock space, $\mathbf{H}_{red}(j)$, and separate it out as its own Hilbert space (multiplied by a direct product to the other part of $\mathbf{H}_{red}(j)$). And we can then do the same for $\mathbf{H}_{CL}$, only where the 0-momentum sub-Hilbert space would in this case be a Fock space over a k-space with one less k for each $\mathbf{H}_n$. And with that done, it wouldn't surprise me, if it would be almost just as easy to do ``Task 1'' and ``Task 2'' from here, given that you have already solved the same tasks for the Hamiltonian without the vacuum-perturbing terms (and without the separation just mentioned). And that would then yield that the actual, full Dirac Hamiltonian is self-adjoint (and that it can be turned into path integrals, which follows from ``Task 2'')!! (13:21)

And with that, I actually think that I would be able to do all of the five ``Tasks'' that I mention in the `Future work' section of my QED paper! For if I remember correctly, I believed that I had already solved ``Task 3'' when I finished the paper, i.e.\ in terms of sketching a proof. So I think that I have that under control, broadly speaking---or at least I think I thought so when I finished the paper. And ``Task 4'' really isn't that serious anyway: Even if I can't solve it, I'm pretty sure that you can make a convincing argument why it actually doesn't matter ('cause we can't physically tell the difference if we are pure states or not!\,.\,.).\,.\,! *(Oh, and I also thought/think that I have a solution to that problem, anyway, as I write in the paper.) And I've just argued why ``Task 5'' also probably \emph{doesn't} need solving, which, let me reiterate, is really just fantastic news in that case!\,.\,.\,!! I went from viewing this problem as something we might never really be able to solve, potentially: It could very well be a truly Hard problem for all we know. So now that it seems to me, that we probably \emph{don't need} to solve it in order to show that the Dirac Hamiltonian is (self-adjoint and) Lorentz-covariant, it is really just.\,. yeah, I've said it: Fantastic.\,.\,! (13:32)

%(17:26) Hov, det kan jo godt nok være, at 0-impuls-delen af H_{red}(j) ligesom exploderer oven på dets (ud-separerede) Hilbertrum, det kan jeg ikke huske, om det vil gøre..
%(17:39) Oh, but on the other hand!: If it blows up, can't we then not just (which would atually be much better) argue that this would tell us, that this 0-momentum part of the Hilbert space will be more and more decoupled from the rest of the Hilbert space in the continuum limit?.!!!..:D It would seem like it, wouldn't it!..:D.. (17:42)
%(18:08) It seems to do the opposite.. It seems that the (vacuum-)perturbing terms vanishes when compared to the free energy.. ..Now, wouldn't that mean, that the ground state solution would approach (becoming more and more parallel to) the bare ground state solution (which is the one where the vacuum is just empty)..? ..Well there would probably still be an infinite number of particles in the C.L. but the expectation value of each individual k-vector would go to zero.. ..Ah, but the problem is that the term work on all states, not just the ground state. So that's why they might still be able to cause a "vacuum" that is much different from the bare one.. (18:16) ..(18:18) But still, if we then look at the 0-momentum Fock space and this Hamiltonian that tends toward its C.L., and we then try a solution where all k-p-p-states are slightly excited into coherent oscillators (with very small amplitudes, smaller and smaller as \delta k \to 0) in a separable way---and note that we get more and more states in thi solution as \delta k \to 0, but that's okay for this argument---and see what happens when we apply \hat H_{vacuum-perturbing} + \hat H_0 *(i.e. \hat H_{free}), won't we then see that the resulting state will be more and more parallel to the initial state (before applying \hat H), and that this solution (of a lot of separable coherent states with smaller and smaller coherent-wave amplitude) as a function of \delta k thus we become closer and closer to an eigenstate when \delta k \to 0? Interesting thoughts.. (18:27) ..(!) ..Hm, well if that is all we need for the argument, why even bother with the coherent states: Why not just look at (1 + \epsilon a^\dagger)-states, or even better, why not just look at the bare ground state? Wouldn't that perhaps also become closer and closer to an eigenstate in the C.L.?(..!) (18:31) ..Well, yeah, it would!, at least if I'm right about how the factor in front of the v.p. terms will become less and less potent in the C.L...!(!).. (18:34) ..Oh, and that would then completely justify the conventional approach for path integrals of just assuming that the vacuum starts out in the bare ground state! Interesting!.. (18:36) ..This would actually be incredible..!

(18:38) I also have some very exciting additional notes out in the source code comments just above this paragraph that I've just added.\,.\,!\,\texttt{:D}

%(23:25) Ah, but if there is a degeneracy, we don't know that the bare ground state will remain in that state in the C.L.; it could then go to other states with.. wait.. no?.. Oh no, never mind, the bare ground state will still remain in the same state. .. 

%(23:50) Oh, I think you can actually argue that you can remove the vacuum-perturbing terms from \hat H, then..! ..(And you are also free to put them back if you want when deriving the path integral (if that makes it nicer).)

%(14.09.23, 9:28) Hm, jeg kan se at mit argument for at ændre C.L.-sektionen og indføre "Task 2" som en fremtidsarbejde-opgave i stedet var, at jeg ikke kunne argumentere for, at følgen af mere og mere almost-egenvektorer (for jeg havde nemlig samme løsningstanke dengang forinden) vil tilhøre domænet af \hat H_{red}(j) hele vejen, når j \to \infty, og at deres billede altså ikke divergerer. Jeg har ikke lyst til at tænke over, om dette nu var fornuftigt, for jeg kan jo bare have ment: givet at jeg/vi ikke står og kender selve Dom(\hat H_{CL}).. Men ja, jeg kan altså ikke se nu, hvorfor det ikke skulle kunne lade sig gøre at lave sådan en følge, givet den Dom(\hat H_{CL}) jeg formoder.. Måske overser jeg noget, men.. (9:33) ..(9:35) Ah, nu var der lige en klokke der ringede og sagde, at det handlede om, at produktionerne til det sidste niveau, for jeg må, pr. min hukommelse og omtalte klokke, altså også have haft laet et cutoff på partikelantallet der.. Hm.. ..Hm, nå, det er også ligegyldigt, for jeg skal jo bruge det i argumentet, at man kan lave den følge, så enten så kan man det, eller også kan man ikke, og hvis man kan (hvad jeg da stærkt regner med), så kan man altså (er jeg næsten helt sikker på) udlede eq. 124 ("Task 2") heraf. (9:40)

%(9:41) Jeg overvejer så nu, når jeg altså får tid til det for mit SDB-projekt, først at lave en artikel omkring min helt-vildt-spændende konklusion fra i går om vakuumet, og hvor jeg så i den artikel starter fra den diskretiserede \hat H (i.e. "\hat H_{red}"), og så både referere til min 2022-artikel, men også udleder den startende fra dens formelle kontinuumsgrænse (med de divergente vakuumperturberende termer), nemlig ved at gentage C.L.-sektionen fra 2022-artiklen lidt. Og i den forbindelse kan jeg så også lige lappe denne argumentation ved altså denne gang at argumentere for eq. (124). Når det så er gjort, så kan jeg så endelig gå videre og argumetere for min vakuum-konklusion og slutte den artikel af med denne. Efterfølgende kan jeg så lave en artikel om selv-adjungerethed, hvor jeg kan referere til denne forrige artikel som argument for, at vi kan fjerne de vakuumperturberende termer fra \hat H i dens kontinuumsgrænse. Og dette gøres så altså, når jeg slutter den artikel af og "perspektiverer til," at det fra sætningen så bl.a. følger, at QED-Hamilton-operatoren så vil være selv-adjungeret, og at (den konventionelle!) QED så er konsistent---og at man faktisk ikke behøver nogen renormalisering i stiintegralerne!! (9:52)

%..Og efterfølgende kan jeg så også altid lige lave et samlet værk, der sammensætter alle disse artikler, og så kan jeg i øvrigt også overveje her, om jeg skal prøve at få klaret "Task 3" (og også lige "Task 4") i dette værk også (men man kunne også sagtens bare udsætte dette yderligere..).

%..(9:58) Åh, den pointe der om, at man ikke behøver renormalisering i teorien, den gør faktisk lige det hele en \emph{væsentlig} tand mere interessant...!!

(14.09.23, 14:07) Okay, despite my notes above in the source code comments, the vacuum is not solved yet. I thought that the vacuum perturbing terms would get a $1/\sqrt{\mathcal{V}}^3$ in front, but if course it is just $1/\sqrt{\mathcal{V}}$. That means that the 0-momentum part of the Hamiltonian on the 0-momentum part of the Hilbert space will have ``perturbing terms'' that drowns out the free energy in the continuum limit. You \emph{could} probably then introduce another factor of $1/\sqrt{\mathcal{V}}$ and show that that has a self-adjoint C.L., and then from there argue that the original 0-momentum $\hat H$ would have similar dynamics as that one going to the CL, only with a growing phase factor as the difference when approaching said limit. Now, \emph{if} you could then show that the self-adjoint CL (when having the extra $1/\sqrt{\mathcal{V}}$ factor in front) of the 0-momentum $\hat H$ will have a true, non-degenerate ground state, or at least just one part of the energy spectrum with no degeneracy, you could argue that the 0-momentum part of the wave function will stay in that state forever, not interacting with the rest of the wave function. At least you might be able to argue this. But since I don't know how to show such the existence of such a non-degenerate state, I can't necessarily show that we can remove the vacuum-perturbing terms this way.\,. (14:20)

.\,.\,(14:24) You could then try to return to my argument about: What does it matter that the vacuum state / 0-momentum state is part of the physical state? And sure, but that does mean that we can't rely 100 \% on path integral calculations, 'cause the state of the ``vacuum'' might then play a role.\,. Well, if that's how it is, so be it: Nature could be like that, and then there's nothing to do about that, other than settle for a theory that include this.\,. Hm.\,. (14:27) .\,.\,Yeah, and the resulting theory will then just have a Hamiltonian, where there is a vacuum / 0-momentum part of the Hilbert space that only includes the space spanned by a set of degenerate states with the same energy, and where that (diverging) energy is then just subtracted (at every step going to the CL). So that kind of theory would/could be a consistent theory indeed.\,. (14.32)

.\,.\,But this prospect is definitely not \emph{as} exciting.\,. (14:33)

.\,.\,(14:35) Oh, bt maybe you could go the route of trying to argue that since the.\,. let's just call it the ``vacuum Hamiltonian'' for now for brevity.\,. since this is self-adjoint (if it can indeed be shown to be this), it will, remarkably, mean that the expectation value of the combined particle number operator will be finite. Intuitively this might be because the eigenstates of the ``vacuum Hamiltonian'' will all get a kind of symmetry that means that transitions up to states with higher numbers will be canceled by other similar transitions from below (but from different k-states) with an opposite sign in the transition amplitude. So that's how this might be possible (and why the self-adjointness of the vacuum Hamiltonian will not constitute a paradox this way). And the idea from there is then to look at.\,. Hm, let me think ('cause I haven't actually thought beyond this point yet (this time around; I've certainly had similar thought before in the past)).\,. (14:44) .\,.\,Hm, well heuristically you could say: If there is a finite number of particles an average in the total space despite that space, $\mathcal{V}$, tending to infinity, then we shouldn't care about those particles' interactions with our experimental/physical state, that's the general idea of the argument.\,. (14:47) .\,.\,Hm, this \emph{does} actually sound like exactly the right route to go.\,.\,:) (14:48)

.\,.\,Yeah, and mathematically, this would then be to show that, due to the.\,. oh, wait, how can you know that this limited amount of particles are spread out.\,. because of translational symmetry.\,.\,?\,.\,. (14:52) .\,.\,(14:53) Hm, doesn't this lead to a paradox, 'cause it would mean that.\,. no.\,. It wouldn't mean that the eigenstates would be close-to-parallel to the ground state, right?\,.\,. .\,.\,No, of course not. The expectation value for the particle number can be quite large.\,. (14:55)

.\,.\,(14:56) Ah, you only need to look at the non-vacuum part of the end state of the vacuum-interaction transitions.\,! I'm almost sure that you would thus be able to argue (and this is btw definitely something that I've thought about before---and so is most of all this, I would say) that the amplitude of the ``physical'' part of the end state of such a transition would be vanishing, meaning that the transition as a whole would be vanishing.\,! (14:59)

And in that case, you would be able to remove the ``vacuum'' / ``0-momentum'' part of the Hamiltonian---despite whatever the state the vacuum is in initial!\,:) In other words, we would be able to indeed remove the vacuum-perturbing part of the QED Hamiltonian.\,:) (15:02)

%(15:13) Hvis dette holder, så gør det faktisk bare det hele \emph{endnu} en tand mere interessant (end da jeg skrev sidst om, at det hele var blevet en tand mere interessant, her tidligere i dag).! For så vil jeg kunne nå det samme glædelige resultater, som jeg tænkte da, men nu hvor disse resultater vil afhænge endnu mere af min teknik (hvis den holder; 7, 9, 13) til at bevise selvadjungerethed for sådanne ubegrænsede Hamilton-operatorer.!:) (15:16)

%(16:07) Men så bør jeg jo så faktisk lave selvadjungeretheds-artiklen først, og så bagefter lave en om at håndtere vakuumet. Det tror jeg, jeg vil. Og så vil jeg bare vise det for en halv-generel mængde af ubegrænsede Hamilton-operatorer, og bare lige nævne det specialle eksempel med \hat H_{QED}, hvor vakuum-termerne altså er fjernet (men hvor jeg ikke argumentere for, at de også \emph{kan} fjernes). Jeg tror så, at jeg bare vil arbejde på næste artikel i forlængelse af denne, så jeg bare kan udgive dem stort set lige efter hinanden. Jeg tror så faktisk ikke, at jeg vil gøre at stort nummer ud af at retfærdiggøre mine \hat H'er i den (nr. 2) artikel. Måske vil jeg endda ingen gang gennemgå CL-sektionen igen, som jeg ellers snakkede om, men muligvis bare referere til den. Og hvad angår "Task 2," så kunne jeg i såfald bare tilføje et appendix til den artikel, hvor jeg lige lapper dette manglende skridt i min reference (altså i CL-sektionen af mit 2022-paper). (16:13)

(15.09.23, 9:15) It was wrong that the expectation value for the number operator will be finite: We won't know that. But luckily this should not ruin the actual, mathematical argument for why the transition amplitudes must vanish (given that the vacuum Hamiltonian is self-adjoint). (And it's by the way interesting enough to note, that there will be some growing $f(n)$, where the $f(n)$-operator (e.g.\ the $n^{-10}$ or the $e^{-n^{10}}$-operator) will have a finite expectation value.)

(18.09.23, 6:26) I realized in the bed earlier that my method of regularization actually does change the path integral. For in principle, if you have the bare vacuum as both the initial and final vacuum state (around the experiment), then you might get lower transition amplitudes than the actual ones since you would suspect that the bare vacuum only remains partially as that (and partially turns into another vacuum state). So my results might actually alter how we do path integrals!

Now, I think I might actually use part of today working on making the self-adjointness proof 'cause it could be really nice to know if I do have this great, great result---or result\emph{s}, rather---or not. (Because if I do have this/these result(s), and if it also seems like a short proof to write a paper over, then I think it might be worth my time to do now, due to the exposure that would very likely give.) (6:35)



\section{Notes about/while proving self-adjointness}

(18.09.23, 6:37) I'll stick to using shells instead of balls because it means that we can make it so that the ``cancelation tails'' always have higher $k$ than the previously highest $k$ (i.e.\ of all the photons involved). \ldots But they shouldn't be thin, I don't think, since the tails of the tails etc.\ has to be smaller and smaller.\,. (7:12) .\,.\,Ah, no, they could be thin and then just start out a long distance from $k_{n-1}$, the previously maximal $k$.\,.

(7:57) Ah, I will need to show $\mathrm{Dom}(A^*)\subset\mathrm{Dom}(B)$ as well, and I have not done that yet.\,. .\,.\,(8:06) Oh no, wasn't that actually kind of trivial, since we don't need anything about having a converging $A\psi$ for a sequence of $\psi$'s that produces a larger and larger $\braket{\phi |A\psi}$.\,! .\,.\,Yes, that will be almost trivial to show.\,! (8:12) .\,.\,I guess.\,. Hm.\,. .\,.\,Except that we also need to take care that the difference in
\begin{align}
\begin{aligned}
	\braket{\phi'| A \psi} =&\, 
		\braket{\phi'_{n}   | A^- \psi_{n+1}} + \big[
		\braket{\phi'_{n+2} | A^+ \psi_{n+1}} + 
		\braket{\phi'_{n+2} | A^- \psi_{n+3}} \big] + \big[
		\braket{\phi'_{n+4} | A^+ \psi_{n+3}} + 
		\ldots\\
	\braket{A \phi'| \psi} =&\, 
		\big[
		\braket{A^+ \phi'_{n}   | \psi_{n+1}} + 
		\braket{A^- \phi'_{n+2} | \psi_{n+1}} \big] + \big[ 
		\braket{A^+ \phi'_{n+2} | \psi_{n+3}} + 
		\braket{A^- \phi'_{n+4} | \psi_{n+3}} \big] + 
		\ldots
%	\label{symmetry_considerations_ldots}
\end{aligned}
\end{align}
doesn't ruin it.\,.

\ldots Ah, but I think you don't have to show $\mathrm{Dom}(A^*)\subset\mathrm{Dom}(B)$ separately; I think that you can instead just let it be part of the argument where you see what happens if $\phi\notin\mathrm{Dom}(A)$, where you then use that $\phi$ must keep canceling its production, 'cause otherwise you could just exploit these infinite productions with a $\psi_{n+1}$ that aligns itself more and more to the formula of $A\phi_{n}$ for the given $\phi_{n}$ that does not have its productions canceled.\,. (8:43) .\,.\,(And those productions have to be canceled from above.\,.) .\,.\,Hm, but $\phi_{n+2}, \phi_{n+4}, \ldots$ could still cause trouble.\,. .\,.\,Hm, oh wait, couldn't you just always choose a $\phi\notin\mathrm{Dom}(A)$ by taking a $\psi\in\mathrm{Dom}(A)$ and then removing any *(particular) inner $\psi_n$ from $\psi$.\,.\,!? (8:53) .\,.\,(8:56) No, perhaps not.\,.
.\,.\,(9:01) Hm, it might actually be true that the argument (analyzing a $\phi\notin\mathrm{Dom}(A)$) does not need to change, and that we don't need to have proven $\mathrm{Dom}(A^*)\subset\mathrm{Dom}(B)$ beforehand to complete that argument.\,.

\ldots (9:19) I think that you can argue that $\phi_{n+2}, \phi_{n+4}, \ldots$ can't achieve much: If we look at e.g.\ $\braket{\phi_{n+2} |A^-\psi_{n+3}}$, this matrix element divided with $\|\phi_{n+2}\|$ is very limited (and increasingly so for higher and higher $n$). And if you look at e.g.\ $\braket{\phi_{n+4} |A^+\psi_{n+3}}$, that will, at some $n$ and afterwards, just keep being canceled by $\braket{\phi_{n+4} |A^-\psi_{n+5}}$.
%..I type so slowly.. I have never gotten used to this keyboard; it's so clonky.. (9:27)
.\,.\,And that's why $\phi$ can't allow itself not to cancel its own productions enough that they become effectively finite, for otherwise there's a $\psi$ exploits this while $\phi$ also cannot do anything to counteract this divergence for this $\braket{\phi |A\psi}$. (9:30) .\,.\,Yes.\,.\,:)\,.\,.

(11:30) Oh yeah, I probably should show $\mathrm{Dom}(A^*)\subset\mathrm{Dom}(B)$ first, but I can do that with said argument (where you also argue that an infinite image that is finite at every layer will also yield an unbounded $\braket{\phi |A\psi}$ functional, for the possible $\braket{\phi |A\psi_{n}}$/$\|\psi_n\|$ will only grow with $n$). And then I'll use an argument when assuming that $\psi\mapsto\braket{\phi |A\psi}$ is bounded that defines a process to rewrite $\phi$ repeatedly so that the end result will be a vector that can be shown to be in $\mathrm{Dom}(A)$ given that we already have $\mathrm{Dom}(A^*)\subset\mathrm{Dom}(B)$. (11:36) .\,.\,And I believe that this will work.\,.\,!\,!

(13:43) My $\mathrm{Dom}(A^*)\subset\mathrm{Dom}(B)$ argument here doesn't hold, sadly, 'cause there is a very big area where $\phi_{n+2}$ can lie that $A^-\psi_{n+3}$ can't touch. \ldots (14:04) Oh, wait a minute.\,. .\,.\,If you let $\phi_{n+2}$ be so that $\braket{\phi_{n+2} |A^+\psi_{n+1}}$ cancels $\braket{\phi_{n} |A^-\psi_{n+1}}$, aren't then just on your way to building a new vector in $\mathrm{Dom}(A)$?\,.\,.(!) .\,.\,(When you locate $\phi_{n+2}$ in that very area that is designated for $\mathrm{Dom}(A)$.\,.) .\,.\,Haha! Yes! (14:12)
%(Lad mig btw lige nævne, at det jo må være Reitz' (eller hvad han nu hedder) sætning, man må bruge her.)

(15:09) Well, I can use that argument to show that $\phi$ cannot have any infinite $A\phi_n$, which should be sufficient for the next argument, I think.\,. .\,.\,Well, maybe not, but let's see.\,.
%(15:17) For dette næsten-\mathrm{Dom}(A^*)\subset\mathrm{Dom}(B)-argument kan man også dele \phi op i en Dom(A)-del og en ikke-Dom(A)-del, sidstnævnte med uendeligt billede, hvor denne ikke-Dom(A)-delen så kan ses altid at kunne udnyttes.. ..Tja, nej, men man kan dele \emph{halen} op i to dele efter samme princip. ..Tja, det ændrer nu ikke argumentet; det var nok fint, som det var.. ..(15:24) Ah, men kunne faktisk ikke næsten lave begge argumneter på én gang, hvis man altså deler halen op i to således?.. ..Jo, måske!..! (15:26) ..Så at argumentet altså kommer til at starte med, man kan udnytte så meget af A^+\phi_n, som lige nøjagtig ikke udlignes af A^-\phi_{n+2} fra det designerede område..! (15:28) ..Ja! Nu bliver det virkeligt elegant!
(15:30) I think that I might have an elegant solution to showing.\,. Well, to showing $\mathrm{Dom}(A^*)\subset\mathrm{Dom}(A)$ at once (after having shown that $\mathrm{Dom}(A)$ is dense and that $A$ is symmetric)! I've written shortly about this solution out in the source code comments.

(15:43) Yes, I really think it works.\,.\,!! The argument is that, first of all, all of $A^+\phi_n$ that is not canceled by a legal $A^-\phi_{n+2}$ can be exploited to let $\braket{\phi |A\psi}$ grow. Let us then factor out the finite part of the tail that is canceled by an illegal part of $\phi_{n+2}$ and first of all note that the part of its image in the $n-1$-layer is finite as well. Then we again ask, how much can we exploit of the out-factored part, and again we see that is must for the most part have its productions canceled på a legal $\phi_{n+4}$. We can continue such factorizations indefinitely to obtain a set of vectors that are all in Dom($A$) plus something else in principle. But that part will vanish at every level (point-wisely), when subtract the sum of this set of vectors, so we are left with nothing.\,. (15:53) .\,.\,By.\,. Riesz' theorem, we should then see that all these vectors have a finite image.\,. And we should also see that their sum has a finite image, right.\,.\,? .\,.\,Uhm.\,. .\,.\,Oh, they are all orthogonal, by the way, which is quite nice!\,.\,. (16:01) .\,.\,Hm, or maybe not.\,. (16:06) .\,.\,Well okay, we can argue, I'm sure, that they have finite images when we factor them out.\,. .\,.\,Yeah.\,. So by the nature of this out-factoring argument, we'll now have a sequence of finite, Dom($A$)-like vectors with finite images under $A$ (as I tend to say), which makes them part of Dom($A$), exactly. .\,.\,And what about their combined image, then?\,.\,. (16:13) .\,.\,Can we use that we know that there exist that $\chi$.\,.\,? .\,.\,(16:18) Ah, we know that the sum of these vector formulas will converge at each level! .\,.\,Yeah, each level of the combined image will only have contributions from a finite number of $L^2$-functions! (16:20) .\,.\,That will make each level an $L^2$-function, which then must be equal to $\chi_n$ of a finite ($L^2$) vector $\chi$. And therefore the sum of all the vectors' formulas must be an $L^2$-function itself (equal to that $\chi$). !! (16:23) (And this therefore shows that $\phi\in\mathrm{Dom}(A)$.)

%(25.09.23, 10:20) Jeg kom i tanke om, da jeg lagde mig i seng, at mit argument om at \hat A er symmetrisk på domænet ikke helt holdt, men i sengen i nat kom jeg så frem til, at det stadig holder med mit nuværende domæne, for \braket{\psi_n | \hat A^- \psi_{n+1}} kan kun blive ved med at holdes stor (for voksende n), hvis man breder \psi_{n+1} mere og mere ud, men så får man også et større og større billede pga. den første betingele for Dom(\hat A). Og her kan man altså mere specifikt argumetere ved at sige, at der bliver en begrænsing på \braket{\psi_n | \hat A^- \psi_{n+1}}, hvis \psi_{n+1} ikke må overstige en vis norm. (10:25)

%(27.09.23, 9:05) Jeg har lige startet dagen med at tænke lidt over SA-argumentet (det sluttelige; det jeg har skrevet om ovenfor i den sidste renderede paragraf). Hvis nu jeg kan vise, at man kan danne \psi-sekvenser, hvis billede vokser og vokser i \psi'_n og i \psi'_{n+2}, men forbliver begrænset i alle højere niveauer, jamen så er det pludeselig rigtig nemt at sige, at \phi_{n+2} \emph{må} skulle modsvare \psi'_{n+2} \equiv A^+\psi_{n+1}..!.. (9:10) ..Hm, og det burde være til at vise ok nemt, for hvis man har et \psi_{n+1} der er understøttet af større k'er, så må dette kun gøre, at de "grimme" termer fra A^-_j\chi_j må blive mindre (norm-mæssigt, selvfølgelig).. ..Ja, så når jeg viser, at de.. åh, deja vu.. nå.. når jeg viser, at de konvergerer, så bør jeg også lige vise/bemærke, at normen ikke vokser, når \chi_m understøttes af større k'er.. (9:25) ..Ja, dette må virke, og så jeg jeg frem til, i første omgang herved, at \phi_{n+2} kun må stå for at kvæle en endelig del af A^+_n\phi_n.. ..Og denne del kan man så separere ud.. ..Så får vi to nye \phi'er, hvor den ene indtil videre følger V, og hvor den anden er på sit første niveau (n=m).. (9:29) ..For sidstnævnte kan man så lave samme argument, og herved kan man splitte \phi i undeligt mange, der alle følger V i n=(m+2)-niveauet.. ..Og hvis vi så ser på hver af deres n=(m+4)-niveau.. ..Noget af hver af disse kan så følge V.. Hov, nej, følge Dom(A).. og noget af dem kan bryde Dom(A)-områderne.. ..Hm, og her har vi allerede at sidtnævnte del må være endelig, men vi ved dog ikke at denne dels billede nedadtil må være endeligt, hvilket vi skal bruge for at kunne separere det ud som et muligt.. Hov, nej, jeg mente faktisk V, ups.. et muligt V-hoved.. (9:38) ..Hm, men vi kan ikke bare bruge helt det samme argument som før?.. (til at konkludere at den del kun kan kvæle en endelig del nedadtil).. ..Jo, det må vi jo kunne.. Og så ruller det; så kan vi forgrene \phi i undeligt mange dele, der alle følger V for altid. ..Hov vent, kan vi så bruge Riesz, for vil dette ikke kræve, at A er surjektiv.. Hm.. (9:44) ...(9:59) Ah nej, jeg bruger jo bare, at der findes et \chi, så \braket{\chi | \psi} = \braket{\phi | A \psi}.. ..Hm, og kan jeg så konkludere, at.. Hm, men hvordan i alverden giver det mig, at \phi.. ..Hov, jeg har allerede, at normen af \phi er endelig. Hm, så har jeg ikke allerede her, at \phi må være i Dom(A), det virker da sådan.. (10:02) ..Hov, ups, jeg skal jo netop vise, at A \phi konvergerer. Så spørgsmålet er rigtigt nok, om man så kan konkludere, at A\phi = \chi.. vent, er det ikke givet? ..Nej, vi ved at A^*\phi = \chi, ikke at A\phi=\chi.. ..Hm, gad vide om det så alligevel er her, at man så skal vise at A\phi er endelig først (altså at \phi \in Dom(B))..? (10:07) ..(10:10) Hov, jeg glemte, at jeg jo nok kan vise, at alle \phi_j er endelige! ..(10:15) Hov, men jeg skal jo bruge, at alle (A\phi)_j er endelige, ikke..? ..(10:19) Hov, hvis man nu lavede Dom(A) om til at bruge kulgeskaller i stedet for kulger, får man så ikke, at alle disse \phi-dele vil være ortogonale? ..Hm nej, alle hovederne i et vist niveau behøver ikke at være ortogonale. ..Men til gengæld er alle disse hoveder endelge, og da der er et endeligt antal af dem, kan man også sætte dem sammen til én. Og så får man \phi delt op et sæt a V-vektorer, der alle er ortogonale indbyrdes.:) (10:23) .. ..Og det er klart at alle disse \phi-dele selv må være i Dom(A^*) også.. ..Det er de, ja, når de er vist at være ortogonale.. ..Hov, og jeg har jo også, at deres produktioner er endelige i hvert lag! Ah, det er det, jeg skal bruge! ..Altså at den "gode del" af hvert \phi_n's hale to niveauer oppe sørger for at kvæle alt andet end en endelig del a A^+_n\phi_n. Og så behøver vi ingen gang noget om, at de kan gøres ortogonale (virker det til). For så vil hvert niveau af A\phi være endeligt. ..Hm, og kan vi så ikke argumentere for, at \chi = A\phi overalt (\chi som vi ved har en endelig norm)..? ..Hm, men hvis ikke, så kan jeg muligvis også lave et bevis for, at A\phi også må være endeligt i sig selv, når \braket{\phi | A \cdot} skal være begrænset.. ..Ja, det må jeg også kunne.:) (10:37) ..Ja, så jeg kan komme helskinnet igennem uanset hvad---7, 9, 13!---:).. (10:43) ..Ja, og måske gør dette ikke beviset meget sværere, for jeg skal sikkert alligevel argumentere for, hvor meget vi kan "udnytte" hver del af \phi, og så er det let lige at sørge for, at man også kan argumetere for, at \|A\phi\| må skulle konvergere, når man summer over n.(!):) (10:50)
%(11:05) Ah, jeg tænkte i går aftes, at det måske slet ikke gjorde noget med de "grimme termer" til A^-\chi, får de forsvinder måske alligevel for større og større D. Men så fik jeg alligevel tænkt, at det nok var omvendt. Men nu tænker jeg igen: Det er da sådan, er det ikke?!.. ..Jo, selvfølgelig! (11:07) ..Ork, jamen så bliver det jo SA-argumentet jo pludselig en hel del pænere og nemmere!^^ (11:08) ..Åh, hvor er det altså dejligt, at det stadig virker til at ville lykkes, og også at det ovenikøbet ikke virker alt for besværligt med det sidste nu. ..! (11:10)
%(12:21) Åh vent, måske kommer det ikke til at løse alle problemer, det med at sende D'ernes "radius"/afstand, hvad jeg nu kalder d_{n-1} for hver D_{n-1}, mod uendeligt, for så jeg får jo i hvert fald så ikke herved, at A\psi-sekvensen bliver større og større kun i \psi'_n og i \psi'_{n+2}.. ..Hm, men der er så også en chance for, at jeg ikke længere behøver dette, når nu jeg er fri til at lade de "grimme termer" (kalder jeg dem bare; så grimme er de heller ikke for mig, men hvad ellers skal jeg kalde dem?.) gå mod 0.. (12:26) ..Hm, hvad sker der, når det specifikt er d_{m+1}, men gør større og større..? ..Hm, så kan \phi modsvare alt det.. hm.. (12:32) ..Ja, det hjælper os ikke at lade d_{m+1} være andet end det minimale.. ..(12:37) Hm, nu virker det som om, at det med at gøre D'erne større slet ikke hjæler os, for selvom det reducere de "grimme" termer fra A-\psi, så skaber det bare samtidigt også produktioner til den anden side, som \phi så kan "udnytte imod os," og det gør det jo bare værre.. (12:39) ..Okay, der er vist ingen vej udenom det. Så bliver beviset altså bare lige noget mere kompliceret, fordi man så skal trække rundt på de "grimme termer".. (12:42) ...(12:55) Okay, det kommer nok til at gå fint alligevel, tror jeg. Jeg tror stadig, at argumentet bliver klart nok, og ikke så vildt kompliceret igen..:)..

%"
%(08.10.23, 9:24) Som sagt fik jeg nogle gode idéer i går aftes. Jeg skriver dem ind her, og så kopierer jeg dem også lige til mine 23--xx-noter.
%Det var en rigtig god idé, den der med at jeg kan tage en kompakt basisvektor i et område af m-niveauet, og så kan jeg opløse først m-laget.. Ja, eller nu forklarer jeg faktisk den videreudviklede version af idéen, som jeg kom frem til i går.. man kan så opløse m-laget ved også at dele det op i områder og så starte med 1_S_{m+1,j}A^+\phi_{m,i}, hvor S_{m+1,j} er det område i m+1-laget, man ser på, og \phi_{m, i} er den basis-vektor, man startede med. Herefter kan Graham-Schmidt-producere et set af andre basis-vektorer i dette S_{m+1,j}-område, som sammen med 1_S_{m+1,j}A^+\phi_{m,i} skaber et ortogonalt set (efter at man har normaliseret nævnte vektor også). Jeg mener så, at man kan gøre dette.. eller det må man kunne: Man kan lave denne procedure på samme måde for.. Hm, eller lad mig lige tænke mig om.. (9:34) ..Hm nej, vi kan ikke lave proceduren på samme måde for hver delta-funktion i \phi_{m,i}.. ..Men vi kan lave den på en vis fast måde for hver delta-funktion, som så også kan bruges for alle andre \phi_{m,l}, der også er i samme område, lad os sige at dette område hedder S_{m+1,i} (også selvom jeg burde kalde det S_{m+1,l} så l'et og i'et her ikke clasher..).. (9:39) ..Ja, og er det ikke også bare det, vi skal gøre for at opnå, at alle disse vektorer bliver ortogonale i m+1-laget?.. ..Jo.:) (9:40) Og de bliver altså så ortogonale.. Hm, lad mig kalde det S_{m+1,l} i stedet.. de bliver så ortogonale for alle i og .. k.. Ah, lad mig kalde S_{m+1,j} for S_{m+1,k} i stedet, og lad så j betegne den j'de funktion i Graham-Schmidt.. ..Gram-Schmidt, rettere.. den j'de funktion fra Gram-Schmidt-processen. Så vil alle \phi_{m+1, i, j} være ortogonale, altså for hvert (i, j) \neq (i', j') vil \phi_{m+1, i, j} og \phi_{m+1, i', j'} være ortogonale. Og! Vi kan så fortsætte denne proces hele vejen op for alle lag, således at hele Fock-rummet nu bliver ortogonaliseret på denne måde, ikke mindst hvis vi starter med m=0, altså.:) Og det fede ved denne basis er, at det altid kun er den første j, som man starter med i Gram-Schmidt-processen, altså den man fik på forhånd fra 1_S_{n+1,j}A^+\phi_{n,i}, så vil bidrage til \braket{\phi_{m,i} | \hat A^- \phi_{m+1, i, j}}! For alle andre j vil dette indre produkt (/matrixelement) være nul! Og for i \neq i' vil \braket{\phi_{m,i} | \hat A^- \phi_{m+1, i', j}} også være 0 for alle j, fordi.. (9:50) ..fordi hvert \braket{\hat A^+ \delta{m} | \phi_{m+1, i', j}} vil give det samme bidrag for hver \phi_{m,i}, men.. ..Hm nej, hvordan skal jeg formulere dette..? (9:53) ..(9:56) Nå, det skal jeg faktisk lige tænke noget mere over. Lad mig vende tilbage og indsætte tekst her, efter denne sætning, for jeg har lyst til at fortsætte og skrive om nogle andre ting. (9:58)
%*[(10:19) Nej, jeg skriver det bare i forlængelse nedenfor, når jeg for tænkt over dette.]
%(9:58) Det er ret fedt, hvis jeg kan forsimple alting sådan her, men det er nu ikke sikkert, at jeg vil bruge det i mit paper her, selv hvis jeg kan. For det gør ikke noget, hvis mit domæne også ser alle de "ubrugelige" \phi_{m+1, i, j}'er (j \neq 1) som "gyldige" vektorer alligevel (i modsætning til hvis man gik ud fra disse basisvektorer i stedet for bare områder i prarameterrummet, og at man så direkte gik ind og sagde, at alle andre \phi_{m+1, i, j} end den første (j = 1) er ugyldige \emph{vektorer} ift. V). Nå, men noget andet fedt er, at jeg kom frem til (det var forresten det sidste, jeg kom frem til der kl. halv ti i går), at for SA-argumentet, der kan.. Lad mig lige skifte linje..
%(10:04) For SA-argumentet, der kommer jeg sikkert til at kunne argumetere for, at f.eks. den første vektor, man udseparerer ved hele tiden kun at tage de "gode områder" fra alle lag, at den vektor også må skulle være endelig (norm-mæssigt) for ikke at få et ubegrænset indre produkt-funktionale. Og så kom jeg på, at resten af argementet derfra vel bare må være, at.. ja, eller først skal man lige sige, at dette kan vi gøre for alle andre også, og nu har vi så en (muligvis uendelig) sum af endelige vektorer i V. Og så er det derfra bare at sige, jaman for hver vektor i V, der kan vi mindst "udnytte" så og så meget fra hvert hovede. Så hvis ikke det skal være ubegrænset samlet set, så må amplituderne på et tidspunkt aftage ret drastisk, klart drastisk nok til, at den samlede norm kan blive endelig. Det må kunne lade sig gøre at argumetere sådan, i hvert fald, og det er den eneste lille hage---eller det skal jeg selvfølgelig ikke sige; 7, 9, 13---at i "hvert fald" ikke hvis man også lige kan argumetere for, at.. Ja, at det ligesom er ortogonale, de her vektorer i denne sum.. ..Og/eller at deres billeder er det. Men det føler jeg nu også, at jeg når frem til med, når man betragter disse basisvektorer, jeg lige har snakket om, men som jeg dog pt. mangler at snakke færdigt om.. (10:12)
%Nå, så det vil jeg altså også vende tilbage til. Men en rigtig stor idé fra i går, det er, at jeg fik tænkt over argumentet for, at man kan diskretisere \hat A, og jeg blev lige lidt bekymret, for jeg glemte, at selve k-cutoffet også potentielt set kunne være problematisk. Men så kom jeg på dette argument: Med et stort k-cutoff (k_max) så er det ikke sikkert, at alle produktionerne.. Hov.. Åh, jeg skal faktisk tænke noget mere over det, for det er jo ikke kun produktioner fra områder med store k, hvor det ikke er sikkert, at man får kvælt alle.. Hm.. Nå, jeg skal tænke noget mere over det.
%Øv, sikke meget af det, som jeg alligevel skal tænke mere over. Det kan være, at i dag bliver en tænkedag, så.. Jeg havde ellers håbet på en god skrive/regne-dag.. Jeg tror heller ikke det giver mening nu, at indsætte tekst ovenfor; lad mig i stedet bare indsætte det herunder, når jeg får udtænkt det... (10:19)
%..(10:21) Hm, hvis jeg vender tilbage til \braket{\phi_{m,i} | \hat A^- \phi_{m+1, i', j}}, så er min intuition altså, at når hvert punkt i S_{m, l} fører til den samme delvektor for \phi_{m+1, i', j}, som altså kan delvist separeres til.. Ah, lad mig se på den vinkel: \phi_{m+1, i, j} kan delvist separeres til
%\phi_{m+1, i, j}(k_1,...,k_{m+1}) = \phi_{m, i}(k_1,...,k_m)\Phi_{j}(k_{m+1}).. ..Hm, nu ligner det da en fuldt separabel funktion.. (10:28) ..For en mere kompliceret \hat A kunne den også afhænge af p, som så ville optræde begge steder, men det behøver jeg ikke at tænke på.. .Hov nej, \Phi skal nok afhænge af de andre.. Hm, lad mig lige prøve at opskrive:
%\phi_{m+1, i, j}(k_1,...,k_{m+1}) = \phi_{m, i}(k_1,...,k_m)\Phi_{j}(k_1,...,k_{m+1}).. ..Og når man integrerer over k_{m+1} i \braket{ \phi_{m+1, i, j} | \phi_{m+1, i', j'} }, så må man i hver delta-funktion over (k_1,...,k_m) få nul, hvis j \neq j', og hvis j = j', så må man få det samme, men når man så integrerer over resten, så vil \phi_{m, i} og \phi_{m, i'}'s ortogonalitet medfører, at integralet samlet set bliver nul også. Ja, jeg tror, jeg har ret.
%Og dette gør jo problemet meget mere simpelt---og det vil helt sikkert i så fald blive en del af et mere elegant bevis for den proposition, som jeg prøver at vise nu i det her paper, samt også for mere generelle operatorer. (10:36) Men som sagt, så er det ikke sikkert, at jeg når at gøre brug af det..
%*[(20:07) Jeg kunne også lige nævne, at det at lade r_{m+1} vokse (for D_{m+1}), det vil så i denne version af domænet bare skulle erstattes med, at man fjerner flere og flere basisvektorer fra m+1-laget, samt de tilhørende i alle øvre lag, fra \chi.]
%(10:37) Angående SA-argumentet, og om de forskellige vektorer, jeg får vil være ortogonale.. ..Hm, jeg bør næsten gå-tænke over dette i stedet, og hvis jeg så når i mål i god tid, så kan jeg bare fortsætte med diskretiseringsproblemet, som nemlig også er et rigtigt godt gå-tænke problem (altså i sådan en grad, at jeg tror gå-tænkeri, vil være det mest effektive, og det gælder for begge disse problemer)... (10:41)
%(13:02) Okay, ift. SA-argumentet, så er det rimeligt trivielt, at de bliver ortogonale med min nye måde at lave de gyldige områder på, hvor rækkefølgen af k'erne altså kan udledes fra deres størrelser. Og så kommer jeg altså i mål sådan med det.:)
%Noget andet er dog det der med at diskretisere \hat A og Hilbertrummet. Jeg fik den tanke på gåturen, at man måske kan "snyde" og kvæle nogle områder i sin tilnærmede vektor med nogle andre områder to niveauer oppe (som så \emph{er} i Hilbert-rummet, i modsætning til de områder som den rene egenvektor selv bruger).. Men jeg kan desværre ikke lige fuldføre det argument, især ikke fordi n-begrænsningen, man kan sætte, vil afhænge af k(_max)-begrænsningen.. Hm, nu kom jeg så godt nok på, lige her for kort tid siden, at man måske kunne begrænse n delvist ved også at diskretisere og begrænse p(_max) for fermionerne.. Hm, var det ikke en idé, der er værd at tænke mere over?.. (13:08) ..(13:14) Hm, det kan også være, at det her bare skal være aften-tænkeri i stedet.. Lad mig sige det.. ..(/ pause-tænkeri).. Ok.. (13:15)
%"
%
%(17:22, 08.10.23) Ah, men diskretiseringsproblemet hænger jo kun sammen med mit (samlede) Loretnz-invarians-argument; det er jo ikke nødvendingt for at kunne udlede feltintegraler, er det!? ..Nej, det tror jeg ikke(!), men lad mig lige tænke over vakuum-delen igen.. Her er det jo tanken, at.. Ja, der må man kunne lave samme slags begrænsninger på k'erne, nemligt hvor man tillader, at k_max kan være forskelligt for hvert n, altså hvert niveau i Fock-rummet. (Eller man kan forresten også lave andre regulariseringer, f.eks. kan definere en form for (meget langsomt) eksponentielt aftagende faktor over hele Fock-parameterrummet, og så kan man ændre \hat A således at hver del får ganget en faktor svarende til brøken af, hvad den faktor er i henholdsvis start- og sluttilstanden for den givne transition.) Så det jeg gør, er jo at sige, at hvis vi kan.. Nå, ja, og det med at håndtere vakuumfluktuationerne handler bare om, at man skal diskretisere k-rummene med en spacing (svarende til et volumen-cutoff (i positionsrummet)), og det kan man jo sagtens. Og når man så gør det, så skal jeg bruge, at der eksistere en almost-egenvektor for vakuum-delen, og at dennes transitioner med ikke-vakuum-delen af Hilbert-rummet vil være forsvindende. Så vakuum(-perturberende)-termerne vil altså bare give en konstant energi, der afhænger af k-spacingen/positions-volumen-begrænsningen, og ellers vil vakuum-delen ikke interagere med resten. Så den kan man bare fjerne for felt-integralet (ved at man så også trækker denne konstante energi fra, hvilket er trivielt, givet at man også har vist, at \hat A er self-adjoint uden vakuum(-perturberende)-termerne) sammen med vakuum(-perturberende)-termerne, og så får man et felt-integrale, der konvergerer, uden nogen yderligere regularisering eller normalisering påkrævet! Men bemærk dog, at der \emph{ligger} en ikke-triviel regularisering, for jeg får disse felt-integraler, for, foruden at man jo skal fjerne vakuum-termerne (hvilket jo er den lykkelige del), så kræver det dog lige en af det omtalte regulariseringer af k-rummet. Men man ved dog i det mindste altså, at jo mere man "ophæver" denne regularisering (hvis man har konstrueret den på en sikker måde), så vil felt-integralet konvergere imod et resultat, og det vil være resultatet af \exp(-i \hat A) (eller \hat H kunne jeg også skrive her). Hvor er det fedt! For selvom at Lorentz-kovarians-beviset er noget, der betyder noget for mig i princippet, så er jeg ret sikker på, at det ikke betyder så meget for så mange andre; folk er allerede rimeligt overbeviste om, at vi har fat i den rigtige \hat H_{Dirac} (som er den samme, som jeg udledte; de viste sig jo at være ens alligevel), så det eneste folk bekymrer sig om derfra, er netop at få feltintegralet til at konvergere (og til det rigtige). Fedt! :) (17:42)

(19:43, 08.10.23) As written out in the source-code comments (in Danish) above this paragraph, I've discovered an error in my argument for how you can discretize the Hilbert space and the operator, and then go on to develop the path integrals from that. But as I've realized a few hours ago, this doesn't stop me from being able to derive path integrals (/ field integrals) in k-space! Because you can discretize and regularize that, so that you get almost-eigenvectors that approaches the real (non-discretized) ones. And while you cannot then immediately go to position space from here, I only need to do that for the Lorentz-covariance part of it all. If we just assume that $\hat H_{QED}$ is Lorentz-covariant, which most people already believe, then there's no trouble. We can introduce a spacing, as well as a kind of skew k-cutoff (or some other kinds of regularizations, see my source-code-comment notes), and this then allows for my argument of how we can get rid of the vacuum-perturbing terms. And then we get our path/field integrals. These path/field integrals then do have a regularization in them, but we can make this regularization such that when we lift it gradually, the result will converge to the true $\hat U_{QED} = \exp(-i \hat H_{QED})$.\,:)

%(8:41, 10.10.23) Hov nej, angående SA-argumentet (self-adjointness-argumentet), så kan jeg ikke bruge, der til sidst, at deres billeder skal være endelige, ikke på samme måde i hvert fald som i (Hermitisk-)symmetri-argumentet, for har ved vi ikke umiddelbart, at deres billeder skal være endelige. Så hvis jeg skal have den del til at virke, så skal jeg jo først argumentere for, at man kan udnytte.. Ja, udnytte D-billede som minimum.. ..Hm, men så er det lige før, at man bare skal omskrive \phi med det samme til V-funktioner, for det må man jo kunne.. (8:48) ..Hm.. ..Nå ja, det gør jeg jo på en eller anden måde også i forvejen; det er bare et spørgsmål om, hvornår jeg skal bruge et ortogonalitetsargument.. Hm.. (8:50) ..Tror måske, jeg vil arbejde på skriveriet, og så kan jeg tænke over dette i mellemtiden.. ..Nå nej, for det betyder noget ift. båndene, for der er en lille change for, at jeg skal ændre dem.. ..(9:00) Ah okay, det er faktisk simpelt nok: Når man deler \phi op i V-funktioner, så laver man så et argument for, at.. ..at man "udnytte" dem propertionelt med, hvor stort et billede, de hver især efterlader. ..Derfor skal deres samlede billede summe til noget endeligt, og bum, så er man i mål.. (9:03)

(9:05, 10.10.23) I think a good regularization wold be to do as I've written (briefly) about in the source code comments, which is to introduce a factor over all parameter space, that could go something like $\exp(-\alpha \sum_i \mathbf{k}_i^2)$, where $\alpha$ is then extremely small. And then you change $\hat A$ (/ $\hat H$) such that all transitions get a fraction that is the factor at the end-ket (where these kets are generalized momentum eigenvectors) divided by that of the in-ket. I think you might then be able to argue, that you can then go on to also make a cutoff on the k-space that is then the same for all $n$ (levels in the Fock space). And that would be desirable, I think. I need to think a bit more about it, I guess, but I think this two-fold regularization could work such that you get a desired (if desired) cutoff on the k-space that is the same for all $n$. (9:12)

%(9:13) Nå, tilbage til SA-argumentet, for lad mig så lige sikre mig, at mine bounds så er gode nok, som de er.. ..Og her har jeg altså tænkt mig at bruge, at \hat A^+ bevarer ortogonaliteten imellem lokalt bundne tilstande, i hvert fald ligesom når sluttilstandende også skæres ud og begrænses til at lokalt område.. ..For så kan jeg nemlig få et begrænset C^2 for hver komposant af \phi, som jeg prøver at udnytte med et \psi. .. ..Ah, og jeg skal nemlig lige præcis bruge \psi'er, der er en cutoff (begrænset i k-rummet, i.e.) version af \hat A^+\phi^i, hvor \phi^i er en komposant af \phi.. (9:20) ..Nå ja, en cutoff og normaliseret version.. ..Og det gode er nemlig, at her kan jeg få en C, der så går som normaliseringsfaktoren! ..ikke?.. ..Jo, lige netop!.. ..Og når den således bare bliver mindre og mindre, så er der jo ingen ko på isen.. er der vel?.. (9:24) ..Nej, det er der så netop ikke; jeg kan snildt vælge f.eks. aldrig at lade C overstige 1, hvis jeg vil (er jeg ret sikker på). :) (9:26) ..Ja, så alt hvad \phi^i \in V efterlader af sit billede, det kan jeg udnytte en vis andel af som minimum (altså ganget med en faktor (\leq 1)). For hvis andre dele af \phi skal forstyrre min "udnyttelse," så skal de gøre det i laget over min specifikke del af \psi, som vi ser på. Men her kan man så vise, at \phi faktisk ikke får noget ud af at gøre dette, for \psi's hale kan nemt sørge for, at det meste af \phi's modsvar hele tiden bare bliver modsvaret ét lag oppe igen, og hvor det samlede resultat altså konvergerer til, at \phi ikke får særligt meget ud af det, slet ikke nok til, at det betyder noget (for tilstrækkeligt store a (aka. \alpha)). Og dermed kommer jeg i mål. (9:32) ..(9:41) Ah, og jeg skal også lige bruge, at \phi ét lag over min \psi kun kan "forsøge" at reparere én komposant af sig selv ad gangen! Og dette er altså igen fordi, at \hat A^+, og dermed også \hat A^-, ligesom bevarer ortogonaliten mellem begrænsede start og sluttilstande. (9:43)

%... (13:15) Ah, til SA-argumentet, der skal jeg faktisk starte med at opløse Hilbert-rummet i de der vektorer, som hver især er lokale, og som bygger oven på (lokale) vektorer fra laget under sig, således at.. Hm.. ..Hm.. ..Hm.. (13:19) ..Ah jo, måske går det netop hvis jeg gør mine \chi'er symmetriske.. (13:21) ..Men gælder det med ortogonaitetsbevarelsen så stadigvæk (når den producerede k ikke behøver at være stor ift. resten)..? ..Nej, nok ikke, faktisk.. (Øv..) ..Hm, heller ikke hvis \chi_m er symmetrisk..?!.. ..Jo, gør det ikke!?. (13:27) ..Jo, det tror jeg!.. (13:30) ..Tja, eller.. ..(13:38) Hm, men måske er det også i virkeligheden bare \psi_{m+2} osv., vi skal opløse, lad mig nu se.. ..Hm, jeg kunne nu forresten nok godt lave en S_{n,m}, hvor man kan identificere rækkefølgen af alle k'erne unikt.. (13:40) ..Hm, og så kunne jeg nemlig måske faktisk gøre G_{n,m} til den, der definerer V i stedet.. Men lad mig lige tænke over det med \psi_{m+2} først.. ..Hov, hvad taler jeg om?.. \psi_{m+1}..? (13:43) ..Hov, måske var den god nok, den der med ortogonaitetsbevarelsen når \chi_m er symmetrisk, lad mig nu se.. ..Tja, måske ikke.. ..Hm, men måske kan vi opløse Hilbert-rummet, så alle områderne (på nær en uendelig lille del) har distinkte k, også hvis vi kigger på det løsninger, der bygger oven på.. ..Ja..! Og vil \hat A^+ så ikke være ortogonalitetsbevarende?..!.. (13:50) ..Nej, ikke når to områder i laget under producerer til det samme område i laget over.. (13:52) ..(14:00) Nu fik jeg lige en idé om alligevel kun at lade E_n afhænge af k_{n+1}, og så bare hive D_{m+1}^\complement-faktoren ind under integralet, når jeg skal integrere over k_j, j \leq m.. ..Hm, jeg har det bare som om, at jeg kom frem til, at det ikke kunne lade sig gøre; at k_n skal vokse-vokse-vokse.. (14:04) ..Hm, ser umiddelbart lovende ud, men så skal jeg nu nok bare fjerne k_j'erne for j \leq m i hvert E_n, således at hvert E_n altså stadig afhænger af alle k_j, j > m. (14:14) ...(14:30) Ja, det er bare det, jeg gør---simpelthen så simpelt.. Virkelig fedt.. Og så kommer jeg nemlig til at kunne bruge, at \hat A^-_m \chi_m her endelig norm, og så får jeg ikke længere det der C i mit bound. Og det er rigtig godt, for så behøver jeg ikke længere at opløse \phi. For man kan nemlig også sagtens vise, at \hat A^-_m \phi_m skal være begrænset, og så kommer mit \psi_{m+1} også nemt til at opfylde det. :) (14:33) ..Hm, og nu har jeg ingen grund til at symmetrisere domænet, har jeg..? ..Nå jo, for det skal jo som minimum symmetriseres lidt, for at mine \chi'er kan være der.. ..Men vigtigere: Har jeg nogen som helst grund til at give G_{n,m} den der egenskab? (14:36) ..(14:40) Nej, for det begyndte jeg kun på, mener jeg, fordi jeg blev nødt til at opløse \phi pga. den der C-begrænsning på \chi_m.. ..(14:44) Ja, og hvis jeg ser på symmetri-argumentet, så havde jeg faktisk tænkt mig nu her, at jeg også ville opløse Hilbert-rummet før dette, men det behøver jeg faktisk slet ikke, og selv hvis jeg vælger at gøre det alligevel, så behøver der ikke at gælde noget særligt om den opløsning rigtigt alligevel (andet end at vektorerne er lokale (igen: ikke at jeg behøver det *[Jo, måske er det faktisk meget fornuftigt alligevel.. (14:58)])). (14:46) Og i SA-argumentet skal jeg ikke opløse \phi andet end at jeg selvfølgelig skal dele den op i V-funktioner. ..Og så argumenterer jeg for, at det man kan "udnytte" af hvert \phi_m, det vil være propertionelt med, hvor meget dens egen V-følgende hale lader dens billede fra \hat A^+_m være, nå ja, og det samme med alle n over m. Og så kan jeg så argumentere for, at \hat A_{form} \ket{\phi} må være endelig. (14:50)
%(15:06) Hm, SA-argumentet kræver så nok også lige, at man argumeterer for, at man kan udnytte \hat A^-_m \phi_m, for så kan man nemlig måle alle \|\chi^{1-}_{n-1,j}\|, j \leq m, op imod denne.. ..Og kan man udnytte \hat A^-_m \phi_m..? ..Ah, er det ikke gratis, så at sige? (15:11) ..Jo..!:)

%(18:15) Nå ja, jeg fik aldrig skrevet:
(10.10.23, 18:15) Yes, that two-fold regularization would work, I'm pretty sure. The point is that once you've done the first one, then there will be some large enough $k$, for any given $\epsilon$, such that the combined image of all those states that you cat away from the state (that has only undergone the first regularization), even if we don't cancel any of $\hat A^+ \psi$, where $\psi$ is the state that we cutoff (i.e.\ with $k$'s above a certain size), it would still only yield a state with norm less than $\epsilon$. Because once the first regularization is in place $\hat A^+$ will than only produce a (very large but) finite vector. So if you just choose a $k$-cutoff that is large enough that $\psi$ will be smaller than $\epsilon$ divided with the maximum norm that $\hat A^+$ can produce (or something like that), then the image will only be off the one that was before this second regularization with a vector that has smaller norm than $\epsilon$. (And the image before the second regularization can also be made arbitrarily close to the one before the first regularization, i.e.\ the original one.) So that's the general idea. And I don't really see that $\hat A^-$ could cause any trouble that ruins this trick either.\,. So it seems to me that it would indeed work.\,:) (18:27)


%(11.10.23, 10:43) Jeg kopierer lige de her tilfælde noter ind fra min SA paper draft, bare for fordi.. (jeg ved ikke hvorfor..):
%"
%*(14:50) Jeg har fundet ud af, at jeg ikke behøver den der egenskab omkring G_{n,m} alligevel.:) Så lad mig gå i gang med at ændre det. Nå ja, og så har jeg også fundet ud af, at mit R (eller måske vil jeg begynde at kalde det lille r, og rettere r_{n,m}) kun skal afhænge af k_{m+1},...,k_{n-1}.:) (14:52)
%(16:03) Hov, måske er det ikke så nemt at få E_{n} til kun at afhænge af de sidste n-m k'er. Men måske kan jeg få den til kun at afhænge af k_{n-1}, men så ved jeg dog ikke, om det kommer til at gå længere nede.. ..Hm, jo måske gør det.. (16:07) ..Tja, nu fik jeg godt nok et ikke så godt *(nærmest-)deja vu.. ..(16:10) Jo, det kommer da til at gå snildt, gør det ikke!?.. ..Det tror jeg! (16:12) ...(16:36) Til norm-udregningen skal jeg så beholde r'erne, som jeg før smed væk sammen med T, men så går den udregning ellers også.:) .. ..Og det ser altså også d til at gå med de j'er mellem m+1 og n for \chi^{1-}_{n-1, j}..!:).. (16:40) ..Hm, hvorfor var lige, at jeg satte \beta til 3/4 og ikke bare til 1..??.. ..Hm, det forstår jeg faktisk ikke lige---var det virkeligt bare helt skørt af mig.. Ah, nå nej, det var for at få \beta der i eksponenten.. ..Hm, men kommer jeg så til at behøve det nu?.. ..Nej, for nu er der slet ikke andre k_i'er end k_n i de grænser!:) (16:46) ..Så skulle kun lige være for ikke at nappe hele \exp(-2\alpha n), men måske kan jeg godt det, det kan jeg lige se på.. ..Nej, det er ikke sikkert, jeg kan det, men så må jeg jo bare lade \beta=3/4 i så fald.. (16:50) ..Ah, og nu kommer jeg til at kunne sætte summen af \chi^{1-}_{n-1, j}'erne med j \leq m sammen, så jeg får \hat A^-_m \chi_m direkte i udtrykket.:) (16:58) ..Ah, hvorfor fik jeg ikke gjort dette noget før, jeg overvejde det jo klart!x)x) ..(Men af en eller anden grund kom jeg frem til, desværre, at det ikke holdt.) ..x) (17:00) ...(17:32) Ah, B_n skal være symmetrisk.. Og det skal D_{m+1} så også, og så kommer vi til at få noget for n = m+2, som er endeligt givet min antagelse om, at \hat A^+_m \chi_m 1_{D} skal være endelig.. ..Ok, nice.. (17:34) ..(Hm, har lidt svært ved at finde enrgien til at gå i gang med at lave det om; er ret træt i hovedet, så kan godt være, at det først rigtigt bliver i morgen.. ..(17:41) Puh, blev faktisk virkeligt træt lige pludseligt..!..)
%(11.10.23, 10:35) Har sovet længe i dag. (Vågner mærkeligt nok altid ved fire-fem-tiden om natten lige for tiden (plejer jeg ikke), men faldt heldigvis i søvn igen nogenlunde hurtigt.) Nu hvor jeg sidder og kigger på det, så kom jeg til at se, nu her, at jeg måske kan bruge lutter rekursive argumenter med den her ændring. Lad mig lige tjekke.. ..Ah, men det passer jo. Hvor er det mærkeligt, at jeg kom væk fra denne idé/mulghed, har har jo overvejet den mere en én gang.. Kan ikke huske, hvorfor jeg gik væk fra den igen, men enten var dt noget med, at jeg troede, at det ville gøre udtrykkene meget komplicerede, eller også kom jeg på et tidspunkt frem til, at det ikke duede. Nå, men nu har jeg endeligt set den mulighed, og set at den er overlegen til mine andre muligheder, så det er jo godt. ..Kunne sikkert have sparet en del dage *[måske en hel uge, måske endda lidt mere.. (11:19)], men jeg er da på den anden side også kommet på en del andre gode idéer i disse dage, så ikke græde over spildt mælk; det er nok heller ikke så skidt alligevel. (10:41)
%"
%
%(11:49) Hov, det er ikke fordi, G_{n,m} så bliver mærkelig at definere..? ..Ah, det må næsten være derfor..!.. (derfor at jeg valgte et E_n, der ver symmetrisk mht. de andre k'er..).. ..Hm, men kan jeg ikke bare lade E_n (omdøbt), som jeg bruger til G's definition være en symmetriseret udgave af den E_n, jeg bruger til \chi'erne?!.. (11:53) ..Jo, det er jo det, jeg skal gøre!.. (11:54) ...(12:21) Hm, men måske bliver det så lidt svært at skære B_{m+1} ud, det skal jeg lige tænke over.. ..Hm, men jeg kunne måske bare ændre i mit nuværende H_n og lave det til et H_{n,m}.. (12:23) ..Hm, det her gør det helt klart meget mere mudret, hvordan man lige skal identificere m-laget, så jeg kan nu faktisk godt forstå, at jeg har undgået dette asymmetriske E_n førhen. (12:27) ..(Hvilket faktisk er ret rart; så har jeg ikke været en klovn at overse denne mulighed---hvis det altså overhovedet er en mulighed!..) ..(12:29) Ja, og det bliver nemlig lige netop ret problematisk, hvis jeg ikke kan få lov at kanselere en masse produktioner, fordi de kommer til at ligge i B_{m+1} \times ..., jeg ved, hvad jeg mener.. ..(12:32) Hm, ja, så jeg tror faktisk ikke den går alligvel, jeg bliver nødt til at beholde det symmetriske E_n.. ..Hm, men kan jeg ikke got alligevel bruge rekursive argumenter?..!.. (12:34) ..Jo, det virker da sådan!:) (12:37) ..(Ikke at det gør mit arbejde meget nemmere, men det kommer til at gøre læserens arbejde nemmere..)
%(12:52) Hm, jeg kunne stadig godt have haft set det rekursive argument for de to sidste bånd noget tidligere, men igen: ikke græde over spildt mælk. ...(13:33) Hov, måske kan jeg ikke lave det rekursive argument alligevel, når nu E_n, altså den jeg skal bruge til k_n-integrationen, er så kompliceret.. Hm.. ..(13:37) Ja, det er jo det.. Nu overvejer jeg dog lige, om man mon bare altid kan lade en radius af \max(|k_1|,...,|k_m|) være af produktionerne, nemlig hvis man så bare sørger for at E_n-radiussen vokser hurtigt nok.. ..Hm, det bliver nu nok lidt mærkeligt, så.. (13:40) ..Ja, jeg tror altså ikke, jeg kan lave om på det.. (13:43)
%... (15:50) Det tog lidt tid, men på en regnfuld gåtur nu her kom jeg langt om længe frem til, at jeg jo faktisk gerne vil tilbage til mit R_n med det der L_n, for jeg vil jo gerne have til symmetri-argumentet, at halerne lader hinanden være helt. Men så bør jeg bare bruge (k_i^2 + 1) i stedet for k_i^2 i eksponenterne, i stedet for at komme med den der grimme (viste det sig) ekstra-begrænsning til E_n. (15:52) ...(16:33) Vent, er jeg nu også helt sikker på, at jeg behøver dette?.. ..Ah, som om min hjerne lidt hellere vil arbejde med formler i dag, end den vil tænke over delmængder af 3n-dimensionelle parameterrum.. (16:35) ..Hm, jeg behøver det nok.. (16:37) ..Ja.. (16:42) ..(16:43) Ah, jeg kunne måske dog lave r_n mere symmetrisk.. Hm.. ..Sure.. ..Hm, tænke nemlig at sætte en g_n(k_1,...,k_{n-1};k_i) ind på alle k_i'er, men hvad med i stedet, at gange g_n(...) på n..? ..Ja, eller bare plusse den på i eksponenten.! (16:48) ..Ja, det er det sidste, jeg gør..

(12.10.23, 9:49) It just occurred to me that I never even go to position space in my planned Lorentz-covariance argument, and maybe that exponentially decaying regularization is actually just as good if not better than a $k$-cutoff.\,! I don't know at all, 'cause it's been ages since I looked at that argument. And I by the way don't think I will look into it again any time soon. But it's still so nice to know that there is a good chance that.\,. well, that the double regularization, where you first use the exponential decay and then cut off the $k$-space, might work for the Lorentz-covariance argument still.\,:)

(11:20) Yeah, the exponential decaying regularization should actually just give you much more power, in principle, to show that the two integrals, or rather sums, in $(\omega, k)$-space converge to the same value! .\,.\,At least I think so!\,.\,:)

%(13.10.23, 10:16) Okay, jeg har lige fået tænkt noget mere over mit domæne. Det kræver lige lidt argumentation, lidt mere, end jeg regnede med endda, men jeg kommer helskinnet igennem med min g-funktion. Jeg er så dog også kommet lidt frem til, at man nok godt ville kunne komme igennem med et E_n, der kun afhang af k_{n-1}, men så ville symmetri argumentet til gengæld kræve, at man udledte tilsvarende bånd for hele V, som jeg har gjort for W. Og det er jeg personligt ikke lige klar til, selvom det på sigt måske kunne føre til et mere elegant bevis (når først man har regnet den ud og udført arbejdet).
%..(10:23) Hm, nu overvejer jeg lige, hvad der ville ske, hvis man gjorde g afhængig af m's paritet.. ..Hm, det gør nok ikke noget, nej, så never mind..


(15.10.23, 8:54) Even if my argument about how the vacuum particle--physical particle interaction transitions will vanish in the continuum limit does not hold for some reason, the perturbative argument that the kernel of the vacuum-perturbing part of the operator will be.\,. point-like, so to speak.\,. is actually a pretty good intuitive argument still for why you must be able to remove that part of the operator (the Hamiltonian, i.e.). All intuition tells us, that the functions with exactly 0 energy will be these non-normalizable functions, and that.\,. Hm, or I guess maybe there could be a space of them, that could yield normalizable function when you integrate over just that space.\,. .\,.\,Hm.\,. .\,.\,I don't know, my intuition says that there won't be.\,. .\,.\,Well, but I hope my other argument works (and I think that it does).\,.


%(9:50) Jeg kopierer lige følgende ind fra mit SA paper draft:
%"
%We recall that
%\begin{equation}
%\begin{aligned}
%	G_{n,m} =
%		\bigcap_{j = 2, 4, 6, \ldots}^{n-m} \big(
%			E_{m+j} \times \mathbb{R}^{3(n-m-j)}
%		\big)
%		\,\cap\, \big(
%			(\mathcal{P} E_{m+1} )^\complement \times \mathbb{R}^{3(n-m-1)}
%		\big),
%\end{aligned}
%\end{equation}
%and
%\begin{equation}
%\begin{aligned}
%	E_n = \big\{
%		(\mathbf{k}_{1}, \ldots, \mathbf{k}_{n})\in \mathbb{R}^{3n} \;\big|\;
%			e^{ \alpha n + \sum_{i=1}^{n-1}\mathbf{k}_i^2 } - 1
%			<
%			|\mathbf{k}_{n}|
%			< 
%			e^{ \alpha n + \sum_{i=1}^{n-1}\mathbf{k}_i^2 }
%	\big\}.
%\end{aligned}
%\end{equation}
%..
%
%(9:29) Åh! Jeg har snakket om at bruge, at $\hat A \chi$ mest ``befinder sig'' på niveau $m-1$ og $m+1$. Men jeg kan gøre meget bedre! Jeg kan bruge, at på lag $m+1$, der befinder $(\hat A \chi)_{m+1}$ sig mest kun på $D_{m+1}$, hvilken jeg sætter lig $\mathcal{P} E_{m+1}$. !! (9:42) .\,.\,Så allerede der får jeg jo, at udligningen af $\chi_m$'s ``udnyttelse'' af $\phi_{m-1}$ må skulle modsvares på.\,. .\,.\,Hov, nu blev jeg lige forvirret, 2 sek.\,. .\,.\,Ja, jo, så jeg skal gerne få herved, at $\phi_{m+1}$ derfor er tvunget til at arbejde på $\mathcal{P} E_{m+1}$, hvilket så gerne skal gøre det på vej til at følge $G$ (og dermed på vej til at følge $V$ også).\,. :)\,.\,. (9:49)
%"



\ 

(16.10.23, 11:36) Copied from SA paper draft:

``

(16.10.23, 10:33) I felt a bit dumb yesterday, and a bit disappointed in my self: Why did I think that I could just remove that lower part of $G$ (what I have called $V$ in my old qed.tex notes.\,.)?\,. But having thought some more about it all this night and this morning, I actually don't feel quite so stupid after all, I mean, I did get actually get remarkable far with this strategy.\,. And it is remarkable how this idea of of cutting out that $(\mathcal{P} E_{m+1} )^\complement \times \mathbb{R}^{3(n-m-1)}$ part not only seems to lead us towards (Hermitian) symmetry (although I couldn't quite complete the argument that it leads to symmetry; it might not), but it also restricts Dom($\hat A^*$) so that any $\phi$ in Dom($\hat A^*$) has to cancel itself enough that $\hat A_{form} \phi$ get a finite norm, and it has to cancel itself using
$
\bigcap_{j = 2, 4, 6, \ldots}^{n-m} (
	E_{m+j} \times \mathbb{R}^{3(n-m-j)}
)
$! (At least that's what it seems.\,.) So the idea actually really seems quite promising, in a sense.\,!\,.\,. Today (this morning and noon) I've thought about some more options, and it is also enticing to think about, what happens when we \emph{reduce} that the $E_{m+1}$-/$B_{m+1}$-image of some $\psi\in\mathrm{Dom}(\hat A)$-heads: This has the influence.\,. Hm, let me think again.\,. (10:46) %..(10:56) Nå, min hjerne kan ikke lige fokusere, åbenbart.. ..så tager en pause..
.\,.\,.(11:02) Oh yeah, that has the effect that $\phi$'s in the same area will now always contribute some to the braket functional, and if we remove the $E_{m+1}$-/$B_{m+1}$-image completely, it should just make the functional unbounded.\,. right?\,.\,. .\,.\,Yeah. So there is this tug and pull between $\mathrm{Dom}(\hat A)$ and $\mathrm{Dom}(\hat A^*)$ that seems really interesting and almost promising. And the fact that $\mathrm{Dom}(\hat A^*)$ already consists of $\phi$'s where $\hat A_{\text{form}} \phi$ has a finite norm, I mean, I really seem to be so close.\,!\,.\,. .\,.\,But as things stand, I've actually lost the hope that I will be able to complete this strategy (and I only have a very small hope that it is even possible).\,. I guess I should think more on it, but it does seem now that the task is actually much more difficult.\,.

There are, however, also a lot of other things, that one could try, i.e.\ to search for a way to find a ``symmetric domain'' that can also ``tug'' $\mathrm{Dom}(\hat A^*)$ closer and closer to it, such that hopefully, it can pull it all the way into itself. So unless someone knows a theorem that tells us that this will not be possible, I guess there is still hope. (11:12)

And I don't leave this period of work (a month now of working as much as I could each day, save for that single one-day vacation.\,.) completely empty-handed. Well, first of all, I am a quite a bit wiser on the problem now. And importantly I also realized that I could actually solve the other tasks *(that I left after my QED paper), it seems (especially if we don't count the Lorentz-covariance task(s), which are not so important when my operator is equal to the conventional one, although I don't see why I wouldn't be able to complete that task if I was right about thinking I would be able do so before). And the most exciting part of this is that I have renewed my believe in my old solution to getting rid of the vacuum fluctuations / the vacuum-perturbing terms of the Hamiltonian. Unfortunately, this argument requires that the (renormalized) vacuum-perturbing part of the Hamiltonian will be self-adjoint on its own in whatever theory of everything for which the full Hamiltonian is self-adjoint. So unfortunately we can't conclude exactly that we \emph{will} (100 \%) be able to remove the vacuum-perturbing terms. But, it is nevertheless an important point still: If it turns out that the renormalized vacuum-perturbing Hamiltonian is self-adjoint, and that it thus has generalized eigenvectors, then we should be able to get rid of the vacuum fluctuations, just like that, without changing the physics, and therefore without breaking any symmetries such as the Lorentz covariance. It's not the paper (and I'm talking about what I thought would be a follow-up paper to this one, but now I don't think I will finish this one, not at this point in time at least) that I hoped for, but it's still something. And it's actually enough that I think that it justifies this month of work (taking away from my Semantic Database project), which is really comforting.\,. 

.\,.\,Yeah, so while I did really question if this month of work had been worth my time yesterday, I now think that indeed it has been. (11:29) .\,.\,I think I ought to try to get that other paper done, or at least close to done, this week, but I might also want a little break from the physics first.\,. I'll see. (11:31)

''


(11:37) As can be seen here in this copied text, I think I've given up on my strategy for now. I do still have to think a bit more on it, but it seems like a much harder problem than I thought (this time around), and I'm not sure that it's even possible, at least not with my strategy exactly. So I think I will most likely leave this self-adjointness problem for now, and thus put it on the shelf, so to speak.\,. (11:40)

(12:09) Oh, I just had the thought/realization a moment ago that the vacuum-perturbing part of the Hamiltonian is just what we are effectively left with.\,. hm, when there is no physical particles in the system.\,.(?\,.\,.) .\,.\,Yeah, exactly (I think).\,. So maybe we can argue that this ``part'' of the Hamiltonian must be self-adjoint for any full theory of everything after all.\,.\,!! (12:12) .\,.\,This would great!\,.\,.


(17.10.23, 11:08) Wow!! Maybe I'm actually a lot closer than I thought!! I have been so close to putting the problem on the shelf, but I've just thought some more about it this noon, and now I get that we can actually already conclude that $\phi \in \mathrm{Dom}(\hat A^*)$ needs to use $E_{m+2}$ to cancel its productions at $m+1$, \emph{and} that it however cannot do anything about its productions at $E_{m+1}$ in terms of their contribution to the maximum of the braket functional! It's.\,. I almost can't believe it---and in fact I am hesitant to believe it.\,. .\,.\,I have to mention, then, that the restriction that $\psi \in \mathrm{Dom}(\hat A)$ should ``leave its productions to $E_{m+1}$ be'' should not count when $\psi$ is already in $E_{m}$.\,. (11:15) .\,.\,If I'm not mistaken about this, I actually feel that at this point, I should publish the results, even if I can't quite complete the proof (myself) at this time.\,.\,!\,.\,. (11:18)

.\,.\,The argument, by the way, for why $\phi$ can't do anything about its ``productions'' (as I like to call it) to $E_{m+1}$ is that we can add a state with its head in the $(m-1)$-layer, and then give that state a tail that ``overcorrects,'' i.e.\ one that ``cancels'' much more of its ``productions'' to the area where $\phi$'s head is located/supported, such that in the end, $\hat A \psi$, where $\psi$ is this $(m-1)$-head-state, is approximately parallel to $\phi$'s head at $m$. (11:24)

.\,.\,Right now I'm also hopeful, that this argument will collapse if we look at the layers above from $m$, i.e.\ where $\phi$'s ``head'' is located---or \emph{one} of its ``heads,'' rather. This would be quite great, if this is so, wouldn't it.\,. (11:27)

(11:41) Oh, but this seems to indicate that I've made a mistake in my (partial) symmetry argument, doesn't it?\,.\,. .\,.\,(11:48) Or maybe not.\,.(?\,.\,.)

.\,.\,(11:52) Ah, it's not $\psi$'s located in $E_{m}$ that doesn't need to leave its productions be, it's $\psi$'s in $G_{m}$/$S_m$.\,. I think.\,. %..(11:56) I can feel my brain grinding to a halt; this is also a bit much to take in. I should take a break and then "hum" (in my mind) over it. ..(Jeg tror, at det danske begreb bare betyder, at man snakker (lavmælt) sammen om en ting i grupper, men af en eller anden grund tænker jeg på det og bruger det, som om det betyder at summe over en ting i hovedet (at tankerne ligesom summer lidt i baggrunden af hovedet)..)

%...(16:07) Åh, måske er det lige præcis det, at jeg ikke begrænser $\psi$'er, der selv ligger i $E_n$, til at skulle lade deres egen $E_{n+1}$-produktioner være, der gør at det går op..!(!).. Men lad mig se videre.. %..Tog forresten en lang gåtur lidt tidligere, hvor jeg summede lidt videre over det, men på den sidste del af turen lod jeg det egentligt være (til jeg kom hjem til noget papir). Nu har jeg tegnet lidt på et papir, og er altså kommet frem til dette 'måske,' jeg lige skrev om. Men ja, jeg kunne sikkert godt have arbejdet hurtigere/mere i dag, men det har nu også været rart ikke at skynde mig med det---og bare være glad for, at jeg i det mindste ser ud til at kunne komme en millimeter tæt på en løsning, hvis altså jeg ikke ligefrem \emph{kan} (fucking) løse det.. ..Og jeg vil nemlig være stolt, selv hvis bare min løsningsstrategi/idé kommer så tæt på..
%
%..(16:18) Og jeg har vist ikke nævnt, så lad mig lige gøre det, at det med, at jeg nu ser ud til at kunne få, at $\phi$ ikke må have et uendeligt stort samlet $E_{m+1}$-billede, når man summer dem sammen, det er jo så netop det, der kan gøre, at jeg kan antage det for Dom($\hat A$) og så sikre mig, at $\hat A$ bliver symmetrisk (Hermitisk).
%
%..(16:25) Tja, måske er den ikke-begrænsning faktisk lige meget, men princippet i den/det kan altså stadig være det, der får det til at gå op, så at sige..
%..Udkommenterer lige dette her, jeg lige har skrevet, for bedre at have det stående herude i kommentarerne.. ..Jeg kan ikke samle mig om at fokusere på problemet head-on, så tror lige, jeg går mig en aftentur (for tror stadig benene er friske nok)... (16:32) ..(eftermiddag, ikke aften---føles bare som aften allerede, når jeg ikke har arbejdet så meget/intenst i løbet af dagen (havde det på samme måde i går ved denne tid).)

%(18:27) Nej, men skal ikke lave den "ikke-begrænsning"/begrænsning, eller om ikke andet så behøver man den altså ikke. Puh, jeg tror altså faktisk, at min løsning, hvor man altså bare skærer $E_{m+1}$ fra for G_{n,m} (og dermed for S_{n,m}), holder alligvel, eller sådan ser det altså lidt ud (7, 9, 13)..!.. ..Det ser sådan ud..!.. (18:31)

%(18.10.23, 9:41) Årh, det ser altså ud til at holde..!.. Jeg har en ret stor følelse af ærefrygt/awe ligenu---en følelse som jeg sjovt nok ikke rigtigt havde så meget i går, måske fordi jeg et eller andet sted ikke rigtigt turre tro på det (efter at jeg først mistede håbet (næsten helt)).. ..Men nu har jeg altså lige kigget på det igen, og det ser altså umiddelbart ud til, at det holder. Og nu snurrer det altså lidt i min krop (nakke, ryg), hvilket også er fortåeligt..

(18.10.23, 9:46) I think my solution holds.\,.\,(!!!\,.\,.)

%..(9:48) Jeg fik også lige kigget lidt i en QFT bog i går morges, og hvor er der bare meget underligt fysikteori, som vi nu bør kunne skære fra (det tror jeg). Så det er jo en helt vildt, fantastisk stor opdagelse..!..
%..Det føles måske også bare ekstra vildt, fordi de sidste brikker her faldt på plads af sig selv for mig, så at sige (selvom jeg da lige skulle indse det---og hvor var det utroligt godt, at jeg lige akkurat ikke nået at lægge det helt på hylden..!!).. ..Det for det hele til at virke endnu mere fantastisk.. (9:53) ..(Jeg har godt nok, i øvrigt, haft en intuition om, at \phi'erne ikke kunne ende med at bryde symmetrien for \psi'erne, altså at \phi ikke kunne være assymetrisk med \psi, altså at matrix-elementet ikke måtte give noet andet, når man vendte det om, men jeg kan ikke helt huske, hvad argumentet var, og jeg er bestemt ikke sikker på, at det er relateret til det faktiske argument, jeg står med nu. Og jeg tror altså ikke rigtigt, at den argumentation var rigtig eller tilstrækkelig i sig selv, men lidt svært at sige, når jeg ikke kan huske præcis, hvordan de tanker gik. Hvis jeg husker det, må jeg lige nævne det her..)
%..(9:58) Ej, den der følelse af awe/ærefrygt er altså ret stor.. ..Igen: totalt forståeligt også.. ..(I nakken især og i skuldrene, og lidt i rygraden i det hele taget (fik lige lyst til at beskrive følelsen).) ..Ah, og hvor er det også bare vildt dejligt at tænke på. ..Det er svært at beskrive, hvor meget det betyder for mig, og hvor meget jeg tror, det kommer til at betyde for mig (men på den anden side giver det på en måde også lidt sig selv).:) (10:05)

%(10:33) Jeg har lige taget en stund, hvor jeg bare har tilladt mig selv at nyde denne følelse. Og i stedet for at gå i gang med arbejdet om at finde frem til, hvordan SA-argumentet så skal udformes færdigt, så tror jeg faktisk, at jeg lige vil tage det stille og roligt, og så lige skrive om nogle andre ting, som jeg har på todo-listen, noget fra i går og så også en del ting, som jeg har haft på den i lang tid (i hovedet, altså).

%(11:55) (Sådan.) Ah, det var meget også meget rart lige endeligt at få noteret de småting. Selvom det bare var nogle småting som sådan, så var det altså stadigt ret rart. ..Har stadig den der awe-følelse i rygraden, btw. ..Den sidder længe.. ...(12:17) Ej, jeg er helt sat ud af spillet..xD (^^)
%... (14:13) Ej, jeg har ikke følt mig så lykkelig i lang tid.! Jeg føler mig virkeligt lykkelig nu.. ..Det validerer også bare ligesom alt mit arbejde, og hele mit liv, faktisk, indtil nu. Og samtidigt så får det også bare min nære fremtid til at se så lys ud, så ja, på et personligt plan betyder det bare så meget, hvis altså jeg ikke tager totalt fejl med mit bevis (og særligt den nye sidste del her af det) (7, 9, 13).:) ..Det er bare virkeligt fantastisk..
%(14:48) Puh, det er ret hæftigt: Den lykkefølelse bliver bare ved og ved. Det er lige før jeg bliver i tvivl om, om jeg overhovedet når at samle mig om at arbejde igen i dag.xD ..(Det er nemlig sådan en døsende lykkefornemmelse.) ..Samtidigt føler jeg også et eller andet sted, at jeg bør nyde det.. ..Nyde det ordentligt, at jeg har gjort denne opdagelse, og nyde denne særlige lykkefølelse, der følger med.. (14:57)
%... (16:19) Det var faktisk nok noget lidt tilsvarende til den her sidste del af beviset, jeg havde tænkt omkring, hvorfor \phi ikke kan bryde symmetrien, som jeg nævnte tidligere i dag. *(Men jeg er ikke 100 % sikker *[er faktisk langt fra sikker... *(Men det var nu nok noget af det samme, jeg har været inde på der.. *[..Måske..])], og det ver nok ikke helt så gennemtænkt under alle omstændigheder..) Så på den måde er det ikke dumpet totalt ned i turbanen, at min løsning holdt hele vejen (som den ser ud til nu, 7, 9, 13). Men det synes jeg nu alligevel ikke, gør lykkefølelsen mindre.:) ..Så er det bare dejligt at have genfundet (og sikkert i en meget mere velovervejet udgave) det argument, især nu hvor jeg nærmest var en hårsbredde fra at give op for denne gang; det virkede nemlig som om, at jeg var det.:)xD (16:24)

%(16:43) Ah, man skal vist alligevel have den der "ikke-begrænsning" med, som jeg har talt om.:)

%(17:43) Og lad mig lige få det på det rene: Jeg tror altså, at dette kan revolutionere QFT fuldstændigt.:)^^


%(20.10.23, 10:57) Nå, jeg har sovet lidt dårligt i nat, bl.a. fordi jeg kom til at tænke på, hvordan man kunne vise SA, hvis man tilføjer den frie energi til operatoren, og så indså jeg, at mine \chi-løsninger jo tilsyneladende ikke vil sendes til noget endeligt af \hat H_0. Og så har jeg tænkt lidt i, hvad man mon kunne gøre for at reparere dette. Jeg har nogle få idéer, men min hjerne er lidt langsom.. ..Jeg skal lige have den op i gear (og det tager lidt tid..).. ..(11:06) Okay, det virker som om, at det kunne være en løsning at gange med \sqrt{\mathbf{k}_n} i stedet for at dividere med det, og så dividere med r_n^2 i stedet for med r_n, men lad mig lige se på resten så.. ..(Men virkeligt fedt at jeg allerede har en ret god kandidat til en løsning.!..) ..Hm, det virker nu lidt hacket, godt nok.. (er lidt skeptisk).. ..Ah, jeg glemte også at kvadrere i hovedet et sted, så never mind; tror ikke, at det løser det.. ..Hm, nu overvejer jeg, at gå den anden vej.. (11:13) ..Ja, nej.. ...(11:29) Hov vent, skulle jeg også kvadrere der?.. ..Ja.. ...(11:47) Uh, måske kan jeg godt komme igennem, også ift. \chi^{1-}_{n-1, j}, m < j < n, -båndet, hvis jeg bruger en kugleskal-tykkelse, der går som r_n også!.. ..For så får jeg godt nok et udtryk i lign. (\ref{bound_for_limited_E_n_over_k_j_integral}), hvor der kommer til at stå 2b i stedet for 4b i potensen (i nævneren), men så kan jeg til gengæld få lov at bruge alle b < 2 (i stedet for b < 1).:).. ..Hm, men kan det hjælpe med at løse problemet med at tilføje den frie energi..? (11:54) ..Jeg får vil så noget, hvor faktorerne udligner hinanden, og det er vel desværre ikke helt godt nok.. ..(12:05) Jeg fik idéen i morges/nat (kan ikke lige huske om det var efter jeg stod op, eller om det var i sengen i nat) om at lade tykkelsen gå som \exp(\sum_i |k_i|) (ikke \exp(\sum_i k_i^2)), og nu ser den idé pludselig endnu mere frsitende at gå i gang med at undersøge.. ...(12:18) Eller måske som \exp(\sum_i(k_i^2 + |k_i|)).. ..Eller rettere, at den øverste grænse går som det..
%(12:22) Hm, jeg bør egentligt også overveje at lave prefaktoren om til, hvad jeg får fra lign. (\ref{E_n_over_k_n_integral}) eksakt, nemlig for så måske at space \chi^{1-}_{n-1,n,2}. Det må jeg lige huske at overveje..

%(12:37) Nå, det med \exp(\sum_i(k_i^2 + |k_i|)) hjælper mig vist ikke. Lad mig prøve i stedet at tænke i noget, der går som.. ..k_n^{-5/2}, og så med et tilstrækkeligt stort volumen, for det er det, der bør løse det, ligesom.. ..(Eller k_n^{-3}..) ..Hov!.. ..Ah, k_n^{-5/2} er jo den grænse, hvor både \hat A^{-}-integralet og energien bliver uendeligt; jeg er ret sikker på, at jeg har gået og troet, at det var forskellige grænser!.. Hm, lad mig lige se nærmere.. (12:48) ..Hm ja, så der er faktisk ikke længere noget der fortæller mig, at dette problem \emph{kan} løses.. Hm.. ..Ej, det er virkeligt ærgerligt, for selvom jeg har det her store resultat, så betyder det bare ret meget, om det også ser ud til, at man nemt kan tilføje den frie energi (som jeg har gået at troet.:\), eller om dette vil blive et nyt avanceret problem (hvor man så muligvis kan prøve at få \psi'erne i Dom(\hat A) til også at udligne deres egen frie energi via \hat A^- \psi..)..:\..

%(13:02) Okay, det virker faktisk til, at jeg kan løse det, måske, hvis jeg kan få
%(r_2^2 - r_1^2)/(r_2^2 + r_1^2) til at aftage nok!.. ..Igen: Måske!.. ..Men så burde min (d=1)-løsning næsten allerede virke..(?) ..(13:09) Hm, men det kan da være, at den alligevel gør det, så!..(?..) ..For min tanke er nemlig, at jeg får en prefaktor (nu hvor jeg laver denne mere pragmatisk) på 1/(r_2^2 - r_1^2). Og for den frie energi får jeg så en faktor, der går som (r_2^4 - r_1^4), når man integrerer over k_n. Og vi har jo---for vi har nemlig kvadreret prefaktoren i mellemtiden---(r_2^4 - r_1^4)/(r_2^2 - r_1^2)^2.. Hov, måske har jeg bare lavet en regnefejl i hovedet.. Vi har 
%(r_2^4 - r_1^4)/(r_2^2 - r_1^2)^2 =
%	(r_2^2 - r_1^2)(r_2^2 + r_1^2) / (r_2^2 - r_1^2)(r_2^2 - r_1^2)
%=
%	(r_2^2 + r_1^2) / (r_2^2 - r_1^2)..
%Ja, så vi ville skulle få førnævnte brøk (den inverse af denne) til at vokse i stedet.. (13:16) ..Hm, og det kan man ikke, kan man vel?..:\ ..Nej, det kan man jo ikke..:\ (13:17)

%(13:25) Hm, og jeg skal ikke bare sigte efter en k_n potens, der lige er lidt "mindre" end k_n^{-5/2}..?
%...(13:53) Nu tænker jeg på at bruge k_n^{-5/2} præcist, og så med \exp(\sum_i k_i^4)).. ..For så vil prefaktoren jo blive 1/(p_2 - p_1), hvor p'erne er potenserne.. eller lad mig se.. ..Det kunne blive 1/((1-a)p).. nej.. Hm.. (13:57) ..Lad mig prøve at gange potensen med a, så det rigtignok bliver 1/((1-a)p). ..Og for den frie energi må man så få ((1-a)p)/((1-a)p)^2 = 1/((1-a)p), right?!.. (13:59) ..Vældig interessant.. Jeg tager lige en lille pause, så jeg kan komme tilbage og se på det med friske øjne.. (14:00) ...(14:15) Tror jeg vil prøve at gå en lille tur i ruskvejret, måske blive mere frisk på den måde.. ... (15:03) Jeg skulle lige til at skrive, at det hjalp at blive blæst lidt igennem, men nu føler jeg mig faktisk lidt træt igen. Men hvad meget vigtigere er, jeg kan altså stadig ikke se, hvorfor denne k_n^{-5/2}-løsning ikke fungere, ift.\ også at få den frie energi til at blive endelig. Men godt nok mangler jeg lige, at gå \chi^{1-}_{n-1,j}, m < j n,-argumentet igennem først, så det skal jeg lige gøre. Men lad mig lige nævne, at det gør mig forhåbningsfuld over for denne løsning, at selvom jeg ikke alligevel har et argument for at \hat A^- \psi \emph{bør} vinde over \hat H_0 \psi, så at sige, så har jeg stadig et intuitivt argument, ligesom, for hvorfor den/det (altså \hat A^- \psi) \emph{kunne} dette. (15:08) ..(Nemlig fordi min intuition siger mig, at \hat A^- \psi er lidt mere "kraftfuld," når vi når ned under k_n^{-5/2}, potensmæssigt.) (15:09)
%(15:27) Hm, det kunne måske være bedre, så, hvis eksponenten var et produkt i stedet for en sum.. ..Hm, selvom det gør \chi^{1-}_{n-1,j}, m < j n,-delen svære at regne på, gør det ikke..? ..Ellers kan det måske også gå fint, hvis jeg beholder det som en sum.. ..Men jeg kunne forestille mig, at jeg så hellere vil gøre det i en artikel nr. 2, således at jeg nemlig tager en lidt nemmere løsning her i denne artikel, hvor den frie energi ikke er med..
%..(15:36) Hov, er det mig, der er helt væk, eller.. ..behøver vi overhovedet det med at invertere E_n?.. Jeg ville blive overrasket, hvis man ikke behøvede det, og nok synes, at det ville være lidt mistænkeligt, men nu må jeg se.. ..Ah, bare jeg var lidt friskere---kunne nok have været godt med en middagslur, hvis jeg havde evnen.. (15:40) ..Hm, jeg burde prøve at gå det igennem i hånden.. (15:42) ..Eller prøve at lægge mig lidt først.. ...(15:56) Man skal bruge E_n til den del, så det lyder meget godt.. ...(16:22) Hov, jeg retter lige k_n^{-2/5} til k_n^{-5/2} ovenfor.. ..Hm, \emph{er} det faktisk ikke ligefør, jeg ikke behøver at invertere E_n alligevel.. For vi får jo k_n^{-5}, når vi kvadrerer.. ..Hm, det virker lidt vildt, men.. ..Hm, det virker altså lidt utroligt, hvis alt det her virker, men det ser det da umiddelbart ud til at gøre..!!.. (Har forresten ikke fået regnet noget i hånden; har kun regnet på det i hovedet, men stadigvæk..) (16:27) ..(Årh, egentligt vildt, at klokken allerede er halv fem..)
%(16:47) Hm, det virker altså umiddelbart til, at det er rigtigt nok.. Og hvis det er, jamen så bør jeg jo bruge den løsning, selv til dette paper, hvor jeg altså nok stadigvæk ikke har i sinde at tilføje den frie energi.. ..Hvor er det bare overdrevet fedt, hvis jeg har ret, men jeg er lidt for træt til at føle mig særligt sikker.. ..(16:52) Er det virker altså faktisk til, at resten af beviset, både symmetri- og SA-argumentet, kommer til at forløbe på samme måde, bare hvor det så er produktionerne + den frie energi gange \phi i samme område, som man \phi \in Dom(\hat A^*) bliver nødt til at sørge for, bliver endeligt. ..!!.. (16:54)
%(18:11) Arh, og det skal også være.. Hm, jeg forestiller mig, at \|\mathcal{J}\psi\|-restriktionen også lige skal ændres, lad mig se.. ..(18:15) Ah ja, vi skal ændre den, så at vi i stedet sætter begrænsningen på $\| \sum_i \mathcal{J}(\phi^i) \|^2$ (i stedet for på $\sum_i \| \mathcal{J}(\phi^i) \|^2$)! Og så skal dette så yderligere også ændres til, at man begrænser $\| \sum_i \mathcal{J}(\phi^i) + \hat H_0 \phi^i \|^2$ i stedet! (18:18) ..Og så skal symmetri-argumentet nemlig bare lige justeres, så man også lige sørger for at argumentere for, at for store nok N.. Hm, jeg skulle til at sige, at så vil \hat H_0 \phi^i-delen blive mindre og mindre betydende, men det kan man vist ikke bare slå fast så nemt alligevel.. (18:21) ..(18:27) Ah vent, måske behøver man slet ikke at bruge $\sum_i \mathcal{J}(\phi^i) + \hat H_0 \phi^i$ i stedet for $\sum_i \mathcal{J}(\phi^i)$; måske får vi allerede vist, at bidraget til billede fra \hat H_0 vil blive mindre og mindre betydende... ..Hm, eller måske ikke.. (18:31) ..(18:34) Hm, men vi må næsten kunne argumentere for, at den der $\hat H_0 \phi^i$-del vil blive svagere og svagere.. ..(18:43) Hov, det kan da være, at det faktisk lige netop bliver nemt at argumentere for, at \hat H_0 \phi^i ikke kan gøre en forskel her.. ..Ja, så måske kommer det ingen gang til at ændre symmetri-argumentet særligt meget, at man nu har $\sum_i \mathcal{J}(\phi^i) + \hat H_0 \phi^i$ i stedet for bare $\sum_i \mathcal{J}(\phi^i)$!:D (7, 9, 13.) ..^^ (18:46)




(25.10.23, 12:11) Until yesterday my plan was to use that $\chi_n$ is either non-negative or non-positive everywhere for all $n$ in the part of the proof that shows that $\|\hat A^-_{n,l} \chi_{n,j} \|$ for all $l \neq j, n$. But I then got a bit worried that this argument would not be generalizable to coupling factors that might depend on $\mathbf{k}$ (and be complex). So I considered showing a bound for all
\begin{equation}
\begin{aligned}
	\hat A^{-(q)}_{n,l} \psi_{n}(
		\mathbf{k}_1, \ldots, \widehat{\mathbf{k}_{l\,}}, \ldots, \mathbf{k}_{n-1};
		\mathbf{p}
	) =
		\frac{1}{\sqrt{n}} \int
		\frac{1}{(\mathbf{k}_l^2 + 1)^{2q} \sqrt{|\mathbf{k}_{l}|}}
		\psi_{n}(
			\mathbf{k}_1, \ldots, \mathbf{k}_{n-1}; \mathbf{p} - \mathbf{k}_l
		)
		\,d\mathbf{k}_{l}
\end{aligned}
\end{equation}
instead. But this then limits $\phi$ in the SA argument, as I've just realized. But luckily, I just had the realization, that my argument using that $\chi_n$ is either non-negative or non-positive everywhere might actually very well be generalizable after all. In fact, I'm pretty sure that it is. For you can just redefine $E_n$ such that it only includes a volume where the phase of the coupling factor, call it $\alpha(\mathbf{k})$, is almost constant. And then you just make sure that the deviation from this constant decreases exponentially (or more) as $n$ increases, and Bob's your uncle. So I \emph{will} therefore just use my argument, that uses that $\chi_n$ is either non-negative or non-positive everywhere, as was the plan beforehand. (12:20)

(16:54) Oh no, you don't even need to make the deviation decrease, actually. You can just define an $E_n$ that spans a solid angle where $\alpha(\mathbf{k})$ does not vary too much, and then you can just make sure that the deviation to both sides (of the phase factor that you're going for) cancel each other, pretty much.






\section{Perpetual motion machines and GR}

(18.12.23, 10:08) For some reason, I just thought a bit about the 2nd law and all that, and last night in bed, I recalled an old idea of mine about letting two objects exchange heat (``vekselvirke'' in Danish) via heat radiation where one object is high up enough that it experiences a time dilation due to GR. I just looked at my notes from '17 this morning and recalled that if we filter out all radiation except some which has an angle that it close to the radial vector (between the heavy object, e.g.\ a planet, and the outer object, and also the inner object, since we can assume that they are in line), then the light beams should not be distorted to 1st order (only to higher orders) of the beam angle. And I have several times before calculated that the Planck curve when red/blue-shifted does not turn into a new Planck curve, as the amplitudes are wrong. When distant galaxies are red-shifted, the beams are also expanded in the transverse directions on velocity vector, which means that the Planck curves \emph{does} turn into other Planck curves. But without that transverse distortion, this does not happen, and as I said, I don't believe that the light will be distorted this way between two object like I have described here (one could be on the ground and the other could be on a theoretically high and solid tower on one of the poles of the planet (or the planet could have zero rotation)).

Now, I have abandoned thinking about perpetual motion machines (PMMs) in the past, since one can quite easily (it seems) argue from quantum mechanics that they cannot exist: For any quantum mechanical system that we might enclose in a large (perhaps extremely so) container, then having a PMM that, say, sorts the gas molecules of a giant box into one partition of that box, without changing the temperature (as a PMM of the 2nd kind would be able to), would lead to a contradiction: Even if we take a many-world interpretation of QM, if the box is large enough, this situation will always result in us having less entropy than what we started with, giving that the box was an ensemble (in thermodynamic equilibrium) to begin with. So PMMs an QM does not mix! (And maybe one can make a similar argument for classical physics as well, but I'm not sure that it is quite as easy (for how do you really define the combinations of possible states in a meaningful way to achieve this, even if you simulate the system via a discretization?\,.).)

But of course, we don't know for sure that GR can be made into a quantum mechanical theory. And, I've just realized, if we consider a mixed theory where we have QM on a curved space-time, then I don't know that you can necessarily use the same arguments.

This was also my conclusion back then, except that I maybe didn't think about the last part here about QM on a curved space-time maybe does not lead to a situation, where you can describe the system in terms of energy eigenstates.

.\,.\,Of course, the 2nd law is one of the most---I would personally even say \emph{the} most---fundamental symmetries of nature, since it only relies on very light assumptions, namely that the laws of physics can be reverted so that time can run backwards (and with the second law, it does not matter that the physical laws might be time-dependent, as opposed to the 1st law (of energy conservation); as long as you can just reverse the time-dependence of those laws). In other words, as long as information about the universe isn't destroyed, then you have the 2nd law. But QM does give a potential for information destruction if we look at the standard interpretation where measurements causes wave function collapses.\,. Now, this normally does not ruin/hinder the 2nd law, as per the argument that I just gave. But when we include GR.\,. Who says that the combination of GR and QM could not lead to irreversible physics in a way where the 2nd law becomes broken?\,.\,. (10:49)

When I abandoned PMMs, I probably did so partly because I believed (and probably still believe) in a theory of everything that is quantum mechanical. And even though I'm sure that I also considered the potential for GR not.\,. Wait a minute, now I just recall that I actually kind of believed back then (and maybe I actually do still, come to think of it) that the union between QM and GR would include a true, physical measurement process where states with enough decoherence would undergo a wave function collapse such that only of of those states goes forward in time from there. So why did I abandon these thoughts?\,.\,. Maybe just because I had better and more interesting things to do at the time (.\,.\,reinventing QED\ldots), but whatever.\,.

Now I'm actually a little bit excited about this topic once again. .\,.\,It would unfortunately probably take a while for us to confirm experimentally that this kind of PMM that i described above (with the two objects, etc.) \emph{might} have a potential (never mind experiments to \emph{confirm} it). Oh, and of course, I might also simply have overlooked something or be wrong in my calculations. But imagine if we could someday make an experiment that would conf.\,. or rather which would \emph{suggest} that such PMMs might be possible.\,.\,! (Oh, and I should mention, that the PMM part then comes from shifting between filtering out different parts of the spectrum, such that the two objects will reach different temperature differences when they are in equilibrium, given the current filter (and the point is that this temperature difference is dependent on the filter).)
It would then give us some very important clues about how we can expect QM and GR to mix, and more precisely it will give of some clues about how they probably does \emph{not} mix. (11:04)

%(11:05) Let me also just mention a thouhgt out here in the source comments: Imagine if the mix between QM and GR would be non-linear. Then we could in theory (at least until some other aspects of that theory is discovered which might ruin this) make QM--GR computers that can effectively just kill all computations which does not yield an interesting result, and then P would be equal to NP. Now, that kind of computer would probably be enormously difficult to make, and would not be worth the effort. And to begin with, I really don't believe that we will find non-linearity. But it is an interesting and funny the thought, still. And given how much people are excited by things like warp drives and tacheons, etc., I'm sure a lot of people would find these thoughts interesting as well. (11:11)


%(19.12.23, 13:46) Hm, I'm trying to calculate on the problem today, but I get a bit stuck. So it's very much possible that I was simply incorrect and that there is a lensing effect that is proportional to the time dialation. I'll calculate some more on it, though.. By the way, my vacuum paper was released on arXiv today! Unfortunately, the moderator(s) "degraded" it to "general physics," so they must not think much of it. (And weirdly enough they didn't include the CC BY 4.0 licence! ..Oh well..) So yeah, that's not good, but I hope somebody will read it and get the point. ..Or else I kinda rely on my SA paper to break through..

%(14:43) Okay, har lige læst mig frem til, at et sort huls radius ser \sqrt{3} gange større ud end foton-sfæren. Og time dialation ved foton-sfæren er også \sqrt{3}, så hvis det indre sorte legme erstattes med en sfære lige over foton-sfæren, så passer pengene altså; man vil få en samlet intensitetskurve der passer med en Planck-kurve. Kan være, jeg bare holder her, men det kan også være, at jeg lige vil tænke lidt mere over, hvis man nu kun ser på stråler, der er tættere på den radiale akse..
%..Hm vent, hvad hvis man sætter den indre sfære lige under foton-sfæren?.. (14:50) ..Så vil intensiteten stadig stige, for så vil keglen, hvormed man kan se ud, blive mindre..
%..Hm, det kan være, at jeg bare holder for nu med dette problem, for jeg regner ikke med, at det vil lede mig nogen vegne, eller rettere lede mig til andet end, at EM-idéen ikke holder. For som sagt, den 2. lov er \emph{virkeligt} bare en fundamental lov; der skal nogle meget særlige omstændigheder til for at et univers kan bryde den.

(19.12.23) I've looked some more at the problem, and I can't reproduce my result, so it's probably nothing after all: The 2nd law most likely holds.

%(15:03) Wait a minute!.. If the total magnification is \sqrt 3, but the surface that is visible is far greater than just the semi-sphere (and you will even see the same surface repeated several times at the edge of the \sqrt 3 \times r_\text{photon sphere} radius circle), will that not mean that the magnification at each local point is \emph{less} than \sqrt{3}!?

\ldots (15:10) Okay, now I actually just had a thought---see the source comments---that has reignited my interest quite a bit.

%...(15:42) Oh, but this isn't enough.. My argument here is not complete. (So it probably doens't work..) ..Yeah, that argument does not work, but let me just think about it a bit more..

\ldots (15:57) Yeah, no, it probably doesn't work.\,.

%(16:01) Oh, now I recalled how I probably want to do the calculation (the way I did back then in '17 (..or at least at some point)), so let me just do that.. ..Hm, or maybe it's not that simple, let me see..

(16:49) Oh, I actually just managed to (finally!) do the intensity factor calculation, and once again found that it ought to be 1 (intensity is the same as in flat space) when the beams are very close to following the radial axis.\,. (.\,.\,!\,\ldots)


%(20.12.23) Instead of a tower, you could also have a Dyson sphere around a dead star, and then put the parabola on the sphere, together with the reservoir, the temperature of which you want to change, and the people and/or machines who needs the energy from the PMM.


\subsection{Considerations about the 2nd law in general}

(20.12.23, 16:16) I was very excited earlier, out on a walk, since I kinda reached the conclusion that classical physics, and GR in particular might break the second law. But then I've had some other ideas since then, which makes it much more complicated. Let me recap my thoughts on the walk: I thought about how a classical universe in which some wizards (this is a toy universe) also magically have the ability to shrink *(and also enlarge) objects at will actually seem to break the second law, without breaking energy and momentum conservation (if all velocities are preserved after shrinking). The problem is that in classical physics, one has to actually discretize before entropy can be truly defined. But then when you shrink something, assuming that the discretization is in position space, you will lose information, since $2^3$ points will map into the same point, i.e.\ if you shrink to half the size. Now, GR is exactly a theory where space is not flat, so maybe there is potential here, that the 2nd law might not apply. Then I thought more about it, and thought about how photons.\,. Oh, wait a minute, now I just realize that the fact that photons gather when they approach a heavy object is exactly what might \emph{prevent} my PMM idea of working (though it doesn't seem to do that), not \emph{make} it work. Ah well, but anyway, that was my thought: That photons can gather in curved space-time, and that was what made me quite excited. Although I soon had the thought then: Well, why not just make the discretization space-dependant, and in particular make it finer the closer you get to the heavy object?\,. So that idea ruined that argument already, it seems (and now it is further ruined since my PMM does not require this gathering). Then on my way home, last leg, I thought about simulations. Now, the second law should also apply for a simulated universe, as long as information is not erased, and as long as the system is discretized, at least if it is classical. Of course my PMM relies on Planck curves, which can only be explained by QM, so how to construct such a universe/simulation? Well, after I have gotten home, I thought about what would happen, if you put two quantum systems together and then simply coupled them via the photons, making it so that photons changes wavelength when they cross the boundary between the two systems.

And that's where I'm at now, and this idea is actually quite intriguing. You should be able to simulate a whole.\,. space station, let's say, in a quantum system without GR. And they way to make photons shift there wavelength is just.\,. Oh wait a minute.\,. .\,.\,Oh, wait maybe it is nt so easy, for if the photons changes energy  when they cross the boundary, they can't be form standing waves which are energy eigenstates.\,. So what would one do to realize this universe.\,.\,? .\,.\,Hm okay, maybe that's not so easy.\,. (16:41) \ldots (16:54) Oh wait, how about you just slow down time for the other system across the boundary?\,\texttt{:D} That should work, and that also even fits the GR situation of my PMM idea better.\,:) .\,.\,So you simply just reduce all energies and interactions with a factor in the system that models what we would have far away from the heavy object. This i a fully quantum mechanical system, so the second law cannot be broken. Yet it really seems like one would be able to make PMMs of the second kind (via the red/blueshift of thermal radiation across the boundary that connects the two partitions of the system). So what on earth is going on here??\,\texttt{:D} (16:59)

(17:22) Oh wait! Maybe I have just simply forgotten to factor the time dilation into the intensity calculation.\,.\,! .\,.\,Right, that must be it, but this then begs the question, what about my earlier idea (maybe only detailed in the source comments) of having an inner Dyson sphere just outside of the photon sphere of a black hole? And given that this idea \emph{does} rely on the photons gathering in space.\,. could this not potentially result in a GR--thermal radiation PMM?\,.\,. (17:27)

Anyway, great that I caught that realization. The intensity should also increase.\,. Oh, and come to think of it, I did probably also realize that back then in 2017---I was wondering about why those notes was from so early, 'cause I'm pretty sure last time I thought about the subject was later than that perhaps even as late as the beginning of '19. .\,.\,Yeah, that makes sense, so the increased intensity is what makes it add up (making it not a PMM).

But I'm still a bit intrigued by that photon sphere version of the idea.\,.

.\,.\,(17:38) Hold on a minute.\,. The intensity should only increase by a factor of the time dilation, but when space is expanding, the intensity should increase (or decrease rather) by that factor squared, right.\,.\,? .\,.\,(17:45) And you do need the intensity to increase as the square of the time dilation to get a right Planck curve.\,. .\,.\,(Well, it needs to be increased by the cube, rather, but the increase in frequency already takes care of increasing it by one factor.) .\,.\,Oh wait, the Planck curve is intensity \emph{per} frequency, of course (as it is a distribution), so what does that mean, that expanded light shouldn't redshift into Planck curves?? .\,.\,(17:54) Hold on further; doesn't this fact just cancel the.\,. .\,.\,the increase in frequency do to the energy increase in the blueshifted light.\,.\,? .\,.\,(18:02) Ah, the intensity then needs to be increased---or decreased in the case of redshift by expending space---by the frequency shift factor cubed, compared to if one simply turned all photons more red/blue magically. But come to think of it, this is also exactly what will happen when space expands, as each spacial dimension that is stretched will result in a decreased intensity, also the longitudinal one.

But then I'm back to the puzzle of why my PMM, either in the GR form or in the simulated form, doesn't break the second law.\,?

(19:15) Oh, I actually think I eye the solution for both cases\ldots

(21:35) Ah, nu ved jeg det måske. Jeg skal sikkert også bare tage højde for, at afstande er komprimerede i $dr$-retningen. Og så tror jeg hermed, at jeg har en løsning på begge problemer. Skriver videre om det i morgen.

(21.12.23, 9:47) In terms of the simulation that I thought of, one would also need to shrink the dimensions of the faster-moving system (with faster time) compared to the other in order for the photons to get a new wavelength when they cross the boundary. And then the situation is just similar to what happens when light crosses an interface to a volume of glass or water (etc.). So no PMM after all there.

And in terms of the GR PMM, I have most likely simply overlooked that the space is compressed.\,. or rather stretched, actually, in the radial direction when seen from the observer close to the heavy object compared to an outside observer. That means that the solid angle of a beam that is close to perpendicular to the surface (i.e.\ close to the radial direction) will seem smaller, and the incoming light will thus seem to come from a smaller solid angle when looking out. This increases the intensity, and by exactly the right factor (squared), it also seems. So no PMM in this case after all either.

I can thus put this problem and these thoughts to bed. %(which actually feels nice..)



\section{Quantized, discretized GR}

I actually kinda want to look into if one really can't make a pretty simple discretized theory that models GR, namely by taking a lattice of Cartesian coordinates as the parameter space, where the distances to the adjacent points (from which the spacial metric can be derived) as part of the parameters for each point, and then also the time factor.\,. Oh, this is where I remember, that GR is second order in time.\,. But it does have some gauge invariance, but I'm not sure that this invariance is strong enough that one can eliminate the second time derivative.\,. .\,.\,Is it even worth for me to look into, then, at this point?\,.\,. (9:28, 22.12.23) .\,.\,Hm, let me read up on the gauge symmetry of GR first.\,.

(28.12.23) I've thought a little bit about this topic, but I'm not going to continue with it. One could of course try to make the first time derivative a separate parameter, and then try to make a Hamiltonian where the actual time derivative always follows this artificial parameter. But then I've thought a little bit about today: Couldn't you try to follow the exact same approach as how I derived the theory of QED in my QED paper? If there is a good Lagrangian formulation of the full dynamics, i.e.\ including matter, then it should be possible, except\ldots (\emph{pause for effect}) \ldots that second time derivative.\,. But one could maybe (not that I'm going to do it now) look into if one could make some magic happen and find a kind of Hamiltonian which can yield second time derivatives in the Lagrangian formulation, after you make the/some Gaussian integral.\,. So yeah, one could look into some of all this at some point.\,. (12:39)



\section{What on Earth?}

(03.02.24, 15:24) What on Earth?? I've just read a bit about QFT today, and I had the realization, that the argument of Weinberg, Section 8.5, only works to show that you can replace the `real' photon propagator with the Feynman photon propagator for all diagrams with a \emph{single} photon exchange! But for all other diagrams, e.g.\ with two photons that are exchanged between two fermions, you still have to use the original, `real' propagator! .\,.\,?? (15:28)

Does this not mean that I actually have a correction to conventional QED after all (in terms of how calculations are done in practice, at least)?? It kinda seems so.\,.\,!\,! (15:29)

\ldots (15:45) Well, I guess it's more correct to say that only \emph{one} photon propagator should be the Feynman propagator for any particular diagram, and the rest should be the ``real'' propagators.

(04.02.24, 16.36) Ah no, I think not. I don't think that there is an error there after all. The key is that one get that delta function *(at the top of p.\ 355) in time, which means that the full Coulomb interaction comes from having instantaneous photon exchanges between any two given fermions.


\section[More about my H\_{QED} versus the conventional one]{More about my $H_{QED}$ versus the conventional one}

(20.02.24) I just had an interesting thought. What happens with the Coulomb interaction pair production in the conventional theory?(!\,.\,.) (9:53) .\,.\,Hm, surely it is also there somehow.\,. (I'm talking about the diagrams, if you use the `real' photon propagator rather than the (Lorentz-covariant) Feynman one, where one particle comes in and three particles goes out.) .\,.

\ldots (10:24) Hm, I'm sure it is the same.\,. .\,.\,i.e.\ that the two different version of the path integrals (with the Feynman or the ``real'' (this name sounds presumptuous, but I don't know what else to call it) propagator) gives the same outcome in the end (even if the individual diagrams are completely different; but when you sum them together, it probably gives the same).\,. .\,.\,But it could be interesting to see that calculation/proof.\,. .\,.(Oh, of course there could be something about divergences, where my version for instance might converge and the other not. But I'd even bet that if one can be handled, the other can as well.\,.)
 

(29.02.24) I can actually see now how one must get the same path integrals after the Dirac sea reinterpretation (only with arrows turned around). (16:27)







\section{Decoupled vacuum}

*[(16.02.24)]
I'm actually intending of writing a second (supplementary) paper on how the vacuum decouples from the physical states. And I just went for good walk where I got a possibly very good new idea. This idea is to make the discetization such that the parameter space of $\mathbf{H}_\mathrm{vac}$ is descretized with one $\delta k$, and then the full $\mathbf{H}$ is discretized by having one more momentum parameter that is discretized with another $\delta k$, call it $\delta k_2$, and call the first one $\delta k_1$. The grand idea is then to send $\delta k_2$ to zero first, before sending $\delta k_1$ to zero! I actually think that we then might not even need $\hat H_{\mathrm{vac}}'''$ to approach a self-adjoint limit after all..!!.. (16.02.24, 14:08) .\,.\,This is really fantastic if it holds.\,.\,!\,.\,.

(15:35) Ah, but maybe there is a problem in the fact that $\mathbf{H}_\mathrm{vac}$ is only meaningful after the Dirac sea reinterpretation (DSR), and that this special discretization probably cannot be done before the DSR.\,. .\,.\,(15:42) Hm, but as long as the (anti-)commutation relations are preserved\ldots

\ldots (15:50) Hm, maybe this idea just doesn't really work. Let me therefore consider the other idea, which I had earlier on that same walk\ldots

\ldots (16:14) Trotter.\,.(?)\ldots\ \ldots (16:29) Or Theorem 16.15 in Hall and the definition above it.\,. \ldots Or a mix, rather.\,. .\,.\,No, maybe just Trotter, actually.\,. (16:54) .\,.\,(16:57) No, I am probably on the right track wanting to utilize the identity above Theorem 16.15 for bounded operators (which is not hard to derive, I'm pretty sure).\,. .\,.\,(17:07) Or maybe this Trotter idea is actually no good after all.\,.

\ldots (17:28) Åh, nu har jeg det måske, lad mig se.\,. .\,.\,Yes.\,. The idea is to simply discretize the formula of $\hat H$ first, and then discretize the ladder operators afterwards, but irrespective of the formula discretization: The discretization of the ladder (creation and annihilation) operators will have a $\delta k$ that can be send to 0 while keeping the formula discretization (which can also be done with another $\delta k$ (call it $\delta k_1$)) constant. I think this solves my trouble.\,. (17:37) .\,.\,(Oh, and it would btw be easy to update my first vacuum paper with this solution.\,.) .\,.\,Hm, but I'm pretty sure I've been over this idea before, namely when I worked on the first paper, so.\,. hopefully I just overlooked its potential and went away from it for some unjustified reason back then.\,. (17:45)


%\ 

(21.02.24, 9:03) I believe I have it now. So the first step is to discretize the formulas (rounding everywhere to the nearest point in the $\mathbb{K}$ lattice), which then allows us to rewrite in terms of the discretized ladder operators for free. The UV cutoff is by the way a part of the starting condition. I will then do the Dirac sea reinterpretation (DSR) and refer to an appendix where I show that the Lorentz covariance is preserved. This is done by Dyson expansion (treating all of $\hat H'$ as interaction terms), which is possible since $\hat H'$ is bounded. (And I'll derive this expansion in the appendix, using a similar procedure as the standard oe for deriving the path integral formulation in physics literature). I will then argue that $\hat S(\Lambda, a)$ can be resolved in terms of ladder operators (creation--annihilation operators, rather). Then I can argue that if the circuit (i.e.\ $\hat S(...) \hat U(t') \hat S^{-1}(...) \hat T(a) \hat U(t)^{-1}$, where $\hat T(a)$ is a translation) works before the DSR, when $\delta k_1, \delta k_2 \to 0$, then it must also work for the DSR case, only where you then define $\hat S$ by simply flipping the daggers on the $\hat b_2$'s as well. So far so good. Then.\,. Oh, and let me mention that yesterday, I got worried about the $\sqrt{n}$ or $\sqrt{n-1}$-factors for the ladder operators (because I very recently heard a professor worry about them), but of course, these doesn't matter unless we're in a cavity: If we are in an unbounded volume of space, then two photons will never transition to the same mode (of course). So the UV cutoff is enough to ensure that the operator is bounded.

Now, the last piece of the puzzle is about that $\phi$ state: How nice it would be if that was an actual eigenstate. And this morning, before getting out of bed, I finally finished solving this part. The solution is to simply use the Pauli exclusion principle.(!) This means that for the vacuum, when there are no `physical particles,' there are a \emph{finite} number of states that span the space of all states that can be reached (from the bare vacuum, i.e.). (Recall that we also have the initial UV cutoff.) So therefore, the system is governed by an operator that works an the same way as some Hermitian matrix, which is exactly what we hoped for! So this system will have a finite, yet spanning set of \emph{actual} eigenvectors. And then the rest is just to use this to go through a similar process as i my first vacuum paper, only where I don't argue via $\Delta - d/2$, or whatever, this time, but instead try to do this calculation more directly and explicitly. (9:33, 21.02.24)

(17:50) Hm, I have made a mistake; I don't think my double discretization technique works after all. And I probably don't get around needing $\delta k^{3/2}\hat H_\mathrm{I, vac}''$ to have a self-adjoint continuum limit.\,. .\,.\,Luckily it's bounded and symmetric.\,.
.\,.\,Hm, or maybe my double discretization is actually a good idea after all, let me think.\,. (17:57) .\,.\,(17:59) Hm, I just thought of a funky Fock-like Hilbert space, where there's ``almost only the $\mathbf{p}$ parameters''.\,.
.\,.\,Hm, this is actually really nice; I think I'm on to something good.\,. Now, what about that $\mathbb{K}_1$ discretization?\,.\,. .\,.\,Yeah well, that should then exactly make $\hat H_\mathrm{I, vac}'''$ discrete, right?\,.\,. .\,.\,Yeah, I think so.\,.\,!\,.\,.

(21:31) Hm no, it's more complicated.\,. .\,.\,Yeah, my double discretization (or `$\mathbb{K}_1$ discretization) probably doesn't work after all.\,. (21:32)

(21:50) Ah. One must be able to show a uniform upper bound (times $\delta k^{2/3}$) for the `interaction terms' for all possible $\phi$ states at once. And then I actually don't need (I think) anything other than to have either that $\hat H_\mathrm{I, vac}''$ has true eigenvectors or that $\hat H_\mathrm{I, vac}'''$ is self-adjoint.\,.


(22.02.24, 10:07) Oh no, there's a thing I've overlooked until now.\,! Maybe the $\varepsilon$-almost eigenstates of the $\hat H_\mathrm{vac}'''$ operator (for this toy theory and/or for QED) approach non-normalizable states when $\varepsilon\to 0$ in a way where the norms of the $\psi_n$'s takes a longer and longer time to decrease. So maybe the expectation value of the particle number operator grows to infinity when $\varepsilon\to 0$.\,.\,:(\,.\,. 
\ldots Well, that does make sense.\,. I'm glad I've realized this; I feel like I understand the situation better now.\,. (10:21)

(10:27) Okay, so now the only way seems to show some upper bound (times $\delta k^{2/3}$) for the `interaction terms,' as I mentioned that I thought (well, believed, but now I'm not completely sure) was possible yesterday.
.\,.\,Wait, and this isn't just trivial when the operator is bounded?\,.\,.
%
%By the way, let me mention here in the comments, that I thought about the fact that my infrared cutoff for the last sections of my SA paper i actually redundant. So I thought about whether I should correct it, but then I realized that I probably also knew that back when I introduced it, and that it probably is still actually simpler to keep it in, at least as long as I don't know whatever theorem in literature tells us that \hat A^- is bounded when given a(n) UV cutoff only.
%
\ldots Hm, 'cause $\hat H_\mathrm{phys}''$ is still bounded, right?\,.\,. (10:41) .\,.\,(i.e.\ for the DSR case.\,.)

\ldots (11:31) Oh wait, maybe my double discretization is still the key!.\,. Let me see.\,. .\,.\,Yes, I believe so!\,.\,. (11:32)


(23.02.24, 12:23) Okay, I think I have it.\,! I think I'm saved by the Baker--Campbell--Hausdorff formula! .\,.\,It's a bit complicated, but I'm pretty sure that one can show, with my double discretization procedure, that if you let $\phi$ be the eigenvector of $\lim_{\delta k_2 \to 0} \delta k_2^{3/2} \hat H_\mathrm{vac}''$, then $\exp(-i\hat H''t) \phi$ will have a fermion density that only grows as $\delta k_2^{-3/2}$, not $\delta k_2^{-3}$.\,! So that means that $\ket{\chi} \neq 0$. .\,.\,Which is \emph{so} much work just to show \emph{that}.\,.\,!\,\ldots\ (12:31)

.\,.\,Oh, and I \emph{do} believe that one can show an upper bound for the `interaction terms,' uniformly for all eigenstates $\phi$ for any given $\delta k_2$, and where this bound goes as $\delta k_2^{3/2}$, or something nice like that.\,. (12:35)

\ldots (12:46) Hm, but maybe I can do it without the double discretization (turning $\delta k_2$ back to $\delta k$).\,. \ldots Or can I.\,.\,? .\,.\,Maybe not.\,. (13:00)
\ldots (13:12) Oh wait, let's see, you could still turn $\exp(H_{vac}'' + \hat H_{phys}'')$ into $\prod (\exp(-i\hat H_{vac}'' \Delta t) \exp(-i\hat H_{phys}''\Delta t)) + O(\Delta t / \delta k_2^{3/2})$.\,.
.\,.\,Hm, or $\prod ((1 - i \hat H_{vac}''\Delta t) (1 - i\hat H_{phys}''\Delta t)) + O(\Delta t / \delta k^{3/2})$.\,.
.\,.\,(13:22) Ah, so if you simply start out with a well-behaved fermion density, then your vector will end up in as a sum of two vectors, $\chi_1  + \chi_2$, where $\chi_2$ goes to 0 and becomes arbitrarily small (norm-wise) compared to $\chi_1$ when $\delta k \to 0$, and, importantly, where $\chi_1$ has a well-behaved fermion density as well!\,. (13:25)
.\,.\,Hm, and what exactly can I do with this?\,.\,. (13:28) .\,.\,Hm, I guess the point is to be able to extract $\exp(-i \hat H_{phys} t) \psi$ afterwards.\,. (13:30)
.\,.\,Hm, maybe I should focus on the expression of the RHS of Eq.\ (29) in my 2023 vacuum paper, v1.\,. (13:36) .\,.\,Hov, der er forresten lige et $\Psi$, der skal rettes til et $\Phi$.\,.
.\,.\,Hm, if only the interaction terms decreased more rapidly than $O(\delta k^{3/2})$.\,.
.\,.\,Or wait, is that necessary?\,.\,. (13:52) .\,.\,Oh, maybe it isn't!\,.\,. (13:53)
.\,.\,Yeah, I think I'm good! The contributions from the interaction terms in the Trotter--Lie expansion will go as $\Delta t \delta k^{3/2}$, and since $\Delta t$ is allowed to go as $\delta k^{3/2}$ (due to what can be shown from the Baker--Campbell--Hausdorff formula), they can thus effectively go as $\Delta t^2$. And since there is only $1/\Delta t$ of them, their combined contribution should vanish when $\delta k \to 0$. But let me just think about exactly how the whole argument should be constructed, then.\,. (14:01)
%...(14:11) Nå, det er for godt vejr til at sidde og tænke over dette indenfor, når jeg kan gå ud a tænke over det i stedet.. Så lad mig lige overveje det lidt mere her foran skærmen, og så går jeg ud.. ..(Det handler om, hvordan jeg lige når fra Baker--Campbell--Hausdorff-formularen til at få Trotter--Lie-ekspansionen over på $\prod ((1 - i \hat H_{vac}''\Delta t) (1 - i\hat H_{phys}''\Delta t)) + O(\Delta t / \delta k^{3/2})$-formen..) ..Hm, nå, lad mig gå ud og tænke..
%..(14:19) Hov, det \emph{er} jo faktisk, så simpelt, som det kan være: Når jeg omskriver e^{-iA\Delta t}e^{-iB\Delta t} til (1 - iA\Delta t)(1 - iB\Delta t), så får jeg kun en fejl på.. hm, på O(\Delta t^2( \|A\| + \|B\|)).. ..Ah, men kunne jeg ikke undgå at omdanne e^{-iB\Delta t} til (1 - iB\Delta t), hvis vi siger at B er \hat H_{vac}''?.. (14:23) ..Jo! (14:24) For e^{-iB\Delta t} kan jo skrives som en.. ja, en Taylor-udvidelse (af en exponentielfunktion), or så kan man her bruge, at \hat A_{\psi}^\dagger ikke har nogen komposanter i sig, hvor impulserne summer til 0!.. (14:26) Okay, jeg tror, det kommer til at virke. Lad mig gå en tur (solen er godt nok gået lidt v.. næ, når man taler om den...)... (14:27)

\ldots\ (17:15) As I wrote out in the source code comments, we should actually just keep $\exp(-i\hat H_{vac}'' \Delta t)$ as is in the expansion, instead of rewriting it as $(1 - i\hat H_{vac}'' \Delta t)$. So I'll only rewrite $\exp(-i\hat H_{phys}'' \Delta t)$ that way.

\ldots (18:04) Hm, it will be easiest if I remove all final states from $\hat H_{phys}''$ that has three or more momentum vectors sum to zero, before the Trotter--Lie expansion (since this modified $\hat H_{phys}''$ will approximate the original $\hat H_{phys}''$ arbitrarily well when $\delta k \to 0$).

(18:07) Okay, so I show some upper bounds on $\hat H_{vac}''$, $\hat H_{phys}''$, and $\hat H_{vac}'' + \hat H_{phys}''$ *(and of course $[\hat H_{vac}'', \hat H_{phys}'']$). Then I use the BCH formula to show that

\begin{equation}
	\exp(-i (H_{vac}'' + \hat H_{phys}'') t) \approx
		\prod (\exp(-i\hat H_{vac}'' \Delta t) \exp(-i\hat H_{phys}''\Delta t)),
\end{equation}
where $\Delta t$ is allowed to decrease only as some constant times $\delta k^{3/2}$ for the approximation to become better and better when $\delta k \to 0$. Then I also rewrite $\exp(-i\hat H_{phys}''\Delta t)$ to $(1 - i\hat H_{phys}''\Delta t)$. .\,.\,Oh, and before that I also modify $\hat H_{phys}''$ like I just talked about. .\,.\,Then (or beforehand) I show (or have shown) the upper bound for the `interaction terms'.\,. Hm, and then I'm almost through, but let me think for a minute.\,. (18:15)

\ldots (18:43) Oh, maybe one just modify $\hat H_{phys}''$ like that. I'll look into that.\,.

\ldots (19:07) Oh, I've maybe made a mistake when I used that $\hat H_{vac}''$ commuted with $\hat A_{\psi}^\dagger$. It probably doesn't. And that's probably the root of the thing that I thought seemed fishy about my result.\,.\,:)\,.\,.
.\,.\,(19:14) Yeah, that might indeed by the key to why I need the $\phi(t)$ state to have a well-behaved fermion density (or at least the majority of it) \emph{throughout} the whole line of $\exp(-i\hat H_{vac}'' \Delta t) \exp(-i\hat H_{phys}''\Delta t)$-operations, which is what my intuition also tells me that I need.\,:) The only downside to these news is of course, that it might not be too easy to argue all this, but oh well\ldots\ (19:17)

(21:12) Oh, I think I actually want to let $\Delta t$ go as something like $\delta k^{4/2}$ (or $\delta k^{5/2}$, or $\delta k^{4.5/2}$), and then write $\exp(-i\hat H_{vac}'' \Delta t)$ as $(1 - i\hat H_{vac}'' \Delta t)$ as well.\,:).\,.

(24.02.24, 10:46) Okay, the bound on both the interaction terms, i.e.\ of $\hat H_{vac}''$ interacting (via annihilation) with the physical state and of the physical and vacuum states interacting via $\hat H_{phys}''$, will depend on the particle number of the vacuum state, as I see it. But from my expansion, you can assign a bound on the amplitude for each particle number for the vacuum state, and that should get us through.\,:)

\ldots (11:08) Oh wait, the bounds on $\hat H_{phys}''$ and $\hat H_{vac}''$ might also depend on the particle number, might they not.\,. Let me see.\,. .\,.\,Yeah, of course.\,. .\,.\,Oh, but maybe I don't need the BCH formula after all; maybe my argument works for arbitrarily small $\Delta t$ for the expansion.\,. (11:12) .\,.\,Well, I still need to rewrite $\exp(-i\hat H_{vac}'' \Delta t) \to (1 - i\hat H_{vac}'' \Delta t)$, and similarly with $\hat H_{phys}''$, but maybe\ldots\ (11:14)

(11:59) I think I forgot to square before summing!\,.\,.\,!\,! When I calculated how big the discrepancy of $\hat H_{vac}'' \phi$ and $E_\phi \phi$ was, I think I forgot to square the amplitudes before summing them! So now it seems to me (I have to go over it a bit more, though) that $\phi$ (i.e.\ an eigenvector of $\lim_{\delta k_2 \to 0} \delta k_2^{3/2} \hat H_\mathrm{vac}''$, where I'm back to using the double discretization) will be an $\varepsilon$-almost eigenvector of $\hat H_\mathrm{vac}''$ where $\varepsilon$ will go as $O(\delta k^3)$ (or maybe $O(\delta k^{3/2})$.\,.)! But let me go over it some more to be sure\ldots\ (12:06) 

.\,.\,(12:08) And if this is true, then I can just go back to the simple argument of my 2024 vacuum, v1, paper, just where I now also have the double discretization, and where I also take more care with the $\hat H_\mathrm{vac}''$ (annihilation) interaction terms.
%..(12:12) I feel like taking a walk and do the calculations of whether I'm right about this there. So let me do that...

\ldots\ (15:30) Damn.\,.\,! So close.\,! I even caught my mistake about the operator not being bounded due to the (bosonic nature of the) photons and found a way to deal with it.\,!\,.\,. But unfortunately, I've overlooked (for this latest solution idea) the fact that I also need $\hat H_\mathrm{phys}''$ to work on $\phi$. So now I guess I need to try to go back to my perhaps-single discretization idea with perhaps my BCH formula argument, or something like it.\,. So let me think about that.\,.

(17:38) I just got an idea.\,. Even if a photon-number-cutoff version of $\hat H''$ might not approximate $\hat H''$ uniformly for all input states at once, it might still approximate any finite set arbitrarily well, i.e.\ when the maximum photon number is sent towards infinity. .\,. .\,.\,And the way to show/use this could be to use a Trotter expansion.\,.

(18:49) Okay, I think I can solve it with my double discretization solution. But I'll have to \emph{assume} self-adjointness, because the starting $\hat H$ is not bounded (and I used to know that, although I've forgotten it this time around). But with that assumption, one can then argue the $\mathbb{K}_1$ discretization still. And one can make the Lorentz covariance circuit argument still. And when we then obtain $\hat H''$, we can then at that point make the.\,. Well, maybe I'll also have to assume $\hat H''$'s self-adjointness, by the way, and when I do, then I can argue that for any finite set of initial vectors, $\exp(-i\hat H''t)$ can be approximated arbitrarily well by a photon-number-cutoff version. And that photon-number cutoff version is, as far as I can see, equivalent to a Hermitian matrix, which is.\,. Hm, two seconds.\,. (18:55) .\,.\,Oh no, but if we take an vacuum eigenstate $\phi$ (or $\phi_{\delta k}$ if you will), then.\,. well, then that state will exist, first of all, right?\,.\,. .\,.\,Yeah, but more specifically, $\phi$ is an eigenvector of an idealized version of $\hat H''$, where we assume.\,. that no three momentum vectors sum to 0.\,. Something like that.\,. .\,.\,Rather its the eigenstate of a modified $\hat H''$ expressed in terms of some.\,. hm, some special ladder operators, except\ldots\ Well, I have to look more into this.\,. But if I'll get through all this, then the rest should be pretty simple from there.\,. (19:04)
.\,.\,Yeah, I think I know what to do, and I think it'll work.\,. (19:09)

(21:58) By the way, the `idealized version' is actually when we let $\delta k_2 = \delta k_1$, except in regards to the factors in front of the operators, I guess. But I'll look more into all this tomorrow.

(25.02.24, 11:11) Oh, couldn't you let $\phi(t) = \exp(-i \hat H_{phys}'' t) \phi(0)$?! .\,. .\,.\,No.\,.

(11:55) Okay, I've actually had a very productive morning/noon in terms of thinking. So here's the plan I have in mind now. I need to assume self-adjointness of $\hat H$, and also assume that it can be approximated to arbitrary precision by a photon-number-cutoff $\hat H$ for any finite set of initial states. With this, one must be able to argue that $\exp(-i\hat H t)$ for any $t$ will converge when $n_\mathrm{max} \to \infty$ such that when writing it in terms of a linear combination of ladder operator terms, the factors for each individual term will converge. So when you make the DSR, you get a bounded operator (whose bound depends on $\delta k_2$, though) where if you make a Trotter--Lie expansion of that operator, and write it in terms of a linear combination of ladder operator terms, the factors will also converge when you let $n_\mathrm{max} \to \infty$ for the DSR theory. (12:04) *[(12:55) Oh, and the you of course can't commute the $\hat a$ and $\hat a^\dagger$ operators in the same way, but.\,. Yeah, but.\,. Hm.\,.] So with that in mind, the plan is then to consider a fixed $n_\mathrm{max}$ such that the operator is bounded with a bound only depending on $\delta k_2$. Well, and it is only the vacuum part of the operator, i.e.\ $\hat H_\mathrm{vac}''$, whose bound goes as $\delta k_2^{-3/2}$; $\hat H_\mathrm{phys}''$'s bound should be constant for a fixed.\,. Oh wait, not quite.\,. Hm.\,. (12:08) .\,.\,Well, before putting my brain to work again, let me just mention, that the plan was to then figure out a way to turn the Trotter expansion into a more Dyson-like expansion, namely where one gathers the ``interactions'' (where everything, including the free energy, is then treated as an ``interaction''). And if one can show an upper bound for the contribution for each order of $\Delta t$, then one might be able to.\,. refine/bolster the bound of the operators through the expanded line of $(1 - i\hat H \Delta t)$-operators, so to speak.\,. (12:12)

(Oh, and I'm by the way not very confident anymore about my plan from last evening/ night.\,. (12:13)) \ldots (12:28) Well, maybe I do need this plan (with $\mathbb{K}_1$ etc.) after all.\,. .\,.\,Or rather, maybe it won't be too hard to make it work, which would then likely be worth it.\,. \ldots (12:40) Hm no, let me go back to thinking about the Dyson-like expansion.\,.

(12:57) I'll continue here on the inserted comment above about the $n_\mathrm{max} \to \infty$ argument.\,. .\,.\,Hm, can you say that when you commute the operators, the result has to converge (and more specifically each factor in the (reduced) linear combination has to converge)?\,.\,. .\,.\,Well, yes, of course.\,.\,:) (13:03) .\,.\,Oh wait, not `of course:' I forgot that the $\hat a$'s eat the $\hat a^\dagger$'s. Let me think for a moment.\,. (13:05) .\,.\,Oh wait, it doesn't matter, I think. If the circuit works approximately for one photon-number-bound operator, then it also works approximately for its DSR'ed version.\,. (13:13) .\,.\,Yeah.\,.

(13:16) Hm, going back to the Dyson-like expansion, when $\Delta t$ is small enough, the contribution from each order of $\Delta t$ will approximate the exponential Taylor series.\,. .\,.\,No, each order $\hat H''$, rather.\,. .\,.\,Oh wait, why don't I just try to Taylor expand it, rather then to Trotter--Lie/Dyson-expand it?\,.\,! (13:20) .\,.\,Hm, how do I compute/find the convergence speed, or more precisely the error for using a finite sum in place of the infinite one?\,.\,. .\,.\,(13:30) Hm, well I guess that the contributions start to become small when the order, $m$, becomes larger than the upper bound on the operator.\,. .\,.\,No, already when $m!$ becomes larger that said bound.\,. (13:33) .\,.\,which is very good for me.\,. .\,.\,Yeah, very good indeed.\,. (13:35)
.\,.\,Yeah, this seems to solve the problem---no double discretization needed.\,.

Okay, so how exactly to complete the argument with this nice thing in mind.\,.\,? .\,.\,Well, I should be able to just use the Taylor series directly, and then show that the `interaction terms' (both kinds) will become insignificant when $\delta k \to 0$, namely if we start out with $\phi = \ket{\,}$. .\,.\,Yeah.\,. (13:42)

\ldots\ (16:04) I was (more) right about my initial thought that the error starts to become small when the upper bound is comparable to $m$, not $m!$. But I've figured out what to do instead. For fixed photon number bound, there is an upper bound that depends on the fermion number (maxing out when all possible fermion states are occupied in the $\mathbb{K}_2$ lattice). And this upper bound should be proportional to the fermion number (times some function that depends on the \emph{fixed} photon number as well). And if that is the case, then we'll get a $O(b^m m!)$ bound for $\hat H^m$, canceling the $m!$ in the denominator to yield a series that goes as $b^m$. The point is then to simply divide $\exp(-i \hat H'' T)$ up into $\exp(-i \hat H'' t)\cdots \exp(-i \hat H'' t)$, where each $t$ is small enough that.\,. well, that the $t^m b^m$ series becomes convergent. .\,.\,And so far, so good, then how to complete the argument exactly from there?\,.\,. (16:14)
.\,.\,Oh wait, it's just $O(b^1 m!)$.\,. .\,.\,Hm, which somehow makes it a bit worse.\,. .\,.\,Yeah.\,.
\ldots But maybe that idea of looking at a small $t$ (or $\Delta t$) is worth diving more into, still.\,. .\,.\, Hm, well, it doesn't change the problem, but maybe it can still give me a good angle on it.\,. (16:47)

(17:00) Oh no, it is $O(t^m b^m m!)$ indeed.\,. Hm.\,. .\,.\,Right, so we can make the $t^m b^m$ series convergent.\,.

(18:49) Åh!\,.\,. Fik lige en muligvis rigtig god (i hvert fald interessant) idé!\,.\,. *(I just got a very interesting idea.) The idea is to do a different discretization for the different $(\hat a + \hat a^\dagger) \hat b^\dagger_{s'} \hat b_s$ terms, i.e.\ for different values of $s, s'$.\,! .\,.\,Wow, I'm really excited to look more into this idea.\,.\,!\,.\,. (18:53) .\,.\,(And I felt really stuck before that.)

.\,.\,(My first, and current, thought is that I can use it to make $\hat H''$ equivalent to a matrix after all on the subset of states reachable from the bare vacuum, i.e.\ for a constant $\delta k_1$ (so with my double discretization as well).)

(20:14) Wow.\,!\,.\,. I have considered having $\hat H_{phys}$ consisting of momentum-conservation-breaking (at scales lower than $\delta k_1$) terms, and now I've just done some $\Delta/2 + d$ thinking, and\ldots (pause for effect) it seems that $\hat H_{phys}''$ working on a $\hat H_{vac}''$ eigenstate, $\phi$, will result in a vector whose norm goes as $O(\delta k_2^{3/2})$.\,!\,! (20:18) I hope this is true.\,.\,!

(26.02.24, 9:09) It seems to work! I went over all the $\Delta/2 + d$-calculations in the bed this morning (woke a bit early), and it all works out as I've hoped.(!) And I even did it all for the Coulomb interaction as well. The result is that all the interaction terms between $\phi$ and $\psi$ will go as $O(\delta k_2^{3/2})$. And this includes the interaction terms coming from $\hat H_{vac}''$ (which I overlooked in the first version of the paper), which, by the way, one has to remember uses the momentum-conserving variant of the discretization. And $\phi$'s interaction with itself, i.e.\ coming from $\hat H_{phys}''$, also goes as $O(\delta k_2^{3/2})$ (which confirms what I concluded here last evening). And just to repeat, I did this not just for the Dirac interaction, but for all the various Coulomb interaction vertices as well.

A great thing is furthermore that I then don't really need the cutoffs on the initial operator. Well, I do, but only for part about the preservation of the the Lorentz covariance, which I intent to put down in an appendix (and just assume the validity of the DSR prescription for the main body of the paper). (And I can then also keep the appendix that discusses such cutoffs.) So all I need is to assume that the initial---oh, and final---Hamiltonian is (are) self-adjoint. (9:25)


(28.02.24, 9:49) Oh, I think I've been wrong about the thing that was my original motivation for the double discretization, which is that $\hat G_{\mathbf{k}, \mathbf{p}}^\dagger \hat G_{\mathbf{k}, \mathbf{p}}^\dagger = 0$, where $\hat G_{\mathbf{k}, \mathbf{p}}^\dagger$ is what I currently call the operator that creates two fermions and a photon with wave vectors around $\mathbf{p}$, $-\mathbf{p} - \mathbf{k}$, and $\mathbf{k}$, respectively. .\,.\,So what to do now.\,.\,? .\,.\,(9:59) Well, I guess I just need to consider the clean version of $\hat H_{vac}'''$ where the operators are bosonic ladder operators, and then use an assumption of self-adjointness instead.\,.

\ldots (10:25) Hm, I actually know that that operator will be self-adjoint (the clean version), since it is just like the position operator (expressed in terms of ladder operators). But can I work with that?\,.\,. .\,.\,Not really; I think the photon number (expectation value) will increase very rapidly, when $\varepsilon \to 0$ for the almost eigenstate.\,.

.\,.\,Hm, this all of a sudden looks bad; I'm no longer so convinced that my whole vacuum solution idea here will work.\,. But I still don't have a completely bad feeling about it, so I'm still gonna give it my best.\,. (10:35)

.\,.\,(10:39) Oh, there is still the potential to try to utilize a photon number cutoff, where $\delta k$ (aka.\ $\delta k_2$, previously) is allowed to be sent to 0 while keeping said cutoff constant.\,.

.\,.\,(10:46) Hm, is there anyway that I could use $\delta k$ for, say $\hat a$ and $\hat d$ in $\hat G$, but use $M\delta k$ (previously known as $\delta k_1$) for $\hat b$?(.\,!\,.\,.)
.\,.\,Hm, or use what I now call $\hat B$, equivalently.\,.

\ldots Hm, maybe the photon number cutoff makes more sense.\,.

.\,.\,Hm, on the other hand, maybe that $\hat b \to \hat B$ idea is really worth something.\,. (11:05) .\,.\,For it still makes the vacuum particles be confined to a $2\times 3$-dimensional space.\,. .\,.\,Well, or rather each vacuum particle triple is confined to such a space.\,. .\,.\,Hm, let me think.\,. .\,.\,(I also want to think more about the photon number cutoff, by the way, since I actually think that that idea might work. And the reasoning about whether it works or not is also worth going through more thoroughly, regardless.\,.) (11:14)

.\,.\,(11:20) Oh wow, I think that $\hat b \to \hat B$ might work.\,!\,.\,. %\ldots (11:54) Hm, or maybe it does not work.\,.\,? .\,.\,Oh, never mind; it might very well.\,.

\ldots (12:07) Yeah, and I think that the $\hat G_{\mathbf{k}, \mathbf{p}} \hat G_{\ldots}^\dagger \hat G_{\ldots}^\dagger \cdots \hat G_{\ldots}^\dagger \hat G_{\mathbf{k}, \mathbf{p}}^\dagger \hat G_{\ldots}^\dagger \cdots \hat G_{\ldots}^\dagger \ket{\,} \approx$

\noindent
$ \hat G_{\ldots}^\dagger \hat G_{\ldots}^\dagger \cdots \hat G_{\ldots}^\dagger \hat G_{\ldots}^\dagger \cdots \hat G_{\ldots}^\dagger \ket{\,}$
argument still works, as well as the rest of them. So yeah, this new $\hat b \to \hat B$ idea might indeed work.\,.\,!(!) (12:13)

.\,.\,My brain is really incredible at getting ideas.\,. And especially in cases when I seem to have just hit a dead end, then it so often happens, that I get the next awesome idea to get out of that dead end very shortly after.\,!\,:) %..It's a bit frightening in some way, since in some ways, I don't know if I will lose that skill (and/or the potential luck). But it has kept with me for so, so long now, and I guess if I ever lose it, I'll just be greteful for the time that I've had it.. Anyway, back to considering the photon number cutoff and, more precisely, the Lo. cov.-preservation of the DSR process..

.\,.\,About the  photon number cutoff and the Lorentz covariance-preservation of the DSR process, it seems that my argument works best (and perhaps only) if one can show that $\exp(-i\hat H t)$ can be grouped by perturbation theory, such that you can sum up the Taylor series up to some order, $m$ of $t$ (i.e.\ up to the term proportional to $t^m$), and then have that when we lift the cutoffs for that fixed sum up to $m$, then the dynamics converge such that when you \emph{subsequently} let $m \to \infty$, they converge to Lorentz-covariant dynamics. (12:33) .\,. .\,.\,If that applies for the initial Hamiltonian, and if the dynamics also converge for that same process, then you can (I'm pretty sure) argue this way that the DSR'ed Hamiltonian is also Lorentz-covariant.\,. .\,.\,Let me take a walk and think some more on this\ldots 


%(29.02.24, 15:26) Nå, jeg har været lidt igennem en mølle, men nu ser det rigtig godt ud. Det startede med at jeg på min gåtur her i går, lidt i to var den, fik en ret stor åbenbaring. Den handler om, at Dirac-havet faktisk godt kan approksimeres med et endeligt antal partikler (for $\delta k \to 0$).! Det har åbnet mine øjne, så jeg nu har en endnu bedre forståelse af fysikken, og af problemet. Men så ledte det mig så til at indse, at spørgsmålet om hvorvidt vakuum-løsningerne så Lo.-transformerer til andre sådanne løsninger, jo så egentligt er rigtig væsentligt.. Anyway, og i morges i sengen (ikke fordi jeg lå længe; ikke som her den anden dag, hvor jeg vågnede tidligt og lå og regnede; bare hvor jeg lige ligger nogle få minutter) kom jeg så frem til to gode ting, hvor det andet var, at jeg skal huske, at samle tingene i ordner af koblingskonstanten i stedet for f.eks. i ordner af t, og at man ovenikøbet så kan skrue på denne koblingskonstant uden at det ændrer ved Lo.-kovariansen. Nå, men det er nu nok faktisk ikke så vigtigt alligevel. Ude på en gåtur her i dag kom jeg så, lidt før kl. tolv, frem til, at jeg faktisk bare bør kunne tage udgangspunkt i de normale QFT-aksiomer. For nu er jeg nemlig ikke længere i tvivl om, at man ud fra en diskretiseret og DSR'ed Hamilton-operator må nå de konventionelle stiintegraler for QED. Og her antager man bare, at det findes en vakuum-tilstand, som transformerer næsten til sig selv. Og jeg kan altså faktisk gå baglæns fra de stiintegraler (aka. Lagrange-formalismen) og så udlede $\hat H''$ fra dem. Og bum, så kan jeg altså konstruere et skarpt argument derfra. Det ærgrede mig så dog lidt, at jeg ikke selv kunne finde frem til vejen til et bedre Lo.-kov.-argument end det, så jeg gik videre og tænkte videre. Og lidt i et kom jeg så frem til.. eller rettere, der faldt den sidste (for nu; jeg skal så til at gennegå argumentet på tasterne nu her) brik på plads, som var, at man må kunne argumentere for, at $\varepsilon$-almost-vakuum-egenvektorer også må *(Lorentz-)transformere til $\varepsilon'$-almost-vakuum-egenvektorer, hvis bare det også er $\varepsilon$-almost-egenvektorer for impulsen også (i alle tre retninger). Og her må $\varepsilon'$ så i øvrigt gå mod 0, når $\varepsilon$ gør det. Så de næsten-egenvektorer, som jeg udleder, de må altså Lo.-transformere til andre næsten-vakuum-egentilstande. Og de er jo lige netop det, jeg gerne vil vise: at der findes vakuumtilstande, som de fysiske partikler er dekoblede fra, der også transformerer til vakuum-tilstande, som de fysiske partikler også er dokoblede fra. (15:51)
%..Hm ja, og er det ikke bare det..(?) Lad mig se.. ..(15:58) Jo, for man må også kunne komme igennem hele min dekoblings-argumentation, hvis man bare starter med at have en sekvens $\varepsilon'$-almost-vakuum-egenvektorer, hvor man både har at $\epsilon'$ går mod 0, samtidigt med at vektor-sekvensen endda konvergerer til en vektor. (16:01) ..Ja, det tror jeg..!

(29.02.24, 16:02) I had a pretty great revelation yesterday, on a midday walk. I've realized that the one does not need $2\times (2\Lambda)^3/\delta k^3$ antiparticles to fill the Dirac sea.\,! Well, to \emph{fill} it, yes, but if we say only used half of that, then the Dirac sea would still work just as well in the limit when $\delta k \to 0$! I'm proud of this realization, 'cause it's so natural to think of the Pauli exclusion principle as simply meaning that two particles can't occupy the same state, e.g.\ a particular discretized momentum eigenstate. But the antisymmetry of fermion are much stronger than that (which is why it holds in all bases at the same time). And if you took a gigantic number of momentum-eigenstate antiparticles and spread them over all.\,. Hm, or let me put it this way, more simply: If one took a filled-up Dirac sea for some $\delta k$ and $\Lambda$, where the momentum eigenstates those that are created when $\hat a^\dagger(\mathbf{k})$ is integrated over a small ($\delta k^3$, to be precise) volume in momentum space, then this Dirac sea would also lead to approximately the same physics, then you look at the state in the continuum limit theory, where $\delta k \to 0, \Lambda \to \infty$. In other words, are universe could actually be approximated arbitrarily well (given that it is not \emph{actually} constructed this way in reality) by the initial, non-DSR'ed Hamiltonian, where the physical particles then sit on top of a Dirac sea with a finite (but unfathomably big) number of particles in it! This would make the third law not apply in theory, but in practice, it would still apply, since the decay rate to the unfathomably-low-energy states would be close to 0. And even though one would be able to have a seemingly (non-anti-)particle go down and disappear into the sea, the transition rate of this happening would also be (unfathomably) close to 0, due to the high density, and the anti-symmetry, of the approximate Dirac sea. (16:20)

This has made me understand the physics a bit better, and it has lead to some good ideas, and a better understanding of how one would show Lorentz covariance of my $\hat H_\mathrm{phys}''' = \hat H_\mathrm{QED}$. I have briefly described these ideas (in Danish) in the source code comments above the previous paragraph. (16:23)


(17:10) Hm, there is actually something a bit fishy about the last part of my new argument: I was arguing that my $\varepsilon$-almost eigenstates would transform into $\varepsilon'$-almost eigenstates, but that is not necessarily true, is it?\,. And it depends on the discretization, which is also not nice\ldots\ \ldots (17:33) Oh, or maybe does work.\,.

(01.03.24, 12:19) My argument here from yesterday, which the previous paragraph concerns, does not work, no. But I've had some very good ideas today. Overall the ideas are about going back to the photon and particle number cutoff, and then argue about perturbation in the order of the coupling constant. And in the shower this morning, I realized how I could use the axioms of QFT to complete my argument (my strategy for doing this from yesterday was not complete, I think). The point is to start with an axiom that one can calculate to order $m$ in the perturbation series while being free to send $\delta k \to 0$ for a fixed $m$. This is a standard (albeit perhaps somewhat implicit.\,.) axiom of QFT. You can then use this to make a particle number cutoff for the Hamiltonians, namely since this cutoff theory will still produce this exact perturbation procedure, i.e.\ when $n_\mathrm{max}$ is gradually lifted. And there you go, this derives $\hat H''$. Now, this version of $\hat H''$ does not have the double discretization, but on the other hand, it has the particle number cutoff! And I'm almost certain that I can make the argument that the vacuum decouples work with this starting point. This argument will then be very similar to the argument in the first version of my vacuum paper (but remembering the annihilation interaction terms coming from $\hat H_{vac}''$ this time around). The point is that you don't need the eigenvector sequence (i.e.\ of some eigenvectors that are all ``reachable'' from the bare vacuum) to converge when $\delta k \to 0$. For as long as the particle cutoff is constant (which it can be, as I've explained), one can make a uniform bound on the interaction terms, which goes to 0 when $\delta k \to 0$. (12:36)

Now this is all quite fantastic---except that I then don't get to show of any of my double discretization ideas (which are quite cool, and I believe that I just managed to make them work in the latest iteration, described here above). I'll get to write a very convincing second version of my paper, which does not have to change structure all that much (unless I want to change it up.\,. (for maybe I still might want to look at a simplified interaction first.\,.)), but where I just make sure to make this argument about the particle number cutoff derived from the axioms of QFT first. But it still bugged me a lot that I hadn't yet found my own way to argue (well enough) for the Lorentz covariance. However, now I think I'm also on to something quite good there.

The idea in regards to that also concerns a particle number cutoff, as well as gathering in terms of orders of the coupling constant. .\,.\,Consider an experiment under the original, non-DSR'ed Hmiltonian, but where one has filled up all $\delta k$-momentum states (i.e.\ states that are created by integrating $\hat a^\dagger(\mathbf{k})$ over some small volume of momentum space of size $\delta k^3$) of the negative-energy variety up until some $\Lambda$. We are thus dealing with an approximate Dirac sea of finite negative-energy particles. The idea that I've just figured out here a little while ago is to then observe that this approximate Dirac sea falls off in amplitude when you move away from the origin of the coordinate system in \emph{position} space. Then think about a Lorentz transformation in position space. Now if the coupling constant is 0, this transformation will just turn the approximate Dirac sea into another approximate Dirac sea (which is of course great). And then, if we turn up the coupling constant, and think of the path integral in (particle--)position space, where particles propagate to interaction vertices, interact, and then (potentially) propagate on from there, and potentially over to additional interaction vertices. The point is then that, heuristically, it makes sense that we can group this transformation in terms of orders of the coupling constant. For the Dirac sea falls off far away from the origin ($\mathbf x = \mathbf 0$) in position space, so it makes sense that we can approximate the transformation with only a finite number of interaction vertices. Then when we transform these position interaction vertices back into momentum space, we should thus still get a perturbation series of terms up to some $m$ order of the coupling constant. (That was poorly expressed, but you get what I mean, hopefully.) Now, what does that mean for the Lorentz-transformed approximate Dirac sea?\,.\,! It means that we get another approximate Dirac sea, plus a correction coming from only $m$ interactions! And what is a Dirac sea that is worked on my only a finite number of interactions?\,.\,! That is just another approximate Dirac sea, only now with up to $m$ more positive-energy particles and up to $m$ more holes in it! So this is my heuristical explanation of why an approximate Dirac sea with some particles on top must transform into another approximate Dirac sea with some particles on top. Now, you could surely also make a similar argument to argue (heuristically) that an `approximate Dirac sea with some particles on top' must approximate a real Dirac sea with some particles on top when the $\delta k$ and $\Lambda$ parameters for the approximate sea is respectively sent towards 0 and $\infty$. And with all this, and of course with the fact that $\hat H$ becomes Lorentz-covariant in the continuum limit (for any fixed number of (maximum) particles), then we obtain (heuristically) that.\,. well, that if a meaningful limit to $\hat H''$ exists, then it must be Lorentz-covariant. .\,.\,Yeah.\,. (13:12) .\,.\,!\,:) 

%(19:41) Åh, måske har jeg det... ..Hm, well.. Næsten, måske.. ..(19:46) Åh ja, næsten måske..

(02.03.24, 10:11) My heuristical(?) argument above does not hold. The problem is exactly the three-particle creation interaction, and the fact that the particle density.\,. Hm.\,. .\,.\,Yeah, the particle density (in position space) increases as you let $\delta k$ (as a Dirac sea parameter, not a parameter of $\hat H$) go towards 0.

(10:30) Oh, maybe there is a way still for my $\hat G$--$(\hat b \to \hat B)$--etc.\ idea!\,.\,. .\,.\,Oh, if we let $\hat d \to \hat D$ instead, it might actually be natural, even.\,. (I expect to see why this idea doesn't work in a minute, but I'm still somewhat excited.\,.) (10:34) .\,.\,Hm, let me see.\,. .\,.\,No, I bet this idea doesn't hold.\,. .\,.\,Oh, I must mention that the original $\hat G$--$(\hat b \to \hat B)$--etc.\ idea does work, I think, in a sense. Only it does not, perhaps, adequately explain why the Lorentz-transformed bare vacuum doesn't cause us trouble.\,.

(11:47) I took a break before continuing thinking about this new idea, which I didn't think would lead anywhere. But now it actually kinda seems like it might.\,.\,!\,!\,.\,. .\,.\,The idea is to do my $\hat A, \hat B, \hat D, \hat G$-discretization, actually without the turning $\hat b \to \hat B$ (nor $\hat d \to \hat D$, actually) for $\hat G$, and then consider this $\hat H'$ on an approximate Dirac sea.\,. .\,.\,(11:53) Oh wait, maybe the idea does not work, after all.\,. .\,.\,Yeah, nah.\,. .\,.\,Hm, unless maybe one broke momentum conservation to.\,. Hm, to make it work around.\,. No, 'cause you need to be able to go the the continuum limit while keeping the approximate DS constant.\,. (12:00) .\,.\,Ah, but you could still do it, just where $M \delta k$ for $\hat D$ is also allowed to tend towards 0 for the constant approximate DS.\,. (The idea is to actually indeed change $\hat d \to \hat D$ for $\hat G$ after all.\,.) .\,.\,Hm, this \emph{is} a bit interesting.\,. (12:05) .\,.\,Hm, nah, it probably won't work, but let me think about it still.\,.

(12:41) I've not been too motivated to continue thinking about this newest idea, but now I'm actually a bit motivated once again; isn't there actually a chance that it might work.\,.\,?

(13:04) Ah. The $\varepsilon$-almost eigenvectors of this doubly-discretized $\hat H'$ won't converge to $\varepsilon$-almost eigenvectors of $\hat H$. I have been wrong in thinking that.\,.
*(Just to underline: This ruins my whole $\hat A, \hat B, \hat D, \hat G$, etc.\ (double) discretization idea. *(Well, maybe it can work in a lot of instances, but not in this latest instance where there the final states of some transitions converge/diverge into delta functions.\,. (13:53)))

Okay, so I really seem to have come to a stop in my search for.\,. repairing my Lorentz covariance argument.\,. Luckily, it is still a very great result, if I can show that with the conventional axioms of QFT, you can remove the vacuum-perturbing terms/vertices from the calculation. Not only because this might help the renormalization calculation a great deal, it might seem, if one otherwise have to divide with a diverging $\braket{\, | \hat U(t) | \,}$ term, but not least also because this makes us able to write up a well-defined Hamiltonian.

So yeah, I should definitely continue with those ideas.\,. (13:12)

%"Planen er, at man prøver at vise selv-adjungerethed for H efter et basisskift til en tællelig basis (e.g. SHO-tilstande eller sådant). Så får man i første omgang en realistisk teori! Og hvad mere er, når man så går tilbage til mit koblingsargument, set fra impuls-basen, så er delta k allerede infinitesimal til at begynde med!! Så man kan altså muligvis fuldføre mit argument sådan! (15:53, 03.02.24)" skrev jeg i en lille note her på min (ret lange) gåtur, som jeg lige er kommet hjem fra nu her. Og for lidt tid siden her på vej hjem fra den gåtur kom jeg så i tanke om, at almost-egenvektorerne af denne $\hat H'''$ (nu dog uden nogen diskretiserede skridt, \hat H' og \hat H'', imellem \hat H og \hat H''') jo ikke i reglen vil være impuls-egenvektorer (med impuls lagt sammen til 0 præcist), men vil også kun være næsten-egenvektorer af impulsen. Men! Fordi \hat H kommuterer med impulsen, så vil hvert rum af vektorer med sammenlagte imuplser inden for et lille inteval/volumen være invariant under \hat H. Så hvis man har en næsten egenvektor af \hat H, så kan man faktisk sagtens bare ud fra denne konstruere en ny egenvektor, i et vilkårligt lille interval af sammenlagt-impuls-rummet (I ved, hvad jeg mener), nemlig sådan set bare ved at skære resten af "sammenlagt-impuls-rummet" fra. Og dette vil ikke forøge forventingsværdien af partikel-antallet! Og dermed bør man kunne komme igennem argumentet! (17:40)


(03.03.24, 12:16) I've written some great and perhaps very important notes out in the source comments above this paragraph, which I will repeat here in English at some point. But let me see about something first.\,. We have $\braket{|\hat A_{\phi}  \hat H  \hat A_{\psi}^\dagger|}$.\,. .\,.\,Hm, is this the right thing to do.\,.\,? .\,.\,Hm, yeah, and then we should move all $\hat d$'s and $\hat d^\dagger$'s over, right?\,.\,. .\,.\,Sure.\,. %..(Hm, my brain is a quite slow today..)
.\,.\,Right, the whole point is to try to verify that this rewriting is legal for the `physical' part of $\hat H$, and hopefully I will then also see that it is illegal for the `vacuum-perturbing' part of $\hat H$ (and gain insight into why).\,. (12:32) %..If my brain worked a bit better right now, I could have done it in my head, but maybe I should try to do it here on "paper".. ..Or perhaps on some actual paper for once.. (I for some reason very rarely do physics on paper nowadays---haven't done that much at all since the bachelor.. ..Probably only a handful of sheets of papers combined, I think.. *[Ah, probably a little more, perhaps... ..Hm, or maybe not..] ..Not counting study notes from the master's, of course.. ..And not counting designing Hiq..) ..Anyway, I'm stalling.. (12:39) ..No, let me take another break, see if I get my brain back, and then hopefully do it in my head (perhaps on a walk).. (12:44)

\ldots\ (14:21) Okay, so it's actually very simple. One can show that when you DSR the physical Hamiltonian, whether you do it before or after changing to a countable basis (such as e.g.\ the SHO solutions, or the spherical whatevers), it gives you the same result regardless. This also works for the discretized vacuum-perturbing part, but here the DSR'ed $\hat H$ just doesn't have a well-defined formula---at least not one that can be easily derived---in the pure momentum basis, as it diverges when you let $\delta k \to 0$. And that's the simple difference between the two.

Now, let me finally explain what this new idea is. The key part of it, as alluded to, is to change the basis of $\hat H$ to a countable basis before DSR'ing it. %(Funnily enough, this was how my thought on the DSR came to a stop when I worked on my QED paper in 2022. But now, instead of stopping me, the idea of going to a countable basis seems to be what will carry me through to the finish line, 7, 9, 13.)
If then the thusly DSR'ed Hamiltonian can be shown to be self-adjoint, perhaps using a similar technique as the one from my 2023 self-adjointness paper, %..Two seconds... ...(14:54):
then we're pretty golden already, since this provides us with a Lorentz-covariant Hamiltonian. But we can get further still: The `physical part' of the Hamiltonian can still be readily transformed back to the momentum basis, while leaving the `vacuum-perturbing' part in the countable basis. Then we can investigate a state created by $\hat A_{\psi}^\dagger \hat A_{\phi}^\dagger$, just like in my vacuum paper, v1. And because the (DSR'ed) Hamiltonian still is momentum-conserving, we can from any $\varepsilon$-almost vector $\phi$ construct a new $\phi$ with support restricted only to states whose momentum sum to some constant, plus/minus some $\delta \mathbf{p}$. And the big point is that one can make this $\delta \mathbf{p} \to \mathbf 0$ while not changing anything about the expectation value of the particle number (and more: even all orders of the particle number).\,! And then all that is left is simply to calculate the so-called `interaction terms' (this time remembering those coming from the annihilation part of the vacuum-perturbing part of the Hamiltonian, which I neglected in v1), and see that they vanish (which I believe they will).\,! And since $\varepsilon$ can now be made arbitrarily small without changing the fact that $\text{`interaction terms'}=0$, we can thus complete the argument in the same way as in v1 from there. (.\,.\,!) (15:08)

(17:04) Hm, there is also the free energy of the antiparticles, which has the divergence as well (in terms of a constant energy at each step, which however goes to infinity in the continuum limit). So how does one deal with that.\,.\,? .\,.\,Hm, that means that we do still need to discretize as intermediary steps for the DSR.\,. The argument then follows the.\,. wait, no, this does mean that the `interaction terms' are once again not completely vanishing, but are only vanishing when $\delta k$ is sent towards 0.\,. (17:10)
\ldots (17:36) Okay, so we'll just need to also assume that $\hat H''$ (discretized and DSR'ed) in the countable basis approximates $\hat H'''$ (continuous and DSR'ed) arbitrarily well. Then $\phi$ can be an $\varepsilon$-almost vector of $\hat H'''$ and $\hat H''$ at the same time. Therefore we then go to $\hat H''$ and investigate its action on $\hat A_{\psi}^\dagger \hat A_{\phi}^\dagger \ket{}$. .\,.\,And if we let $\psi$ be an almost eigenvector of $\hat H_\mathrm{phys}'''$ and/or $\hat H_\mathrm{phys}''$, we see that, because the same $\delta \mathbf{p} \to \mathbf 0$ argument still applies for $\phi$, the interaction terms can be shown to tend towards 0 when $\delta k$.\,. Hm, or $\delta \mathbf{p}$.\,. Let me think.\,. (17:44)
.\,.\,Oh, maybe there's a problem here, namely if $\phi$ indeed needs to be an almost eigenvector of $\hat H_\mathrm{phys}'''$ and $\hat H_\mathrm{phys}''$ at the same time: Then we can't just let $\delta \mathbf{p} \to \mathbf 0$ without also letting $\delta k \to 0$ at the same time, right?\,.\,. (17:47) .\,.\,Or can we.\,.(?) .\,.\,Hm, but wait, does it really matter that $\delta k$ also needs to go to 0 (before $\delta \mathbf p$).\,.\,? (17:52) .\,.\,All that matters is the particle number converges nicely (this is imprecisely put but I know what I mean.\,.) when $\delta k, \delta \mathbf p \to 0$, right?\,.\,. (17:55) .\,.\,Yeah, I think so.\,.\,:) .\,.\,Yes!\,:) (18:00)

(04.03.24, 14:55) For the $\delta \mathbf p \to 0$ argument, I'll actually use the axiom of choice to construct a $\phi \in \mathbf{H}_{DSR}$, where $\varepsilon$ is non-increasing (perhaps even sharply decreasing) for smaller and smaller $\delta \mathbf p$ volumes around $\mathbf 0$. (And one also uses the completeness of $\mathbf{H}$ in this argument.)

(05.03.24, 10:26) The thing about using the axiom of choice does not work. However, as I realized laying awake (for a few hours) this night, I don't need $\phi$'s combined momentum to be 0 for the argument to work. We can just pick out a $\mathbf p$ ($\mathbf P$) from anywhere (close to 0 or even away from it). We just need for $\phi$ to be finite almost everywhere on the hyperplane that we pick (of constant combined momentum), and also have that the contribution to $\varepsilon$ on that hyperplane is $\geq \varepsilon$.
*[(10:43, 10.03.24) Oh, and about this, we should first of all pick a $\mathbf P$ where $\phi$ is \emph{continuous} at all levels in this hyperplane. And I've found out that the argument for us being able to do this, is simply to use the Lebesgue measure definition, specifically the definition of sets of measure zero, which shows that the discontinuous point of each $\phi_m$ has zero measure. And even if we union all the discontinuous points for each $n$, the resulting set will still have measure zero. *(11:47) Oh, and from at least some of the remaining continuum of $\mathbf P$'s, the contribution to the overall $\varepsilon$ will be $\leq \varepsilon$, such that the cut-out vector around $\mathbf P$, when normalized, has a $\varepsilon' \leq \varepsilon$.]


(10.03.24, 9:50) Okay, it's not quite so easy. I've gotten some ideas since I wrote last, but there's still some trouble. Right now I'm troubled by the fact that the vacuum terms might diverge from the beginning. But I think I might have some ideas how to solve it, which concerns assuming the $\delta k$ can be sent to 0 first for the cutoffs.

But on the bright side, let me mention some ideas about ``Task 2'' (from my QED paper). I was concerned by the fact that even with a $\Lambda$, the upper bound for the interaction for each particle number, $n$, increases as $\sim n$. But first of all, I've had the good idea (in bed last night) to use the free energy to help cancel the ``productions'' (as I have called it) to the last level at the $n_{max}$ cutoff. And this cancellation is also strengthened by the fact that the interaction increases when there are more particles to positively interfere. 'Cause if the are photons already out at the $E$ area, which by the way has constant radii, as explained in an Appendix in my vacuum paper, v1, then these photons will just increase the free energy. (And the photons need to by out there already for positive interference to happen in the first place.\,:)) (10:02) And for the cancellations that needs to happen at the lower levels at the edges of the productions, cut off by $\Lambda$, one can also see that the more particles are there, the more ways to construct ``cancellation tails'' one level up.\,. Hm yeah, and this shuld also matter to the $n_{max}$ level, I guess.\,. .\,.\,A higher particle number increases the upper bound on the interaction, which is a bit troublesome, but on the other hand, it also means that more states can be used to cancel the productions. So it should balance out, I think.\,:) And note that this applies even for the photons, namely since the productions can also be canceled by states one level up where a photon has split off into two fermions (due to the ``Dirac interaction,'' as I'm calling it.\,.).\,:) (10:08)

\ldots (10:26) Ah, now I might just have gotten an idea (about the problem with the interaction terms).\,. .\,.\,With the solution that I have in mind for ``Task 2,'' if it works, wouldn't we then also be able to construct an almost eigenvector from any given original almost eigenvector, such that the modified almost eigenvector---with only a slightly larger $\varepsilon$, i.e.---decreases very rapidly after some $n$ (or rather it's norm squared does)? .\,.\,This could be it.\,.\,!\,.\,. (10:31) .\,.\,Yeah, that's it.\,.\,! Oh what a relief---7, 9, 13.\,. .\,.\,So I therefore think it's reasonable for me to assume, for the vacuum paper v2, that we can find $\varepsilon$-almost eigenvectors, $\phi$'s, of $\hat H'''$ with a rapidly decreasing norm squared for each $\phi_n$ after some large enough $n$. (10:36)

.\,.\,Hm, the downside is that this assumption is not just a standard physicist assumption, so it won't be so immediately convincing. But I think I just have to make do with that.\,.
.\,.\,Yeah, that's just life.\,. .\,.\,I'm just glad.\,.\,:) (10:42)

(11:38) Hm, maybe that `$\delta k \to 0$ first' idea is also very much worth pursuing further\ldots .\,.\,Oh yeah, for sure.\,. Then I'll assume that there is a cutoff (both ultraviolet, infrared, and particle-number-wise) but continuous (in momentum space) version of $\hat H'''$, which approximates (the dynamics of) $\hat H'''$ arbitrarily well. And then I should be able to just show that the interaction terms.\,. hm.\,. (11:44) .\,.\,(11:51) Hm, intuitively this line of thinking works: Why should the approximate Lorentz covariance be worse for a low-$\delta P$ state when $\delta k = 0$ than for one with a higher $\delta P$?\,. But mathematically, I'm not so sure about how well it works.\,. (11:53)

(13:09) Oh. If we make this assumption about the w.r.t.-$n$-rapidly decreasing almost eigenvectors of $\hat H'''$, and then go and consider $\hat H'''$ and a $\phi_{\delta P}$ in the position space, then it becomes kinda trivial that the `interaction terms' (combined) goes to 0, doesn't it?\,.\,.\,\texttt{:D} .\,.\,Well, unless they diverge to begin with, let me see.\,. .\,.\,Hm, which the might because of the Coulomb interaction.\,. Hm.\,. (13:15) .\,.\,Oh wait!\,.\,. Maybe I should consider if there could be a method for changing $\hat A_{\psi}^\dagger \hat A_{\phi}^\dagger \ket{\,}$ slightly, such that it is a member of $\mathrm{Dom}(\hat H''')$.\,.\,!\,.\,. (13:18) .\,.\,Well, there obviously is, but I need one that doesn't depend on $\delta P$, then, or something like that.\,.

(16:31) Hm, I might have just had an idea.\,. How about using a $\psi$ with localized/bounded support in position space, and then simply cutting that part of position space away from $\phi$?\,.\,. .\,.\,And the point is that $\phi$ then won't necessarily be an almost eigenvector, but it will be an ``almost almost eigenvector,'' which is `almost as good as an almost eigenvector' in some sense, isn't it.\,. (16:35) .\,.\,Hm, this actually kinda seems like it would work(!)---although it does seem a little bit magical, perhaps, so it requires some more thinking.\,. But I'm pretty positive *(as in hopeful), actually.\,. (16:37)

(16:54) No, it actually makes great sense! And even though the argument that the Dirac interaction vanishes between states that are away from each other in position space it a bit shaky, I don't need that anyway, since it is only the Coulomb interaction that seems to be a potential source of divergence *(and the Coulomb interaction is obviously bounded between particles whose distance between them in position space has a lower bound), i.e.\ once we have already assumed that $\phi$ is rapidly decreasing w.r.t.\ $n$ after some point, as I have talked about. So yeah, this must be my new plan.\,! :) (16:57)

(11.03.24, 9:15) I've thought some more. I think I will actually try to keep v2 (of the vacuum paper) on a heuristic level, where I might even just argue from simply looking at the fact that the particles are infinitely spread out in position space. And then I will just make another paper where I take a cutoff Yukawa(?) theory with $(1+1)$-spin particle and antiparticle fermions, and from there argue mathematically that the vacuum-perturbing vertices can be removed from the path integrals. But I'm getting ahead of myself. First I need to figure out how to solve the problem at hand, still.

The idea about cutting out a localized part of $\phi$ has made me think---and given me some useful thoughts. It \emph{is} a bit magical that an almost-finite number of particles can cure the vacuum-perturbation everywhere in position space at once. But with such an unbounded operator as we have here, this is still not out of the realms of possibility. These infinitely spread out particles.\,. wait a minute, let me think.\,. (9:24)

\ldots Hm, now I'm actually starting to doubt this countable-basis solution.\,. (9:54) .\,.\,It is too magical/weird, when you look at it in a countable basis of localized states in position space.\,.

.\,.\,(10:05) Hm, and don't I run into the same problem with my previous solution (described in v1 of my vacuum paper).\,.\,? .\,.\,Hm, not necessarily, 'cause there the wave functions are never \emph{infinitely} spread; only as a limit.\,. .\,.\,But I might.\,. (10:14)
\ldots (10:36) The possibility lies in the fact that the vacuum solution might change characteristics in position space and be more and more potent in each local volume when $\delta k \to 0$ ($L \to \infty$) for canceling the local vacuum fluctuations, making up for the decreasing local amplitude when $\delta k \to 0$. .\,. So yeah, I guess I need to abandon this countable-basis idea, where the discretized steps can essentially be skipped, and go back to my original ideas described in v1, where the discretized steps are essential.\,.

(12.03.24, 8:37) I think I'm nearing a solution, perhaps. I'm back to my original idea of assuming---and showing in the future (although I don't want to undertake that alone; I have done so much already)---self-adjointness of $\lim_{\delta k \to 0} \delta k^{3/2} \hat H''$, as I've talked about. Here there is not the paradox (which otherwise tells us that it won't work) of the vacuum solutions consisting of infinitely spread particles. But there is something a bit weird about how the particles can become less and less dense over any local volume, because you are extending the position-volume cutoff, far away from that given local area. But on the other hand, the action of an unbounded operator can depend on the domain. And no one says that this dependence is local: What happens out at the edges of position space can in principle change the dynamics over local volumes within, since it might change the overall physical \emph{interpretation} of the operator. And if the \emph{interpretation} of the operator changes, it might change the dynamics globally. So even though an operator is formally identical to another one over a given local volume, they might still cause different dynamics over that volume, if the have different $L$-cutoffs at the boundaries of the position volume (i.e.\ they have different $\delta k$'s).

Now, I got the great idea also yesterday to consider the Lorentz covariance in terms of having a local volume in space-time where the interaction is ``dialed up'' from 0 to $q$. Then the Lorentz transformations can be done before and after that volume where they are trivial. And if we then further go back to my idea of an approximate Dirac sea, let us consider the following thought experiment. Say that we have a vast approximate Dirac sea within an infinite, or just much vaster still, position space. Draw a line around this volume in space-time where this approximate Dirac sea is uniform and looks close to a perfect Dirac sea for the particles inside the volume, within some degree of precision. Now go deep inside this vast space-time volume and draw a smaller volume, which s where we will turn the coupling constant, call it $q$, up from 0 to its actual value. Suppose that this much-smaller inner volume is still incredibly vast. The idea from there is to then argue that the approximate Dirac sea should follow $\lim_{\delta k \to 0} \delta k^{3/2} \hat H''$ with some precision in terms of the vacuum fluctuations, albeit perhaps only with an $L$ ($\propto \delta k^{-3}$) as large as either the inner or the outer volume.\,. Anyway, whichever it is, the vacuum fluctuations will only cause a finite number of particles, effectively, to be created from the bare vacuum. And if you do the Lorentz covariance circuit (i.e.\ Lorentz transformations outside of the inner volume and two time evolutions across the entire inner volume in the two respective inertial frames), the same will therefore apply in the other inertial frame as well. .\,.\,It needs some polishing, and I'm not too confident that it would be a good route to take mathematically, but it's a very good heuristic argument, it seems.\,:) (9:10) \ldots (And the point is, that the `finite' number of vacuum particles is not proportional to either of the volumes (and thus not to $\delta k$ of the appr\ldots the ADS).\,. (9:32)) .\,.\,And more importantly, the vacuum particles do not interfere with the physical particles, such that the vacuum-perturbing terms can be removed for both time evolutions.\,.

(10:08) Oh, and I don't think I have mentioned yet---and I don't think I have written much about that line of thinking before, by the way, even though I have thought it before: If we consider the path integrals alone, one should also be able to make a pretty good heuristic argument that the vacuum-perturbing terms ought to be removed there. For if we consider paths in momentum--time space (not momentum--(angular )frequency) and look at a path where sme part of the path includes particles created from the bare vacuum, then consider the same path but where all the (.\,.\,or just the initial) vacuum-perturbing vertices/vertex happens just slightly earlier. This would give the same contribution but with a different phase, do to the altered free energy. So when you sum over all such path, it's intuitive that, unless you get a divergence (which you would then naturally try to renormalize away), you should get 0 when you sum all such paths together! And to make the argument even more clear, one might consider a case much like the one I've just described, where the coupling constant is dialed up for a local volume. And let us here say that the coupling constant is dialed up slowly (``adiabatically''). Then it should be quite clear that these paths should sum to zero, shouldn't it?\,:) (10:19)

(10:29) I'm very happy with this new approach to the Lorentz covariance argument, i.e.\ the one described in the paragraph before the previous one. And yeah, the fact alone that the vacuum-particles don't interact/interfere, and that they are very, very spread out, including especially after the volume in time, where one wants to make a measurement, perhaps, and where they thus don't interfere with the measurements of the physical particles of this end-state, these two facts alone should be enough.\,.\,:) I actually think that this argument for Lorentz covariance is enough for me, personally. I will think just a tad bit more about it, and then I will probably get on to write v2 of the vacuum paper, which should now just be a lot like v1, as it turns out. (I might make some changes, though, and I will definitely include the position-space heuristics, arguing from the fact that the vacuum particles becomes infinitely spread out, and I will also change my Lo.\ cov. section.\,.) And then I might look into writing a more mathematical paper, where I look at a cut-off $(1+1)$-spin Yukawa theory where one spin represents particles and one spin represents antiparticles, as I've mentioned above. I can then try to derive mathematically, that the vacuum-perturbing terms can be removed, given the assumptions of this theory. (10:40)

.\,.\,Yeah no, I really believe in the soundness of this new Lorentz covariance argument.\,\texttt{:D} (10:42)

(12:01) In terms of the fact that the vacuum solution changes locally based on $L$, you can say that if not for the fact that the domain of the operator has to be limited on order to retains its symmetry, the operator would have to potential always to use arbitrarily small states to cancel the vacuum productions, or rather, it certainly very well might have that potential. But it's limited by the restrictions on its domain. But when $L$ changes, these domain restrictions changes as well, and this might thus make the operator able to use smaller states (when $L$ grows (meaning that $\delta k$ decreases)) to cancel the local vacuum fluctuations. So yeah, there is potential for my idea (the one described in v1) to work.

.\,.\,(12:08) I also have to mention that I'm actually no longer quite as troubled about the potential for the expectation value(s) of $\hat n$ to grow when $\delta k \to 0$ for this argument, since I can imagine, that you would be able to show, when working on proving the self-adjointness, that the $\phi_{\delta k}$-solutions have a well-behaved convergence when $\delta k \to 0$. But I should think some more on that now.\,.

.\,.\,Hm, and more importantly, perhaps, the convergence might be well-behaved when $\varepsilon \to 0$.\,. (12:14) .\,.\,(12:22) Well, I don't know that.\,. .\,.\,(12:30) Hm wait, couldn't you also do some $\delta P$ argument (like I did for the countable-basis idea) here.\,.\,? .\,.\,Starting with an $\varepsilon$-almost eigenvector of the continuous $\lim_{\delta k \to 0} \delta k^{3/2} \hat H''$.\,. .\,.\,Hm no, here it's already a problem that $\braket{\hat n}$ might depend on $\varepsilon$.\,. .\,.\,So I'm not out of the woods yet.\,. (12:37)

\ldots\ (14:57) There actually might still be a potential for the countable-basis idea. Even though the vacuum solution is infinitely spread out, it is not necessarily uniformly spread out. So it might still work. I actually thought about this, but for some reason, I didn't like the idea before. (If a had a good reason, I have forgotten it now (but I don't think I had a good reason.\,.).) So it might still be possible to show Lorentz covariance of, well, $\lim_{\delta k \to 0} \hat H''$.\,. Hm.\,. .\,.\,Okay, it seems that it is one or the other: Either you can show that $\lim_{\delta k \to 0} \delta k^{3/2} \hat H''$ is Lorentz-covariant, and non-trivial, or you can show that $\lim_{\delta k \to 0} \hat H''$ is.\,. (15:03) But luckily, I see a potential route to make the $\lim_{\delta k \to 0} \delta k^{3/2} \hat H''$ idea work as well, at least on a heuristic level.\,. In terms of momentum space, I actually just had the idea, before sitting down, that one might be able to argue and use the fact that the $\varepsilon$-almost eigenvector stays very small in amplitude when $L$ is large, at least for some local volumes of space-time, when it is time-evolved. That opens up a potential route for completing the argument in momentum space.\,. Oh wait, that uses position space arguments as well, of course.\,. (15:08) .\,.\,Well, nevertheless, that's one potential route. And another one might be to Trotter/Dyson expand, and then argue that for large enough $L$, you should be able to continuously remove all vacuum particles in a local volume (incredibly small compared to $L^3$) between each operator (after each $\Delta t$) in the expansion. So there's another potential route.\,. (15:11) And I was about to say, that I'm actually satisfied with having reached this point now, but now I guess I should think a tad bit more about whether both the $\lim_{\delta k \to 0} \delta k^{3/2} \hat H''$ idea and the $\lim_{\delta k \to 0} \hat H''$ work at the same time (probably not), and about which I think will work (probably the original one.\,.).\,. .\,.\,But yeah, I think I'm soon good to just say: `this is as far I'll get this time around,' (and a very decent distance at that), and then hopefully when I return to the problem, it will not be alone.\,. (15:15)

(15:52) To be fair, it is way more plausible that my self-adjointess domain technique (from my self-adjointness paper) can be used for $\lim_{\delta k \to 0} \delta k^{3/2} \hat H''$ rather than $\lim_{\delta k \to 0} \hat H''$. So I would probably put my money on my original idea at this moment.\,.\,:)

Right now, I'm also wondering, at that `the $\varepsilon$-almost eigenvector stays spread out when time-evolved' idea can be transferred to the momentum space argument somehow.\,. (14:56) .\,.\,For in momentum space, it could then perhaps just become: `the $\varepsilon$-almost eigenvector stays in the $\mathbf{P}_0$ hyperplane when time-evolved'.\,. .\,.\,Hm sure, that sounds quite reasonable, at least on a heuristic level, certainly.\,. (15:59) .\,.\,And then you just need to have assumed the cutoffs so that you can make the Trotter--Dyson expansion.\,. You should then be able to gather the terms again into the time-evolved $\hat A^\dagger$-operator, I'd bet. So yeah, I think this might just work.\,.\,:)

I'd need to think more about it though. But let me think if I even want to do that, or if I should aim at making v2 by maybe just assuming something nice about $\phi$ for the momentum-space argument.\,. (16:04)
.\,.\,(16:14) Oh, but then I also need to show that $\phi$ doesn't grow it's particle number (expectation values), and that sends me back to the same square. So I guess I should just move on now, and then fix v1 of my paper (but probably keeping it much the same).\,.

(16:44) Hm, maybe I should also take that path integral (in momentum--time) idea more seriously, and perhaps combine it with Hamiltonian arguments. First of all, if we look at any $\varepsilon$-almost eigenvector, $\phi$, that is ``based around $\ket{\,}$,'' so to speak, and who has a non-vanishing inner product with $\ket{\,}$, then couldn't one show that when we dial the coupling constant, $q$, down, we can also decrease the amplitudes of the excited states of this $\phi$ state and then obtain a new $\varepsilon$-almost eigenvector of this dialed-down $\hat H$? Then the conventional wisdom will tell us, that if we dial up $q$ slowly for a space-time volume, like the one from the thought experiment described (above) this morning, then the bare vacuum state, $\ket{\,}$, will slowly turn into.\,. well, turn into.\,. Okay, some problems with this argument, first of all because there might very well be degeneracies.\,. Hm.\,. (16:51) .\,.\,Hm, but I think this line of thinking can still be made to work. So it would surprise everyone, if the bare vacuum does not slowly turn into another vacuum solution. And when we then go and consider the path integral, we can see that.\,. Wait, never mind the line between a Lagrangian/path integral and a Hamiltonian argument, 'cause why draw a hard line? Couldn't I, more to the point, not use the Dyson-expansion into a path integral in order to argue the the vacuum perturbing terms cancel out from the time-evolution (for my Lorentz covariance circuit)?\,.\,. (16:57) Hm.\,. .\,.\,Hm yeah, maybe.\,. .\,.\,So I have a lot of potentially good routes, even though they all seem kinda hard, where they are now, to make a rigid/solid mathematical argument out of.\,.

.\,.\,But then again, the Lorentz covariance argument is (I believe) heuristic as well, so it doesn't matter too much, even if we only (in my lifetime or so) make it as far as showing heuristically that the theory without the vacuum-perturbing terms is Lorentz-covariant, but still manage to show mathematically that it is well-defined. *(Oh, I meant to also say: especially if it can also be confirmed, numerically and/or experimentally, that we are right to cut the vacuum-perturbing vertices out of the paths in the path integral. (17:11)) .\,.\,So I'm pretty happy with where I'm at, actually. .\,.\,And yes, it is definitely worth trying to take the route of arguing directly from the (momentum--time) path integrals that the vacuum-perturbing vertices does not affect the dynamics of the physical particles. (17:07)

(13.03.24, 12:27) Instead of momentum--time space, one could also do this argument in position--time space up until the last vertex, far within (generally) the volume where $q$ is dialed up. And after that vertex, you could go to momentum space. Then you consider similar interaction trees for the argument, where you then argue that the different time gaps between the last vertex and the final state means that the overall contribution from this group of paths will sum to (almost) zero.

So there we are, but this is not all. For the vacuum paper, I could also derive the momentum--time path integral via a Dyson expansion (this time a true one, i.e.\ where the free propagation is kept as $\exp(-i \hat H_0 \Delta t)$). And then I could argue directly from that that all the paths that contains vacuum-perturbing vertices---and which are not closed loops(!)---will yield a zero contribution (when we take the adiabatic limit of dialing up $q$ in the past before the given experiment). (12:35) So I might actually make this argument in v2 of my vacuum paper.\,.\,! (12:35)

(14.03.24, 10:11) I was getting really happy with my path integral argument yesterday, but it seems that I might have thought to simply about it; it now seems a lot more complicated. I'm not sure my argument holds.\,. \ldots Wait, let me think some more.\,. .\,.\,Hm, with the assumption that you can calculate it as a perturbation series (in the coupling constant), doesn't the argument actually work?\,.\,. \ldots Hm, and the fact that $q$ can be anything gives a pretty good heuristic reasoning, at least, that you should be able to calculate by gathering orders of $q_0$, where $q_0$ then represents the maximum coupling in the middle of the volume, which $q$ is dialed up to.\,.

.\,.\,Okay, let us consider momentum--time space where we only consider one inertial frame, where $q$ is then a function of time (measured in that single inertial frame).\,. .\,.\,Some (quite conventional) assumptions then let's us do a Dyson expansion and gather the paths in orders of $q_0$, i.e.\ number of interactions. (And note that I'm talking about an \emph{actual} Dyson expansion here, where the action of the free energy is kept as $\exp(-i \hat H_0 \Delta t)$.) .\,.\,I think I should consider paths where the initial vacuum-perturbing vertex is the one that's allowed to vary.\,. .\,.\,By the way, let us consider a case where $q$ is slowly dialed up and then dialed slowly back down again afterwards.\,. The idea is then that when the first vertex that embodies an interaction with a `vacuum particle' and a `physical' one is close to the beginning of the time interval, the coupling is very low, and this path should not contribute with very much. And if it is away from the beginning of the time interval, then when you sum/integrate over all times where the variable initial vacuum-perturbing vertex sits, you should also get a very low contribution due to the oscillations that the free energy (between the vacuum-perturbing vertex and the first physical--vacuum interaction vertex) will cause. Hm, this does not seem so bad after all.\,.\,!\,.\,:) (11:43) *[I'm no longer very convinced at all that this argument holds. For when $q$ is dialed up more slowly, there is also more time values to sum over for the vertex/vertices.\,.]

.\,.\,(11:51) Hm, of course, the assumption about the perturbation series is not necessarily correct, but then again, standard QFT assumes that it is (I'm pretty sure, but one could look into it more), so\ldots\ (11:53)

(15:40) Okay, I think I know how to complete my original $\lim_{\delta k \to 0} \delta k^{3/2} \hat H''$ idea now.\,. I think one should be able to show that $\lim_{\delta k \to 0} \delta k^{3/2} \hat H''$ can be approximated by a bounded version, where the bound does not depend on $\delta k$. For if the continuum limit can be shown to be self-adjoint, and to be approximated arbitrary well be a version with a $\Lambda$ and an $n_{max}$, then if you introduce a small discretization to that in momentum space, one can probably show that this operator still approximates the original one arbitrarily well when $\delta k \to 0$. So $\delta k$ can be sent to 0 first, before $\Lambda$ and $n_{max}$, in other words. And then we are good, since we can then just take an $\varepsilon$-almost eigenvector, $\phi$, and.\,. wait, no.\,. Hm.\,. .\,.\,Hm, or could we take a sequence of actual eigenvectors, perhaps.\,.\,?\,.\,. \ldots (15:58) Hm, but maybe the point is to use this to show that $\hat U(t) \phi$ stays (approximately) bounded in its particle number.\,. .\,.\,Yeah, that must be the point.\,.(!\,.\,.) .\,.\,Oh, maybe this is it: the idea I've been searching for.\,. (16:02) .\,.\,(16:11) Oh, there is a problem, I think: How well an operator `approximates' another also depends on the time interval, $t$, or similarly, it depends on the energy, which is a problem, since this goes as $\delta k^{-3/2}$.\,.

.\,.\,Hm, but back to the idea of looking at a sequence of actual eigenvectors, couldn't you also ague that the continuum limit approximates the discretized (and bounded) operator in some sense.\,.\,? (16:15) .\,.\,Hm, maybe not.\,. (16:17) \ldots Hm, how about thinking about the more and more rapid oscillations of $\phi$?\,.\,. (16:38) .\,.\,(In terms of its energy.) \ldots\ (17:55) No, I don't want to try to go that route. Hm, I wrote above that I thought one could argue, that $\phi$ stays ``spread out'' when time-evolved, but I don't remember what I was thinking.\,.

(18:16) Oh, if we go back to the path integral argument/idea, wouldn't it make more sense to integrate the vacuum-perturbing vertex in position space over all possible positions, and then look at combined transitions to momentum states.\,. hm.\,. .\,.\,Oh, no. It wouldn't.\,.

.\,.\,(18:26) Oh, I guess you could argue that a $\phi$ that `stays spread out' can be found simply do to symmetry reasons.\,.\,! *(This is not enough: My big problem is really that I seem to not be able to argue that $n$ doesn't grow at some point (too soon, and to rapidly) for any $\varepsilon$-almost eigenvector, $\phi$.\,.)

Hm, I kinda want to take a break from this problem.\,. (18:40)

%(21:07) Jeg fik lige en idé om at approksimere \phi med egenvektorer af en diskretiserede H med en n_{max} også, og hvis man så kan argumentere for, at n_{max} ikke behøver at stige, når \delta k formindskes.. Hm, måske, måske ikke, men bestemt værd at tænke videre over...

(15.03.24, 10:02) Unrelated side note: In my existence paper, I write about a $\hat U(T)$ becoming an approximate identity operator, but I guess that this does not necessarily happen. I'm not completely sure. The overall argument still holds, though.\,.

(10:04) I think I'm about to leave this topic for now. The thing is, which route to take seems to depend on which of $\lim_{\delta k \to 0} \delta k^{3/2} \hat H''$ or $\lim_{\delta k \to 0} \hat H''$ can be shown to be self-adjoint. And the process of proving this might yield valuable insight which could be used for completing the last part of the argument, i.e.\ what I've been working on here. It might even be the case that such insights are \emph{needed} to complete the argument. It might for instance be the case that we need to show something about how the $\varepsilon$-almost eigenvectors depend on $n$ (and on $\varepsilon$).\,. .\,.\,So yeah, I'm thinking about putting this problem aside for now, and just make some adequate corrections to the vacuum paper (v1) on arXiv.\,. .\,.\,Yeah, it seems like the right thing to do.\,. .\,.\,putting it aside, i.e.

.\,.\,Copied from above: ``My big problem is really that I seem to not be able to argue that $n$ doesn't grow at some point (too soon, and to rapidly) for any $\varepsilon$-almost eigenvector, $\phi$.\,.'' (10:15)


%(18.03.24, 11:32) Jeg fik en muligvis kæmpestor idé her i sengen for små to timer siden---gik tidligt i seng og stod sent op---men min hjerne har af en eller anden grund bare været rigtig sumpet siden da, på trods af en god, lang nats søvn, så.. Men nu prøver jeg lige at sparke mig selv i gang ved at skrive lidt løst her om den nye idé: ..Lad mig lige fortælle først, at jeg egentligt har lagt.. ..Vent lad mig lige tænke over noget først.. ...(12:16) Årh, jeg kan virekligt ikke tænke særlig godt.. Men jeg tror nu, at jeg har fat i noget. Lad mig bare fortsætte, så, og sige, at jeg egentligt havde lagt det på hylden. Og i går tror jeg nærmest ikke, jeg tænkte over det overhovedet. Jeg havde virkeligt givet op, egentligt. Men så i sengen her i morges kom jeg alligevel til at tænke over, hvor meget interactions termern vokser som funktion af partikel antallet. Dette er jo meget natrligt at gøre, men jeg troede ikke rigtigt på før, at det ville lede mig hen til noget interessant. Men så kom jeg alligevel frem til, at amplituden både i første såvel som i anden må gå som $n$, nemlig fordi de individuelle bidrag vist ikke overlapper. Og så har vi jo pludselig noget interessant alligevel, for interaktionstermerne går jo som $\delta k^{3/2}$, kvadreret til $\delta k^{3}$, som er omvendt proportionelt med $n$ for et diskretiseret (approksimativt) Dirac-hav.! Og så kommer den store idé, for dette i sig selv er jo ikke så brugbart, når de to ting bare går ud med hinanden. Men hvis vi ser på en egenvektor af $\hat H''$, så kan vi jo ikke have, at de alle sammen kun har amplituder oppe ved $n=n_{max}$. Og man sågar argumentere for, at.. ..Ja, og nu bliver det så meget løst men: at der må være lige så meget amplitude.. Nej, eller rettere at for en konstant $\varepsilon$-almost egenvektor, \phi, som bliver under en vis $n$, så må denne opløses i vektorer, der alle har.. Hm.. Okay, det skal jeg tænke mere over, og især hvis det skal gøres matematisk, men min tanke i morges i sengen var: Hvis to egenvektorer udligner hinanden oppe omkring n_{max}, så skal de være antiparallelle der, hvilket, da de er ortogonale, må betyde at de er parallelle nede ved de lave n. Og dette kræver at amplituderne altså også er tilsvarende store dernede. Så når \phi opløses, så kan må egenvektorerne altså være nogenlunde ligeligt fordelt, nærmest, over og under en vis $n$-grænse.. Ja, det er ikke et særligt godt argument, men det var altså, hvad jeg tænkte. Og jeg er stadig ret sikker på, at man kan komme videre med den tanke. Nå, og det slog mig jo så, at det kunne vise, at de mest normale interaction terms ville blive mindre og mindre for $\hat H''$ / for et approksimativt Dirac-hav, når \delta k \to 0. Men så var der lige problemet med de interaction terms, hvor to vakuum-pertikler annihileres. For der går amplituden som n^2, fordi man så får alle kombinationer. Men efter at være stået op (vistnok i badet, eller kort efter, men det lige røget.. ..Hm ja, jeg tror i badet eller mens jeg tørrede mig..) så kom jeg i tanke om, at $\Delta/2 + d$-billede jo netop også ændrer sig, når man ikke tager to partikler, der er med i samme "triplet" (af partikler med impuls 0 sammenlagt), men når man tager to partikler fra hver deres vakuum-triplet.! Og sidenhed er jeg så lidt kommet løst frem til igen (og det minder i øvrigt om mine tidligere tanker omkring udelukkende-annihilations-interaktions-termerne (dem jeg glemte i v1)), at ja, når man gør det sidstnævnte, så vil man få et endnu mindre bidrag, som så lige netop kan konkurrere med det der n^2.! (12:46) ..Og hvis det holder, og fordi amplituden for egenvektorerne af \hat H'' jo nok må falde omkring n_{max}, når denne stiger, så vil den faldende amplitude altså nok vinde over det stigende antal kombinitioner for interaction term-transitionerne, hvilket må bringe os i mål.!! ..7, 9, 13. (12:49)

%Nå, jeg vil stryge min hjerne lidt med hårene nu, og nok gå en tur inden længe, og så håbe på, at den kondenserer mere og mere, så jeg lige kan få regnet det mere igennem---og muligvis finde (lidt) ud ad, hvordan jeg skal udføre argumentet for, at "amplituden for egenvektorerne af \hat H'' [...] må falde omkring n_{max}."...

%... (16:40) Mit argument holdt ikke, for selv hvis normen er jævnt fordelt over all n, så kan det godt være, at normen er så meget desto mindre i hvert niveau, men så bidrager hvert niveau jo til gengæld bare hver især.
%Nå, men jeg fandt min hjerne i skoven, hvor jeg så fik indset dette. Så kom jeg dog til at tænke på min Baker--Campbell--Hausdorff-idé. Og omkring tyve minutter efter, kl. tyve i to, kom jeg så frem til noget rigtig stort, tilsyneladende.! Hvis vi har en Trotter-udviklet $\hat H''$, og så lader tiden stige med en faktor \delta k^{-3/2}, så vil dette jo nok med al sund fornuft kun kræve i omegnen af \delta k^{-3/2} flere faktorer i ekspansionen. Og hvis vi f.eks. lod der være \delta k^{-(3+\varepsilon)/2} gange flere faktorer (i.e.\ operatorer på formen \exp(-i\hat H'' \Delta t)) i ekspansionen, hvor \varepsilon er meget lille, så vil vi sikkert få højere og højere præcission, endda. Og lad os så erstatte \exp(-i\hat H'' \Delta t) med (1 - i\hat H'' \Delta t)! Så får vi en ekspansion af kun \sim \delta k^{-3/2} af disse operatorer, som hver især kun kan forøge partikelantallet med 1--4 partikler. Så vi kommer altså aldrig op i nærheden af \delta k^{-3} antal partikler via denne tidsevolution, hvis vi altså starter med en \phi, der har er meget hurtigt aftagende efter et vist, konstant n.! Og så kan jeg (ved at bruge det jeg ellers skrev om her i morges) komme igennem på denne måde! :D (16:54)

%..Sikke en kæmpe lettelse, hvis jeg alligevel kan komme igennem dette argument for min originale idé også (jeg er jo rimeligt overbivist om, at vi sagtens kan komme igennem, hvis operatoren med den tællelige basis kan vises at være selvadjungeret). Det er dog som om, at det ikke helt er sunket ind endnu.. eller også er jeg bare skeptisk, hvilket er klogt nok.. Men det vil virkeligt være kæmpe stort for mig, ingen tvivl om det.. (Jeg skrev egentligt her forleden, at jeg var godt nok tilfreds, men jeg har alligevel bare kunne mærke siden, at det føltes som om det tog luften lidt ud af hele projektet, nemlig at jeg kun muligvis kunne pege i retning af målet, hvor jeg, hvis dette holder, nu kan pege meget mere kraftigt og sikkert på målet..(!..)) (16:59)

%(18:30) Ah, når jeg nu antager UV og IR cutoffs, så kan jeg lade \phi være en næsten-egenvektor af \hat H_{vac}''' i stedet, og vigtigere, se på egenvektorerne af \hat H_{vac}''. Og så kan jeg nemlig lige netop få, at vakuum-partiklerne kun er entangled med op til 4 partikler hver især, hvilket jeg nemlig skal bruge for at kunne bruge det/de argument(er), som jeg beskrev i morges, hvor n^2-afhængigheden altså alligevel (i hvert de eksempler jeg lige har fået regnet (lidt) på i hovedet) udkonkurreres. (18:34)
%...Hm, jeg glemmer vist annihilations-delen af \hat H_{vac}'', som også kan foresage yderligere entanglement.. ..Hm, hvís man nu starter fra det bare vakuum... (men tør jeg det ift. Trotter-ekspansionen?..)..  ..Hm, men måske kan man også godt bare vise, at denne annihileringsdel vil have forsvindende virkning, når den ikke annihilere tripletter (eller kvartetter), men annihilerer partikler fra en større entangled gruppe.. (18:57) ..Det må man kunne, ja.:).. ..(19:05) Hm, og så kunne man starte med en pre-\hat H_{vac}'', hvor tripletterne er entydigt identificerbare, og hvor annihileringsdelen så kun virker på tripletterne (eller kvartetterne, når det kommer til Coulomb-delen, selvfølgelig) hver for sig. Og ved så at se på "perturbationen," hvor man lader annihileringsdelen virke på kryds og tværs af alle partiklerne, således at vi kommer tilbage til den rigtige \hat H_{vac}'' med denne "perturbation," så kan må man så kunne argumentere for---med UV og IR cutoffs---at forskellen på (næsten-)egenvektorerne kun er forsvindende, når $\delta k \to 0$. (19:10)

%*(22:54) Jeg kan bare bruge, at der er $\sim \delta k^{-3/2} - x$ partikel-tripletter/kvartetter, der ikke er blevet yderligere entangled, og $\sim x$ partkler, der er.. ..(muligvis..)

%*(19.03.24, 10:36) In a way, I was wrong about the \delta k^{-(3+\varepsilon)/2} thing: We can only derive a bound on \Delta t that goes as \delta k^{3}, it seems. But I've actually realized that it might work still. For the thing is: even though their might be some parts of the (1 - i\hat H'' \Delta t)^N expansion that reaches up around n_{max}, these parts will generally go as \Delta t in transition amplitude for large enough.. $N$.. Hm no, let me see.. (10:43) ..Hm, it should go as \Delta t, right?.. ..Oh no, not generally, but when \Delta t goes as \delta k^{3}, and you look at a transition to some level with particle number equal to $x \delta k^{3}$, where $x$ is some constant fraction, then yes, it should go as $\Delta t \sim \delta k^3$.. ..And there we go.:)(!!) This therefore means that one \emph{can} argue, that the vacuum particles becomes less and less dense when \delta k \to 0, within the whole time interval that itself goes as \delta k^{-3/2}.:) ..!! (10:58)

%*(11:32) Hm, I should probably use a \Delta t that decreases even more rapidly, actually, or simply sent it towards 0 for every \delta k.. ..Right..:) ..Or equivalently use the Taylor expansion formula.
%*(12:05) Åh, måske skal jeg faktisk tilbage til den idé fra i går aftes, som btw nok nærmere burde have været formuleret som: "der er $\sim \delta k^{-3/2} - x$ kreationstermer og $\sim x$ annihileringstermer." Og så skal jeg måske bare bruge denne idé allerede her for at vise, det jeg overvejer nu, nemlig at: "the vacuum particles becomes less and less dense when \delta k \to 0, within the whole time interval." ..Ah, jeg kan mærke, at dette kan bringe mig i mål (7, 9, 13).. (12:10) ..Hm, og så skal jeg jo nok ikke Taylor-udvikle, men skal i stedet $(1 - i\hat H'' \Delta t)^N$-udvikle.. ..Hm, tja... ..Lad mig forresten springe ned under de to kommende renderede paragrafer..


(18.03.24, 19:20) Some seemingly very(!) important notes (in Danish) above this paragraph in the source code comments.\,!\,.\,. .\,.(I will summarize them here at some point.\,.)

(19.03.24, 10:31) Maybe the two operators $\lim_{\delta k \to 0} \delta k^{3/2} \hat H''$ and $\lim_{\delta k \to 0} \hat H''$ \emph{can} both be self-adjoint (and non-trivial). Maybe this is not a contradiction. For they might just have different domains that each makes one well-defined and non-trivial, and not the other.\,. Very interesting, but luckily, I think I can complete the argument for $\lim_{\delta k \to 0} \delta k^{3/2} \hat H''$, as I'm currently writing about in the source comments. \ldots\ (17:18) Oh, I've also completely forgotten that the Hilbert spaces are also different to begin with (not just their domain).\,x) .\,.\,So yeah, maybe they can indeed both be self-adjoint.\,:)


%(12:15, 19.03.24) Jeg havde en rigtig god fornemmelse med den her idé fra forrige ikke-renderede paragraf, og det har jeg stadigvæk, men jeg kan også mærke, at jeg lige skal tænke noget mere over det først... ...(12:46) Okay, jeg kan (vist) bruge Taylor-udviklingen, og så netop bruge omtalte argument til at vise, at man kan lave et vist cutoff på m, hvor m er ordnen i Taylor-udviklingen. ..Og "omtalte argument" handler altså om at bruge, at selvom, ja, der er flere partikler i spil for \hat H_{vac}''^{m} \phi, så er de fleste af dem kun entangled i tripletter og kvertetter, hvorved de deremd ikke kan bidrage med transitioner med særligt høje amplituder alligevel. ..Nå, så nu skal der altså tænkes over, hvordan jeg helt præcist finder dette øvre bound på \hat H_{vac}''^{m} \phi... (12:51)

%(20.03.24, 11:37) Okay, Coulomb-interaktionen er faktisk virkeligt problematisk.! Uden den tror jeg sagtens godt, man kan komme igennem med mit nye argument her (for min originale $\lim_{\delta k \to 0} \delta k^{3/2} \hat H''$ idé). Med med den virker det bare ikke rigtigt til..!:S ...(12:11) Ah, vent.. ...Nej..

(20.03.24, 13:03) I feel like I've come so far on the way to completing the argument for the original $\lim_{\delta k \to 0} \delta k^{3/2} \hat H''$ idea (see the source comments), but the Coulomb interaction actually seems to be in the way of completing it fully. I kinda want to keep at it, but I also have to get on with my life (and more importantly, other projects) at some point.\,. .\,.\,The good thing is that now I see a higher chance the the $\lim_{\delta k \to 0} \hat H''$ idea could also work, i.e.\ the `countable basis' idea. And if that works, it already yields us a well-defined theory, even if one cannot get rid of the perturbed vacuum. Yet I feel pretty confident that one could complete the argument I had in mind (carving out a $\delta \mathbf P$ and all that) for that route. So I guess I should just try to leave it be and put this problem on the shelf for now.\,. (13:11) .\,.\,Hm, I guess I ought to do that, yes.\,. I probably cannot help thinking about it here on my afternoon walk soon, and maybe I'll also think about it some more throughout the rest of the day, but I should probably also try to tell my mind to move on to new things.\,. (13:14)

%(13:29) Hm, men hvad nu hvis man kunne bruge Trotter-udviklingen for \hat H''' og så på en måde argumentere for (og så bruge), at man godt kan lade \delta k \to 0 men samtidigt beholde et ikke-forsvindede \Delta t..?

(13:36) Okay, I just had an idea: `What if one used the Trotter expansion and were able to argue that when $\delta k \to 0$, you could still keep a constant (small enough) $\Delta t$ in order to adhere to some precision?' And now that I've thought a tiny bit about it, it does seem somewhat reasonable, and what's more, it would solve my problems, wouldn't it.\,. Well, perhaps.\,. Hm, it's actually somewhat back to an earlier point of my recent idea; maybe it could even work if I only showed that $\Delta t$ had to decrease only as fast as $\delta k^{3/2}$.\,. Okay, I should think\ldots

(14:20) I've realized that even if I manage all this, it still might not be quite enough, as I'm worried that when we get back to the `interaction terms,' it might also be trouble even if the particle number only grows as $\delta k^{-3/2}$ over the whole time interval. So maybe we actually need for my countable basis idea to work, anyway. So I guess I'll actually put my money on that: I hope (and find it reasonable) that the Dirac-sea reinterpreted Hamiltonian in a countable basis will be self-adjoint on some domain. And in that case, I'm pretty sure that my `carving out a $\delta \mathbf P$ and all that' route will work, at least in the end. This idea is described above (and perhaps my poorly encrypted working notes about it can also help a little bit in understanding it). So I think I'm actually satisfied with where I am enough that I can actually put the problem away for now. I ought to also make a correction to v1 of my vacuum paper, but maybe I should focus on finding a job first, and get on with web-development.\,. (14:28) .\,.\,Yeah, I'll probably at least take a decent break before I go back to doing that (no one is reading it anyway, so I guess there's no hurry at all).\,.

.\,.\,Let me just reiterate: I think my countable basis idea, described above, will work (and I feel like I basically solved the post-showing-self-adjointness part above, 7, 9, 13).\,. (14:31)














\chapter{Energy and climate ideas}

(17:23, 11.01.24) In my 2021 notes, I wrote about some green energy ideas, some of which are pretty far out. One of the ones that are pretty far out, but which I nonetheless think ought to be investigated more is my `grasshopper idea' (see those notes).

Then there were also some ideas about growing algae, some far out, some less so. I just wanted to quickly write (perhaps again) about a not-too-far-out version of this idea: Imagine laying out a large net on which algae/seaweed can grow (big) in the Pacific Ocean, or some other relatively quit part of the world's oceans. At certain points in this net could be buoys which also (at least some of them) had the task of pumping up nutritious water from deeper below. Algae could grow on the net, and once in a while, you could pull the net in and remove the algae, dry them, and burn them *(to get energy)---preferably in a way that collects and preserves their nutrients (nitrogen and phosphor). This would then be a source of energy, and it would also have the ``side effect'' of increasing the Earth's albedo. (17:33) *[(16:38, 22.03.24) And instead of burning the algae for energy, it could also potentially be used in food and/or fodder instead.]


(22.03.24, 10:07) I have thought a bit about an idea of mine about building ice mountains on the poles. It was also combined with thought that this might be a potential idea for a space elevator as well. But I guess the temperature would rise too high on the mountain slopes and melt the ice. And there's also a problem with using the idea to cool the planet, 'cause then you'd also have to get the frozen ice back into the ocean, which would be costly---not saying that pumping that much water, even slowly, wouldn't be very costly as well.

But then I also thought a bit more about the seaweed/alae idea, and I really think that I might be on to something very great there. Let me see.\,. .\,.\,Okay the combined agricultural area of Earth is almost 1 \% of the total surface. And then think of how costly it is to grow and maintain all those fields, and compare that to just having a net of (very spread out) tubes in the Pacific Ocean, say, where nutrients from the deep water can be pumped (slowly) up and through the tubes, and where the surface of the tubes is rough and fit for seaweed to grow from. Oh, and where the nutrients can also diffuse out (from holes) of the tubes. The point is since these tubes could potentially be spread out quite far, it maybe wouldn't require many meters of tubes to cover the area corresponding to a single field on the land. And the cost of these tubes, and the cost of maintaining them, ought to be much much lower when comparing to maintaining a whole field on land with all the tasks that that requires throughout the year. .\,.\,Maybe the costs aren't even really comparable: Maybe it would be incredibly more cheap to build and maintain the seaweed net. And from what I (think I) know, if we cover around a percent or two of the earth's surface, it should make a very significant change to the climate, and could prevent climate change, in part due to the captured carbon in the seaweed, and due to the increased albedo. I also thought, if the main tubes can be pretty much parallel to each other for large patches of the area, before any supporting tubes or wires crosses over them, then there could be these large rectangles where boats are free to sail unhindered (without having to cross over a tube or a wire). This could mean that boats/ships could sail in these rectangles and harvest seaweed/algae, and potentially also all the fish that would naturally seek shelter in and feed on the seaweed algae. *(And of course you don't fish all the fish at once; you fish only a fraction and let the others multiply to fill the space afterwards.) So their might even be a great yield for this climate idea: Who knows, it might even be profitable even without counting the good of increasing the albedo and capturing carbon. It might potentially be an incredibly great idea. Definitely worth investigating/researching more.(!!) (10:40)

.\,.\,Hm, and the idea might especially work if one could find a good type of algae (or several types) which can grow on top of each other, or better yet, grow together as one (and I know that there are one-celled seaweed/algae that can do this) and create a symbiosis such that the algae closer to the tubes share the nutrients with the algae further out, and the outer algae share their generated sugar (perhaps) with the whole symbiotic organism ``in return.'' (10:46) .\,.\,(Oh, and preferably one that floats, of course (if they don't all do that, I don't know).)




















\chapter{Notes from 2022 (out-commented)} \label{notes_from_2022}




\begin{comment}

Disse noter er bare nogle korte ting, som jeg ikke har lyst til at skrive ind i mit nuværende "main-tex"-dokument (altså mit 2021-22-notesæt), og jeg gider heller ikke starte et nyt (2022-xx-)notesæt lige nu, bare for det.. Så dette dokument bliver altså et slags mellemled. (08.07.22, 12:19)



## Tanker fra i morges (08.07.22) omkring bl.a. børneopdragelse, men også meget mere

Jeg tænkte bare lidt på, at der sådan noget som børneopdragelse, og også sådan noget som hvordan man skruer en hverdag og et (sam-)liv sammen som et andet godt eksempel, at der kan jo være rigtigt mange forkellige parametre og stille på: rigtigt mange forskellige tilgange, man kunne eksperimentere med. Og min pointe, jeg har lyst til lige at notere, er, at med mine web 3.0-idéer så kan folk jo på globalt plan diskutere sådanne tilgange, og ikke mindst arbejde på at sætte omtalte parameterrum op --- og her kan man helt sikkert bruge ML som en stor hjælp. Så vi vil altså i fremtiden kunne få et meget bedre overblik over sådan et helt rum af forskellige tilgange. Dette kan man så diskutere omkring og analysere, og bl.a. prøve at gætte på, hvilke parametre, der kunne spille godt sammen, og hvad der kunne passe bedst til forskellige omstændigheder/forudsætninger. Så man vil altså i dette globale netværk meget bedre kunne opstille en masse forskellige muligheder, og derfra bruge dette til at komme med gæt og forudsigelser, som er værd at slå ned på og "undersøge." Og i de to tilfælde, i.e. børneopdragelse, samliv generelt, og også bare >>liv<< generelt, der betyder at "undersøge" jo så, at nogle mennesker og/eller nogle lokalsamfund prøver at teste nogle af disse hypoteser simpelthen ved at udleve dem (i en længere periode i det mindste). Og med sådan et globalt (videns)netværk, så vil man hurtigt kunne opnå det samme, og meget mere endda, end hvis man havde kreative teoretikere (eller hvad man skal kalde sådan en som mig) til selv at udtænke diverse tilgange, der kunne vise sig at bære frugt under diverse forudsætninger. Og en side-konklusion er så derfor også lidt, at selvom jeg tror, dette emne *(omkring børneopdragelse og sådan noget) lige præcis er et, hvor jeg kunne være god, og hvor jeg kunne lægge rigtigt meget arbejde potentielt set (i fremtiden), så vil dette altså være endnu en ting, hvor mine 3.0-web-idéer også bare (formentligt(7, 9, 13) og fohåbentligt!) vil komme og ændre billedet totalt (og i sådan en grad, at der vil være langt mindre behov for enkeltindivider, eller enkelte små grupper, til at designe sæt af gode tilgange fra bunden og op). (12:38)
%*(18.08.22, 13:39) Denne idé/tanke er jo meget en naturlig fortsættelse af mange af mine andre tanker. Det er jo lidt bare, at man kan skabe gode muligheder for diskussioner, og så vil befolkningen meget hurtigt og effektivt kunne udvikle en masse gode nye idéer, gode nok til at de er værd at afprøve. Denne del af det ligger senere end nogle af de andre forestillinger (f.eks. vil disse muligheder sikkert først komme rigtigt en del tid efter, at man får gode muligheder for debatter.. men ja, jeg tror helt sikkert at dette også vil blive et resultat af hele den udvikling på sigt). Og lad mig så også lige nævne en lille ting, som nok egentligt (også) burde stå i en "sektion" med et andet navn: Jeg vil bare gerne lige understrege, at ja, jeg tror virkeligt på, at vi med denne udvikling, som jeg forudsiger, vil blive gode til at diskutere ting godt. Og ja, faktisk tror jeg på, at vi i en ikke al for fjern (faktisk rimelig nær) fremtid også vil blive i stand til som befolkning(er) (globalt og lokalt), virkeligt at få diskuteret grundigt, hvordan f.eks. vore politik skal være (lokalt, men også mere globalt), og i det hele taget hvilke nogle retninger, vi skal bevæge os som samfund, og hvilke mål vi skal betræbe os --- og hvordan vi skal bære os ad med dette. Dette bliver dog ikke en ting vi opnår lige med det samme: Det ligger altså nok som en af de lidt fjernere muligheder. (Der er nemlig mange muligheder, som denne udvikling vil bringe, som vi hurtigt kan få gavn af, og så er der altså også nogen, som nok vil tage længere tid om at komme ordentligt skub i. Og ja, denne sidstnævnte ting er nok ikke en situation, man skal forvente vil opstå med det samme, men jeg tror altså som sagt, at der ikke vil gå mange mange år, før den beskrevne situation bliver en realitet.) (13:50)


## Fortsat omkring diskussioner og videndeling, som det fremtidige internet vil åbne op for

(05.09.22, 20:08) Jeg har sikkert nævnt dette hurtigt et sted i mine 2021--22-noter, men noget andet som virkeligt bare vil blive godt i fremtiden, er når vi kan få bygget en god ontologi / et godt kort over, hvilke personlige problemer og/eller klager og/eller ønsker folk har i samfundet. Det ville hjælpe samfund (altså vores nuværende store samfund, i.e. lande) gevaldigt, hvis forskellige befolkningsgrupper nemt kunne få langt større indblik i, hvordan de andre befolkningsgrupper har det, og hvilke problemer de slås med. Og så vil man jo i det hele taget også bare kunne overveje politiske beslutninger sammen meget mere effektivt, hvis man har tingene (altså ønsker/klager/problemer) kortlagt så godt på den måde. Selvfølgelig kan man komme ud for, at folk smørre tykt på med, hvor store deres problemer er i forhold til andres, men så skal man jo bare lige sørge for, at det hele først bliver diskuteret og analyseret endnu mere (hvor man bl.a. kan tage stikprøver især fra folk der ligger lidt på kanten mellem to befolkningsgrupper (og/eller på anden måde har en position, hvor de har indsigt i, hvad sandheden egentligt er, men ikke har en personlig bias for selv at lyve/smøre tykt på)), inden man begynder at behandle det som fakta, at så og så mange borgere har et så og så stort problem med det og det. Så ja, det kan vi altså også se meget frem til --- det er desværre nok en af de ting, der kommer til at ligge meget sent i hele udviklingen, desværre, men vi skal nok nå dertil på et tidspunkt som (global) civilisation. (20:19)



[...]

*(Jeg har skrevet noget på et tidspunkt her om børneopdaragelse, men jeg vil lige understrege igen: Bare glem det. Scratch that. Men som sagt var hele pointen også bare, at alle sådanne nogle tanker og forestillinger, om hvad end emne det lige skulle være, det bliver altsammen meget nemmere at diskutere og udvikle i fællesskab i fremtiden, når vi får det Semantiske Web..)



## Web 3.0-bevægelse og forretningsidé

(07.08.22, 20:51) Hvis jeg skulle starte en virksomhed for at komme i gang med at opnå de drømme, jeg har om dette emne, så ville jeg fokusere på at starte med at lancere en web 2.0-side, det opfylder kravende fra min "forretningsidé" (om at kunder skal blive til medejere, og at det hele skal gå på omgang osv. osv. (se noterne i main.tex fra i januars og/eller februar, eller hvornår jeg helt præcist skrev dem)), og så vil jeg også virkeligt prøve på hurtigt at få indført, at betalende brugere for stemmemagt over en rigtig stor del af.. ja, af hvad jeg vist har kaldt skaber-aktierne, men nærmere bestemt, så vil jeg sørge for, at disse starter med at udgøre en rigtig stor andel af de samlede kunde/skaber-aktier, og så vil/ville jeg altså sørge for ret hurtigt at få indført, at det er brugerne/kunderne, der har høj stemmemagt over, hvordan diverse skaber-bidrag belønnes (med de skaber-aktier, som virksomheden uanset hvad alligevel er kontraktbunden til at udstede til nogen). (20:59) ..Og ja, så vil jeg bestemt også sørge for, at det hele er open source (og jeg ville bestemt prøve at få eksisterende open source programmører med på bølgen (som "skabere")). ..Og ja, derfra må man sige, at jo hurtigere brugerne kan begynde at føle, at der er flere muligheder på siden, bl.a. ved at der kommer flere og flere (open source) algoritme-muligheder, jo bedre, for det er jo så der, man kan begynde at tiltrække brugere/kundere på baggrund af selve indholdet/rammerne(/mulighederne).. (..og altså ikke bare på baggrund af hele forretnings- og open source-idéen ved det; pga.\ nutidige muligheder for brugerne, og ikke bare på baggrund af fremtidige visioner.) (21:04)

(17:42, 19.09.22) En god måde at starte et web 2.0-til-3.0-firma (med min forretningsidé), kunne bare være at starte et firma og en kickstarter, og så bare love, at alle donationer hurtigst muligt vil blive omdannet til kunde-aktier, så snart papirarbejdet er gjort. Angående iværksætterenes og arbejdernes egen aktie-gevinst, så kunne man jo bare sige, at der lige i starten gælder, at.. Tja, eller man kunne faktisk sørge for hurtigst muligt at brugere kan uploade og stemme om vedtægter på en hjemmeside over, hvordan lønnen skal fordeles. Og så kan der bare være en fast klausul fra starten om, at en vis andel af al denne løn i denne indledende fase skal gå som løn til iværksætterne, og/eller at disse så også for nogle kunde-aktier genereret herved, svarende til en lille procentdel af denne løn. Måske kan man endda også vedtage, at lønmodtagerne i denne indledende fase også skal have nogle procentdele af deres løn i form af kundeaktier. Og i starten vil alt dette så bare baseres på løfter (men hvor iværksætterne muligvis alligevel kan retsforfølges, hvis de bryder disse løfter, fordi de så har handlet falskt og har fået betaling for en vare, som de så har valgt ikke at levere --- hvilket kun er godt, hvis de kan det, også for iværksætterne selv, fordi dette så vil få flere kunder til at stole på opstarten). Men hurtigst muligt skal man altså have udarbejdet kontrakter osv., så man kan gå ind i en ny fase, bl.a. hvor folks stemmeret omkring løn m.m. er mere konkret og detaljeret udarbejdet og sikret.. (17:53) 
%..Og hvad skal firmaet så starte med at lave? Jo, det skal såmen, udover at få styr på kontrakterne til fase 2, planlægge og give løn for programmeringsbidrag til en open source web 2.0-side (gerne én der både kan fungere som YouTube, Twitter og Reddit (m.m.) på én gang (og også gerne Wikipedia, men det kan godt komme lidt senere), men hvor man altså bare kan starte ét sted (f.eks. som en Reddit- eller en Youtube-agtig side)), og så må man så regne med, at tingene bare kan rulle derfra --- det tror \emph{jeg} i hvert fald helt bestemt på, at de kan. ..(For man bevarer jo selvfølgelig bare et system, hvor aktionærerne (og dermed kunderne!) kan stemme på vedtægter omkring lønfordelingen.) :) ..Og så kunne man jo oplagt have endnu en faseovergang efter lidt tid, hvor man også får de sidste ting på plads, bl.a. om hvordan fissioner af firmaet (og måske fussioner med andre, hvis det virker realistisk) skal kunne foregå, plus hvad jeg ellers må have glemt her fra mine noter (i januars/februars)..:) (18:02)
%..(18:07) Hm, og selvom det godt må være open source lige i starten, så kan det godt være, at man hurtigst muligt vil lave et system, så det er rimeligt åbent at se, hvem har gjort hvad, og hvor det måske ikke kræver særligt meget at få adgang til selve kildekoden også, men hvor kildekoden alligevel er eget af firmaet og ikke må tages/stjæles af andre. (18:09)

(21.09.22, 11:09) Jeg kan ikke huske, om jeg har skrevet om dette før, men jeg kom i tanke om i går aftes, at det jo er ret vigtigt, at normale kunder ikke ligestilles med f.eks. andre firmaer. Et firma/"underfirma" skal altså gøre det klart, om dets services er til private kunder eller til andre firmaer (for hver service i det mindste). Man må f.eks. ikke komme ud i en situation, hvor en instans bare kan købe og videresælge produkter, og så få de samme kunde-aktier for det, som de kunder, der køber til eget forbrug. Så derfor skal man altså generelt kun sælge produkter beregnet til eget forbrug eksklusivt til eget forbrug (hvilket i øvrigt sikkert også er meget normalt for firmaer allerede her i nutiden). (11:13)

(27.09.22, 17:47) Okay, jeg har tænkt en hel del mere over forretningsidéen i dag (og også lidt i går aftes), og nu kan jeg se at: Never mind den der forestilling om at lave en kickstarter eller lignende og så forvente, at firmaet så kan brede sig videre og videre derfra. Det er jo for nemt for alle andre firmaer bare at konverterer over, hvilket jo i bund og grund er godt, men det gør jo altså, at der slet ikke bliver noget (BitCoin-agtigt)venture-hype omkring idéen, sådan som jeg ellers kom til at tænke det nu her, hvor jeg er begyndt at tænke over denne idé igen. Så never mind alt det med (som jeg sikkert har nævnt under "Planer" nedenfor) at idéen kan blive den nye "helt store ting" i den forstand. 
Tvært imod vil det nok ikke kunne betale sig at investere helt vildt i normale firmear, der begynder at konvertere til forretningsidéen, medmindre man på en eller anden måde kan mærke, at de konkurrerende firmaer ikke vil have evnen eller viljen til at hoppe med på bølgen, og derfor altså vil blive udkonkurreret (formentligt, hvis man tror på idéen) af det firma, man så investerer i. Så medmindre der kun er nogle gangske få firmaer, der formår at brande sig godt på at være med på den nye bølge, så vil det nok mere bare være en situation, hvor flere og flere firmaer langsomt vil konvertere til de nye forretningsprincipper. 
Der er så også lige den undtagelse, at nogen brancher jo netop kunne få rigtig meget god synergi med denne idé, hvor kunderne/forbrugerne/brugerne kommer til at bestemme meget, og her tænker jeg jo så særligt lige præcis på min idé til en ny web-forretning/bevægelse. Så lige akkurat her vil der altså muligvis være gode investeringsmuligheder, men bid så mærke i, at dette så ikke vil skyldes.. hvad der svarer lidt en pyramide eller boble, hvor de første investorer altså kan tjene kassen på baggrund af, at de kom lidt før de andre. I stedet vil det simpelthen bare skyldes, som jo er normen omkring investeringer, at den nye forretningsløsning har potentiale til at tilfredstille kunderne meget mere --- ikke bare fordi disse også er investorer (og i og med at de så får en pengesum i vente), men altså lige præcis bare i forhold til det produkt de bliver leveret som kunder! Fordi der altså er mulighed for at sådanne hjemmesider m.m. kan komme til at levere et meget bedre produkt (altså bedre funktionalitet, bedre tilpasningsmuligheder, større udvalg og bedre kvalitet af indhold osv.), så vil det altså være værd at investere i, og kun ligesom af den grund.. Tja altså, medmindre selvfølgelig at man også regner med et vist hype omkring det, men det er jeg nu slet ikke sikker på, vil komme, hvis man netop ikke har nogen grund til at tro, at virksomheden vil brede sig til andre brancher derfra (fordi dem med aktiver i forvejen der også bare selv kan joine den nye bevæglese til hver en tid). (18:07)

(02.10.22, 16:52) Det kan faktisk godt være, at der kan lægge en stor investerings/forretningsmulighed i, hvis nogen kan finde på et rigtigt godt brand og en tilhørende rigtig god (offentlig) plan for, hvordan upstarts-firmaet skal være forbrugernes falgskib for at få bragt liv i den nye forretningsbølge: Hvis man kan overbevise en stor gruppe kunder til, at "det er her det sker," og at firmaet er hvad, man bør "investere" i som kunde, hvis man gerne vil sikre sig, at bevægelsen bliver til noget.. Så ja, dette kunne altså potentielt være en mulighed, især hvis man altså kan finde på en godt sted at starte (måske med en supermarkedkæde, eller en eller anden stor og alsidig handels/salgs-forretning), som virkeligt har mulighed for at brede sig meget ud, og som dermed kan vokse sig kæmpe stor, hvis bare alle kunder pludselig begynder at priotere handler med denne i høj grad.
Men ja, dette er nu ikke ligefrem noget jeg forudsiger, bliver en mulighed; jeg siger bare, at der måske kunne være et potentiale. Og ellers så tror jeg altså på, at man hellere skal tænke i firmaer/brancher, hvor firmaet vil have direkte gavn af (ift. det produkt, de ender med at levere!), hvis kunderne kommer til at bestemme mere, og hvis det også er sikret, at det bliver de ved med. 
Og i den forbindelse, så tror jeg altså faktisk på, at dette kunne være tilfældet for nærmest alle brancher, der handler med noget digitalt på en eller anden måde, enten med indhold, film, spil, læsestof, nyheder, bruger-til-bruger-indhold.. you name it.. Alle sådanne brancher, hvor det enten er sådan, at brugere selv i høj grad til at bidrage til værdien af det digitale, man nu end snakker om, og/eller hvis bare vi snakker kreative ting som kan konsumeres digitalt, hvor brugerne samlet set vil drage gavn af, hvis der kommer bedre forhold for skabere/kunstere, og også ikke mindst at alting bliver mere åbent (uden at folk behøver at bekymre sig om, hvis andre stjæler). For ift. sidstnævnte, så tror jeg jo på, at man, ved at kunderne styrer, kan nå en situation, hvor skabere/kunstere kan "bagud-belønnes" for deres arbejde. Og derfor kan alt sådan noget blive meget mere open source. Hvis vi så f.eks. tager spilindustrien (som et rigtigt godt eksempel), så er det ret nemt at se, at den samlede brugerskare kunne drage kæmpe fordel, hvis skabere ikke var nødsaget til at gøre alting så lukket. 
Ok. :) (17:11)

(06.10.22, 9:29) Lad mig lige præcisere noget i den tekst i 21--22-noterne, som jeg skrev d. 12/02-22: Jeg skriver noget med at "opkræve penge" fra aktionærerne. Her mener jeg selvfølgelig ikke, at man sender dem en regning, men altså at man bare nedjusterer det afkast, de har i vente. (Det fremgår sikkert et sted, men nu synes jeg lige, jeg ville kommentere og rette det her.) ...Hm, vi kunne da sagtens snakke 40 år i stedet (20 virker da ikke vildt langt..), appropos samme tekst.. *(Ah, det var for ikke at gøre udsigten for lang til en ægte kd.v., så tja.. ..Ah, men i princippet kan den jo blive "ægte kundedrevet" efter en ret kort periode alligevel, for det handler jo bare om, hvor stor en stemmemagt aktionærerne giver til sig selv i starten og i hvor lang en periode den stemmemagt varer.! Så der er faktisk ingen grund rigtigt til at sætte en kortere kundeaktie-periode.!:) (10:12) ..Nå nej, det passer så ikke helt alligevel, for hvis perioden er for lang, så kan der blive et demografisk (m.m.) skel imellem gamle og nye kunder. Så ja, hvilken periode man skal vælge fra starten er lidt et åbent spørgsmål, men man skal så huske, at denne dog stadig skal justeres (langsomt) løbende, således at den kun er en vis faktor større end, hvad anlagsaktiv-størrelsen som minimum kræver..) ..Og appropos samme tekst, bemærk så at det der med at have en instans, der vurderer firmaets samlede værdi til forskellige tidspunkter (ved at se lidt tilbage i tiden, så måske et år eller to efter), det skal ikke forstås som et væsentligt krav. Det er bare godt at have, bl.a. fordi det altså så gør det mere fair overfor aktionærer, hvis aktier udløber over en periode, hvor firmaet gjorde mange nye investeringer, og at de samlede mere direkte penge-omregnelige aktiver faldt i perioden, på trods af at værdien steg. (Men måske kan sådan en instans også bare se på aktiernes værdi i handler som en god kilde, man lad mig lige genopfriske, hvad jeg endte med at beslutte omkring aktiehandler..) 
...(11:04) Det var måske ikke så tydeligt, da jeg skrev om at opdele virksomheden, sådan at IP(/IM)-skaberne lidt fik deres egen "undervirksomhed".. tja.. Tjo, tja, giver det ikke lidt sig selv, selvom jeg ikke lige fik formuleret det tydeligt? Tanken er bare, at de så kan komme til at tilhøre og sælge deres bidrag til en "undervirksomhed," som så kan have andre "undervirksomheder" som kunder, der så bruger IM-bidragene til at implementere f.eks. en Web 2.x/3.0-side. Ja, det var nok rimeligt selvsagt, men nu har jeg også sagt det her. 
(11:21) Det kan i øvrigt godt være, at jeg her ovenfor på et tidspunkt har glemt lidt igen, at der skal være klare sætninger for, hvem der er de primære kunder (som skal have kundeaktier), og hvem man ellers bare handler med. Men ja, dog kan man jo sagtens starte med at have "donorer" eller "investorer," som altså kun giver rene pengebeløb.. med som kunder.. tja, men det kommer ikke rigtigt til at fungere. ..Nej, i stedet skal sådanne investorer jo bare købe aktier med deres "pengebidrag," hvilke jo så i høj grad naturligvis vil være "start-aktierne," eller hvad jeg nu har kaldt dem (dem til de indledende iværksættere og investorer). 

(11:42, 06.10.22) Jeg bliver nødt til lige at slå følgende fast, for jeg har jo snakket lidt om, her for nyligt, at der "ikke er den helt store investeringsdrøm." Men det passer ikke, eller rettere: sætningen skal i hvert i så fald bare forstås relativt til, hvis nu situationen var, at en enkelt kundedrevet virksomhed ville kunne udbrede sig til det meste af markedet. Jeg siger som sagt ikke, at der ikke er en vis sandsynlighed for, at ikke-så-web-baserede kd.v.'er kan udbrede sig rigtigt meget, men det er nok lidt for stor en drøm at forvente, at en sådan kan udbrede til stor mængde af markede, for som sagt kan andre firmaer jo altid bare følge trop.. Tjo tja.. Whatever, det giver ikke mening for mig at sidde her og prøve at forudsige den ene eller den anden vej på det punkt. Det jeg i stedet ville nævne var bare, at man jo (og det havde jeg måske kortvarigt glemt ovenfor, det ved jeg ikke..) skal huske, at de web-relaterede bracher jo også er \emph{kæmpe} store i sig selv. Så never mind, "at der ikke er en stor investeringsdrøm i det," for hvis jeg har ret, og at mine idéer omkring en stor web 2.0--3.0-virksomhed virkeligt vil kunne udkonkurrere gængse web-virksomheder, jamen så vil der jo potentielt set være en kæmpe investeringsdrøm i det, det er klart. Selvfølgelig er intet sikkert, hvorfor det er vigtigt at understrege 'potentielt' i den sætning. Men ja, følte bare, det var ret vigtigt lige at pointere. :) Det ville være lidt ærgerligt, hvis jeg unødvendigt kom til at ende på, at "der ikke er så stor en investeringsdrøm i idéen." Det kan der jo nemlig selvsagt meget vel gå hen og blive. :)
Lad mig også bare lige gentage, at hvis nu det var mig, der skulle starte sådan en "kundedrevet" web 2.0--3.0-virksomhed, så ville jeg altså virkeligt prøve at gøre virksomheden tiltrækkende for ""open source"-programmører" og andre skabere som muligt, nemlig ved meget hurtigt at prøve at implementere et "bagud-belønning"-system, rigtigt gerne hvor kunderne (og måske også gerne tidligere skabere/programmører) hurtigt for stemmemagt ift. bagud-belønningen også (og i øvrigt gerne hvor man også prøver at opstætte retningslinjer omkring, hvem fortjener hvad for hvad). Og her skal "open source" altså forstås meget i gåseøjne: Vi snakker nemlig slet ikke open source bidrag, for IP-rettighederne skal meget gerne gå til en fælles pulje som eges af virksomheden (eller endnu bedre: en mere uafhængig instans/"undervirksomhed" som virksomeheden så er kunde hos..). Men når jeg alligevel kalder dem ""open-soruce"-programmører," så er det altså bare for at pointere/hentyde til, at deres arbejde i høj grad så kommer til at minde om open source-arbejde, fordi tanken altså netop er, at bidragsyderne bare kan bidrage rimeligt frit og altså uden at være ansat og/eller have underskrevet en masse kontrakter, men hvor de så alligevel kan få løn for arbejdet via bagud-belønnings-systemet. Så ja, det ville jeg sandsynligvis nok prøve at sigte efter, hvis det var mig, der skulle starte sådan en ("kundedreven") virksomhed. (12:07) ..Ah, og vigtigt: Jeg ville også bestemt sørge for, at denne "bagud-belønning" også i høj grad (i starten især) ville komme i form af "IM-skaber-aktier," det er klart, for så kan man jo dermed belønne dem (hvis alt går godt) meget mere fra starten, også selvom man ikke har de store indtægter (fra kunder) endnu, og samtidigt så også gøre alle disse programmører/skabere mere investerede (også altså i overført betydning) i projektet. Det kan godt være, man lige skal se denne sidstnævnte ting efter i sømmene og regne efter på det hele først.. men ja, det ville jeg jo så gøre, hvis det var mig, der skulle være med til at opstarte en kd.v., for umiddelbart ser det ud til, at denne sidstnævnte ting også kunne gå hen og blive rigtigt smart at gøre. Nå. :) Følte lige for at gentage/understrege disse ting. :) (12:17, 06.10.22)


(19.10.22, 10:29) Jeg har fået tænkt noget mere over min forretnings(bevægelse)idé. Jeg har skrevet lidt ny brainstorm i et andet dokument, hvor jeg i går overvejde igen at tage mere udgangspunkt i omsætningen, men det går ikke. Og nu er jeg faktisk kommet frem til, at jeg nok bør ændre idéen til en mere simpel udgave (overordnet set, for jeg har også nogle nye tilføjelser, som jeg fandt på i går, om frit at kunne købe en vis størrelse kundeaktie oven i sin egen som kunde).
I bund og grund tror jeg nu på (bl.a. fordi jeg har indset, at mange af mine tidligere bekymringer skyldtes en tanke om, at virksomheden skulle være den eneste af sin slags, men det skal den slet ikke.. hm, ikke på nær måske hvis man tænker en web 3.0-virksomhed.. det må jeg lige tænke over, men lad mig her bare skrive om idéen med tankerne rettet mod normal industri og handel).. Jeg tror nu på, at idéen faktisk er bedst, hvis bare man simpelthen har start-aktierne og kunde-aktierne som før beskrevet, begge med en vis fast udløbskurve, således at aktiernes "størrelse" starter på et punkt og efterfølgende aftager efter hver lille salgsperiode. Nu mener jeg så, at det så bare skal være frit op til den samlede mængde aktionære (via deres stemmemagt) at beslutte løbende, hvor stort et afkast skal betales pr. aktiestørrelse efter disse salgsperioder. Virksomheden skal så bare have åbne regnskaber, så alle kan følge med i, inklusiv fremtidige kunder, hvad virksomheden har af reelle omkostninger, og dermed hvad pris-markup'en er for hvert produkt over tid (hvor man så selv kan vælge som iagttager, hvordan man vil regne udviklingsomkostninger ind sammen med "produktionsomkostningerne"). Det er så fornuftigt at forvente som kunde, og fornuftigt at drive virksomheden som aktionær, således at markup'en er rimelig konstant, når man midler over en periode, f.eks. over et år eller to. Og den skal i hvert fald helst gøres så stor, at kunderne er mere investerede til hver en tid, end hvad de samlede aktiver er hver, hvis man skulle sælge dem. Og desuden er det også smart at have en højere markup, hvis man gerne vil give større encitament for aktionærerne til at træffe gode beslutninger frem for dårlige --- plus dette giver også en vis investeringsbuffer, så virksomheden ikke hele tiden teknisk set er på randen af konkurs, altså fordi den "kun lige løber rundt," kan man sige. Men en al for høj markup er dog heller ikke at fortrække, for det kan skræmme nye kunder væk, som ikke rigtigt har nogen kundeaktier i forvejen. Dette vil så gøre virksomheden sårbar over for, at en konkurrent kan melde sig på banen og tiltrække alle disse kunder. Så disse tanker bør man altså gøre sig, når markup'en og det løbende afkast skal udregnes (i forhold til produktions og udviklingsomkostningerne). Men det er selvfølgelig rart lige at huske, at i sidte ende så kommer virksomheden jo meget hurtigt til at være styret af en stor (og i mange tilfælde almen) gruppe mennesker, som dermed ikke vil have meget ud af at prøve at presse citronen over for nye kunder, da disse jo ofte i høj grad vil være dem selv. Og i de få tilfælde, hvor der kan være en anseelig forskel på gamle og nye kunder, jamen så må man også forvente, at hvis en (\emph{stor}) gruppe mennesker vil presse en anden (\emph{stor}) gruppe mennesker som forbrugere, så er der jo stor chance for, at den anden gruppe vil gøre gengæld. Hvis der altså vil ende med at være visse store grupperinger af forbrugere, så er det altså naturligt at forudse, at disse bare vil indgå aftaler med hinanden i stedet for at prøve at presse citronen og skrabe til sig.. Ja, og al denne snak er jo stort set ligegyldig, for det vil jo være meget sjældent, at der vil være stor forskel på gamle og nye forbrugere af en virksomhed, og hvis der er, jamen så vil det jo kun lige være midlertidigt, må man regne med. Ja, så never mind al denne snak i bund og grund. (11:00) 
Så ja, afkaststørrelsen pr aktiestørrelse, eller rettere aktiestørrelse der udløber, hvis nu kurverne ikke er lineære, skal altså bare bestemmes rimeligt frit af aktionærerne via deres stemmemagt, og det samme gælder alle priserne. "proportionalitetsfaktoren," som jeg har snakket om, hvad der også svarer ret meget til "markup'en," den er altså nu bare en implicit størrelse, som folk selv kan regne ud hver især (idet alle regnskaber skal være offentlige (samt i øvrigt også alt muligt andet i virksomheden, f.eks. også hele beslutningsprocessen, når det kommer til den overordnede ledelse af virksomheden)). Så nu skal kunderne altså bare foholde sig til en enkelt pris, og så kan de selv regne ud, hvad markup'en er på denne. I denne version af idéen tænker jeg så også bare, at aktierne udstedes i slutningen af enhver lille salgsperiode, således at den altså er propertionel med prisen divideres med det samlede salg i den pågældende periode. Det vil sige, at kunderne ikke ved eksakt hvor stor en aktie de får ved købet ned til hvert decimal, men de kan stadig regne det ud tilnærmelsesvist eksakt i de fleste tilfælde, for man må jo formode, at salget vil være rimeligt konstant. Og hvis det lige tager et hop op på et tidspunkt, så vil det jo ikke gøre det vildt store. Det virker altså ikke som om, at det vil være værd at indføre et buffersystem eller tilsvarende, bare for den mikro lille generelle usikkerhed omkring aktiestørrelsen, man får med i købet, slet ikke.. (11:09)
Så det er altså den store nye ændring. Jeg har i øvrigt så også lige nævnt, at virksomhedens regnskaber og ledelses-beslutningsprocess gerne skal være offentlige (for det vil helt klart være det værd fra kundernes synspunkt, frem for den lille makedsfordel det vil kunne være, at holde visse ting hemmelige). Så det vil jeg også fremføre som en del af idéen. Og så har jeg altså nogle nye tanker om, hvordan kundeaktionærerne skal kunne sælge og ikke sælge deres aktier.
Jeg har som sagt fundet på, at kunder jo gerne må kunne sælge deres kundeaktier til andre kunder, i hvert fald så længe en specifik kunde bare ikke kan købe mere en en vis aktiestørrelse i forhold til dennes originale kundeaktie(størrelse), altså den mængde aktier, vedkomne har tilegnet sig via eget forbrug. Hm, jeg skal egentligt lige tænke over, hvad man gør, hvis.. Hm.. (11:14)
(11:24) Hm, der er ingen grund til at give så mange restriktioner. Man kan bare sige, at man altså kun må sælge sine kundeaktier til andre kundeaktionærer, og at enhver kunde ikke må købe en aktie(størrelse), således at deres samlede aktie bliver større end, vi kunne jo sige det dobbelte, af deres nuværende del af deres aktie, som de har tilegnet sig via forbrug. Fordi nykøbte aktier dog godt kan aftage langsommere i størrelsen (f.eks. hvis man bruger en lineær forskrift), så kan man godt komme ud for, at forholdet overstiger det dobbelte i den efterfølgende fremtid, men det er også fint nok; man kan bare sige, at det ikke må overskride det dobbelte i selve handelstidspunktet. Denne forordning bør være tilstrækkelig til at sikre, at folk kan finde købere, hvis de nu gerne vil sælge deres kundeaktier (måske til en anesle lavere end, hvad de er værd), men systemet forhindrer stadigvæk tredjeparter i at komme udefra og opkøbe en majoritet i virksomheden, så denne ryger væk fra kundernes hænder. (Det gør også, at afdøde kunder, kan få "solgt" deres aktier videre (og dette bør man altså sikre sig, at de kan, selvfølgelig ved at deres arvtagere får lov at styre handlen). 
Jeg har vist i øvrigt også en lille note om fissioner, lad mig lige se, og var der så ellers andet, jeg lige skulle nævne?.. (11:34) ..Hm, nogle ændringer i mine planer, men var der ellers andet?.. ..Nej, det var der vist ikke, og ellers kommer jeg i tanke om dem. ..Ah jo, lad mig lige berøre amnet omkring, hvem der er kunder kort.. Virksomheden skal stadig have en beskrivelse og, hvad der er dets "servicer og produkter," og hvad der ikke er, og dette skal det kunne ændre i løbende, men gerne hvor der så er en vetoret, således at enhver stor nok mængde aktionærer (også alt efter hvilken type) kan vetoe enhver ændring. ..Ja. Mere er der sådan set ikke at sige om dette..
Min tanke angående fission var bare, (hvilket jeg også har tænkt på før) at man jo også potentielt set kunne forstille sig virksomhedssplittelser, hvor virksomheden bare dels i flere afdelinger, som administrerer (og har magt over) forskellige ting. Og så kan det så altså stadig være sådan, at kunder, der er mere kunde det ene sted, så vil få mere aktie og stemmemagt hos denne afdeling. Vi kunne altså forestille os en form for "blød fission," hvor den "hårde fission" så altså vil være, at virksomheden skilte sig totalt ad i to (eller flere). Dette er helt klart værd at have med i tankerne, når man skal overveje fissioner. Hm, i øvrigt tror jeg da egentligt sagtens, man bare kan planlægge fissionsreglerne efter at virksomheden er i sving; man behøver vel ikke nødvendigvis at planlægge disse ting fra starten af? Nej, det må man jo ikke behøve, for hvis kunderne har træng og lyst til, at sådanne fissionsregler skal være en realitet, så kan de jo også indføre dem.. Hm tjo, men det kunne dog måske være smart nok, hvis man som startaktionær lovede sine kunder, måske med en kontrakt indblandet, hvis det giver mening.. at man rimeligt hurtigt vil forsøge at udforme gode fissionsregler for virksomheden.. Hm.. ..Tja, det allerførste kd.v.'er på markedet kan jo nok sagtens bare give dette som et løfte (hvis de vil), og når så teknologien bliver mere udviklet, så kan eventuelle nye kd.v.'er jo bare adoptere andres fissionsregler. Og det vil betale sig for en virksomhed (der har udviklingspotentiale) på et tidspunkt at lave sådanne regler, da dette sandsynligvis vil behage den brede kundebase, og dermed vil det sænke risikoen for, at en konkurrent med gode fissionsregler melder sig på banen (hvis vi altså tænker på en virksomhed, hvor startaktionærerne stadig har magt og så overvejer, om det kan betale sig at indføre fissionsregler på et halvtidligt tidspunkt).. Ok. Lad mig bare lade det være det for nu. Og i det dokument, jeg har tænkt mig at skrive nu her i de kommende dage, regner jeg så bare med, at jeg nævner "virksomhedsfission" kun ultrakort, måske bare i en liste over ting, jeg kan uddybe på et senere tidspunkt. Ok. Nu vil jeg så lige opdatere mine "planer" nedenfor.. (11:58)
...(12:13) Nå ja, jeg vil også lige nævne, at der jo er stor forretnings- og investeringsmulighed (for start-aktionærerne), for den positive kunde-feedback, nemlig i form af at kunderne i højere grad vil fravælgekonkurrenter, jo mere de selv er investerede, gør at kd.v.'er vill udkonkurrere ikke-kd.v.'er i samme branche, hvorved der jo vil være et stort vækst- og fortjeneste-potentiale. ..Og denne indsigt, hvis folk kan forstå den, gør også, at idéen vil sælge lidt sig selv, når først bare nogen vil have forstået den (tror jeg, 7, 9, 13). (12:17)

(25.10.22, 16:17) Okay, jeg har nogle nyheder. Nej jeg tror ikke længere, at idéen vil sælge sig selv helt så meget, som jeg ellers sluttede den sidste paragraf af med at sige. Min forretningsbevægelse vil nok i høj grad skulles gennemføres på baggrund af en stor politisk vilje i folk til at opnå de fremtidsudsigter, den handler om at opnå. ..Hm, jeg kan forresten også lige nævne, at jeg nu mener, at det nok kunne være en god idé at gøre, så at kunder i starten er frie til at handle med hvem som helst, og at det så bare er efter et vist tidspunkt, at nye kundeaktier kun må sælges til andre kunder. For det kræver jo, at mængden af kunder (for heri tæller vi jo ikke start-aktionærerne) er stor nok, før at det kan fungere, at de kun må sælge til andre kunder. Jeg mener så stadig, at man kunne gøre det sådan, at ingen kunde må få mere end dobbelt ved tidspunktet af sælget, end hvad denne ville have haft, hvis denne aldrig havde solgt eller købt kundeaktier. Og det skal så i øvrigt siges, at disse restriktioner måske er ret skrappe ift., hvad der måske er nødvendigt, men ja, om ikke andet så tror jeg altså, at de er gode nok, hvis ikke man kan finde på et mildere system, der også stadig klarer ærterne. Nå, det var lidt et sidespring: Det var egentligt ikke med i de 'nyheder,' jeg tænkte på.. ..Ja, for at fortsætte de egentlige nyheder, jeg tænkte på, så tror jeg altså, at forretningsidéen nu skal sælges meget mere på baggrund af den 'gode bevægelse' ligesom, mere end at 'de første kunder også bliver belønnede'.. Og nu tænker jeg så at skrive mine "bright future"-noter om, så at afsnittet om denne idé så mere bare kommer til at sige: Jamen hvis nu det går endnu mere ned ad bakke, jamen så må man jo på et tidspunkt nå et punkt, hvor der bliver grobund for sådan en bevægelse, hvis altså den ikke bare finder god nok grobund med det samme. Så afsnittet bliver så ikke så meget: "Nu skal I se denne sikre plan, som vi kan gå i gang med med det samme," men mere: "Okay, selvom kapitalismen for nogen kan se lidt sort ud pt., så kan det altså ikke gå helt galt; det skal nok gå den rigtige vej overordnet set." Og jeg kan se på, om jeg så vil prøve at vinkle afsnittet mere som et "fix af" kapitalismen eller som et "forsvar for" kapitalismen, det kan godt være, at jeg så vælger det sidste i stedet.. ..Nå, men på en god eftermiddagsgåtur her kom jeg så også på en masse nye ting. Jeg skal faktisk udbygge mit e-demokrati-afsnit en del: Det er ikke nok bare at lægge op til det majoritetsenevælde, som den gør; der kan være meget mere komplicerede og spændende forhold, som gør, at folk gerne vil kunne oprette grupper, hvor de så kan handle med de andre grupper med deres stemmer til diverse ting ("hvis vi stemmer for det og det, så stemmer I for det og det"), og også i øvrigt handle omkring, om gruppen overhovedet vil bakke op om den samlede enhed (hvilket f.eks. kunne være et parti eller et firma), hvis ikke de får sådan og sådan. Så det skal jeg altså også lige skrive om, inkl. at skrive om, at det digitale system skal indrettes, så brugere altså kan oprette disse grupper og sådan. Og noget helt andet er så, at.. Ja, eller der er faktisk tre ting mere, og måske skulle jeg starte med denne i stedet: Jeg har tænkt på, at.. (16:42) ..Hm nå, der gik jeg lige lidt død, så lad mig i stedet starte med: At jeg fik tænkt over, hvad der egentligt lidt er en gammel version af en anden idé (nemlig min "donationskæde-idé"), nemlig at man også kunne igangsætte en bevægelse, hvor folk simpelthen lover dusører for, hvis virksomheder eller organisationer m.m. opnår et eller andet specifikt i fremtiden. ..Nå, nu gik jeg også lidt død i det igen.. Hm, og den tredje ting var så omkring.. Hm, den første/anden ting var bare noget omkring at give de nuværende kunder mere magt, hvilket jeg faktisk tror kan være ret vigtigt især for en Web 2.0--3.0-virksomhed. Hm, men mere er der vel ikke nødvendigvis at sige/nævne om den ting her, så det var én ud af tre.. Og den tredje ting var så.. ..Nå jo, det var at jeg også nu har tænkt mig at hive "forbrugerforeninger" m.m. (også samt hvad jeg lidt har kaldt "civilforeninger" på et tidspunkt) mere i forfronten nu. Jeg kan så skrive om dette, efter jeg har skrevet om e-demokrati og det. Og så kan jeg altså kort gøre rede for, hvad man kan opnå med sådanne "forbruger"-/"civil"-foreninger, eller hvad vi skal kalde dem, og så også at man jo kan gøre brug af et e-demokrati her. I øvrigt kan jeg lige gentage/præcisere, at min idé om "civilforeninger" i høj grad bare handlede om, at man går sammen i grupper til at representere sig som borger og/eller forbruger i et samfund (gerne altså sammen med nogen i en lignende båd), og hvor man så begynder at samarbejde og opføre sig meget som en slags forrestning, både idet man så begynder at lave handler samlet og betale nogen for at stå for at indgå (handels- etc.)aftaler med andre grupper/instanser, og også idet man så begynder at betale folk der kommer med nye smarte idéer til, hvad man kan gøre som gruppe. Hm, det lyder godt nok løst, når jeg skriver det her (og det er lidt blandet sammen med "forbrugerforeninger"), men på den anden side er jeg også ret træt nu, kan jeg mærke, og ja, det er lang tid siden, jeg har tænkt så meget over det, så det skal nok give god mening, når lige jeg får støvet det af.. ..Men ja, så nummer tre ting er altså bare, at jeg også vil skrive om disse forbrugerforeninger, og altså sikkert også "m.m.".. Hm, og lad mig så vende tilbage og skrive om donations-/dusør-idéen på at senere tidspunkt, når jeg er mere frisk i hovedet igen.. (17:06, 25.10.22)
%(26.10.22, 10:58) Okay, jeg har tænkt lidt mere over min nye version af denne dusør-idé, og jo, det er lidt kød på den, men ikke nok til, at jeg vil skrive om det, og måske ingen gang nok til, at jeg vil bruge tid nu på at forklare den. ..Nej, lad mig bare forklare den på et senere tidspunkt ved lejlighed, for idéen er altså ikke så vigtig (den handler bare om, at investorer, der øjner nogle gode fremtidsmuligheder i en idé, men ikke synes investeringsmulighederne/afkastudsigterne er helt gode nok, de kan så bede folk om at søtte idéen ved at udlove dusører, betinget af at idéen går godt og at disse folk vil drage nytte af den; så kan de så love at give lidt retur for dette. (Så ja, ikke den vildt store idé, når man tænker over det..)).. Hm, nu fik jeg faktisk næsten forklaret den her i den parentes.. Og ellers tilføjer idéen bare lidt om, hvordan disse dusørløfter kunne gøres.. men det gider jeg ikke skrive om nu.. Ok. Jeg har så også tænkt mere over nogle af de andre ting, jeg vil skrive om, og nu tror jeg planen er, at skrive en lidt mere simpel version af min business movement-idé, at skrive e-demokrati-sektionen færdig (med de nye tilføjelser), og så også bare lige inkludere et afsnit om forbruger-/civilforeninger, inden jeg når til Web 2.0--3.0-sektionerne (og så videre derfra). Og jeg kan så forklare, at denne idé altså i bund og grund handler om, at gå sammen i store grupper og ansætte agenter til at finde gode tilbud til gruppen og til at finde frem til mulige gavnlige aftaler for gruppen i det hele taget.. (11:08) Ok.. Mere er der vist ikke at sige her. Nu tror jeg så derfor, jeg vil fortsætte skriveriet, hvor jeg så nok lige begynder på en version 2 af "bright future"-dokumentet i øvrigt. (11:09)
(12:34) Okay, nu har jeg godt nok lige tænkt lidt mere, og.. Ja, det korte af det lange er bare, at jeg faktisk virkeligt tror, det kunne blive en stor bevægelse. Nærmere bestemt så skal jeg vist bare lige fokusere på, at det især er detail- (retail på engelsk) forretninger, man nok bør starte med virkeligt at fokusere bevægelsen på. Alle kd.v.'er kan så have et bestemt mærke, som folk kan gå efter. Fordelen er her, at denne branche indeholder mange små virksomheder, og generelt kræver det ikke så meget kapital at starte en butik m.m., og hvis vi tænker butiks\emph{kæder}, så er der også alligevel så mange, så man kunne godt forestille sig at mindst én vil konvertere. Nå ja, og webshops / web stores (det første er muligvis et begreb vi mest bruger Danmark, men det ved jeg ikke helt) er selvfølgig også en rigtigt vigtig mulighed at satse på også. Så herved kan bevægelsen altså starte og begynde at få mere og mere opmærksomhed og kapital til rådighed. Og når man så har fået samlet kapital nok, så kan man så også begynde at brede sig ud til andre brancher, hvis altså ikke der ellers er nogen virksomheder, der har konverteret endnu her. :) Okay, så min idé kan altså muligvis stadig rykke en hel del, selv her i nutiden; det er nok alligevel ikke bare en idé, der ligesom kan være et sikkerhedsnet i fremtiden, den er mere end det.. :) (12:44) 




## Energi, ressourcer, klima

(18.08.22, 13:30) Ja, vi bør helt klart fremelske en slags tang- og/eller vandplante, der kan fungere som en slags hvede (eller lignende), men på havoverfladen. Og hvis vi så kunne opdyrke f.eks. dele af stillehavet, så kunne man jo i teorien få en KÆMPE ny ressource, som kan bruges til alt muligt (energi, føde, og potentielt set også til at grave ned for at indkapsle CO_2, hvis man altså \emph{[virkeligt} får overskud..). Man kunne jo så evt. gøde planterne bare ved at suge næringsholdningt vand op fra dybet. Kunne have potentiale til at blive kæmpe stort, hvis det kan fungere.. 

(08.09.22, 9:57) Kom lige til at tænke på: Gad vide, hvad der ville ske, hvis man bare konstruerede en masse rev i havet, måske bare ved at lægge et netværk a flydende slanger/rør ud eller lignende. Tanken er lidt, at der måske så ville dannes en hel masse tang/alger og måske andet fiskeliv. Og en follow-up-tanke er jo så lige, om man eventuelt så skulle pumpe næringsholdigt vand op og igennem slangerne/rørene.. Jeg tror, jeg vil give dette emne nogle flere tanker i min fritid, og så vende tilbage hertil, hvis jeg skulle få yderligere idéer omkring det, der er værd at nævne. ..Men ja, den helt simple version er disse tanker er bare: Gad vide, om man kunne skabe en masse plantevækst, og vækst i betanden af diverse havdyr, hvis man bare lagde flydende rev ud. Jeg ved jo godt, at alt bliver vildt dyrt at udføre, hvis det skal skaleres meget op, før det får en effekt, men idéen er da nogle flere tanker værd.. (10:05)

(26.12.22, 11:06) Idéen med at køle planeten med "aske" eller lignende er selvfølgelig fundet på, og det er faktisk en rigtig populær idé endda. Den går under navnet "stratospheric aerosol injection," og den virker nemlig faktisk rigtigt lovende (rent teoretisk altså)..:)



## Andre ting, der relaterer sig lidt web- og forretnings-idéer m.m., men som er lidt uden for kategori

(18:28, 27.09.22) Jeg kom til at tænke lidt over, i går eller i forgårs, retsystemer i fremtiden. Jeg vil så bare lige nævne, at jeg jo allerede har skrevet om (i mine 21--22-noter), hvordan man kan få klare fælles etiske retningslinjer i fremtiden i diverse samfund. Og hertil kunne man jo så lige tilføje, at man så også kunne forestille sig et retssystem, som baserer jeg lidt mindre på lovskrifter og deres fortolkninger, men lidt mere på en.. ontologi/model/.. mængde.. af retningslinjer for, hvordan man skal dømme diverse forseelser og andre sager/konflikter osv. Og så kunne man jo naturligvis have et rangsystem af en slags dommere, men hvor hele befolkningen i det samlede samfund ligesom sidder i toppen (i praksis) og som fællesskab så har ret til.. måske hvor forskellige mennesker får ret til forskelligt data.. ret til at udtage stikprøver af under-dommerinstansernes bedømmelser, og hvor man derfor kan rette op på.. Ja og/eller man kan selvfølgelig også bare have et anke-system, som jeg også tænkte på, hvor parterne --- og måske også vedrørende til disse (eller måske bare folk, der har fulgt med i retsagen) --- jo så kan få lov at anke til en højere instans.. Så ja, men den primære pointe er altså, at man kunne forestille sig et alternativ til et lovsystem baseret på en masse paragraffer, hvor man måske i stedet bare havde en stor mængde (hierarkisk ordnede) retningslinjer og eksempler at gå ud fra.. (18:40) 




## Evolutionsspykologi

(18.08.22, 13:35) Jeg tror ikke, jeg har understreget dette i mine 2021-22-noter, men ét punkt, hvor jeg virkeligt tror man kan komme langt med evo.-spyk., er til at analysere og prøve at forstå, hvad der bringer os lykke som mennesker. Jeg tror virkeligt man kan skubbe meget til den analyse, hvis man tager evo.-psyk. godt i betragtning.


## Lykke

(18.08.22, 13:38) Angående lykke, så har jeg også lige nogle flere ting, jeg vil skrive om det emne, men det kan være, at jeg lige udsætter det en gang.. 

(31.08.22, 20:02) Okay, lad mig lige prøve at forklare de her tanker lidt. Jeg havde/har for det første lyst til lige at kommentere noget omkring, hvorfor man bl.a. har så mange glæder som barn (hvis man altså er heldig nok). Ja, der er vel mange mange grunde, men jeg har bare lige lyst til at fremhæve, at man (måske især som drengebarn) kan have en virkeligt stor lyst til eventyr --- i hvert fald til tanken om dem, men man kan alligevel godt på en måde få udlevet sin eventyr lyst (også selvom man ikke rent faktisk tager på et eventyr) via lege og via bøger, tegneserier og film m.m. Jeg kan personligt huske at tanken om et eventyr (og nu tænker jeg faktisk selv meget på One Piece som et eksempel på et "eventyr") bare var "helt oppe og ringe" dengang. Samtidigt havde man også en anden ting som barn, som virkeligt gjorde mange glæder mere tilgængelige: Man blev så nemt awestruck af ting. Jeg kan huske at en af de helt store øjeblikke i mit liv, var da vi fik vores første pokemon (blå) gameboy-spil. Vi var bare Helt oppe at køre, og det var bare sådan en lykke; det var sådan en fed følelse; så spændende. Nå, hvorfor har jeg så lyst til at nævne disse ting (for de er jo rimeligt velkendte)?. Jo, min pointe er så, at vi jo altså lidt kan tabe nogen af disse lykke-givende faktorer --- eller "parametre" kunne man kalde det --- i vores sind, når vi bliver ældre. Eller de dæmpes i hvert fald lidt. Men man kan dog have disse ting for øje, når man skal overveje, hvordan man konstruerer et lykkeligt liv sammen i et fælleskab. Særligt den der awe: man kan gøre mange til for at give ting mere mening.. Ah, jeg kunne også nævne det her med, at gamle ting, man er så nostalgisk omkring (hvis man altså har sådan nogle ting), der er ofte en god grund til, at man synes de var/er så store, og faktisk en ting som ikke nødvendigvis har rent med alder at gøre: Når mange mennesker går og er hypet omkring det samme, f.eks. når et nyt spil (eller en ny bog, eller hvad har vi) udkommer, jamen så ligger der bare så meget mere.. underbevist prestige omkring at klare sig godt i det, og selv for middelmådige spillere vil der stadig bare være.. en følelse af at ting "vejer" meget mere (end hvis man går i gang med samme spil mange år efter, eller nu hvor der er sådan et kæmpe udvalg så ingen spiller det samme (medmindre det er et rigtigt populært og nyt spil)). Det er f.eks. også bl.a. derfor Pokemon GO var så stort, fordi så mange interesserede sig for det, og fordi man derfor blev grebet meget af, at avancere i spillet. Og igen, hvorfor er det her så interessant og nævne i forbindelse med emnet om "lykkelige fælleskaber?" jo, fordi man jo så kan prøve at begrænse adgangen til hobbyer og/eller gøre tiltag for at skabe nogle store "diller" (som det hedder; det er bare ikke vildt tit man bruger det ord mere) løbende, som folk i høj grad kan blive grebet af. Og ja, jeg synes det er interessant, for det er jo en helt anden dimension end bare at sørge for, at man har nogle gode muligheder og nogle gode traditioner (og kreative mennesker til at finde på events): Der er også hele den dimension omkring, at folk også tit skal \emph{gribes} af en lyst til at deltage i en ny dille(/sport / kunstnerrisk/udfoldningsmæssig/literær strømning osv.). Så man skal altså ikke nødvendigvis se på bare at lave gode events som folk kan deltage i; man må også gerne overveje, hvordan man får folk grebet af ting i fælleskab. 
Nå, så det var så ligesom tankerne omkring awe og generel begejstring (som også relaterer sig til, hvad man går og har nostalgifølelse omkring). ..Nå ja, og jeg kan forresten også lige hurtigt nævne, at disse betragtninger altsammen er noget, der kan forklares med evolutionspsykologi (hvis man lige udvikler den gren, så den handler meget mere om at se på, hvordan evolutionsprincippet spiller aktivt og dynamisk ind i vores nutid *(og i vores helt nære fortid osv.), og hvordan vi i høj grad stadig fungerer som skabninger af evolutionen, hvad vi er, *(således at vores følelser og handlinger stadig i høj (men dog ikke fuldstændig) grad kan.. "forklares," eller man kan i hvert fald gøre sig meget mere vis på emnet, ved at se det i lyset af, at vi er formet af evolutionen) i stedet for (*himler og tager hånden op til panden* (for effekt)) at fokusere på, hvordan vi er "fortidsmennesker" med basale instinkter, der ikke længere passer til den morderne verden (*himler*)). Nå, det var et lille sidespring..
Og lad mig så lige prøve at vende tilbage til det med eventyrlyst (hvis der altså er noget her jeg mangler at sige..?).. ..Nej, her er der faktisk ikke så meget at sige, andet end at det er lidt ærgerligt, at vi mister nogle af disse barnlige trænge/lyster.. hvad jeg en gang ofte ville kalde "behov" (og måske også "værdier" nogen gange, det kan jeg ikke lige huske (og gider ikke lige prøve)) (hvilket handlede om, at vi jo fra naturens side har behov, og mange af disse behov er vi så så heldige, at naturen har udviklet en "gulerod" til, således at vi føler lykke, når det lykkes os at opfylde behovet.). Det kan være at vi i fremtiden kan opfinde en terapi eller andet, så man kan forstærke disse "behov," i.e. disse lyster, men indtil da må vi jo bare nyde det imens vi er børn, og så ellers prøve i nogen grad ikke at slippe de "behov"/lyster, når vi bliver ældre. Så ja, det var vist rimeligt meget de tanker (plus lidt sidespring), jeg havde lyst til at nævne/notere. :) (20:50)

(05.09.22, 19:55) Mon ikke jeg har været lidt inde på dette, men lad mig lige nævne, at et rigtigt godt råd, og en rigtig god ting at bestræbe sig på, er: Vær gavmild med komplimenter! Giv dem ofte! Igen: Vi har jo i bund og grund mest bare den glæde, vi får fra andre. Og det giver bare SÅ meget mere lykke, hvis man hele tiden sørger for at sætte udtrykkeligt pris på sine nærmeste --- og komplimenter til alle de ikke-nærmeste er også en god idé at bestræbe sig på at være gavmild med: det bringer alt sammen lykke. Selvfølgelig er det mere og mere vigtigt, jo nærmere folk kommer på en, at give komplimenter (og ros og andre tegn på værdsættelse), men ja, så længe rosen/komplimenterne kan gives oprigtigt, så er der ingen grund til at holde igen med dem. Bare en lille ting, jeg lige ville nævne (måske igen), og som virkeligt kan være værd at leve efter --- det må jeg også selv gøre meget for at huske på. 




## Eksistens

(06.09.22, 10:31) Jeg har i øvrigt også tænkt nogle små tanker omkring, hvis man antager at der er en overordnet skaber-gud. Hvis man bare antager, at han ikke er \emph{uendeligt} potents, men måske bare potent langt ud over, hvad vi kan forestille os, og hvis man også antager at han faktisk er god --- ikke bare sådan god som i: "Åh, hvor er du god, gud! ..Vær nådig ikke at sende mig i helvede og brænde..!" eller som i: "Definition af god er hvad gud er, for gud er den største og bedste,"  men som i at han rent faktisk ønsker så mange sjæle som muligt at opleve så meget lykke (og så lidt ulykke, selvfølgelig, der trækker fra af den samlede lykke) som muligt --- jamen så ville det jo egentligt give god mening, at han ville vælge at bruge sine skaberkræfter på at skabe en afsindig stor mængde af universer, som er nemme at opstille lovene for, og som ikke kræver nogen kræfter at styre, således at han ikke hele tiden skal gå tilbage og passe sine gamle kreationer men hele tiden bare kan fokusere sine kræfter på at skabe flere. Jeg synes dette er ret oplagt at forestille sig, at det ville kræve mere energi, hvis man hele tiden skulle overvåge og indgibe i alle de universer, man har lavet --- især hvis man sætter sig selv den umilge opgave for at sørge for at "intet ondt sker imod gode mennesker"---ja, for så skal han jo endda gå ind og forudsige, hvad der sker, og så skal han jo basalt set "køre simulationen flere gange alligvel, indtil han får det resultat, han ønsker, og det må jo tage mange mange kræfter og meget fokus, relativt til bare at fokusere på at skabe det næste uhyrligt store batch af universer, som skal sættes i gang. ..Hm, der er egentligt også andre antagelser, man kunne tænke over, selvfølgelig er der det, men lad os bare begrænse os til dette her.. Og ja, det skal så understreges, at denne analyse ikke handler om, at konkludere på, hvad der må gælde for sådan en gud. I stedet handler det bare om at forklare, hvorfor det ikke er langt ude i hampen, hvis man gør disse antagelser, at nå til en teori/hypotese, hvor guds ikke-indgriben og tings tilsyneladende tilfældighed faktisk kan forklares ret godt, på trods af guds godhed (for en af antagelserne er jo faktisk, at han \emph{rent faktisk} er \emph{god}, altså i en forstand der passer meget bedre til, hvad vi almindeligvis vil betegne (på trods af at der kan være mindre variationer af, hvad folk ser som 'godhed') som 'godt,' når vi snakker om \emph{menneskers} handlinger). (10:52) ..(10:56) Hm, jeg kom lige i tanke om, at gud pr. den kristne (og jødiske --- og sikkert også den muslimske) tro jo skabte verden på seks/syv dage, så en antagelse om at "uendeligt potent" bare skal ses lidt metaforisk må jo egentligt være ret oplagt.. 

(05.10.22, 15:10) Jeg havde tænkt mig at forberede en lille teaser udgivelse, som jeg vill lægge ud på GitHub her som noget af det første, men nu har jeg lidt fortrudt. Her er mine tanker (noter) nu her fra et andet dokument, jeg skrev i:
\# Existence theory

%Let me begin this introduction/teaser on a small personal note.
%
%When I was younger, in my teens, I was quite interested in 

"How and why was the universe created?" "What constitutes consciousness?" and "how does matter, in particular brains, gain consciousness?" 
These are questions that many people have asked themselves, probably often with the same open-ended conclusion: These questions are perhaps just to big for us "mortals" to answer. 

Indeed this seems to be the case: Even if we found a good answer, how would we ever know whether it is actually correct or not? And furthermore, we might not even be able to understand the correct answer if a god/oracle could tell it to us; it might be too complicated, and it even might include some otherworldly logic that we can never comprehend.

So if we look at the %...(10:44, 05.10.22) Jeg søgte lige lidt på filosofi (har bare læst wiki-artikler), og jeg har lige set, at hypotesen/antagelsen om at "alle mulige verdener eksisterer" også hedder "modal realism." Spændende. Jeg har vist hidtil kun læst om "mathematical universe theory." Der står på wiki-siden, at nogle modstandere mener, at hypotesen er i konflikt med Occam's razor, hvilket jo er rigtigt interessant, for det er den nemlig ikke; det kræver bare lige lidt omtanke og analyse for at komme frem til det resultat. (Og altså også en antagelse om at verdener/universer har en naturlig, fundamental ordning i multiverset, nemlig ud fra, hvilken information de indeholder/bygger på.) ..Lad mig lige læse videre om det, og også omkring de andre emner, der relaterer sig til spørgsmålene ovenfor.. (10:51) ...(11:13) Hm, det virker alligevel til at associationerne omkring "modal realism," inklusiv hovedproponentens egne holdninger, alligevel er for forskellige fra, hvad jeg tænker på. Og nu læser jeg lidt om MUH, og det virker helt klart til, at det passer mine tanker. Jeg skal lige finde ud af, og der er forskel på CUH og så det, der også er nævnt i wiki-artiklen, nemlig MUH eksklusivt med kontruerbare universer, det må jeg lige finde ud af. Men ja, hovedparten af mine tanker lægger sig altså rigtig meget op ad MUH/CUH, og så er det altså muligvis bare mine tanker omkring bevisthed (som muligvis lægger sig op ad "idealism" og/eller "Platonism," *(nej Platon var vist "realist," ser det ud til, som så er det modsatte..) men det skal jeg lige have læst op på igen), og så måske også bare min tilgang med ikke at lede efter \emph{den} rigtige eksistensteori, men i stedet bare forgrene analysen, hver gang man støder på et spørgsmål, der med fornuft både kan antages, i nogen grad, at være sandt eller at være falsk. (11:21) ..Wow! "Virtually all  historically successful theories of physics violate the CUH"!! Helt ærligt. Så svært kan det altså heller ikke være at forstå Gödels ufuldstændighedsprincip..! Det ser ud til, at den originale (hvilket jeg på en måde også kan siges at være, mener jeg, men der var altså andre, der kom først..) opfinder/opdager af teorien tror (som i øvrigt ser ud til selv at foreslå CUH som modsvar på en vis kritik (om så end det ham, der fandt på det først, det fangede jeg ikke lige)), at f.eks. mængdelære og andre matematiske teorier, hvor ufuldstændighedsprincippet gælder, at det ikke har fuldstændige modeller.. Suk suk. Jeg ville ønske at Gödels fuldstandighedsprincip ikke var kommet så meget i skyggen af det andet princip; der virker til at være meget forvirring omkring det.. ..Hm, folk burde bare blive undervist mere i Gödels kontruerbare univers, og i hvad det betyder: at al matematik kan deles op i to mængder: matematik over objekter kontrueret af en endelig mængde information, og matematik over (filosofisk questionable) objekter dannet af uendeligt meget information.. (11:34)
%...(12:11) Hm, jeg tror hellere lige, jeg må summe lidt over, om det overhovedet kan betale sig for mig at tease mine idéer på dette område nu; MUH er jo ret gammel --- den går faktisk mindst helt tilbage til 1998, kan jeg se (jeg troede den var lidt nyere, selvom den jo stadig er ret ny overordnet set).. Og hvis man tager MUH, eller rettere CUH, som afsæt, så vil det måske blive svært for mig, at få mine idéer teaset, så de lyder interessante (altså hvis man kender til CUH i forvejen).. Ja, lad mig summe lidt over det.. (12:15)
%... (14:56) Ja, jeg er bange for, at der ikke bliver nok kød på det til ligesom at tease det.. Det er for inviklet at forklare, hvad jeg tror, jeg kan bidrage med til emnet. ..Det kan nok ikke rigtigt gøres kortfattet særligt godt. Og ift. at jeg jo havde tænkt mig primært bare at fortælle den lille hurtige redegørelse for, hvorfor man med meget normale antagelser (udbredt blandt ateister og lignende især) hurtigt kommer frem til, at vi så i bund og grund lever uendeligt og i alle afskygninger, nemlig i og med at der så også vil findes alle (og man kan i princippet blive ved med at zoome ind) mellemtrin imellem to forskellige personligheder og tilhørende liv ("oplevelse," i.e.), så vi dermed i praksis alle er den samme, bare i forskellige udgaver. Og jo, mange af mellemtrinene er vildt usandsynlige, men selv "vildt usandsynlig" er forekommer stadig groteskt "ofte" sat op i mod "uendelighed." Og budskabet er jo så, at vi alle er den samme i praksis, og at alt vi gør mod andre mennesker, det bliver så gjort mod os selv i et fremtidigt liv, i praksis, altså.. Men ja, selvom dette resultat ikke behøver så meget teori i forvejen, så føler jeg stadig, at det er altså bart i sig selv til, at det giver mening at tease/forklare det. Hvis det kunne være en del af en teaser til "eksistensteori" generelt, så ville det give god mening, men jeg tror ikke, det vil blive modtaget med meget begejstring, hvis det bare står helt alene.. ..Også fordi, hvis man skal være lidt streng ved sig selv, så kan det jo i bund og grund reduceres bare til at sige: "hey, har I tænkt over, at multiversets uendelighed vil medføre, at alle afskygninger af "liv"/"oplevelser" vil førekomme?" Og det vil sgu nok ikke skabe særligt mange bølger i sig selv.. (15:07) ..Så ja, jeg venter med at udgive (og brygge videre på) mine eksistenstanker (som jeg dog stadig tror virkeligt kan noget, \emph{selvom} meget af det jo dog er tæt på noget kendt)..
slut. 
Så ja, som sagt, jeg føler altså, at jeg virkeligt har noget at byde på, men jeg tror ikke jeg kan finde på noget kortfattet, der kan skabe meget interesse i sig selv.. (15:13)
... (17:13) Åh, jeg kan også lige nævne, at min intension var efter "Indeed this seems to be the case ..." paragrafen (i readme-filen) så at lægge op til: Men hvad med at droppe målet om at finde \emph{det} korrekte svar, men i stedet bare prøve at overveje/analysere (gerne i fællesskab, btw), det samlede træ, ligesom, over de mulige svar der kan være til de grundlæggende spørgsmål. (Og her jeg jeg i øvrigt lige nævne, at der dog ikke bare vil være ét træ, for man kan godt stille spørgsmålene i forskellige rækkefølger, hvor analysen godt kan have karakter heraf. Særligt kan det vist være betydende hvilket spørgsmål (eller hvilke få spørgsmål), man starter med. Jeg mener dog stadig, at det ikke er sådan, at vi så skal analysere en hel skov af træer på en gang; jeg tror på, at det nok bare bliver en lille gruppe af træer, der vil være interessante for de fleste..) (17:19) 



(05.01.23, 11:33) Jeg har nogle tilføjelser til dette emne, og så har jeg også nogle idéer til, hvordan jeg nok vil strukturere en artikel om det. Lad mig se.. I virkeligheden har jeg nok skrevet meget af det før. ..Hm, jeg tror lidt, at jeg har en ny måde at tænke på det mulige fænomen med at Oplevelser bliver vagt til live, hvor jeg altså nu tænker meget, at man nærmest kan sige, at det er [...] At man nærmest kan sige, at det er "universet" --- og her snakker vi altså om det idealistiske univers: et univers der beskriver Oplevelser (hvilket også bare kan være hele multiverset selv) --- der oplever Oplevelserne. Og ja, mine yndlingsteorier har multiverset som selve dét (eneste) idealistiske univers, så jeg fortolker det altså nu meget som at "multiverset oplever Oplevelserne." (Og da en af mine klart yndlingsteorier nu er den hvor multiverset "udregner" al logik, og at Eksistens dermed ligesom er den fundamentale logik om alt, der så at sige udleder sig selv (eller rettere alle "sætninger" i logikken), så ser jeg det altså meget sådan at "multiverset udleder alle Oplevelser, og dermed også udlever/oplever dem"). [...] Nå, men dette var jo en lidt mindre ting. 

En større ting er så, at jeg er gået lidt væk fra at forestille mig den fundamentale logik som et sprog; altså som noget med en syntaks eller tilsvarende. Nu tænker jeg altså mere, at den fundamentale Logik ligesom er "rent semantisk." ..Vi kunne snakke om "Pure Reasoning".. "Pure ..." Hm.. ..Ja, "pure and fundamental logical reasoning." Og denne opfattelse betyder faktisk rigtigt meget, for det gør det nemlig pludselig meget nemmere at forestille sig, at der bare er én "fundamental logik for alt." ..Så ja, det er altså derfor, at jeg nu hælder rigtigt meget til, at multiverset ligesom bare er en fundamental og "ren" "logik," der forstår mere og mere "af sig selv," så at sige, og dermed også forstår, hvordan diverse forskellige sammenhængende Oplevelser må føles, og idet "den" forstår dette, så vil den også opleve disse Oplevelser, enten netop idet den forstår det, eller for alt tid igen og igen efter den ("den") har forstået det. (Så altså med andre ord: Enten sker udlevnigen af Oplevelserne på kanten af den forståelses-kulge/-mængde, der udvider sig mere og mere, eller også sker udlevningen konstant indenfor kuglen/mængden (hvor der så bare kommer flere og flere Oplevelser til denne mængde).) 

...Nå, og nu kunne jeg så fortsætte med at sammenligne "den fundamentale logik" i denne teori med, hvad man næsten kunne kalde en gud (og den sammenligning er hurtig at lave), men nu vil jeg i stedet prøve at følge den struktur, jeg har i tankerne for en artikel om det. Jeg forestiller mig nemlig at starte med at liste nogle gode kandidater til Eksistens-teorier, hvoraf den ene så skal være den, jeg lige har beskrevet (som egentligt er to teorier, alt efter om Oplevelserne udleves på kanten eller inden i kuglen/mængden af Oplevelser).

Hm, så lad mig prøve at skrive, hvad den første sektion i den artikel kunne indeholde.. (12:56)

Nå ja, jeg skal jo starte med at redegøre for hypotesen om, at "alt hvad der kan eksistere, eksisterer." Med andre ord er hypotesen, at der er en komplet symmetri ift. hvad der kan eksistere, og hvad der rent faktisk eksisterer af denne mængde; hvis ét univers eller ét delmultivers indeholder nogle specifikke "valg," jamen så må der bare eksistere modsvarende universer/delmultiverser i lige mængde. Men denne tanke leder så til at spørge: Hvordan defineres den underliggende teori for det samlede multivers så, for for at man kan afgøre, at multiverset er symmetrisk eller ej, så må man jo have et udgangspunkt for at definere, hvad der er symmetrisk og ikke symmetrik --- hvad vil det sige, at et univers er "modsvarende" til et andet univers for eksempel? Ja, og svaret på det er... Ej, det var bare for sjov; det kan vi selvfølgelig ikke svare på. Men vi kan hypotisere, at der kunne finde en fundamental "teori" for multiverset, selvom "teori" dog i så fald vil være et dårligt ord at bruge for det, fordi det indebærer, at der findes andre teorier. Så lad os hellere kalde det "en fundamental logik for alt," og her skal "logik" altså ikke forstås som en formel logik, men i en meget mere løs forstand, nemlig som det fundamentale koncept om, at visse ting kan være sande og visse ting kan være falske, og ting kan følge logisk af andre ting. Så lad os hypotisere, at der eksisterer en fundamental logik under den samlede eksistens, for hvad er alternativet? At der ikke er en samlet eksistens? At der ikke er nogen "logik" (i ordets meget løse forstand) bag? Nej, det går ikke rigtigt, så det virker som et fornuftigt aksiom. Og lad os forresten også bare benævne den samlede eksistens for 'multiverset,' da det er lettere at sige. (Og så må man bare endeligt ikke antage, at 'multiverset' består af en mængde af universer i den forstand som 'universer' ofte betegner, nemlig en samling love, noget rum og noget tid. Lad os endeligt ikke antage, at det er den eneste form for selvstændige eksistenser, der findes.) ..Hm, faktisk tror jeg, jeg vil bruge et nyt begreb om.. Hm, eller..?.. ..Nå, det vender jeg tilbage til. Men, hvad dælen beskriver denne fundamentale logik så? Ja, det er så her det store spørgsmål virkeligt ligger. Hvad beskriver den fundamentale logik? Den kunne f.eks. beskrive objekter, så som strygejern, computere, jordkloder og hele universer, og så ville vores princip om, at "alt hvad der kan eksistere, må eksistere (i symmetrisk forhold)," føre til at alle "ting" eksisterer. Så det vil særligt sige, at alle mulige universer må eksistere. Jamen det lyder da meget godt, især hvis man er materialist i forhold til spørgsmålet om bevidsthed. Men selv da kunne man så også spørge, eksistere strygejern virkeligt side om side og på lige fod med hele universer? Er multiverset ikke bare en samling af universer? I så fald må man jo hypotisere, at den samlede fundametale logik om alt har en særlig "klausul" om, at det der kan eksisterer, er "universer," hvordan man så lige skal definere det begreb helt præcist. Nå, men det er detaljer: Overordnet set har vi altså bare en mulighed for, at genstandene for eksistens i multiverset --- med andre ord de ting, der kan eksistere --- er, ja, "ting." "Genstande." Fysiske objekter med andre ord, og muligvis altså yderligere begrænset til kun at indebære, hvad vi kan tænke på som 'universer' i en ret gængs forstand af ordet (altså samlinger af love, materie, rum og tid). Der er dog også en anden vigtig mulighed, især hvis man mere er såkaldt idealist frem for materialist, og der er, at genstandene for eksistens i multiverset er: Bevidste (sammenhængende) oplevelser. I denne hypotese er universerne i multiverset altså ikke en samling af rum, tid, materie og tilhørende love for, hvordan dette forløber, men af bevidste oplevelser (jeg vil skrive Oplevelser med stort fra nu af), der så også har nogle love for, hvordan de forløber. Da sanseinput er en stor del af Oplevelser, så vil sådanne Oplevelser jo også skulle indeholde beskrivelser/"love" for, hvad der sanses i Oplevelsen, og disse "love" kan jo så indebære de fysiske love i vores universer. Så hvis vi tænker på vores eget univers, så er der tydeligvis nogle love for, hvordan objekter bevæger sig og udvikler sig i tid. Med den.. objektorienterede hypotese om genstandene for eksistens, så vil disse love være "indskrevet" i multiverset direkte om objekterne, hvorimod i den bevidstheds-/Oplevelse-orienterede hypotese, der findes de samme love også for et univers, men de hører så i stedet bare ind under, hvor jeg-personen/erne oplever. To sider af samme sag. Ingen af os kan empirisk afgøre, om vores univers har love, der tager udgangspunkt i objekter eller om det tager udgangspunkt i de bevidste oplevelser i det. Hardcore materialister vil nok hælde mest til, at universer er orienteret omkring love, da disse per definition ikke ser noget problem i, at bevidste oplevelser bare opstår af sig selv, men alle os andre, der synes, at der ligger noget mærkeligt i tanken om, at bevidste oplevelser bare kan opstå af genstandes bevægelser (og denne forundring bliver kun forstærket, når man dykker grundigt ned i kvantemekanikkens verden, skulle jeg hilse og sige) *(Det skal så dog siges, at jeg hele mit liv selv har hældt mest til materialisme, selvom jeg kunne se nogle store spørgsmål ved det, som er svære at svare på, og at jeg først opdagede det elegante ved idealismen (som jeg slet ikke vidste, det hed på det tidspunkt) der i sommeren 2019, hvor jeg pludselig fik en række åbenbaringer om dette emne, bl.a. også omkring hvad der så svarer til den eksisterende teori om CUH.), jamen vi vil naturligvis være så meget mere desto åbne over for et oplevelse-/bevidsthedsorienteret multivers, fordi dette løser hele den problematik automatisk: I et oplevelseorienteret multivers skal oplevelserne ikke opstå fra noget andet, men i stedet er de der fra starten af, og man kan så nærmere sige, at objekter "opstår" ud fra dem (fordi objekterne altså så kun eksisterer i det omfang, at de bliver oplevet af en bevidsthed). (13:42)

Man kan så selvfølgelig også hypotisere, at multiverset har begge ting som genstand for eksistens, fysiske objekter og bevidste oplevelser, og så vil det så bare være spørgsmålet, om man er materialist eller ej, der afgør om førstnævnte så også fører bevidste oplevelser med sig indirekte eller ej.

Okay, så det var en ret vigtig og grundlæggende opdeling i mulighederne ved, hvad den fundamentale logik om alt har som genstand for, hvad kan eksistere i det samlede multivers. Et andet vigtigt spørgsmål omhandler så subjekterne for Oplevelserne. (13:46) ...(14:10) Hvem (eller hvad) er jeg-personerne i fortællingen med andre ord. En hardcore materialist tror som bekendt ikke på, at der er en sjæl som er genstand for de oplevelser, som objekterne producerer, og en sådan vil derfor nok sige, at der simpelthen ikke er nogen.. hm, vi kunne sige, at der ikke er noget "modul," der indgår i oplevelsesskabelsen, som oplever Oplevelsen; en oplevelse oplever bare sig selv. Hm, jeg vil meget nødigt kalde disse moduler for "sjæle," for vi har desværre nogle associationer til dette begreb, der er uhensigtsmæssige i visse sammenhænge (altså med visse hypoteseantagelser).. ..Hm, lad os kalde det en "oplevergenstand" her.. ..Nej, et "oplevelsessubjekt." Ok. Nå, og det er så slet ikke kun materialister, der kan have denne opfattelse. I hypotesen, hvor den fundamentale logik beskriver Oplevelser som genstande for eksistens er det jo også ret unødvendigt at have eksistensen af en helt trejde ting, nemlig et oplevelsessubjekt, for at Oplevelserne kan udleves. En måske mere naturlig opfattelse (det synes jeg i hvert fald) er nok, at det bare ligesom er multiverset selv, der udgør det samlede "opevelsessubjekt," og at alle eksisterende oplevelser derfor bare opleves af.. ja, af muliverset, eller af den "fundamentale logik for alt," kunne man også tolke det som. Men der findes altså også en mellemvej, hvor at multiverset indeholder mere end ét oplevelsessubjekt, som vi altså ofte kan tænke på som "sjæle" (men ikke i alle henseender). Og hvis multiverset indeholder en samling (meget vel en uendelig samling) OS'er.. Hm, lad mig bare kalde det Subjekter med stort S fra nu af.. Hvis multiverset indeholder sådan en samling Subjekter, så afhænger det så af, hvorvidt multiverset er oplevelses- eller objektorienteret (eller en blanding), om hvert Subjekt så tilknytter sig en Oplevelse i multiverset, eller om de tilknytter sig en "hjerne" (lad mig skrive Hjerne fra nu af), som altså skal forstås i en meget bred forstand af ordet (maskiner kan f.eks. også være Hjerner, og det kan alt muligt andet også (medmindre man specifikt begrænser sin hypotese for multiverset herom)), i et specifikt fysisk univers af objekter. I denne todelte hypotese vil vores oplevelser altså hver især være et produkt af, at der "sidder" et specifik Subjekt et eller andet "sted" i multiverset --- enten i et abstrakt rum eller i et fysisk rum, muligvis lige oven i din Hjerne, som den oplever fra (i hvilket tilfælde "Subjekt" netop bliver helt ækvivalent med vores normale forståelse af begrebet "sjæl") --- og er så i færd med at opleve, det vi oplever ligenu, og nærmere bestemt er vi hver især det Subjekt og den er os. Vi skal senere diskutere noget mere om, hvad dette betyder for os. Men lad os bare her påpege, at det sjove ved denne hypotese, hvis vi kan sige det sådan, er, at hvis man har to universer, der indeholder samme Hjerne med same tidsudvikling, eller hvis man i et oplevelsesorienteret multivers har to oplevelser, der i en vis periode er helt identiske med hinanden, så vil helt den samme personlighed, med de samme tanker og helt den samme selvforståelse, opleves af to forskellige entiteter.. Tja, det kan man jo sige alligevel.. Nå, men.. Ja, lad mig bare lige nævne her i stedet, at lige netop denne (todelte) hypotese kan føre til, at man kan bekymre sig om døden, for hvad skal der så ske med ens "sjæl" (ens Subjekt) bagefter? Dette problem har materialisterne og idealisterne, der tror på at alle Oplevelser udleves af et stort samlet Subjekt (som man meget vel kunne tænke på som multiverset selv), ikke; for dem er to identiske (del-)oplevelser, der udleves i multiverset, også identiske i forhold til, hvad de betyder for den samlede mængde af oplevelser, nemlig fordi der ikke i disse hypoteser vil findes nogen skjult variabel, så at sige, der afgør om Oplevelsen i givet fald opleves af det ene eller det andet Subjekt i multiverset. For dem, eller rettere for os, for jeg er selv idealist med tro på ét samlet Subjekt) er alle oplevelser ligeværdige, for vi vil så mene, at vores egen nuværende oplevelse er en del af ét samlet hele, og at vi altså ligeså meget er en del af alle andre Oplevelser i multiverset, som den Oplevelse, vi selv føler at vi lever lige nu (hvad "nu" så end betyder helt præcist, men det kommer vi til).

Nå, og nu fik jeg så lige akkurat teaset den næste store opdeling, man kan have i hypotesen for multiverset, og det er nemlig i forhold til, om der findes en form for en global tid eller ej. (14:47) ...For materialister er det meget naturligt at antage, hvis ikke en global tid for det samlede multivers, så i det mindste lokal tid for hvert enkle univers --- ja, det er nærmest uundgåeligt. Og herfra er der så ikke meget i vejen for videre at antage, at der også er en global tid. For de idealistiske hypoteser er spørgsmålet derimod en smule mere indviklet. Her er der nemlig ikke et behov for "tid" andet end som noget, der er subjektivt for hver Oplevelse. En oplevelsesorienteret multivershypotese kan således godt bare antage, at "tid" er et rent subjektivt begreb, og at alle Oplvelser (hvad end de bliver oplevet af individuelle, adskildte Subjekter eller af et stort samlet Subjekt) bare er, og at de via deres væren (som altså så er konstant så at sige, i og med der ikke findes nogen egentlig tid (eller måske bare ikke en "tid" som svarer til, hvad vi normalt forstår ved begrebet)) bare resulterer i at de ligesom konstant udlever sig selv, så at sige, eller bliver udlevet af de Subjekter, der har knyttet sig til dem. Dette er faktisk ret dejligt, for konceptet om Tid kan også i sig selv godt virke lidt mærkeligt, lidt ligesom da vi snakkede om, at konceptet om, at bevidsthed skulle opstå af genstandes bevægelser, også kan virke mærkeligt. Så det er dejligt, at der findes Eksistens-hypoteser, hvor tid er et rent "subjektivt" fænomen, så at sige. Nå, men idealistiske hypoteser kan nu også godt indeholde koncepter om tid. For eksempel kunne man have en specifik idealistisk hypotese, der sagde at alle oplevelser udleves samtidigt i multiverset --- enten af et stort samlet Subjekt eller af adskilte, individuelle Subjekter hver især --- og at den globale Tid i multiverset så dermed bare måles i den subjektive tid som hver Oplevelse har. Med andre ord kunne man fortolke dette som, at multiverset indeholder en (uendelig) række af Oplevelser, som multiverset, hvis vi personificerer dette i denne metafor, så ligesom "trykker play på" i Tidens begyndelse, og så kører de ellers hver især samtidigt i henhold til deres subjektive tidsopfattelse. En anden mulighed kan være, at der til hver Oplevelse også er tilknyttet en vis "regnekraft" så at sige, og at man metaforisk set så kan sammenligne hver af de "afspilne" Oplevelser som en slags computer, der regner på, hvordan Oplevelsen forløber. En oplevelse, der foregår i et stort univers med meget materie i og med "regnetunge" fysiske love, vil så "afspilles" langsommere end en oplevelse, der foregår i et mindre "regnetungt" univers. (I øvrigt kunne man også have den hypotese, når det kommer til at objektorienteret univers: Her kunne man også stille alle universerne på række og så sige, at den globale tid ikke svarer til de lokale tider, men i stedet afhænger af, hvor "mange udregner skal klares," så at sige.) Disse tanker svarer altså til en antagelse om at den fundamentale logik ligesom skal bruge tid på at udregne sig selv, og så at sige opdage flere og flere sandheder om sig selv, hvilket, når vi siger det på den måde (og ikke snakker om det, som om hvert univers/Oplevelse udregnes af en computer), så lyder det jo faktisk pludselig slet ikke helt så dumt. Og med den grundlæggende fortolkning, så hører dette faktisk også med til min egen yndlingshypotese, nemlig at den fundamentale logik om alt ligesom fra Tidens begyndelse opdager flere og flere sætninger om sig selv, og at det er i takt med, at den opdager (og nu tillader vi os altså lige at personificere den her) disse sætninger, så udlever den så også de Oplevelser, som sætningerne omhandler. *(Det skal dog siges, at jeg også synes rigtigt godt om flere andre hypoteser.) Nå, men det vender vi tilbage til. Ellers skulle man ikke tro, at denne forskel gør så meget, nemlig om den globale Tid, hvis der er en, afhænger af "udrengernes" kompleksitet eller ej, men faktisk så giver det meget muligt en forskel i den samlede 'prior'-sandsynlighed, som det hedder. Som et sjovt lille eksempel på dette, så kan man faktisk teoretisere omkring, om det faktum, at vores univers er relativistisk, måske ligesom kunne skyldes, at det hermed så faktisk kan have uendelig størrelse, uden at det er uendeligt komplekst at "regne på"/"simulere," fordi man i et relativistisk univers kan tillade sig at regne på/simulere alt ved at starte i et enkelt punkt og så regne på alt med udgangspunkt i en lyskegle derfra. Hermed bliver et uendeligt tung simulering faktisk til en endelig tung simulering. Man kunne også nævne mange andre sjove ting i denne sammenhæng, men lad os bare stoppe her, for det er lidt et sidespor ift. det overordnede tema her. (15:37)

Nå, det næste man så kunne tage fat på, det er så sprøgsmålet, hvis vi specifikt snakker de oplevelsesorienterede multivershypoteser, og det er hvordan.. hm, hvordan de beskrives, men det bør næsten komme i et helt nyt afsnit, for nu bevæger vi os så videre til noget helt nyt, og det er at fundere over, ..ja, over "strukturen" af den fundamentale logik så at sige.. Hm, det er lidt en stor mundfuld, men jeg tror muligvis, der er en god, hurtig vej igennem det, så lad mig lige tænke mig om først... (15:42) ..(Okay, men hjerne skal også lige bruge en god pause, tror jeg...) (15:47) ...(16:02) Ah jo, jeg tror godt nogenlunde, jeg ved, hvad jeg vil sige.. ..Ja.. Men jeg synes næsten, emnet fortjener, at jeg skriver det færdigt i morgen, når jeg er mere frisk igen --- hvilket jeg i øvrigt godt tror, jeg kan; de næste "afsnit" behøver nok ikke at blive så lange..:) 

(06.01.23, 11:45) Okay, det var rigtigt godt, at jeg lige tog aftnen til at tænke mere over emnet, for nu kom jeg i tanke om nogle andre vigtige ting. I forbindelse med de objektorienterede multivershypoteser, så fik jeg kun snakket om genstande/objekter og universer, og fik så også snakket om Subjekter, altså hvad vi nærmest kan tænke på som en slags "sjæle," selvom der dog følger flere antagelser med, hvis vi kalder det 'sjæle,' som vi ikke ønsker at antage om Subjekter. Men ja, jeg fik jo så udeladt den mulighed, at det kun er Subjekter, der eksisterer, og at fysiske universer og objekter bare er noget som de ligesom "tænker frem," så at sige. Sådanne hypoteser indeholder jo også de hypoteser, der siger at multiverset består af en mængde guder, som hver især står for at skabe fysiske universer, samt udleve de tilhørende oplevelser i de universer. Så altså også en rigtig vigtig gruppe af hypoteser at få med. Og i sidste ende bør det også nævnes, at når vi kommer til at antage, at "alt hvad der kan eksistere i den fundamentale logik, gør det," så får vi jo faktisk et samlet multivers hvor en "logik" ligesom skaber ting spontant. Aha, men kunne man så ikke også i stedet forestille sig et multivers af flere end én "logik," hvor hver "logik" hver især så skaber universer/delmultiverser og skaber og udlever de tilhørende Oplevelser (..eller skaber Subjekter, som så udlever dem)? Jo, det kunne man selvfølgelig godt, men i så fald så falder disse hypoteser jo faktisk sammen med de hypoteser, der siger at Subjekter er de fundamentale genstande for eksistens.. Nå nej, ikke helt, vent lidt.. ..Hm, hvis vi ser på hypoteserne, hvor en fundamental logik skaber alt og også udelver alt selv, og hvor der altså ikke er individuelle adskildte Subjekter, men hvor alt opleves af multiverset/"logikken" selv.. Hvis vi tager de hypoteser og omdanner dem, så der nu er flere "logikker" i stedet, så svarer denne mængde af hypoteser ret meget til.. Nej, den indgår i mængden af hypoteser, hvor kun Subjekter er genstande for eksistens, nemlig hvis man tillader sig at bruge en bred definition af, hvad Subjekter kan være (og hvorfor ikke, for det er et super abstrakt begreb i forvejen), således at det også inkluderer "logikker." Hm, og hvad så med de hypoteser, hvor den fundamentale logik også skaber individuelle Subjekter, der er adskildt fra alt andet..? ..Tjo, men her kunne man udvide.. Tja, never mind, det er også lige meget; lad os bare inkludere den mulighed som en selvstændig ting, og lad os bare notere os, at det under visse antagelser også kan svare til en gruppe af hypoteser som hører til den mængde, hvor Subjekter er de fundamentale genstande for eksistens (altså de hypoteser, hvor "guder" (hvis man fortolker dem sådan) er de fundamentale genstande for eksistens, nemlig fordi man her kan omfortolke "logikkerne" til at være det samme som "guder;" at en "gud" er en "logik"). 

Okay, så det var rigtig godt lige at få de former for mulige hypoteser med. 

Nu kommer vi så til at tale om, hvad man så får ud af at antage at "alt hvad der kan eksistere, eksisterer" ovenpå de beskrevne hypoteser om, hvad kan eksistere. Og dette bliver så faktisk et relativt kort afsnit, for det korte af det lange er, at det ville kræve en forståelse af, hvordan den fundamentale logik om alt er.. "struktureret"/"ordnet," før man ville kunne sige noget præcist om vores univers-/Oplevelse-prior-sandsynligheder (og her må man altså lige læse lidt sandsynlighedsregning og statistik for at forstå, hvad menes med 'prior-sandsynligheder'). Og det kan vi jo aldrig komme til. Men! Vi kan teoretisere os frem til nogle ting, bl.a., og dette er rigtigt vigtigt, at man med nogle ordninger vil opnå det, der (desværre allerede er opfundet af en anden;)) kaldes 'Mathematical Universe Hypothesis' (MUH), eller hvis man skal være mere præcis (for selv ham, der postulerede idéen er vist gået over til at fokusere på følgende også): 'Computable Universe Hypothesis' (CUH). Begge teorier (altså teorierne omhandlende hypoteserne) handler så om, at man ved at antage, at alt hvad der kan beskrives i en (ordnet) matematisk teori eksisterer, faktisk nok for en høj frekvens af ikke-kaotiske universer som vores eget i multiverset. (Mere specifikt en høj frekvens af universer, som kan beskrives med relativt lidt information.) Og CUH præciserer så bare og siger: Vi er ligeglade med ikke-konstruerbare matematiske objekter (og hvorfor skulle nogen også kære sig om dem, andet som en filosofisk beskæftigelse? (jeg er matematisk konstruktivist, kan man høre)). 

Men for at nå CUH, så kræver det altså, at der er en vis ordning i den fundamentale logik, samt en ordning i.. ja, i hvilken rækkefølge at Oplevelserne bliver udlevet (men hvor man dog godt i princippet kan have, at et endeligt antal Oplevelser kan udleves på én gang). I mange hypoteser kan dette skabe nogle store problemer. Men det gode er så, at man altid kan sige, at, jamen, bare fordi vi med vores jordlige (er det et ord?..) matematik ikke har mulighed for at definere et fornuftigt sandsynlighedsrum, hvis ikke alle Oplevelser i multiverset er ordnet på en vis måde, så er det jo ikke ensbetydende med, at multiverset ikke selv kan.. ja.. se ud på en fornuftig måde. ..Bare fordi vi vil opnå logiske paradokser, hvis vi prøver at tildele sandsynligheder til noget, der er udvalgt fra en uendelig mænge, så betyder det ikke at multiverset behøver at indeholde paradokser, hvis det nu f.eks. indebærer, at uendeligt mange Oplevelser udleves "samtidigt" --- eller hvis de udleves i rækkefølge, forresten, med hvor prior-sandsynlighederne bare aldrig konvergerer.. Så ja, selv hvis man ikke lige kan finde, eller ikke lige synes om de hypoteser, hvor alle Oplevelser er ordnet pænt, så betyder det ikke at multiverset ikke godt kan følge de hypoteser, uden at det bryder sammen. Vi kan så selv pålægge nogle antagelser til de hypoteser, der får prior-sandsynlighederne til at konvergere alligevel, og her er det så bestemt værd at nævne, at man herved alt andet end lige sikkert også vil komme frem til CUH i sidste ende. 

Der er dog også et problem til den anden side, og det er, at nogle hypoteser fører til et komplet kaotisk univers. Disse problemer er dog helt anderledes, for der kan man bare sige, at fordi vores eget univers/vores egen Oplevelse ikke er komplet kaotisk, så må man forkaste de hypoteser, der siger, at det/den/de bør være det. Dette forklares nemmest, hvis vi ser på et eksempel. ...(13:04) Hvis vi ser på et idealistisk multivers, hvor det er (bevidste) Oplevelser, der er genstand for eksistens, så er det betydende for Oplevelsernes prior-sandsynlighed, hvordan Oplevelserne er "beskrevet" i den fundamentale logik, så at sige. Hvis en signifikant delmængde af alle Oplevelser er beskrevet med udgangspunkt i en Hjerne, hvor man altså ser på de fysiske bevægesler i en Hjerne (som dog med idealistiske antagelser kun eksisterer i kraft af den bevidste Oplevelse og ikke omvendt), og hvor Oplevelsens forløb så afhænger af disse bevægelser.. Hvis en signifikant delmænge af Oplevelserne i multiverset er beskrevet på den måde, så vil vi ikke opnå komplet kaos i multiverset, og hypotesen kan således ikke forkastes. Men hvis vi i stedet antager til vores hypotese, at alle Oplevelser i multiverset er beskrevet lidt som et slags computerprogram, hvor hver linje beskriver en ny følelse i rækken, som Oplevelserne følger, så vil der jo herved blive komplet koas, når man så antager (\emph{hvis} man altså antager), at "alt hvad kan eksistere, eksisterer." Så ville der være 0 orden i alle Oplevelser og alt ville være koas og tilfældigt. Enhvert udsnit af en Oplevelse, hvor denne indebærer en følelse af orden, vil så med al sandsynlighed hurtigt erstattes af noget komplet kaotisk igen. Og selv hvis man prøver at pålægge, at kun Oplevelser, hvor der er en sammenhængende selvforståelse, der gennemgår Oplevelsen, er gyldige, så vil dette stadig ikke kunne forklare, hvorfor vores omgivelser ikke går amok omkring os. Så alle sådanne hypoteser kan vi altså udelukke.

Dette er i øvrigt også interessant i en anden henseende, for nogle af modargumenterne mod materialisme går bl.a. ud på, hvis vi forestiller os.. Ja, der findes en vis xkcd, hvor en mand går i en ørken og flytter sten for at simulere vores univers. ..To sek.. ..Nummer 505, A Bunch of Rocks, hedder den. Så kan man så spørge, hvad ville der ske, hvis han gjorde det to gange? Hvad ville der ske, hvis han gjorde det to steder samtidigt, måske forskudt med en lille tidsforskel eller ej? Og slutteligt, hvad hvis han bare havde to sten hvert sted, som han mere eller mindre flyttede samtidigt? Nå ja, og helt slutteligt, hvad hvis det i stedet var bunker af sand, han flyttede rundt på, måske endda hvor nogle sandkorn faldt fra og nogle kom til i bunkerne, når han flyttede dem. Disse spørgsmål klarer de Oplevelses-orienterede multivershypoteser jo nemt, hvor der definerer hver Oplevelse jo bare selv, som en del af dens "naturlove," hvordan dens Hjerne defineres, samt hvordan denne bevæger sig og udvikler sig i tid. Hm, jeg kan dog nævne, at jeg lige her i går kom til at tænke på, at man måske kunne slippe af sted hvs man prøvede at definere en materialistisk hypotese, hvor man gør brug af entropi og koncepter om, hvad definerer information, hvornår information er unikt, og.. ja, og ting i den stil, men hvem ved? måske løber man bare ind i andre paradokser/svære spørgsmål herved.. Anyway, det jeg egentligt ville hen til, det var at jeg kan huske, at vi på et tidspunkt snakkede om dette i forbindelse med VT (videnskabsteori og etik (for fysikere)) på fysik, hvor en af mine venner fra fysik sagde, at han så (vist nok; sådan husker jeg det i hvert fald) troede på, at to identiske.. ja, "Hjerner" med identisk udvikling bare producerer netop én bevidst Oplevelse i multiverset. Elegant svar. Men nu kan jeg jo så se, at der faktisk er et stort problem med dette svar, for medmindre vi begrænser multiverset til noget meget endeligt, så vil alle mulige Hjerner jo forekomme, hvilket vil sige at alle mulige Oplevelser, der afviger fra hinanden vil forekomme netop én gang i multiverset/den samlede Eksistens. Men dette vil jo derfor medføre en komplet kaotisk prior-sadsynlighed for alle Oplevelser, og denne hypotese går derfor faktisk ikke, interessant nok. (13:46)

(15:10) Hov, jeg har også helt haft glemt noget andet virkeligt vigtigt. Når jeg har skrevet om de objektorienterede/materialistiske hypoteser ovenfor, så har det måske lydt som om, at materialismen har nogle ting, den ikke kan forklare, som Oplevelsesorienterede hypoteser kan forklare, men sådan er det nu slet ikke. Jeg synes personligt, at de Oplevelses-orienterede hypoteser gør det en anelse mere elegant, men det er bare en personlig holdning. For hvis vi nu starter med at se på den her hypotese, som jeg beskrev, med at hver Oplevelse har i/med sig en beskrivelse af/nogle love for, hvordan Oplevelsen starter og udviler sig i tid, eksempelvis ved at definere en Hjerne (muligvis sammen med en større samling af objekter, som Hjernen er en del af, nemlig et fysisk univers) samt nogle love for, hvordan bevægelsen af information i den Hjerne (hvor 'Hjerne' altså er et fuldstændigt abstrakt begreb, og kan endda indebære et helt univers f.eks.) fører til en (eller flere) bevidst(e) oplevelser, så kan man i de objektorienterede hypoteser jo i stedet bare have nogle love, ved siden af lovene der beskriver, hvordan materie i universet bevæger og udvikler sig, som så beskriver, hvordan bevidste oplevelser kan opstå ud fra disse fysiske genstande. Hvis vi så tænker på xkcd-eksemplet (A Bunch of Rocks), så kunne der altså bare være nogle universer, hvor to af hver sten vil føre til to adskildte Oplevelser, nogle hvor de kun vil føre til én, osv (men hvor alle de fysiske love måske er de samme, og hvor startkonfigurationen af universet også er det samme; bare hvor lovene for de resulterende Oplevelser produceret af den fysiske materie er forskellige). Så ja, det kan sagtens lade sig gøre at give et klart svar på, hvorfor fysiske objekter kan føre til bevidsthed i et ellers overvejende objektorienteret multivers, og som altså ikke bare antager hardcore materialisme og siger: "jamen det sker bare helt automatisk, nemlig at når man har en fysisk Hjerne et sted, der kan have en bevidst oplevelse, så har den det også." Men ja, jeg synes så dog, at de Oplevelses-orienterede hypoteser klarer denne del mere elegant, end de overvejende objektorienterede multiversehypoteser, hvor man så indfører Oplevelses-love oveni, ved siden af de "fysiske love" i de indeholdte universer. (15:29)

Okay, nu når vi så til et afsnit, hvor jeg bare lige siger et par ting om, hvilke af de hypoteser, vi har set på, som jeg selv synes er ret nice, og som jeg tror mange sikkert vil kunne finde fornuftige i større eller mindre grad, og derefter kommer så det sidste afsnit, hvor vi ser på konsekvenserne ift. multiversets Subjekter (du og jeg og vi), og også på nogle pointer omkring moral.

Lad mig starte med at pointere, at en hypotese, hvor der er én grundlæggende (og "ren") logik om alt, og hvor alt så forekommer i takt med at denne logik ligesom "opdager flere og flere sætninger om sig selv," så at sige, og dermed også forstår hvordan flere og flere samlede oplevelser må føles.. At denne hypotese faktisk muligvis kunne give et matematisk regnestykke for prioren, ikke som vi kan finde frem til nøjagtigt, selvfølgelig, men hvor vi kan sige, at dette regnestykke faktisk på fornuftig vis godt kunne indeholde en ordning af alle Oplevelser, således at vi faktisk (med vores "jordlige" matematik) ville kunne tillægge en prior-sandsynlighed til hver Oplevelse i princippet. Lad mig prøve at omformulere dette.. ..Det er ikke ufornuftigt med en sådan hypotese, at teoretisere, at multiverset i princippet kunne indeholde en orden, en rækkefølge, kunne vi også sige, hvor alle Oplevelser (og jeg kan som man måske kan gætte sig til godt lide at antage, at hver Oplevelse er endelig --- det er i hvert fald en god antagelse, hvis man gerne vil nå frem til, at der må være en i princippet udregnelig prior i multiverset på denne måde..).. hvor alle Oplevelser udleves mere eller mindre én efter hinanden. Okay, kan jeg sige dette endnu mere klart..? ..Whatever, måske er dette underemne bare for komplekst, således at vi må gemme det til endnu senere (og at jeg altså ikke vil tale så meget om det i min første artikel om emnet). Men det korte af det lange er bare, at jeg altså tror, at der findes hypoteser, der (i hver fald for mig, og sikkert for mange) lyder ret fornuftige, og som kan føre til en fornuftig antagelse om, at multiverset har en pæn ordning af alle dets Oplevelser (også selvom rækken er uendelig), som gør at man matematisk (vores vores "jordlige" matematik) kan tillægge en prior-sandsynlighed til hvert univers/hver Oplevelse. Ok. Jeg vil ikke sige meget mere om, hvorfor jeg tror dette, men jeg bliver dog nødt til lige at nævne her, at jeg i går kom lidt i tvivl om fornuften ved dette, for hvordan skal en stor, samlet, "Ren" logik om alt lige vægte forholdet imellem, hvor lang tid sætninger "tager" at udlede (altså hvor mange logiske skridt, der går til udledningen), og hvor meget information sætningerne indeholder, når de skal ordnes. Nu ved jeg godt jeg "vrøvler" igen, så lad mig lige se på, om ikke jeg kan omformulere dette mere klart..  ..Hm, jo: Hvis vi ordner alle matematiske sætninger i en teori, f.eks. mængdelære, ud fra, hvor mange logiske skridt det tager for at udlede dem, så går det ikke ift., hvad vi ønsker a opnå, for så vil der (så vidt jeg lige kan se) blive uendeligt mange sætninger i hver (skridtantal-)kasse. Men hvis man så til gengæld indfører, at det også koster nogle skridt at læse lange sætninger, f.eks. hvis man har en lang antecedent som skal sammenlignes med en vist sætning i et modus ponens-skridt --- ret meget som om det foregik på en Turing-maskine (eller anden maskine), jamen så vil der pludselig blive endeligt mange sætninger i hver (skridtantal-)kasse. Problemet bliver så, at dette giver noget arbitrært til den "Rene" fundamentale logik, men ja.. Hm.. ..Okay, lad mig bare stoppe her, for det bliver hurtigt vildt kompliceret.. ..Det næste man så kunne tage hul på, det er at sige: "jamen hvad så hvis der så bare er en undelig mængde af fundamentale logikker," hvorved hver "logik" så kan tildeles en matematisk veldefineret prior for dets Oplevelserne, men så render man så bare ind i spørgsmålet: "Hvad hjælper det at der er lokale eldefinerede prior-sandsynligheder for hver 'logik,' hvis de samlede Oplvelser i multiverset, når man sætter det hele sammen, så stadig giver en svært-definerbar samlet prior for hver Oplevelse".. ..Hm.. ..Hm, måske skal man bare give op på, at få en matematisk veldefineret prior (ikke at vi nogensinde ville kunne regne den ud alligevel). I så fald kan man dog godt måske sige, at hypotesen, som jeg beskrev her lige ovenfor, nemlig med en helt fundamental "logik," der ligesom udleder (og "forstår"/"føler"/"oplever") sætninger omkring sig selv, "kommer tæt på," hvis det giver mening.. Det synes jeg i hvert fald lidt det gør..

Nå, men ellers har vi altså ogå bare rigtigt mange andre gode kandidater, må man sige. Jeg kan personligt faktisk også rigtigt godt lide den, hvor det ligesom er en masse "logikker"/"guder," der ikke har et mål med deres tankevirksomhed, og nok ikke har en selvbevidsthed på samme måde som, hvad vi forstår ved selvbevidsthed, som bare fremtænker universer, nærmest som en konsekvens af, hvad man kunne kalde en simpel nysgærrighed --- eller hvis man tænker mere "logikker" frem for "guder," så bare fordi at, jamen det er bare det fundamentale logikker gør; udvikler sig selv og "opdager" (og oplever) sætninger i sig selv. ..Og i sidste ende, så kan jeg egentligt også ok godt lide den hypotese, der bare siger: Alle mulige "objekter" eksisterer, og så forholder det sig i øvrigt bare sådan, at 'objekter' ikke bare indebærer dumme genstande, der flyver rundt og passer sig selv, men at 'objekter' i vores multivers også kan indeholde nogle definitioner af Oplevelser, som så bliver udlevet, enten ved at multiverset indeholder Subjekter samt nogle love for, hvordan disse Subjekter kan opleve ting, eller fordi der i hvert univers simpelthen bare er plads til, at der ved siden af de fysiske love også står nogle love, der simpelthen bare definerer, hvornår og hvordan diverse Oplevelser bliver udlevet i universet (altså et sæt love, som vi nærmest kunne kalde "sjæle-love"). En todelt objektorienteret multivershypotese, som også bestemt lyder ret fornuftig i mine ører, selvom jeg dog selv hælder mere til de første, jeg har nævnt her, som ikke er ligeså "objektorienterede." 

Ok. Jeg synes, vi slap nogenlunde godt igennem det. Så når vi til det sidste afsit, som i høj grad handler om spørgsmålet: Hvordan skal vi forholde os til "døden?" (Ikke at vi vil besvare dette spørgsmål eksakt, men det er altså i høj grad temaet for afsnittet.) Og et andet spørgsmål for afsnittet er også: Hvordan skal vi forholde os til moralspørgsmålet. (16:16)

Det korte af det lange, hvis vi snakker omkring "døden," det er at langt de fleste af de hypoteser, inklusiv alle dem, der garanteret er/vil være mest udbredte hos folk, er at, hvad vi normalt betegner som "døden" ikke rigtigt har nogen betydning. For hvis multiverset er uendeligt, så vil vi leve igen og igen og igen i alle mulige afskygninger af os selv, og dette gælder så f.eks. både hvis man er hardcore eller semi-materialist, eller hvis man tror at ens eget Subjekt, som jeg har kaldt det ovenfor, ikke er fundamentalt adskildt fra andre Subjekter i universet, men bare er en del af det store hele, hvad end "det store hele" så er en "gud" eller en "logik" for ens univers. Så hvis man altså ikke er tilbøjelig til at tro, at vi har en "sjæl," jamen så når man den konklusion (at vi skal leve alle afskygninger af vores liv --- og af alle andres liv, men det kommer jeg til om lidt), og hvis man tror på, at vi har en slags sjæl, men at den sjæl enten bare er en del af Gud (eller en del af noget andet meget grundlæggende i universet og/eller multiverset som helhed), eller at vi returnerer og blive en del af Gud efter døden, og således også blandes sammen med alle andre nuæevende sjæle, jamen så når man også samme konklusion. I sidstnævnte tilfælde (især hvis man også forestiller sig at der er en global Tid i multiverset --- eller bare en lokal til, som den lokale "gud" eller "logik" også følger) så vil det jo nemlig være naturligt videre at antage, at når en ny person fødes i universet, jamen så tages der lidt af "Gud" igen til at danne en sjæl igen, og således vil ens nuværende sjæl altså fordeles ud på alle andre personer/Oplevelser, som leves efter en selv. Og medmindre Gud/"logikken" der foresager det univers, vi lever i, er utroligt begrænset, så vil der være mange universer, som dette væsen foresager, og der vil altså aldrig ophøre med at være liv. Jeg tror allerede disse antagelser dækker, hvad rigtig mange mennesker ville synes giver god mening. En anden antagelse, som ikke har så meget med "alt hvad der kan eksistere, eksisterer"-hypotesen at gøre, men som måske også ville være udbredt hos folk, det er at sige: Multiverset er faktisk ret begrænset, men jeg tror på en Gud, og at man sjæl når op til ham og bliver passet på ham efter døden. Og ja, denne antagelse gør jo selvsagt også frygten for døden ret irrelevant --- ja, medmindre man i stedet tror på, at man skal i helvede, men det er nu nok de færreste, der slås for alvor med den tanke, for hvis man er en person, der tager den tanke seriøst om sit eget "efterliv," så vil man nok bare prøve at leve mere fromt og så håbe på det bedste. Så ja, det virker virkeligt ikke som om, at nogle af de hypoteser, der nok vil være mest udbredte hos folk, vil føre til andet end, at man ikke behøver at frygte dødens komme. Nu mangler jeg så bare lige at forklare mere om, hvorfor at vi ikke bare skal lave alle afskygninger af vores egne liv men også alle andres med de første hypoteser nævnt i denne paragraf, og så mangler jeg også at dykke ned i de få hypoteser, der antager "alt hvad der kan eksistere, eksisterer"-hypotesen, men hvor man stadig kan være urolig for "efterlivet".. Nå ja, og så mangler jeg også lige at sige: Der vil måske også være nogle få helt- eller semi-materialister, som af en eller anden grund tror på, at multiverset er ret begrænset. Men hvis bare multiverset indeholder universer som vores, og hvis det nu indeholder bare ét unvers, som bliver ved med at Big Crunch'e og udvide sig igen i en uendelighed, jamen så er det også med al sandsynlighed det vi lever i *(og alle andre døende universer vil med al sandsynlighed allerede være døde for en fantasilliard år siden), og så vil vi dermed også leve igen i alle afskygninger. (16:42)

Ok, nu til den der pointe om, at vi ikke bare skal leve "vores eget liv" i alle afskygninger, men også alle andres, og det er simpelthen fordi, at hvis vi antager at multiverset er uendeligt, så vil hver eneste mulige liv man kan forestille sig (og også sikkert vildt mange, som vi ikke kan forestille os;)) forekomme, nogle bare med virkelig lav frekvens i forhold til andre. Så hvis vi opstiller to liv overfor hinanden, så vil vi kunne finde udgaver af liv midt imellem de to liv på en kontinuer linje, hvor hvert liv vi plotter ind på linjen har en vis større eller mindre frekvens ift. hvor ofter det forekommer i multiverset. Og vi kan sågar finde uendeligt mange forbindelser på denne måde mellem to liv. Hvis man så spørger, hvad hvis den ene er en mand og den anden en kvinde, hvad hvis de bor på to forskellige planeter, hvad hvis de er af to helt forskellige arter (f.eks. hvis den ene eller de begge er en eller anden alien)? Jamen selv i alle disse tilfælde vil man kunne finde en glidende overgang, hvis altså man bare dykker dybt nok ned og tager fra de lavfrekvente livsforekomster i multiverset. Og målt op mod uendeligt vil selv ufatteligt lav frekvente livsforekomster forekomme, ja, uendeligt mange gange. Så på den måde indebærer "alle afskygninger af vores eget liv" simpelthen bare "alle afskygninger af mulige liv." 

Og hvis man altså dermed tror på, at multiverset ikke er begrænset, men er uendeligt ift. dets muligheder og dets forekomster, så når man altså ret nemt til, at "vi skal leve alle afskygninger af vores eget og alle andres liv igen og igen." Dette er dog medmindre man altså antager nogle ret specifikke ting, nemlig: At vi har en sjæl hver især, som er adskilte fra hinanden, og som aldrig smelter sammen igen på noget tidspunkt. At disse sjæle af en eller anden mærkelig grund også oveni købet er dødelige --- eller at de bare ligesom lever den samme meget begrænsede mængde liv igen og igen. Hvis man mener nogle af disse ting, så når man altså ikke nødvendigvis den konklusion. Jeg tror dog, at førstnævnte udgave, nemlig at vi alle har for altid adskildte sjæle, som dog er dødelige, vil være vildt sjælden at finde hos folk. At ens sjæl f.eks. lever det samme liv igen og igen, enten helt uden eller måske med nogle få variationer, den vil måske være lidt mere udbredt, men på den anden side kun slem, hvis man har haft et ligefremt dårligt liv. Men selv da, så vil mange nok hælde til den version, hvor der dog sker nogle få variationer gang på gang, og hvis man så dykker ned hypotesen herfra, så vil mange nok ende med at erkende, at hvis dette sker i al uendelighed, så vil variantionerne også ende med at blive uendeligt store, og så når man samme konklusion igen. Det kan man om ikke andet håbe *(at folk vil erkende, altså).

Men ja, så det korte af det lange er altså, at hvis man tænker i dybden over multiversets afgrænsning, eller nærmere bestemt mangel på afgrænsning, så vil de fleste nok kunne blive ret afklaret med døden heraf. (Ikke at de fleste ikke allerede er afklaret med døden, men der findes dog alligevel også mange der frygter den på nuværende tidspunkt). 

Og så kan vi så slutte af med spørgsmålet om moral *(hov, jeg mener 'etik,' rettere), for det smukke ved disse teorier er, at når man når omtalte konklusion med at vi skal leve alle afskygninger af alle liv igen og igen, jamen så når man dermed også frem til en utrolig bogstavelig udgave af "what comes around goes around." Man udvisker altså herved helt forskellen på, hvad en filosofisk egoist vil mene er korrekt etik, og hvad en utilitarist (eller andre etikker, der fremhæver altruisme og "godhed") vil mene! Jeg vil altså påstå, at man, uanset hvordan man vender og drejer det (stort set), når frem til en etik der siger: Lev dit liv som om, at alt hvad du foresager af godt og ondt med andre (inklusiv andre arter og livsformer), det vil du selv opleve (med rollerne byttet om) i et efterfølgende liv, og bak om om at andre i dit samfund bør følge den samme etik. Og svaret på, hvorfor denne etik bør følges, er så både, at, jamen, dette er en god etik at følge for et samfund, men også at, jamen, antagelsen i den etiksætningen er sikkert også sand for all intends and purposes. ..Kortere sagt kan man sige: Lev dit liv ud fra en antagelse om, at du og alle andre skal leve hinandens liv i lige forhold i alle jeres efterliv.

Det skal så lige siges, at nogen vil pege på fri vijle og sige, at jamen, bare fordi jeg med min frie vilje gør skade/ondt på en anden person, jamen så betyder det ikke, at den/en anden person vil gøre skade/ondt på mig i efterlivet i de udgaver, hvor rollerne er byttet om. Denne opfattelse fordrer, at man tror at ens handlinger ikke kan forklares alene ved hjernens fysiske bevægelser, men at sjælen på en måde også sidder der med en slags joystick i overført betydning og påvirker, hvad hjernen gør. Hm, tja, det har jeg vel egentligt ikke så meget at sige til, når det kommer til stykket, for det er muligvis så langt væk fra min egen opfattelse af, hvordan virkeligheden fungerer, at jeg nok aldrig har tænkt så meget på at argumentere omkring de antagelser.. Hm.. Oh well, lad mig så bare slutte for nu, og så lade den diskussion stå åbent.. ..Hm, ah øv, den holdning kunne godt gå hen at blive problematisk, når det kommer til at enes om etiksprørgsmålet.. ..Hm, og måske også når det kommer til at trøste folk, der har levet et direkte dårligt liv, og er bekymret for, hvis de skal gøre det igen og igen i al uendelighed.. Hm.. Nå, men jeg lader det være for nu. I de ovenstående noter har jeg bare antaget, at alle Subjekter bare oplever deres Oplevelser, og at Subjekterne altså ikke selv går ind og påvirker de Hjerner, de har tilknyttet sig.. Hm, men det er da egentligt en hypotese-mængde, der er værd at have med også. Ja, ok. Så når jeg på et tidspunkt skriver dette som en artikel, så må jeg lige huske, at inkludere sådanne hypoteser også, og så må jeg også lige sørger for inden da at tænke lidt mere over, hvad man så kan sige om døden og om etik, hvis man antager sådanne hypoteser.

Men slut for nu.:) Det var rigtigt dejligt lige at få gennemgået det hele i en nogenlunde sammenhængende tekst, for jeg tror at alle mine tidligere noter omkring emnet alt i alt har været ret usammenhængede. Så rigtigt dejligt lige at få gået det hele (eller rettere det meste af det) igennem igen i store træk --- og dejligt også at få tænkt nogle nye tanker omkring emnet!:) Og jeg tror altså umiddelbart godt, jeg kunne skrive denne gannemgang her om, så det kunne blive en god lille (eller knap så lille, alt efter hvor kortfattet jeg kan gøre det..) artikel. Det vil jeg se frem til.:) (17:36, 06.01.23)

(07.01.23, 9:13) Okay, der er lige nogle få ting, jeg skal huske at nævne også, og så mangler jeg også at diskutere den mulighed, at vi har dødelige "sjæle"/Subjekter noget mere. Lad mig lige starte med at uddybe, at i de Oplevelse-orienterede hypoteser er hvert "univers" i multiverset ikke et fysisk univers, men et idealistisk univers, der indeholder én eller flere Subjekter, der udlever en eller flere Oplevelser. Jeg mener endda, at det mest oplagte for sådanne hypoteser bare er at have ét univers pr. Oplevelse. Men så skal det altså ikke forstås sådan, at vi er.. alene om at være bevidst i vores fysiske univers --- jo, det er vi på en måde, for det fysiske univers findes kun i kraft af vores egen Oplevelses eksistens i så fald, og ikke af personer omkring os, men man skal så huske på (og dette er så selvfølgelig antaget, at "sjælen"/Subjektet ikke har indflydelse på Oplevelsen, og at hver Oplevelse der fastlagt ud fra nogle love, ligesom også jeg har antaget i resten af denne tekst), at alt hvad man gør i ens "eget" univers så bare bliver spejlet i et tilsvarende univers, hvor "sjælen"/Subjektet har tilknyttet sig en anden hjerne (med lille 'h,' fordi vi her snakker om vores egne "kød-hjerner"). Det var det første, jeg lige ville uddybe.

Det næste, jeg vil uddybe handler om hvordan Oplevelser mon kan defineres i hypotesen. Her kan vi starte med at se på en sjov lille idé om, at alle Oplevelser kunne være meget korte, altså i subjektiv tid, og at vores egen opfattelse af en lang, sammenhængende Oplevelse bare er.. ja.. er subjektivt skabt.. Men nej, vi kan faktisk forkaste sådanne hypoteser, eller i hvert fald givet den indledende antagelse om at "alt hvad kan eksistere, eksisterer," for så vil en vilkårlig sammenhængende Oplevelse jo ikke behøve at følge nogen lovsætninger rigtigt. For eksempel kunne vi have en sammenhængende oplevelse af, at en person træder ud af en dør og med det samme kommer ind ad en helt anden dør; oplevelser der isoleret set måske følger nogle lovmæssigheder, men ikke når man sætter dem sammen. Alt ville derfor blive totalt kaotisk (sandsynlighedsmæssigt), mere eller mindre, og derfor kan vi altså forkaste det. Ok. Så Oplevelser i sådanne Oplevelse-orienterede multivershypoteser skal altså være længerevarende. Men hvor lang tid skal de så vare? Jo, det ville jo være underligt, hvis de alle var en meget specifik længde; hvorfor skulle det store samlede multivers være så specifik? Så de tre eneste fornuftige muligheder er nok bare, at de enten er uendelige alle sammen, at de er endelige men med vilkårlige længder, og som den tredje mulighed at der både findes uendelige og endelige Oplevelser. Nu er det så oplagt at spørge: Jamen slutter en Oplevelse ikke bare ved døden, mere specifikt altså når den pågældende Hjerne ikke længere opfylder de krav der skal gælde for den (pr. de love som "universet" (som i dette specifikke tilfælde er defineret som led i definitionen af Oplevelsen) påskriver)? Tjo, det kunne de sikkert sagtens gøre i mange tilfælde. Men man kunne også sagtens forestille sig, at Oplevelsens/"universets" definition af den iboende Hjerne tillader, at Oplevelsen kan hoppe fra fysisk hjerne/Hjerne til en anden fysisk hjerne/Hjerne. Desuden kunne man også have Oplevelser, der bare simpelthen er sammensatte, i den forstand at de er defineret med en "lovtekst" noget i retning af: "Først skal du hoppe sådan og sådan fra fysisk hjerne/Hjerne i det her fysiske univers for så og så lang tid (eller indtil det og det sker), og efter det skal du så leve i det og det fysiske univers (med de og de fysiske love) og hoppe sådan og sådan fra Hjerne til Hjerne indtil sådan og sådan, og efter det..." På den måde kan man altså definere nogle oplevelser, der er virkeligt lange. Og både hvad angår endelige og uendelige Oplevelser kunne man endda have definitioner, der definerede hver del-Oplevelse i sekvensen ud fra en mere abtrakt formel (eller (Turing-)maskine-starttilstand, eller hvad man nu kan tænke sig), og så iterere over alle de individuelle udgaver som følger den formel (eller hvad man tænker sig). Og hermed kan man så nå nogle virkeligt lange Oplevelser. Og hvis vi videre tillader, at Oplevelsernes definitioner også kan sige noget så som: "Gentag disse iterationer et antal gange lig Grahams tal" (eller TREE(3) eller TREE(TREE(3)) og hvad vi ellers kan finde på), jamen så kan man have (bogstavelig talt) helt ufatteligt lange Oplevelser. Ok. Hertil skal det så pointeres, at hvis vi antager at, "alt hvad kan eksistere, eksisterer," og hvis vi kan danne vilkårligt lange af sådan nogle Oplevelses-beskrivelser, jamen hvis vi så prøver at spå om, hvor lang vores egen Oplevelse-beskrivelse må være, så vil vi jo ikke kunne sige andet end: Dens længde må i gennemsnit være uendeligt. Det virker vildt, men det er faktisk konsekvensen.. Nå, og nu er det så her teorien om CUH kommer ind, for hvis man så overvejer hvilke nogle del-Oplevelser (altså dem med en nogenlunde konstant selvforståelse), der må være flest af i sådan en uendelig mængde af Oplevelser med vilkårligt lange beskrivelser, jamen så kommer man vist rimeligt nemt frem til (tror jeg/mener jeg), at de del-Oplevelser med tilsyneladende relativt lav information vil være mere frekvente.. Tja, eller det giver faktisk lidt sig selv: Der vil være en høj frekvens af del-Oplevelser, hvor det iagtagende univers tilsyneladende følger ret simple principper. Så det er altså sådan, at CUH kommer ind i billedet, når vi snakker Oplevelses-orienterede multiverser. *(Der er kan være lidt forskel på, hvad (prior-)sandsynlighedsfordelingen er i forskellige Oplevelse-orienterede hypoteser, eksempelvis afhængende af hvorvidt multiverset ordner Oplevelser og udlever dem ud fra, hvad der svarer til en "regnekraft" og sådan. Men det er nu ikke fordi, vi alligevel kan regne os frem til den faktiske sandsynlighedsfordeling overhovedet. Så for os behøver vi bare at vide, at vi nok får noget, der svarer til CUH, hvilket det vil gøre hvis det opfører sig pænt, og altså ikke giver os komplet kaos, som vi har set på.)

Nå, og nu kan jeg så slutteligt vende tilbage til den mulighed, at multiverset indeholder endelige ("dødelige") Oplevelser, og hvad det bør betyde for vores tilgang til døden. Og det korte af det lange her er så bare, at hvis der både er endelige og uendelige Oplevelser, jamen så vil der med al sandsynlighed, for dig der læser dette, allerede været gået en fantasiliard år (altså TREE(TREE(TREE(...))) år; find selv på hvor mange TREE der skal stå i rækken) og størstedelen af alle endelige Oplevelser vil allerede være døde, og du vil med al sandsynlighed være en af de uendelige. Og faktisk kan man næsten sige noget tilsavarende, når det kommer til de hypoteser, der kun indeholder endeligt varende Oplevelser. ..Tja, eller det afhænger godt nok af den specifikke hypotese, men under antagelse af at Oplevelsers levetider godt kan være defineret ud fra koncepter så som TREE(TREE(...)) osv., så vil de afsindigt lange Oplevelser også lynhurtigt.. tja, det var et forkert ord at bruge, men set i forhold til uendeligt, så jo, så vil det "lynhurtigt" blive kun dem, der er tilbage. Og ikke nok med det, de vil også veje utroligt meget mere end alle de knap så lange Oplevelser. Hvis man f.eks. ser specifikt på antallet af gange, hvor et Subjekt spørger sig selv (eller rettere har oplevelsen af at spørge sig selv): "Hvor lang mon min Subjektive levetid er endnu?" Hvis vi ser på statestikken omkring det antal for hver Oplevelse, så stort set alle.. nej, basalt set alle (som i: alle for all intents and purposes) forekomster af disse spørgsmål findes i Oplevelser, der er længere end T=TREE(TREE(...)) tid, efter vi den globale tid er lig TREE(TREE(...)). Altså når det globale ur slår TREE(TREE(...)), så vil forekomsten af alle sådanne spørgsmål til sig selv have fundet sted på ligeledes langvarige (eller længere) Oplevelser. Ok, dette er sikkert vrøvl for mange, og desuden så har jeg også her antaget, at der findes en global tid, eller i det mindste at der findes noget der svarer til en sådan. ..Okay, lad mig bare sige det sådan her: Hver gang et Subjekt spørger sig selv (eller rettere har oplevelsen af at spørge sig selv): "hvor lang mon min Subjektive tid har varet indtil nu?" så vil denne tid i gennemsnit være uendeligt (så i praksis, når vi spørger os selv, så vil svaret være: så ufattelig stor at du ikke vil kunne skelne det fra uendeligt). Og når man så spørger: "hvor lang mon min Subjektive levetid er endnu?" så vil svaret være det samme. Forklaringen på, at jeg mener at dette er tilfældet, den er lidt indviklet, og den kræver også lige nogle antagelser, må jeg indrømme, men under rimelige antagelser når man altså ret nemt hen til det samme svar: Hvis alle Oplevelser er dødelige, så vil alle korte og mellemlange Oplevelser "lynhurtigt" dø ud, når man opvejer dem mod uendeligt, og kun de ektremt lange (ja faktisk ufatteligt lange) Oplevelser vil være tilbage, hvilket vil sige at du selv, i det øjeblik du læser dette, i så fald så med al sandsynlighed vil tilhøre mængden af de ufatteligt lange Oplevelser. Okay, så er det vist godt med det for nu.xD^^ 

Det var, hvad jeg havde at tilføje om dette emne.:) (10:31, 07.01.23)







## Blockchain

(31.08.22, 10:25) Jeg havde egentligt lidt tænkt mig alligevel at udgive min angrebsvektor (med tilhørende forsvar) hurtigt på min GitHub, men jeg tænkte lidt over det i går, og det er lige før, at jeg faktisk ikke gør det alligvel; ikke i nogen stor fart.. Jeg kan lige tænke lidt mere over det, men jeg tror faktisk ikke helt, der er kød nok på.. tjo, tja, jeg ved det ikke; jeg skal nok lige tænke lidt mere over det. Men umiddelbart tænker jeg altså ikke at bekymre mig om at skynde mig at få det ud.. 
(02.09.22, 11:01) Nej, jeg tror simpelthen ikke der rigtigt er noget guf på denne idé. Så ja, alle mine blockchain-tanker er nu ret meget ude af vinduet.. Selvfølgelig vil jeg dele idéen om angrebet på et tidspunkt, men jeg tror altså ikke rigtigt, den kan få nogen til at spærre øjnene op (og være vildt interesseret, i.e.).. 


*((18.09.22, 11:51) Okay, glem stort set alt, hvad jeg har skrevet her i går:)
(17.09.22, 12:27) Jeg havde en ret vild (som i 'ude af normen'; ikke vild som i ' fest-vild') nat, hvor jeg gik i seng lidt efter tolv og så var vågen helt til omkring seks. I lang tid kunne jeg bare ikke sove (selvom jeg ikke synes, jeg gjorde noget som helt galt, eller havde det for varmt/koldt; det eneste jeg kan tænke på var, at jeg måske var en lille smule sulten, men kun en meget lille smule og ikke noget, jeg synes forstyrrede mig!..), men på et tidspunkt begyndte jeg også at tænke lidt over fysik, så lidt om mine "planer" (jævnfør sektionen nedenfor), og så fik jeg så også tænkt på blockchain, hvor jeg mellem fem og seks synes jeg fik et hel væld af gode idéer.. Så ja, dem vel jeg så skrive om her (og genoverveje dem)..:).. 
..Hm, lad mig bare prøve at forklare, og så kan jeg overveje imens:
..Hm, eller lad mig egentligt lige starte med at skrive om, at jeg i første omgang fik nogle tanker, hvor jeg bare tænkte: ah, måske kan jeg alligevel godt skrive om blockchain (og mit angreb) i min GitHub-mappe, hvis jeg bare indleder den grundlæggende del af det/hovedparten med at sige, at det altså bare er et argument, hvorfor en kryptovaluta (KV) ikke kan overtage og blive en meget almindelig valuta på lige fod med normale penge. Så fik jeg tænkt på, at pointen i sig selv om, at et angreb kan være mere attraktivt at udføre, fordi man nemt kan ende med ikke at skulle betale alle de mønter, man satte på højkant i replay-angrebet, jo er en vigtig pointe i sig selv, som er værd at dele.. Nå, og der ved femtiden (måske lidt efter; måske tyve over) kom jeg så til at tænke på, at man jo faktisk ingen gang behøver at sætte penge på højkant, i bund og grund, fordi man bare kan forke og lave en gren, hvor man har (brugte!) penge, og så sætte dem på "højkant." I løbet af den næste halve time derfra (omkring tyve over fem altså) fik jeg så en masse gode supplerende idéer (nogen af dem, som jeg har fået før i andre sammenhænge), nemlig om at man jo kan snyde med tiden og dermed sørge for at booste mining-farten en smule til at starte med (ved at skrue tiden frem en smule, nemlig til.. tja, eller også kunne man egentligt bare starte fra nutidspunktet, det ville måske være det nemmeste..), hvilket både gør at man hurtigere kan danne blokke trods stærkt formindsket minin-kapacitet (og man bør i øvrigt helst forke lige inden den blok, hvor "målet" (the target) bliver sat ned) og altså hrutigere kan få sine malicious kontrakter ud, og også gør at det bliver noget nemmere at tiltrække minere (for lønnen er jo den samme pr. blok). Derfra tænkte jeg så også, at man bare kon offentliggøre kontrakterne forud for at blokkende bliver minet. Og så tænkte jeg på, at man jo så også kan rekrutere alle, der har solgt KV siden fork-punktet, for man kan jo gentage alle de kontrakter, medmindre de har betingelser, der nævner tidligere blokke i kæden (som jo nu vil blive erstattet). At sælge sine mønter med smartkontrakter, der nævner, hvad tidligere blokke er, kan så i øvrigt være en måde at sikre sig mod sådanne angreb *(nå nej, man sikrer sig jo ikke herved, så never mind den del (her til venstre for denne kommentar)), hvilket på en måde faktisk bare er godt for angrebet, for det gør det jo bare nemmere at rekrutere folk, nemlig som har sikret sig, at de ikke selv kan udnyttes. Nå, men man kan også gøre endnu mere, tænkte jeg på: man kan også starte med at gøre så den ekstra miningløn, som angreberne sætter minerne i vente på angrebsforken, ligesom bliver administreret på en sidechain af angrebsforken. Her skal folk så kunne melde sig til rimeligt frit, og man kan så implementere, at man kan udlove dusører på betingelse af, at den endelige blok overholder nogle ting, hvorved man altså kan gøre så dusører bliver betinget af, hvilke kontrakter der kommer med, og hvilke ikke kommer med (når man arbejder sig hen imod nutidsdatoen). I øvrigt (tænkte jeg på lige nu her) kan man jo potentielt set, hvis man skal gøre det virkeligt sofistikeret, sørge for at angriberne har en vis frihed til at lave bestemmelser over de dusører, de allerede har udlovet, hvor de altså så får en vis frihed til at vælge, hvilke eksisterende kontrakter skal med og ikke med, men hvor det så skal sikres, at de ikke har mulighed for at skabe nogen modstride og gøre deres dusør-kontrakter ugyldige herved. Og ja, ellers kan man jo også bare have det sådan, at de betingede dusører udstedes, når der er behov for dem, for angriberne kan jo sagtens give flere og flere dusører løbende (og hvor "angriberne" altså også med tiden kan indbefatte flere og flere).. (13:04) ..Nå ja, og prikken over i'et, som jeg kom til at tænke på omkring ti i seks (ja, det gik ret hurtigt, kan man sige ..tja, men mange af "idéerne" minder jo trodsalt rigtig meget om tidligere idéer..), er jo så denne pointe, nemlig at angrebskæden faktisk har en fordel over for den "uskyldige kæde"/den originale ("rigtige") kæde, fordi angriberne jo, i modsætning til folk på den "rigtige" kæde, der skal prøve at gå til modangreb, ikke "mister" noget som sådan, når de udlover dusører, for de penge har de jo allerede brugt!. (13:08)
..(13:09) Okay, nu ser min angrebsidé jo faktisk ud til virkeligt at virke, hvilket ville være kæmpe stort, for det kommer bare til at booste interessen for mit andet arbejde \emph{så} meget mere, kan jeg forestille mig. Så hvis jeg ikke tager fejl i det her, så har jeg altså nu potentialet til, med en rimelig kortfattet tekst (jeg vil bare forklare det simpelt; i kortfattede, måske to-tre-sætnings-lange, paragrafer), at opnå, hvad der ift. mit fysik projekt vil svare til vildt meget arbejde (hvis vi tænker på sådan noget som at arbejde på "future work"-emnerne, og også bare sådan noget som at rette min artikel godt igennem, så den kommer til at fremstå skarp --- det bliver pludesligt ikke nær så vigtigt, hvis jeg også har denne kæmpe nyhed om blockchain (der endeligt kan bane vejen for mere "grønne" blockchains(/soft forks)))..! :D:) (13:15) ..Hm, det er i øvrigt sikkert også det \emph{helt} rigtige tidspunkt at komme med sådan en idé som denne..!.. 
...(13:33) Hm, og det er jo klart, at dette stadig mere er et argument for, hvorfor nuværende KV'er ikke kan fungere som konventionelle betalingsmilder, for det vil aldrig være attraktivt at lave et konspirationelt replay-angreb på en kæde, der så bare mister al dens værdi (hvilket jo er rigtig godt; det gør jeg jeg ikke behøver at have skrubler over at udgive det). Men en etableret kæde, hvor store dele af samfundet pludselig har stake i kæden, det er en anden snak, for så kan værdien nemlig holdes oppe af denne stake. 

(18.09.22, 11:53) Glem alt hvad jeg har skrevet her ovenfor. Nu hvor jeg har fået mere hjerne igen (har sovet godt i nat, men kom allerede frem til i går aftes, at mine tanker her ovenfor ikke kunne bruges), kan jeg se, at det ikke holder. Især ikke den del med, at angriberne "har en fordel".. ..Og de andre ting holder bare heller ikke rigtig; gider næsten ingen gang forklare hvorfor.. Nej.. ..Nej, lad mig bare strege hele den.. hvad skal vi kalde det? undersektion?.. fra i går.. Ok. 




## Planer

(02.09.22) Nu hvor blockchain-idéen lidt er ude af vinduet, så tror jeg let det kan blive en langtrukken proces om at slå igennem. Jeg er så ved lige at planlægge, hvad jeg skal gøre efter min udgivelse. Jeg er lidt kommet frem til, at jeg skal starte med at give nogle korte ("less is more"-agtige) udgivelser (i min GitHub-mappe) omkring mine web 3.0-idéer --- hvor jeg i øvrigt måske kan fokusere lidt på "ratings" i det semantiske web, som en af de gannemgående idéer, men så ellers også bare det at starte det ud fra web 2.0-sider og wiki-sider; ting som virker allerede, men som kan forbedret af brugerdrevet semantik.. ..Nå, men jeg har lige nogle få ting, jeg lige skal planlægge færdigt omkring det.. (11:10) ...Ah, jeg tror måske, jeg ved hvad jeg gør.. Måske lader jeg bare være med sige, at der er mere ved idéerne end hvad jeg skriver --- ah, og måske også skriver om dem som om de er meget nye idéer (hvad de på én led også er, kan man sige, selvom jeg dog har gennemarbejdet dem lidt (men ja, jeg kan så lidt lægge skjul på, at jeg har gennemarbejdet dem overhovedet, og præsentere dem bare som nogle idéer, jeg gerne vil arbejde videre på.:))) --- og så tænker jeg nemlig særligt også at præsentere min forretningsidé som en helt ny idé, jeg godt kunne tænke mig at arbejde videre på.. ..Hm, men jeg tænker nu dog lige at vente en ekstra omgang stadigvæk med at udgive denne idé-skitse af min forretningsidé. ..Ah, eller endnu bedre ift. at kalde dem nye idéer: Jeg kan bare sige, at de alle er ret nye; at jeg har haft lidt tid til at overvejet dem hver især, men at de dog stadigvæk er på design-stadiet (og på et stadie, hvor de bør overvejes endnu mere for at finde fejl og mangler i dem)..:) Nice.!.. For så har jeg dækket ryggen på en fin måde, og så kan jeg bare lade pitchene tale for sig selv. ..Nå ja, og jeg skal så heller ikke reklamere med, at jeg har en forretningsidé til at starte med: Pointen er lidt \emph{ikke} at give folk opfattelsen af, at jeg muligvis sidder og gemmer på en guldgrube --- ikke før det kan betale sig. (11:42) (For på den måde tror jeg, jeg vil få meget mere positiv energi, og nemlig forhindret en masse potentiel negativ energi (bl.a. fordi folk kan få en negativ reaktion til en, de mener, har munden for fuld).) (11:43)
(03.09.22, 11:09) Tror faktisk endda lige jeg venter en omgang med at nævne min wiki-idé og dabatside-idé også. Til gengæld kan jeg måske nævne ret hurtigt, at der er en/nogle ekistensteori(er) på vej også. Men det kan jeg lige se på. Det er forresten lige før, at jeg vil arbejde på at skrive en uddybende tekst (på engelsk) omkring min forretningsidé først, før jeg begynder at skrive om mit selvadjungeretheds-bevis.. 

(04.09.22, 10:11) Jeg skal faktisk lige overveje noget mere, om det nu også er klogt at offentliggøre sine idéer, så de gængse sider faktisk nærmest får et forspring. Jeg tror muligvis, det går, men det må jeg altså lige tænke mere over i mine pauser.
(14:58) Ja, det går; jeg skal helt sikkert bare offentliggøre de idéer med det samme. Jeg skal i øvrigt også huske at snakke om brugergrupper og anonymitet i disse, men ja, jeg vil jo bare gå igennem alle mine punkter, npr jeg når dertil, og så udgive om alle dem, der kan forklares rimeligt kortfattet, nok på nær dem der har med vidensdeling og debat lige i første omgang, dog. (15:00)


(13:17, 17.09.22) Jeg tror muligvis jeg snart vil begynde at oplaude ting til min note-mappe, og måske vil jeg faktisk også allerde begynde at lave nogle små tidslåse (bare over et par måneder), f.eks. til min blockchain-angrebs-idé (hvor jeg så på den anden side vil udgive løsningsforslaget med det samme). 

(11:58, 18.09.22) Hm, nu overvejer jeg faktisk bare at give hints til koden, og så måske lave en kode (også) bare af nogle danske ord sat sammen (og måske gentaget tre gange, hvis det ellers er kort). ..Det virker på en måde sjovere, end det andet, og jeg tænker alligevel faktisk at åbne det hele før snarere end senere.. ..Og jeg overvejer også faktisk lidt at pitche min forretningsidé i samme omgang, som jeg pitcher mine idéer til en ny web 3.0-bølge.. ..Men det må jeg jo lige tænke nærmere over i de kommende dage (i min "fritid").. (12:03)

(19.09.22, 16:11) Okay, nu har jeg nogle meget bedre planer..! Jeg er kommet frem til her i dag (i en pause fra at tænke på fysik her på min seneste gåtur). Det korte af det lange er, at jeg bare skal forklare om min forrestningsidé med det samme, og så ikke være bleg for at sige: jamen, jeg er sikker på, at dette bliver den næste vildt store ting; langt langt større end BitCoin osv. endda (hvad jeg jo helt klart også tror på selv). ..Jeg tror lige, jeg vil vende tilb.. nå nej, det hører jo alligevel til ovenfor. Ok, så jeg har også nogle idéer til, hvordan man kunne opfordre til at starte det meget simpelt, nemlig med en kickstarter og med nogle løfter (som man så hurtigst muligt skal underbygge med kontrakter). Og dette vil jeg så altså også bare lægge op til, når jeg (meget hurtigt efter min fysik-udgivelse) skriver om idéen i min GitHub-mappe.. ..Ok, lad mig vende tilbage hertil, og uddybe lidt mere, hvis jeg synes, jeg bør sige noget mere...
%..(16:21) Nå jo, lad mig også lige nævne, at jeg nu også har tænkt mig at give en kort note om, hvordan der ikke skal "særligt meget uendelighed til" i multiverset for at man når frem til, at vi basalt set genfødes som alle levende væsner igen og igen --- og at man derfor kan tage "what comes around goes around" fuldstændig bogstaveligt, for vi skal på den måde alle opleve de samme glæder og smerter. 
%(17:38) Jeg tænker så også bare at lægge alle mine noter ud med det samme, bare til \emph{hvis nu}, nogen skulle være interesseret i at sneak-peak'e (og ofre noget tid), inden jeg får skrevet mere sammenhængende noter over emnerne (de vigtige af dem i hvert fald). Og så tænker jeg i øvrigt også bare ikke at lægge skjul på, at jeg tror min forretningsidé, hvis den udbreder sig til andre områder, kan blive lidt en kur til de negative sider af kapitalismen (men endda uden at bryde med kapitalismen; forretnings baserer sig helt på et frit markede osv.!). (17:41) 


(18:07, 27.09.22) Jeg tænker nu lidt faktisk at starte med at skrive om min forretningsidé i sig selv (og som jeg lige har skrevet ovenfor, bliver dette altså uden at hype den som den næste store investeringsdrøm, for det er jeg kommet i tanke om, at den jo nok ikke vil være som sådan..). Jeg vil så forklare om, hvordan den fungerer, hvad den lover for fremtiden, hvad hver part vil få ud af den, hvorfor forbrugere i det hele taget burde have magten i et kapitalistisk ("forbruger-")samfund, hvem det kan komme til at gå ud over, og, også rimeligt vigtigt, hvorfor det egentligt ikke behøver at gå ud over de rige som sådan (og hertil hører også en lille idé om, at man kan slå to fluer med ét smæk og gøre idéen mere attraktiv for de rige, og forhindre, at boligmarkedet eksploderer i fremtiden, når bevægelsen har slået rod og de velhavende naturligvis vil begynde at lede efter steder, hvor de alligevel kan få deres penge til at yngle..) (For hele pointen med idéen er jo netop, at man når til et ret lige samfund, hvor der stadig er masser af plads til rigdom, men hvor rigdom i sig selv ikke bare kan yngle; hvis rige mennesker skal gøre sig selv rigere, skal de gøre dette ved at bruge deres (eventuelle) talenter til at forbedre samfundet, i.e. de skal gøre et stykke arbejde (medmindre selvfølgelig, de har haft held med at lave og opretholde en privat virksomhed, der ikke følger princippet i min forretningsidé, for sådanne skal bestemt ikke forbydes --- der skal jo ikke laves nogen som helst nye regler/love i samfundet i princippet i forbindelse med min forretningsidé).) (18:18) ..Og så vil jeg så forklare, hvad jeg lige har nævnt ovenfor under den relevante sektion, nemlig at man kun i visse tilfælde kan forvente, at der kan blive en stor investeringsdrøm i det, og at én (vigtig) mulighed her lige præcis er (nogen af) mine web-idéer, fordi sådanne virkeligt kan have gavn af, at brugerne har magten (og ved at brugerne af systemerne altid vil have dette). Og det vil jeg altså så nok slutte af med at referere til, og så må jeg jo se, hvornår jeg så får skrevet om de emner efterfølgende.. (18:26) 


(11:59, 19.10.22) Okay, der er ændringer i mine planer. Min fysikartikel ser faktisk næsten ud til at være lidt et flop muligvis.. Jeg skal lige have overvejet alle tingene og læst godt op på literaturen, men ja, der er altså muligvis ikke så meget nyt i den. Mine nye planer er så, at jeg skriver et samlet dokument om lidt af hvert: min forretningsidé, e-demokrati, og nogle af mine web-idéer/forudsigelser, samt også om eksistensteori, og så regner jeg med at gøre den samlede overskrift til noget a la "idéer og forudsigelser..".. Hm, eller jeg har også tænkt bare "En lys fremtid".. Men ja, pointen er: Jeg har nogle forudsigelser om den nære og fjerne fremtid, som fortæller, at denne er rigtig lys (og så har jeg også lige nogle eksistensbetragtninger, som gør det hele endnu mere lyst at tænke på). Så altså en meget positiv tekst om den nære fremtid (og idéer til at gøre denne bedre), om den fjerne fremtid også (og det vil jeg i øvrigt også skrive lidt om (at vi nok får et godt post-scarcity-samfund på et tidspunkt)), samt også hvorfor vi sagtens kan gå at glæde os over en lys fjern fremtid, også selvom vi ikke selv kommer til at leve iden (hvor vi altså snakker mine eksistensteori-betragtninger). Det vil jeg altså gå i gang med nu, og så vil jeg prøve også at arbejde lidt på at reparere min fysik-artikel om aftenerne. (12:07)   




## Diverse tilføjelser her i starten af 2023 (muligvis afrundig på dokument)

(04.01.23, 16:36) Okay, jeg har lige fået ig en ny computer, efter at min forhenværende gik i stykker i julen, og har lige fået installeret Linux. Her under nytårsræset (nærmere bestemt natten til d. 31.) fik jeg tænkt lidt over Eksistens igen, og det har jeg også brugt de følgende dage på indtil nu, imens jeg ikke havde en funktionel computer. Jeg har et par nye tanker om emnet, og har også en nogenlunde idé til, hvordan jeg ville strukturere en lille artikel om det. Det vil jeg derfor lige skrive om ovenfor i 'Eksistens'-sektionen, efter (..uh ha, det er et lidt drilsk tastatur, fordi man godt kan trykke ned på siden af en tast uden at den registrerer et ryk.. he, meget passende: jeg skulle have skrevet 'tryk'..) at jeg har skrevet denne sektion. 

Jeg kan starte med at skrive, at selvom jeg tror på at mine idéer omkring tag-ratings, kommentarkategorier, fanetræer og alt det omkring en web 2.0--3.0-side virkeligt indeholder et kæmpe potentiale (også rent forretningsmæssigt), så er det altså ikke sikkert, at de idéer bare sådan lige vil føre et semantisk web med sig med det samme.. Måske vil det hjælpe, at folk bliver vent til at diskutere i træer/diskussionsgrafer, når det kommer til kommentarer, men det kommer nok ikke til at accelerere overgangen til en videns-/diskussionsgraf (med sandsynligheder på, altså en "p-ontologi," som jeg før har kaldt det) super meget. Det tror jeg til gengæld nu mere mine debatside-idéer vil. Og også mine e-demokrati-applikations-idéer. For e-demokrati-idéerne kommer jo måske nok til at give incitamenter til folk om at deltage i (graf-)diskussionerne, og mine debatside idéer vil i øvrigt også åbne op for, at folk vil være meget mere villige til at lytte til hinanden på tværs af grupper, nemlig fordi man gør det til en udfordring: "Hvis du tror denne anden gruppe er helt henne i vejret, hvorfor så ikke bevise det via en grundig diskussion med en saglig og upartisk 'dommer' (eller flere) for diskussionerne?" Så det tror jeg altså mere kunne være dét, der kan sætte skub i den udvikling. 

Nå ja, og så kan jeg også sige, at jeg i går eller i forgårs kom til at tænke på, at (semantisk struktureret) NLP måske kan gå hen at blive en virkelig vigtig kilde til, at vi en dag får videnskabet semantisk struktureret (hvad ville være SÅ (SSSÅÅ!!) godt), hvis nu ikke semantic web-løsninger når at komme inden om først og tilveje bringe den realitet på en mere direkte måde (altså mere via menneskeligt arbejde frem for hjælp fra en A.I.). For når først den tekologi bliver udviklet tilstrækkeligt, hvad den sikkert gør i en ikke alt for fjern fremtid, så vil man ret nemt kunne opnå et kæmpe spring fremad simpelthen ved at få en A.I. til at lave et stort forarbejde med at analysere al eksisterende videnskabeligt arbejde og fylde det ind i en stor semantisk struktureret graf. Og når først man så har sådan en graf, så kan man derfra ved hjælp af menneskearbejde og v.h.a. yderligere forbedriger af A.I.'en (og altså ikke mindst ved en synergisk sammenblanding af disse) relativt nemt få udbygget denne store graf, så man får struktureret al viden semantisk. Så NLP-teknologien kan altså sagtens komme til, hvis ikke sem-web-løsninger kommer indenom først, at blive utroligt vigtige for den samlede videnskab (og dermed hele vores teknologiske udvikling). Og det virker som om, at den allerede er godt på rette spor, for der tænkes vist allerede godt i, hvordan man kan gøre NLP-algoritmer mere semantisk funderet (hvilket jo er klart, for så må man jo i sidste ende ende ud med et mere "intelligent" produkt). Så lad mig da endeligt huske mig selv på at følge noget mere med i den (spændende) udvikling. 

Udover min e-demokrati- og debatside-idéer, som jeg på et tidspunkt vil prøve at iværksætte (er planen), så har jeg altså nogle forskellige politiske og økonomiske idéer. Nå ja, og én af de politiske idéer handler jo så om at bruge en e-demokrati-app, nemlig til at lave et e-demokrati-parti.. ..Hm, jeg skal forresten nævne, at man også kunne forestille sig e-demokrati-appen mere som et socialt medie, hvorved altså alle personer og grupper altså enten direkte eller inddirekte har adgang til hinanden, og mere eller mindre deltager i det samme "digitale rum," kan man kalde det, når de bruger appen. Og så kan alle mulige befolkningsgrupper, og alle andre typer grupper (hvis ikke befolkningsgrupper er et altomfattende udtryk), altså finde sammen på appen og diskutere og forhadle med alle andre grupper på mediet. ..Og ja, så tænker jeg altså også, at man kunne blande appen sammen med debat-appen, således at e-demokrati-grupperne også kan oprette diskussioner/debatter med hindanden ovre i det andet ben af appen, der så altså er "debatside"-delen. (17:18)

Men ja, og udover disse ting, så har jeg altså mine idéer til nye typer af forbrugerforeninger (som forklaret i mit nye dokument ('consumer unions.pdf')) og mine idéer omkring "share-redistributing companies," hvilke jeg begge tror kan blive virkeligt store, ja, og sådan set ligefrem neutralisere alt (ikke ALT, men ~alt) hvad der er skidt i den nuværende udgave af kapitalismen, således at vi kan få en meget bedre form for det. Så planen er altså, at jeg vil prøve at diskutere SRC, CU, og.. EDP (e-demokrati-parti) med andre politik-interesserede, og så prøve at fokusere mit ejet faglige arbejde i retning mod at kunne iværksætte ED- og debatside-app --- bl.a. faktisk også ved simpelthen at læse open source kodebaser i min fritid (når jeg får sådan en igen). (17:25)

Hm, var der mere jeg skulle sige her (som ikke omhandler Eksistens)..? Der ver lige en lille ting, og det er bare, at jeg lige tænkte på igen, at hvis man som befolkning skulle åbne mere op for overvågning, så skulle det være via personlige kamerare, som alle folk helt selv er frie (ikke bare lovligt men også fysisk) til at slå fra og til, hvornår det skal være, og hvor det alt sammen sendes til datacentre, som er offentligt overvåget via kamerarer og lydoptagelser --- og digitale diagnosticeringer --- hvor man så bare altså har alt indholdet krypteret hele vejen, også hvis nu det skal bruges af ejeren og altså dermed sendes tilbage igen.. Men ja, jeg har sikkert sagt (skrevet) noget tilsvarende en gang.. ..Men jeg kom fra: var der andet, jeg skulle skrive her..? 

..Det tror jeg ikke, og ellers vil jeg bare lige vende tilbage. Så nu vil jeg altså skrive nogle tilføjelser til Eksistens ovenfor. Derefter vil jeg gå i gang med at se på at skrive (/ om jeg skal skrive) min SRC-artikel om og/eller skrive en ny version. Samtidigt med dette vil jeg så også tage kontakt til flere omkring det, og her tænker jeg så særligt på en vis tænketank, jeg er blevet fortalt om: Demokratisk Erhverv. Og når jeg så endelig når til et holdt/en pause i det, så vil jeg faktisk se på at få skrevet en Eksistens-artikel. Og ja, derefter snakker vi så at arbejde mig frem mod at kunne realisere mine e-demokrati- og debatside-idéer. Nå jo, jeg skulle forresten også nævne, at min wiki-idé nok heller ikke i sig selv bliver sindsygt accelererende for sem-web-udviklingen, mener jeg nu, selvom den nok dog vil kunne blive en rigtig god ting med tiden. Og lad mig så lige påpege, hvis det giver mening, at det nok er for meget at håbe på, at en videnskabelig semantisk ontologi vil kunne indeholde de helt grundlæggende argumenter til at starte med. I stedet bør man nok huske kun at sigte efter i starten, at den bare kan indeholde samlede videnskabelige værker som dens grundsten, hvilke så godt nok dog kan få noget semantisk data omkring sig om, hvad de siger, men som man dog altså ikke kan forvente skal splittes ad til atomer i den semantiske struktur. Jeg håber, det giver mening.. ..Man må altså forvente, at videnskabelige værker, der belyser et emne, må indgå so mere eller mindre atomare grundsten i den videnskabelige ontologi/semantiske graf til at starte med, og så er det nok først på meget længere sigt --- medmindre NLP-/AI-teknologien virkeligt kommer til at sparke røv på det punkt ---  at man kan forvente at disse værker i sig selv bliver splittet ad til semantiske atomer. ..Og når vi f.eks. særligt snakker e-demokrati-og-debatside-diskussioner, så må man også i høj grad forvente, at folk skal gøre brug af tredjepartsinstanser (altså forskere/forskergrupper, tænketanker, fagfolk, eksperter, ordfører, osv.) og hvad de siger/skriver om en ting, mere end at man skal forvente at hver del af alle disse analyser også bliver uploadet til mediet og behandlet online af brugerne (og analyseret semantisk). Selvfølgelig er det sundt jo mere der kommer online og bliver behandlet der, nemlig således at alle kan få indblik i detaljerne, og så der altså er høj gennemsigtighed, og så det er nemt at finde og udpege fejlslutninger m.m., men i sidste ende må man altså nok regne med, at dette ikke er muligt, og at man er nødt til bare at inkludere værker og udsagn fra andre som grundlæggende, atomart materiale for diskussionerne, uden at dette materiale bliver taget ind og splittet ad (og analyseret) på selve siden/i selve appen. (17:52)

..Men ja, nu fik jeg vist skrevet alt, hvad jeg ville sige, lige inden jeg kom med den sidste tangent her, så jeg kan vist bare afslutte her.:) Det er altså planerne, som de er nu, og for det første vil jeg altså så lige prøve at tilføje nogle ting om Eksistens ovenfor. (17:54, 04.01.23)


\end{comment}




































































%
%
%
%\chapter{E-democracies} \label{E_democracies}
%
%The concept of a so-called `e-democracy' is not a new one. Wikipedia thus has (in the moment of writing) a whole article about the overall concept that one can read. (That article, in its current form, defines the concept perhaps a bit more abstractly than what we need for our purposes here, but it might still be helpful to glance at.) In this section, I will therefore not introduce the overall concept, but simply give some short notes on how one might implement such an e-democracy, which can for instance be used to govern a company like the ones described in the previous chapter (as its shareholders), or a political party, etc. 
%
%
%\section{A basic digital application where voters can build proposition graphs}
%
%Imagine a digital application where all voters in a given democracy (concerning e.g.\ a company, a union, a political party, etc.) can log on and build a proposition graph together, which can then define the policies of the body governed by the given democracy. We are here talking about the `graphs' of mathematical graph theory. (One can make a brief search the internet for `graph theory' to see what this is about, and one might then also want to search for `directed graphs' and `connected graphs' at the same time.) 
%
%Each node of the graph holds a proposition, which is simply expressed in plain text of whatever natural language (such as English) is appropriate for the case. 
%
%When adding a new node to the graph, one can add it by itself (i.e.\ not connected to any other nodes) or add it with at least one of two kinds of (directed) edges to an existing node. The two types of edges then represents whether the node's proposition is an elaboration on the parent node, or if it is a self-contained proposition that should, however, only apply conditioned on the parent node being active.
%
%A node becomes active if it has enough votes and if a majority of those votes are positive rather than negative. Whether `votes' are counted simply by number (such that all voters have equal power) or if the votes are weighted (meaning that some voters have more power than others) of course depends on the case. 
%
%The point of being able to `elaborate' the proposition nodes rather than having to replace it with a more detailed note instead is simply to make the work easier for everyone, and also to make the graphs easier to read. It means that the policies can be defined somewhat loosely at first (and therefore much more quickly and easily), and whenever some vagueness of the propositions is discovered subsequently, either by people studying them or because of a relevant case that reveals it, the voters can then work to specify and mend the propositions. 
%
%The point of being able to add proposition nodes that are conditional on their parent nodes being active is of course some propositions might only be beneficial to implement given that certain other ones are already in place. If a somewhat fundamental proposition node is voted inactive again, it is thus convenient that such `conditional child nodes' follow along. If the parent node is then voted active once again (or perhaps for the first time) at a later time, all the child notes that has retained a positive voting score in the meantime will then become active one again, as well as any child node whose score has become positive in that time. 
%
%The application might also allow these `conditional child notes' to have several parent nodes for convenience. 
%And the same could also apply for the `elaboration child nodes' since there might be case where it could be beneficial to be able to elaborate the interpretation when two propositions nodes are active at the same time, for instance if these two proposition have a slight conflict with each other, or if the create some other issue that needs to be handled when they are both active together.
%
%`Elaboration child nodes' should of course also depend on their parents being active. The difference between a `conditional child node' and an `elaboration child node' is therefore essentially only in the interpretation: The propositions of `conditional child notes' and those of their parents are meant to be independent of each other as statements, whereas `elaboration child nodes' are free to correct and override parts of the statements contained in their parent nodes, thus allowing these to not necessarily be absolutely precise and self-contained. 
%
%Every user should be able to add new proposition nodes and each node should also have a separate `interest score' that users can rate (with the same weights on the votes as for the first score in the case where these are weighted). A proposition node whose `interest score' exceeds a certain threshold becomes visible to all users in the main graph, and people will then have to give their votes to it, if they want to influence whether it is applied or not. 
%
%Users should thus also be able to view nodes in the graph that has not yet exceeded said threshold, perhaps by being able to select various ranges of interest scores to look at. It might also be beneficial to let such nodes expire after a certain time if their `interest score' has been low enough for too long. 
%
%Users should also preferably have their own `workbench' with enough storage capacity to hold a number of propositions nodes. If a proposition node expires, they can thus make sure that the work is not lost as long as they keep said proposition on their own `workbench.' It would probably be beneficial also if users could then have shared `workbenches' as well, where they can collaborate on making new proposition nodes. 
%
%Anonymity is of course generally very important for democracies. So it is naturally very important that no one can see which user has added what nodes, unless of course they have collaborated on it from the same `workbench.' Users should also not (for most cases of democracies) be able to see which users has voted for what. 
%%
%For cases with weighted voting, either with very few voters or with very precise weights, this might be helped further by making sure that the exact voting scores are not visible to the users, and that the can thus only see a number that is rounded to a less precise floating point number. One might also implement intervals such that new votes are always declared together in groups, some time after they have been cast individually. 
%
%
%\section{How the proposition graphs are used to govern a body}
%
%The point of building these proposition graphs is then that the leadership of the body you are governing should to some extent be required to follow the active propositions, at least within some basic limitations of they can be required to do. 
%
%When the proposition graph changes, they leadership should be required to implement these, but here it might of course be a good idea to implement some delays on when new changes are supposed to be carried out. One might thus rule that a change should only be implemented after a certain period from when happened, and only if that change has remained active in the proposition graph during that period. 
%
%If the proposition graph gets some contradictions and/or ambiguities that makes it hard for the leadership to know what to do, they should also be allowed to postpone implementing the relevant changes until the voters sorts out the issues (by which they make some new changes which restarts the acceptance process). 
%
%How to make sure that the leadership follows the democratic decisions of the proposition graph? Well, by making sure that the voters also have enough direct power over the governed body to enforce their will. This might typically be ensured by the group of voters having the power to fire leaderships and/or decrease or increase salaries, thus giving this group ``sticks'' and potentially ``carrots'' that they can use to make sure that the hired leadership does what it is supposed to.
%
%
%It has to be mentioned that a high level of transparency is an all-important part of an effective e-democracy when it comes to the body that is being governed. Luckily, one can say that as long as the voters have the aforementioned ``carrots'' and ``sticks'' at their disposal, they should at least be able to make the body more and more transparent, even if it not very much so from the beginning.
%
%
%
%%Husk:
%	% Fortolkningspolitikker (inkl. hvad man gør, hvis der er modstride) og delays. (tjek)
%	% The point with having conditional propositions.. (tjek)
%
%
%\section{A more advanced application}
%
%A basic system like the one described above is good enough for very simple cases where it is okay to just have a majority rule. But for more complex cases where there are a lot of groupings of voters with different interests when it comes to various topics, to have such a majority rule is not really sufficient. If we for instance think of the policies of a whole country, this is a good example of such a complex case, where most people probably have \emph{some} special interests that are only shared with a fraction of the society. In such a system, it is important for people to be able to \emph{negotiate} with their voting power in order to get what they want, not just to always vote for exactly what they want as individuals. One group might thus want to meet with another to make a deal where they say: ``If you vote for this and this, even though you might not be particularly interested in that, we will vote for this and this which you do have a particular interest in (even though we might not).'' 
%
%In order to accommodate these realistic needs of its users, the digital application in question should therefore also first of all make it possible for users to form groups in the system. On a technical note, having such groups can of course be implemented in a lot of ways, but I can suggest an implementation where the creators of a group start out with some divisible `moderation tokens' that give them power to decide who can join the group and who gets kicked out, and where they are then free to transfer parts of (or all of) these tokens to other users within the group at any time. This moderation system is open enough that the users can implement any other moderation system on top of this, if only they trust some central party (which can then control a user profile in the system) to enforce the results of this external moderation system.
%
%And in order for such groups to be able to start negotiating with their voting power, it is then first of all important that some overall statistics (perhaps where numbers are rounded to ones with less precision for the sake of anonymity) of how a group votes on average is made public at all times. Otherwise a group who has made a deal with another group would not be able to check that this other group holds its promises. 
%
%With this addition to the application, groups can now in principle make all the deals in private that they want to. But of course, a good implementation of an `e-democracy application' would also afford its users with ways to make these deals within the digital application, online. 
%A way to do this might be to add what we could call `conditional votes' to the system. A `conditional vote' is then a vote on a proposition, whose sign can depend on other factors. In particular, a conditional vote should be able to depend on parameters regarding the voting statistics of groups. A group that want to make a deal with another one can then decide to make a conditional vote for something the other group wants and then make the condition such that this latter group has to vote for something the former group wants to unlock the conditional votes. 
%
%On another technical note: Depending on how the system is implemented, such conditional votes might be able to cause deadlocks, where two or more conditional votes all wait for the other to turn the other way in order to turn themselves. But a way to mitigate this is to give a direction to all conditional votes which denotes the sign expected from a successful deal. The system can then continuously refresh the proposition graph by turning all conditional votes in their positive direction and then see if they fall back to the same state or if they settle on a new state, which will mean that some deadlock has been conquered. 
%
%And on a design-related note: The conditional votes can be visualized/rendered as leaves in the graphs, each one attached to a certain proposition node. The users can then create and add these `conditional vote nodes' to the system in the same way as proposition nodes are added, and then all users can decide to cast their vote for the given proposition either by casting it (unconditionally) on the proposition itself or casting it instead on one of the conditional vote nodes (meaning that their vote will now be automatically conditioned on some parameters of the voting statistics in the system, continuously, until they change their vote again). 
%
%%Another thing that a more advanced system might account for, is the fact that the power of the voters might not just have different weights but might also be dependent the area that a given proposition deals with. This could for instance be in a company or a government where there are many departments/ministries in charge of different areas. If such a company/government decided to go for a more democratic leadership, it might still want to keep some division of power within the democracy. This example is perhaps not the most realistic one so here is one that is more so:  
%
%
%Another very important thing that an advanced application should afford its users is to make sure that the voters can choose representatives. It might seem odd to want to implement a direct democracy only for people to end up choosing representatives once again, but is indeed exactly what a direct democracy should aim for. It is nowhere near feasible if the system requires all users to engage in all discussions and decision making in order for the democracy to work, not unless we have a simple case with relatively few voters who are all quite engaged. But in most cases that one could think of, being able to choose representatives and trust these with looking into specific and/or complicated matters and vote on the person's behalf is all-important. The problem with representative democracies that a direct democracy aims to fix should thus not be to get rid of representatives, but simply to ensure that people can change these much more rapidly should they want to, and also that any voter can always choose to look into specific matters themselves and choose to vote differently on those than how their representative has voted.
%
%An advanced e-democracy application should therefore also allow users to choose representatives. With `conditional votes' implemented, users can of course in principle just cast conditional votes on all propositions that they want representatives to decide for them, but this is too cumbersome and we can do much better than that. The application could thus first of all allow the voters to give their votes to others. But it is likely that some users will only trust a certain representative to decide for them in a certain area of concern. And in general, users will therefore probably want to be able to have multiple representatives at a time, each responsible for making decisions for the voters in specific areas. 
%
%I therefore propose that an advanced e-democracy application also implement what we could simply call `areas of concern,' which are then essentially groupings of propositions regarding a certain subject. Whenever a new proposition is added by itself (as what we could think of as the ``root'' of a connected graph) it should thus be given an area of concern such that the application can group it with proposition graphs with the same area of concern. And whenever a child node is added, it should of course get the same area of concern as its parent. With this implemented, users should then be able to give their votes to another user (i.e.\ representatives) when it comes to any specific area, which should then effectively mean that the user will automatically cast the same vote as their representative, at least when it comes to propositions that the user has not voted on themselves. (And one might then implement different settings to this, such that a user for instance might be able to even let a representative override the user's own previous votes.) 
%%(If someone creates an otherwise relevant proposition node but adds the wrong area of concern, one can expect that it will then simply not be voted forth (over the aforementioned threshold), not until the author gives it the right area of concern.)
%
%It now almost goes without saying that each `group' in the system can then potentially choose to have their own specific representatives that the members are recommended (or perhaps required in some special instances) to use. 
%
%The system might also implement `subareas,' such that any user can try to add one such to any proposition node. Users should then be able to vote such subareas in and out, and if one is voted in, the proposition node and all its children will then get this extra area, that users can then also choose to sign representatives to. With these `subareas' implemented, this then allows users to delegate different representatives to these, even if they are also part of the same overall area of concern. **(This paragraph will probably need some rephrasing.)
%%(One could also implement `subareas' simply by requiring that these are also added from the beginning when the relevant proposition nodes are created, but it might make it easier for the users if they can just change the subareas by vote at any later time (instead of having to recreate and substitute the whole subgraph, with similar nodes but with updated subareas).)
%
%
%%These `areas of concern' also allows for something else that might be very useful, namely that the same community of users/voters can govern a variety of bodies with the same overall (potentially disconnected) proposition graph. 
%%Because when the contracts and/or agreements concerning the various bodies' commitment to follow the proposition graph are external to the digital system, a body might as well agree to only be ruled ...
%%The usefulness in this, apart from maybe having everything gathered in one place, is that this will mean that voters
%%(16:06, 06.11.22) Hm, dette kan nok godt blive mere kompliceret, fordi flere foreninger så skal blive enige om, hvordan stemmerne fordeler sig, og så skal det lige pludseligt topstyres på en helt anden måde.. Så lad mig lige se en gang... ..Hm, men handler det så ikke bare om, at forskellige grupper skal kunne "genbruge" de samme propositionsgrafer, og også om at de andre gruppers aktivitet så også godt må kunne gøres synlig i samme propositionsgraf (altså for en vis gruppe, der bruger denne)..? (16:09) ...(16:29) Jo, men så har det så ikke rigtigt så meget med subareas at gøre.. ..Nej, for så skal man også simpelthen gøre, så at graferne.. er helt adskilte, ja, så måske giver det altså slet ikke mening.. hm, andet end at man stadigvæk kunne have graferne side om side, og mere vigtigt, at conditional votes så også kan komme til at afhænge af eksterne grafer.. Ja, er det ikke bare det..?:) 
%
%
%%Furthermore, each group should have its own page and/or own `area of concern,' where the members of that group have all the voting power. This is useful since it means that each group can then build their own proposition graph over its policies and opinions. A group might then also signal external actions via this proposition graph. For instance, a group the represents a workers union might create conditional votes in their own proposition graph that depends on some statistics regarding the main proposition graph.. 
%%say that: ``On these
%
%
%And lastly, it might be beneficial for various groups in society who govern different bodies, e.g.\ political parties, unions, organizations, companies, to also be able to negotiate with each other online and to view each other's policies. For instance, a company might want to say to a governing political party that: ``if you implement certain laws, we will move out company elsewhere.'' And a trade union might then say to a company: ``if you do not give us higher salaries, we will go on strike.'' These are thus examples where a group in society can use their power over one body (including simply themselves as a group) to negotiate concessions from another group with power over a different body. 
%So if the advanced e-democracy application really wants to afford its users with all that they could want for negotiating effectively with each others, it should allow different voter groups to come together in the same space. First of all, each `group' in a e-democracy should have their own proposition graph that only they have voting power over. This local proposition graph can then be used to signal the groups policies, opinions and potential actions. And when it comes to the `conditional votes' in this local proposition graph, these should also be allowed to depend on statistical parameters in the main proposition graph, outside of the local one. 
%And furthermore, different e-democracies (governing over different bodies) that uses this same digital application should also be able to invite another group to join together, such that the two e-democracies can have their proposition graphs shown side by side (but with the same distribution of voting power in each of these graphs), and more importantly, that one e-democracy can then start making conditional votes that depends on statistics regarding the other e-democracy and vice versa. 
%
%
%\section{An e-democracy party}
%
%There are of course a lot of different examples where an e-democracy such as this could be useful; political parties, companies, unions, organizations and other communities. %In this section, I will, however, only give some points when it comes to political parties and companies of the type that I described in the previous chapter.
%%If we ..
%And when it comes to political parties, there is the natural option that these are run only by their members. We could thus imagine two or more parties competing for power, each being run e-democratically by its members. But since politically parties are typically inclusive anyway, why not just strive to have one political party where every person in the society gets an equal vote? 
%
%I believe that such a party could gain massive support over time. It might start out as a small party, especially in the early days where people are still getting used to working with the proposition graphs, and when the technology is perhaps at an early stage. And then as the technology to matures and the userbase grows, more and more people would trust the new system enough that they would want to give their vote to this `e-democracy party.' That party might then, at least in multi-party systems, get some representatives in government and by that point, the interest in the party would grow further, since all registered users would then be able to have a say in the policies of those representatives. And if the technology works, more and more people would then see the potential in an e-democracy. This is especially true in countries where the people in general do not always feel heard by there politicians: When they then see that the resulting proposition graph for most people will fit their interest better than what the traditional political parties offer, they will want for the e-democracy party to be voted in as a ruling party. 
%
%Now, if the party thus lets member of society have an equal vote in it, this might then be problematic at this stage when the party want to take over from the traditional parties, since people might then be tempted to make their vote count twice, essentially, by voting for their favorite traditional party and then also using their vote in the e-democracy party. And since voting is anonymous, there is no real way that the e-democracy party stop this. That is, apart from taking steps to balance out this effect. The e-democracy party might thus choose to temporarily break its commitment to giving all people an equal vote in this phase, and instead promise that it will commit itself to try to counter all representatives in government that are not part of the e-democracy party by giving more votes internally to a group of representatives whom it deems are exactly at the mirrored end of the spectrum than the group of non-e-democracy representatives in government. (The chosen counter-group can, however, be much larger then the group of representatives it is supposed to counter.) This way, a voter who wants the e-democracy party to take over would not be tempted to cast their votes to a traditional party instead. It also means that once the party sits on a majority of the power in government, other representatives are more likely to join it while in power (if the relevant constitution permits such migrations of representatives while in power) if they see that the e-democracy is more practical since the e-democracy party can then just remove the appropriate amount of counterbalance as these former outsiders join. 
%
%
%E-democracies as governments of countries might thus be a much closer reality in the near future, than a lot of literature on the topic seems to suggest, at least in countries governed by a multi-party system. In two- or one-party systems, the development might of course be much slower. But then again, once some multi-party governments successfully switches to an e-democracy, the two- and one-party governments would then be able to analyze and copy the technology, at least giving them a much easier route to an e-democracy, should their voters want one. 
%
%
%
%\section{Anonymity}
%
%
%As mentioned, anonymity is often very important for a democracy, especially if we think about the case of governing a country. Therefore, the digital application should allow the users to vote anonymously. This can be achieved letting each user control an anonymous profile, but if information about which user has which anonymous profile is stored on a server, that server might be hacked. 
%
%So the question is, can an e-democracy system be as safe and anonymous as going to a box, drawing a cross in a field on a piece of paper and putting that paper into a box? Yes, actually: there are ways to ensure complete anonymity of the users where the anonymity is preserved even if the servers of the application is hacked.
%
%The following protocol allows a set of clients to each provide a server with a set of public keys such that each client knows the private key of exactly one of the keys in the set (and no one else but them knows this private key) but where no one knows which public key belongs to which client apart from the clients knowing their own key. The protocol is furthermore resistant to DoS attacks. 
%
%It works by having the clients take turns building blocks in a block chain, which we can think of as a `block spiral,' where the clients form a circle and where the turn to provide a new block to the spiral goes around in the circle. 
%
%\ldots\ \textit{Okay, jeg tror lige, jeg venter med at forklare om min idé her, for det kan godt være, at der findes en lidt nemmere måde. Det vil jeg lige tænke over. Men ellers er det en god idé, altså den hvor hver klient sender nogle nøgler videre til en tilfældig anden klient i kredsen (hvor hver blok krypteres med den næste klients offentlige nøgle (fra begyndelsen) og sendes til denne), og hvor klienter, der modtager nøgler gerne skal sende dem videre og slette dem fra hukommelsen. Herved vil man meget sjællendt kunne se, hvem var den oprindelige sender af en nøgle (medmindre både modtagerklienten og klienterne for og bag brugeren er ondsindede), og selv hvis den bliver sporet tilbage kan pågældende klient bare sige, at ``den nøgle kom fra en tidligere omgang og altså fra en helt anden bruger, men jeg har altså slettet data om, hvor den kom fra, som jeg burde.'' Men ja, jeg tænker nu lige lidt mere over det, inden jeg skriver denne sektion færdig. .\,.\,Jeg har i øvrigt også tænkt mig at sige, at man efter at have brugt denne protokol så bare kan bruge et VPN herfra, men hvis man vil være endnu mere sikker, så kan man endda bruge helt den samme protokol til at indsende data om, hvordan man vil stemme med sin profil, hvor man så altså bare erstatter de (tilfældigt) genererede nøgler i protokollen med tilfældigt genereret data samt det faktiske data, man vil indsende, og til sidst så offentliggør man så bare, hvilket skrald, man har sendt ind, men ikke den faktisk data, man så lader serveren beholde. (.\,.\,Så kan det dog godt være, at man skal ændre protokollen lidt, så man lige sørger for, at hver mængde data også vil nå slutningen af protokollen, så at ingen data-klumper bliver tabt i protokollen --- medmindre der altså er sket en synlig fejl i protokollen.)}
%
%\ldots\ \textit{Nej, der er vist en nemmere protokol, hvor man vist nok også kan finde frem til en DoS attacker. Man kan vist bare have et VPN, hvor klienterne sender beskeder frem og tilbage, og hvor de så kan pakke en nøgle ind i flere krypteringer med forskellige nøgler, hvor beskeden så skal sendes til alle de klienter i rækkefølge, som kan dekryptere beskeden en efter en. Og hvis så man gør det tilfældigt, hvor mange krypteringer, der skal til, så kan ingen igen vide, om en nøgle kom fra en person, bare fordi de får opsnappet, at beskeden på et tidspunkt blev sendt fra denne, for vedkommende kunne jo sagtens have fået den fra andre og så bare have sendt den videre. Og hvis man så har nogle få DoS'ere i netværket, så kan brugere der har sendt en nøgle der aldrig nåede frem jo pege på, hvem der kan have været de skyldige (af den række af brugere).\,. Hm, ja, men hvis man nu vil bevise det også, så kunne disse brugere.\,. Nå nej, man kan ikke bevise det på et VPN, men det gør vist heller ikke noget. For brugere skal jo stadig gerne sende flere nøgler pr.\ protokol, og hvor de så bare opsiger alle på nær én til sidst. Og hvis der så er en DoS'er i netværket, jamen da det ikke vil være fatalt, så må det være fint nok, at brugerne bare kan page dem ud nogenlunde. (Og hvis det så bliver et større problem, så kan man altid bare bruge den mere krævende blok-spiral-protokol, jeg har haft tænkt på.)} %(08.11.22, 10:27)
%
%
%
%
%
%
%
%%Hm, jeg har fået tænkt lidt over anonymitet, men det kan godt være, at jeg lige skal tænke lidt mere. Men jeg har altså fundet på nogen fine systemer til at skjule stemmeres identitet, og jeg tænker, at stemmere generelt skal kunne vælge enhver tredjepartsbruger til at videreformidle deres stemme anonymt. Sådanne kunne så med fordel få lov at give floating point værdier (i stedet for bare 0 eller 1) med deres stemmer, eller de kunne bare råde over et antal stemmer, således at de både kan give et antal positive og et antal negative stemmer til hver proposition (men jeg tænker at det første næsten er nemmest..). Og ja, så kunne én form for sådan en tredjepart så være en organisation med fysiske lokationer, hvor medlemmerne så kan møde op personligt og ændre deres stemmer og/eller repræsentanter, og hvorved organisationen kan opdatere deres stemmer herefter med en frekvans, der kan afhænge af, hvor mange ændrer deres stemmer ad gangen over en gennemsnitlig periode. Og en anden, meget smartere;), måde at have en videreformidlingsrepræsentant på, kunne så også være.. hm, lad mig lige se.. (13:50) ...(14:30) (ordner også vask) Jo, man kan også have en videreformidlingsrepresentant, der fungerer via mindst to tredjeparter, som klienten selv kan vælge. Først er der en trejdpart, eller instans bør vi nok hellere kalde det, bare.. som via asymmetrisk krypering får en nøgle fra hver bruger, som kun denne instans og hver enkelt relevant bruger må kende. ..Ja, eller på nær at de også så skal sende alle disse nøgler til en anden instans, der heller ikke må offentliggøre dem, og som så i øvrigt ikke ved hvor hver enkelt nøgle stammer fra (og må ikke få dette af vide af første instans). ..Hm, vent, giver dette mening..? ..Ah, jo, jeg kan få det til at give mening, men lad mig nu lige se.. (14:36) ..Hm jo, denne instans nr. 2 kan så også få en offentlig nøgle med fra brugeren til hver enkelt nøgle af første instans, sådan at denne altså bare får et sæt af nøgle par, hvor den ene er en offentlig nøgle. Denne instans kan så kryptere.. Hov, nej, så behøver vi faktisk ikke den første nøgle; instans nr. 1 sender altså bare et sæt af offentlige nøgler videre (gennem en krypteret kanal) til instans nr. 2. Denne offentliggør aldrig disse, men bruger dem hver især til at kryptere en besked med en ny nøgle i, og offentliggør alle disse krypterede beskeder. Brugerne prøver så at dekryptere dem hver især, indtil de finder deres egen.. Hm, er dette får ressourcekrævende, eller skal denne instans også lige tilknytte et meget lille hash a hver offentlig nøgle med beskeden, så hver bruger ikke skal igennem så mange..? ..Det kunne man sige.. ..although.. ..Tjo, men brugerne kan så stadig downloade alle beskeder i rækkefølge og så bare nøjes med at beholde dem, de skal tjekke.. Hm, lad mig lige tænke, om ikke der er en smartere løsning.. ..Hm, men ellers var pointen så, at enhver bruger, som ikke får en passende besked, bør så anråbe dette, hvorefter alle nøgler så skal indgives, sådan så man kan finde ud af, hvilken part var synderen (inkl. anråberen, hvis dette var en fejl), hvorefter man så kan starte forfra, muligvis uden synderen. Men når hver bruger så har fået en ny nøgle, som kan kan spores hen til dem, hvis alle de involverede instanser (for man kan godt have flere nr.-2-instanser her) bryder deres løfter og offentliggør deres data (og ikke bare sletter det kort tid efter). Nu kan man så være sikker på, at alle brugere i gruppen har netop én anonym nøgle, som nu kan bruges til at oprette en anonym bruger profil for hver bruger, selvfølgelig med VPNs involveret, hvormed denne frit kan afgive sine stemmer og ændre dem, hvornår det skal være, uden at det kan spores tilbage til dem. (14:52) .. ..Og disse anonyme brugere kan så udløbe således at de skal opdateres en gang imellem, således at hvis nu nogen for lækket deres bruger, så vil det allerhøjest kun være den seneste aktivitet, der bliver lækket (og derudover kan man selvfølgelig også dele brugeren op i flere (der ikke kan kædes sammen af andre), hvis man synes, der er besværet værd, men ja, og sådan vil der selvfølgelig altid være ting, man kan tilføje, hvis man finder frem til, at det giver mening..). Nå, men selv hvis der findes et bedre system end dette, så kan jeg jo bare skrive, at det f.eks. ikke er svært at finde på systemer, hvor man via flere instanser, der hver især holder på sin del af en samlet hemmelighed (hvor alle stykker skal bruges, hvis man vil spore tilbage), kan opnå at hver bruger i en gruppe får netop én anonym bruger. Og ja, hvis man så sørger for at de udløber med jævne mellemrum.. Og at brugerne skifter.. Hm.. ..Hm, men det er nu ikke perfekt anonymitet, hvis man sammenligner med valg, hvor ingen data bliver gemt til at starte med, således at ingen nogensinde kan spore det tilbage.. Hm.. ..Hm, men kunne man ikke bare bruge en teknik, som jeg vist også har tænkt på før, hvor en instans bare offentliggør en mængde af.. Hm.. ..Hm jo, en mængde af dens egne offentlige nøgler, nemlig med et antal svarende til antallet af klient-deltagere i øvelsen, og hvor hver klient så vælger et hemmeligt ID, krypterer.. Hm, nej, lad mig lige se... ..Hm, hvad med at alle klienter bare opretter et VPN kun med demselv som noder, og så begynder at sende data rundt. På et tilfældigt tidspunkt sender hver bruger så et ID videre til en naboknude, som modtager, sender ID'et videre til én naboknude, og noterer også ID'et og modtagelsestidspunktet.. nej.. Hm, dette virker vist næsten, men ikke helt.. ..(15:21) Ah, nu har jeg det måske. Man kunne lave en kæde af krypterede blokke, hvor hver blok offentligt hører til en klient, og hver blok rummer data, som brugeren fik tilsendt af ejeren af den tidligere blok, og data som brugeren har sendt videre til næste klient. Denne blokkæde kører så på omgang i en ring, således at den tager flere runder. Og på et tilfældigt tidspunkt tilføjer hver bruger så et offentlig nøgle, som de sender videre. ..Hm, nej det er endnu ikke helt vandtæt.. ..Ah, men måske hvis man tilføjer sin nøgle i krypteret tilstand, så den først kan lukkes op, når den når til en (tilfældigt udvalgt) anden bruger.. Hm, spændende idé.. (15:27) ..Ja, man må næsten kunne lave sådan et system, hvor klienterne billedligt talt danner sådan en rundkreds, hvisker data videre til hinanden én ad gangen i rundkredsen, og hvor klienter i kredsen så kan kryptere en hemmelighed, som en klient et andet sted så kan forstå. Denne bør så med det samme kryptere en ny besked, hvormed denne hemmelighed kastes videre til en anden person. Hemmeligheden er så en offentlig krypteringsnøgle. Man slutter så, efter et vist tidspunkt, når man er næsten 100 \% sikker på, at alle brugere for længst vil have kastet deres nøgle ind i rundkredsen, og at denne er læst af modtageren. Alle brugere offentliggør så de nøgler, der har været sendt frem til dem. Herefter skal alle brugere/klienter (jeg kan ikke lade være med at skrive "brugere" i stedet for klienter, men det er vel også næsten ligeså godt..) så sige, om deres nøgle er iblandt de offentliggjorte (men selvfølgelig ikke udpege dem). Hvis antallet af nøgler passer og alle brugere/klienter siger, at deres er med i mængden, så stopper "legen" succesfuldt. ..Eller rettere, det gør den, efter at man så beder alle brugere om at slette de nøgler, de ville have brugt til at dekryptere deres egne blokke med. Og sikkerheden i systemet handler så om, at man har tillid til, at størstedelen af klienter vil gøre dette (selvfølgelig fordi de bare bruger det udleverede software til det, og ikke har bygget eller tilegnet sig en malicious kopi af denne software).. Men hvis der er for mange nølger, eller at en klient mangler en nøgle, jamen så må man så bede alle brugere om at dekryptere alle deres blokke. Og så er pointen, at man kun ved at have alle disse blokke dekrypteret, kan finde frem til, hvem der er synderen, fordi man så både vil kunne se, hvis de ikke har opfundet netop én nøgle selv, og fordi man kan se, hvis de ikke har videresendt den rette nøgle hver gang.. Nå ja, og hver bruger skal så også bare i det hele taget indsende deres private nølger, så man kan finde frem til synderen. Og hvis enten en klient nægter at indsende den private nølge i dette tilfælde, eller hvis man finder synderen ved at dekryptere alle nøglerne, så må man så udelukke denne bruger i næste tur (altså give denne karantæne). Men ja, som sagt, hvis legen derimod ender succesfuldt, så skal brugerne endeligt ikke offentliggøre deres private nøgler, nej faktisk skal de slette alle deres nøgler, der blev brugt under selve legen og kun beholde den private nøgle, som passer til den offentlige nøgle, de herved fik indsendt anonymt via legen. Og ja, så længe de fleste brugere bare gør dette, så er man ikke i fare for, at det bliver afsløret, hvilke nøgler i slutmængden hører til hvilke klienter. :) (15:53) ..(16:02) Hm, der er faktisk en lille smule hangman's paradox tilstede i denne løsning, men det kan man vist gøre bod på ved bare at sige, at hver knude.. Hm.. ..Hm, eller hvad i stedet med bare at gøre sådan, at klienter i kredsen generelt skal vente et tilfældigt antal omgange, inden.. hm, men det løser dog ikke problemet eksakt.. (16:07) ..Hm, men jo, man kunne vel også bare sørge for, at sandsynligheden for at ens software sender en nøgle starter virkeligt lille og kun vokser over mange runder, og så kunne man gøre sådan, at hvis en bruger bagefter kan se, at deres software har sendt.. Hov, vent, dette er da slet ikke et problem, netop fordi man kaster hemmeligheden frem i rækken.. hm.. ..Hm, der skal kun tre (specifikke) andre brugere til at afsløre en i denne løsning, men de kan det kun hvis man har været uheldig at softwaren har sendt ens nøgle tidligt.. ..Hm, man kunne også bare give hver bruger mulighed for at afbryde legen, hvis deres sofware har sendt deres nøgle tilstrækkeligt tidligt.. Hm.. ..Hm, i øvrigt kan man hurtiggøre processen, hvis kredesn har mange kæder i gang på én gang, så alle klienter kan bygge en blok i hver runde (nemlig hvis der er ligeså mange kæder i gang, osm der er klienter i kredsen).. ..Hm, men kan man ikke bare generere flere nølger, end der er behov for..? (16:18) ..Jo, og så kan brugerne/klienterne til sidst bare vælge, hvilken nøgle af dem, de har fået genereret i legen, de vil beholde, ved at.. Hm.. ..Ah, ved selvfølgelig bare at bekende offentligt bagefter, at "disse nølger var mine, men jeg skal ikke bruge dem alligevel."!:) Og hvis så der lige præcis bliver det samme antal efterfølgende, som der er klienter, og hvis alle meddeler, at de har en nøgle iblandt de endelige, så når man i mål, og ellers må man så bare til at optrævle kæden, for at finde DoS-synderen, hvis ikke legen ender som den burde. :) (16:25) Og ja, det skal så bare anbefales, at hver bruger ikke vælger en nøgle, der blev genereret helt i starten af systemet, men ved at det stadig er brugerens beslutning at udvælge den ønskede nøgle, så eliminerer man altså hangman's paradox.:) (16:26) ..Nå ja, og lad mig lige præcisere, at hver blok så skal indeholde en liste af krypterede nøgler (som hver er kryperet med en tilfældig andens offentlige nøgle), og denne lister vokser altså bare.. tja, eller man kan måske begynde at fjerne ting fra bunden af listen efter et vist stykke tid, når det er sikkert, at samme nøgle er blevet indsat igen i ny version (nemlig ved at en knude har dekrypteret og re-krypteret nøglen og sat den på). Og man kan så kræve, at hver knude tilføjer netop én ting til listen i hver runde.. how, "runde" er et dårligt term at bruge for hvert enkelt lille step, når vi har en rundkreds, så lad os kalde.. tja, lad os bare kalde det enten hver 'step'/'skridt' eller hver tur.. nej, lad os udelukkende kalde det 'skridt'/'step.' Og hvis en bruger så modtager flere beskeder på én gang i et step.. ..Hm, nej vi kan også godt kalde det turn i stedet (for så tænker man jo bare på et lille turn af hjulet).. Så må denne bruger så altså gerne vente en omgang med at sende nummer 2 besked (osv., hvis der modtages flere end to), og altså så kun videresende én af nøglerne i den første tur, hvor nøglerne modtages. Ok, så det var vist bare det, jeg lige skulle præcisere.. (16:40)
%
%%(16:42) Nå, men der er også et andet issue, jeg skal tænke over, og det handler om: Vil det ikke være for fristende for folk at stemme på deres vante repræsentanter i et regeringsvalg, hvor et e-demokrati kæmper, og ser ud til at kunne vinde? For hvis man gør dette, så vil man vel kunne få dobbelt magt, medmindre e-demokratiet kan se, hvem der ikke stemte på det.. hvad de jo ikke vil kunne.. Hm, måske er dette et ret stort problem, men ja, nu vil jeg altså give mig til at tænke godt over det... (16:44)
%
%%(31.10.22, 9:21) Kort efter, jeg klappede i i går kom jeg frem til, hvad vist også havde været oppe at vende i periferien af mine tanker tidligere på dagen, at den simple og måske eneste løsning nok bare er, at sørge for, at e-demokrati-partiet i starten også har til opgave at booste stemmevægte inde i systemet (på en helt transparant måde selvfølgelig), således, at alle repræsentanter, der ellers har fået mandater udover partiet, de får en modvægt til sig inde i partiet. På den måde kan det ikke betale sig at stemme uden for partiet for at pågældende mening skal få mere magt, for så vil den pågældende mening bare blive countered. Og ja, det er så partiets opgave at finde frem til og være ærlig omkring, hvad der er midten af det politiske spektrum i henhold til forskellige punkter, således at man kan counter'e et vist mandat ved at give mere magt til en (eller flere) fra den modsatte (i.e. spejlede) ende af spektrummet. Når partiet så er i regering, så kan man så også bede de repræsentanter, der ikke er med, om at joine, for så vil e-demokratiet bare fjerne magt igen fra dem, der står for at counter'e/udbalancere magtbalancen.. (9:29)
%
%
%%\section{A note on transparency}
%
%
%\section{E-democracies in companies}
%
%%To finish this chapter, let me just make a small point about how an e-democracy application like this might also be incredibly useful when it comes to democratically run companies, or indeed the almost-democratically run `Economically Sustainable' Companies (ESCs.\,. hm, that looks a lot like `Escape(s)'.\,.) that was described in Chapter \ref{MSE}. 
%%
%%If the company in question has a goal of expansion, such as should be the case for the 
%
%To finish this chapter, let me just make a small point about how an e-democracy application like this might also be incredibly useful when it comes to democratically run companies, or indeed the almost-democratically run `economically sustainable' companies that was described in Chapter \ref{MSE}. 
%
%If the company in question has a goal of expansion, such as should be the case in general for the `economically sustainable' companies as described, I envision that this venture will be all the more exciting for the participants if there is a vibrant online community that engages in discussing and finding what strategies to go ahead and try in order to expand the company. 
%
%And if this e-democracy application can be as useful a tool for this as I believe it can, it could thus accelerate the interest in taking part and supporting such a company immensely. 
%
%%Hm, skal jeg så bare stoppe her for nu? (Eller skal jeg skrive videre på denne sektion, og var der i øvrigt andet, jeg har glemt at nævne..?) (15:21) ..Hm, jeg har glemt at nævne min pointe omkring gennemsigtighed ved at sørge for, at folk med jævne mellemrum bliver udtaget til at sætte sig ind i detaljerne og så rapportere tilbage til den interessegruppe, der udvalgte vedkommende, men måske jeg bare skal gemme denne pointe til en anden gang.. (15:23)
%%...(16:01) Nej, jeg tror ikke, jeg behøver at tilføje mere nu. Når jeg så lige får tænkt lidt mere over spiral-protokollen, så kan jeg skrive om den, og ellers er det nok bare lige at redigere teksten. (16:02)
%
%
%
%%Husk:
%	%Jeg havde tænkt mig her at nævne det med, at det kan være smart at udvælge nogen (som så jo kan vælges til at være upartisk og/eller repræsentativ (men måske smart/intelligent nok)) fra en gruppe til at studere og gennemgå systemet i nærmere detaljer og så rapportere tilbage..
%	%Transparancy.
%	%
%	%You never have to waste a vote (and never have to fear wasting a vote). And never have to be fearful, that who you voted for does something you didn't expect (since this system requires no trust in representatives, at least not except in cases why you don't feel like you have the time (or interest) to go through the details of a matter).
%	%..(16:47, 29.10.22) Hm, og husk det her med at man kan have flere områder, hvor forskellige bestemmer, og at dette så også gør, at andre grupper kan logge sig på i systemet, hvor vi snakker om at styre et land. I et sådant e-demokrati kan grupper altså også tilføje områder. På den måde kan de gøre det offentligt for alle, hvad de har tænkt sig. Hermed kan vi altså få en stor markedsplads, der handler om at lave aftaler og bestemmelser, både i regeringen, men også i andre instanser (det kunne f.eks. være såsom fagforeninger, hvilket jo vil være meget relevant i den sammenhæng). ..Og ja, det kan også være grupper, der egentligt ikke har nogen anden magt over noget, men som alligevel vil oprette et område, der hedder "vi mener sådan og sådan, og vil vil gøre sådan og sådan," altså et område, hvor de kan signalerer til omverdnen, hvad deres interesser er, og hvad de gerne vil / er parate til at gøre. (16:54) ..Og ja, det kan så nævnes, at dette så også kan være sådan noget som at trække sig fra den overordnede gruppe (f.eks. e-regeringspartiet eller trække sig som kunde og/eller investor i et firma). 
%	%Jeg kunne godt nævne muligheden i "forbrugerforeninger" kort også (som et eksempel på anden form for magt), men så tilføje, at min kd.v.-idé så netop nok ville være endnu bedre her, for så kan man undgå sådanne reprimanter (eller hvordan det staves). Men om ikke andet kunne det så blive en måde at tvinge gang i en kd.v., hvis nu virksomhederne indenfor en branche er tøvende med det. 
%	%Jeg skal forresten huske at have område-repræsentanter med under avancerede punkter, sammen selvfølgelig med områderne selv. Jeg kan således nok godt nævne "områderne" først, også selvom det egentligt er vigtigere, det med at kunne vælge repræsentanter.. 
%	%"Det handler om at det bliver: meget lettere at samle sig i små grupper, og meget lettere at sætte i gang i en proces, hvor man overvejer, om ikke der kan gøres noget ved et forhold, netop fordi man bare kan starte denne diskussion i nogle små grupper (som så kan kontakte andre grupper, små eller store, når de har fået samlet en oversigt over, hvad problemet er, og hvad man kunne gøre for at løse det m.m.). Så altså langt større tilgængelighed for den enkelte og dermed mange mange flere mennesker aktiveret ad gangen (som så overvejer og finder på løsningsforslag til problemer i samfundet (ofte særlige problemer for nogen specifikke i samfundet, men det kan jo også være mere almene)). Og så vil der så derefter også kunne være meget kortere tid til, fra løsningsforslag til løsning i sådan et direkte demokrati, der er klart. Og ikke mindst vil folk (i grupper) få langt nemmere mulighed for at indgå selv komplicerede politiske aftaler med andre folk (i grupper (ikke nødvendigvis disjunkte med de første, btw)), således at man får et meget bedre og hurtigere kan få handlet sig til at få opfyldt sine behov som en gruppe af mennesker, og således at smafundet derfor vil blivet meget bedre fintunet, så at sige, til at opfylde så mange menneskers forskellige behov som muligt på en gang."
%	%(15:01, 01.11.22) Jeg skal huske noget, jeg lige fik tænkt på, og det er, at et sådant demokrati kan få en meget meget fladere struktur, hvor at man, når man har en ny idé til forandring, lad os sige som lille gruppe, i stedet for så at skulle indsende og ansøge om idéen til en central, så kunne man i første omgang dele den, med den/de mest relevante nabogruppe(r). Hvis de så også er med på den, så kunne man så brede det til endnu flere. Og når idéen så har samlet nok opbakning, så kan man melde det til det brede fællesskab, hvor idéen så allerede har opbakning, når den ansøges om. Jeg ved godt, at sådanne måder at fremføre idéer på allerede finder sted mange steder, men jeg tror, at man i et e-demokrati kunne gøre den fremgangsmåde endnu nemmere og endnu mere hyppig.. Hm, måske vil jeg skrive om dette, men om ikke andet er det da bare rart at tænke på, at der kunne blive sådan en rigtig flad struktur, hvor relaterede grupper selvstændigt kan diskutere og handle om, hvilke idéer og forslag, man vil gå videre med..:).. (15:08)
%	%Man kan også bruge min blok-spral-idé til når stemmerne skal kastes..!
%
%
%
%
%
%
%%(09.11.22, 9:46):
%\section{(I'm considering adding something like:) A similar application for scientific discussion}
%
%\textit{I have now realized that this application could also be used for scientific discussion graphs, which goes hand in hand with decision making since facts are of course important when deciding policies. In a discussion graph, on would just not really need the `conditional node' edges, but would instead just use the `conditional votes' instead --- which could then be drawn as edges between notes for this type of application. %(This all of a sudden make this idea quite a bit more interesting for me in terms of what I would like to work on myself.\,. .\,.\,Hm, hvilket er relevant for mig at have i tankerne i denne stund, for jeg skal nemlig snart til jobsøgeningsmøde med A-kassen. Og ja, med denne indsigt, så må det da næsten være denne idé, jeg vil prøve at gå videre med (og sige jeg vil iværksætte), det tænker jeg.. (..Altså i stedet for Web 2.0--3.0-idéen/erne.))
%*And it should then be very much recommended (as a key part of the idea), that users try to commit themselves to continuously update their votes for propositions as conditional ones, once more fundamental propositions are added to the system. A scientist might for instance be an expert on drugs and say (or actually ``vote'') that: ``this drug is so and so addictive,'' but then once propositions are added about the existence of relevant studies are added, as well as propositions about trust, then that scientist (along with everyone) are then strongly recommended to change the vote into a conditional vote such that the vote now depends on the study existence proposition and the trust proposition. This way (if the community follows this (strong) recommendation), every proposition can slowly become more and more founded in the basis empirical propositions/data, plus trust propositions (which are essentially propositions about how the users want to apply epistemology, i.e.\ when these propositions are also boiled down to their roots). This both has the advantage of the system being more flexible, when new studies turn up or if old ones come into question at some point, and also, importantly, it makes it easier to browse and find out what fundamental facts our more abstract facts in society are built on, i.e.\ to find the sources, and it also gives a better and easier understanding of what is interesting to research, since it shows were the ``gaps'' are, so to speak, or more precisely: where the research is thin and could use bolstering. 
%}
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%%\chapter{A possible road towards Web 3.0}
%%
%%
%%**(Lad mig bare lige skrive, hvad jeg tænker nu at skrive i dette afsnit/kapitel bare ud i én køre, og så kan jeg altid redigere bagefter..) %(06.11.22, 9:46) (Jeg fik nemlig lige tænkt en del over emnet igen i går aftes, og nu synes jeg alligevel, at jeg bør kunne forklare meget af det ret kortfattet..:))
%%*(Okay, jeg har alligevel ikke tænkt mig at beholde dette kapitel, men lad mig bare lige skrive denne køre færdig, også fordi jeg har nogle små nye gode tilføjelser, mener jeg..)
%%
%%
%%\section{Everything section}
%%
%%
%%My idea for how we can reach the promises of Web 3.0, and specifically the Semantic Web, is to first implement a Web 2.0 site with an underlying semantic structure and then really try to give the users a lot of power to redesign things on the site and to program algorithms themselves. This implementation of the Semantic Web then does \emph{not} rely on XML/HTML. Instead, all semantic sentences should be recorded in relational database. 
%%
%%This is radically different from the first implementations of the Semantic Web, where metadata is simply added to various sites and resources on the web, and then algorithms in the Semantic Web would simply work by querying the web (i.e.\ the World Wide Web) and finding the necessary information online. But when all the semantic sentences (what is also called triplets in the current conventional implementations) are stored in one database, the algorithms can run way faster. 
%%
%%Essentially, one can say that the idea is to start out with a Web 2.0 site as we know them, e.g.\ such as YouTube, Reddit, Twitter, etc., and then implement the Semantic Web there. But hold on, you might say, it can hardly be called the Semantic \emph{Web}, if it is controlled by a private company. No, but if it is instead controlled by a open source organization (similar to how the web is run today, e.g.) it is another matter. Hereby it can be ensured that no one owns all the user contribution, save perhaps for the relevant user, and that any other organization can always come and take up the mantle at any time, should it be needed (just how it also is with Wikipedia).
%%
%%Alternatively, if starting this idea as a non-profit organization is slow and lacks investment, one could also start it as the type of company as described in Chapter \ref{MSE}, such that the ``organization'' can start out as a private, commercial company, but where it is guaranteed that the users will slowly become the owners. 
%%
%%But let us move on from this topic for now and assume that the organization will have plenty of funding (just like Wikipedia has). 
%%
%%
%%Let me now try to explain the overall design of a Web 2.0 site that I envision, which has an underlying semantic structure. Some of the details here are more important than others (and some are less), but it is nice to see a good example that could work (and attract many users), and then from there, I can explain why the underlying semantic structure becomes important. 
%%
%%If I were to design such a Web 2.0 site, where the intention is that it can grow into a Web 3.0 site over time, I would probably give it this following initial design:
%%
%%A main feature of the site should be a page with a category tree, which I would implement basically as a structure of tabs, i.e.\ the kind of tab system we see everywhere in the interfaces of Windows and Mac applications and so on. Whenever a new tab is selected, it will then potentially open a new list of sub-tabs. The user might thus have selected the category `movies' as a tab, and then a submenu of movie categories should open. Thus, we get a category tree (which hopefully should be pretty quick and easy to navigate as a user). Whenever a new list of (sub-)tabs is in focus, it should be expanded as a whole box of selection, in fact one might even implement it as a whole HTML page at some point (instead of just a box containing a lot of tabs). But when a tab/subcategory is selected, the box/page should nevertheless collapse into just a single bar of a horizontally adjacent tabs, where one tab is then selected. And underneath, the new subcategory selection should then automatically expand. Also, if a user has navigated down into a category tree, but want to go to a different super-category, the user can either just click on some of the visible tabs in the one of the above tab bars (which are aligned vertically adjacent, each with tabs aligned horizontally adjacent), or he/she can expand that given tab box once again.
%%
%%Okay, that was a lot of details to explain a very simple design, but it is nice to have an example to hold on to, and one that does the job. But of course, there could be many other types of design that this Web 2.0 site might start with.
%%
%%Moving on, now that we have a category tree, we should also have some resources in it, of course. So at the same time as the user selects these categories and subcategories, there should be a list of resources at the bottom that is updated in principle whenever the user chooses a new category (although the user might want to click a button manually to make the resource list refresh such that it doesn't refresh al the time while the user is navigating the category tree).
%%
%%When the user then selects a resource from the list, the user is led to a the page of that resource. That resource is then displayed pretty much at the top of that page. And how the resource is displayed then depends on what kind of resource it is, i.e.\ whether it a video or a HTML page, and so on. And each resource should then also have a list of comments below, but similarly to the all the main resources of the site, if we can call them that, these commant should also be ordered in a similar category tree. Examples of different categories of comment could be `related resources,' `user reactions,' `related discussions,' `links to source material,' and so on and so forth. 
%%
%%And to finish up this description of this basic design, there should also be a homepage where each user can see one or more lists of the user's favorite categories and resources, such that the user can quickly navigate to some of their favorite spots in the category tree (without having to start from the root and navigate down).
%%
%%Okay, that was a quick sketch of a quite basic site design. 
%%%
%%%...Jeg har fået tænkt lidt mere. Nu ved jeg faktisk bedre, hvad man skal sige gælder for de rating-tal, der skal følge med sætningerne/tripletterne. Jeg tror ikke, det vil tage mig lang tid at færdiggøre denne hurtige udredning herfra, men lad mig lige se, om jeg lige vil skifte emne lidt og skrive på noget andet, eller om jeg vil holde en lille pause.. 
%%%...Okay, jeg prøver at skrive færdigt..
%%%
%%Now I can get on to some of the stuff that is actually interesting.
%%
%%Assuming that the reader knows about the Semantic Web (and about triplets and so on), the reader might have already guessed that the categorization of the resources should then of course be user-driven. The users should thus be able to say for instance: ``this resource belongs to this category,'' and thereby be able to vote resources into various categories. Note that ``this resource belongs to this category'' can be implemented as a triplet. The users should also be able to say ``this category is a relevant subcategory to show under this other category.'' The users should thus also be in control of the category tree --- and of the category trees under each resource (where one can reuse resource category trees for similar types of resources).
%%
%%So far so good: One thus get a Web 2.0 site where the categorization structure is semantic and user-driven. And because it is semantic, all the user data can easily be reused in for other similar sites, and specifically also for other implementations of the site in question.
%%
%%If such a Web 2.0 site can become more and more popular, and if it is run by an open source organization (and/or community) as mentioned, this site might thus effectively become all that people hope for in terms of what Web 3.0 might bring.
%%
%%Okay, at this point I have explained the overall idea, and also explained an overall type of implementation that could be the starting point for a Web 2.0 site that thus aims to become, what we could call af Web 3.0 site (bringing forth the features that people hope for in Web 3.0). Now I will move on to the \emph{really} intersting stuff, because I actually have a few idea that i believe can make such a ``Web 2.0--3.0 site,'' as I like to call it, really take off! 
%%
%%I actually believe that \emph{triplet} system will not be enough to carry forth a really useful Semantic Web (which is a big part of people associate with Web 3.0)! %(12:44)...
%%
%%First of all, it is important that the ``triplets,'' but let us actually just call them `relations' or `sentences' instead, should contain the user ID of who uploaded it, as well as a timestamp for the upload. So they should not just have the three entries. Second of all, I think it is \emph{so} important for the usability of the system, that each relation/sentence can also include a number (with whatever precision is appropriate for the case) that signifies a rating of \emph{how much} the user believes the sentance to be true. 
%%
%%This makes it possible to \ldots \textit{Okay, jeg har skrevet så meget af det her allerede, så lad mig ikke gentage alle pointerne her, nemlig da jeg nu igen har besluttet mig, at jeg alligevel bare børe vente med at fokusere på dette emne. Så lad mig i stedet bare lige ridse mine nye tilføjelser op.\,.}
%%
%%Okay, let me make this short and just mention the new thoughts that a had about this idea. The rest of the ideas, as well as the explanation of why they will be so good, can be found in my 21--22 notes (in \texttt{main.tex}, as the document is still called in the moment of writing).
%%
%%My big idea for making it easy and attractive to rate the resources on their lists, is that they can simply drag them up and down on the lists to rate them (according to the proposition that they are viewing). So when the user moves the resources in the list around, it should generate sentences/relation to the database, where the rating number in these relations are determined by where the user drops the resource in the list (and where only the most recent adjustment applies (which is what the timestamp is useful for determining)). The number might run from 0 to 1, or from -1 to 1, or whatever; that does not matter much (and the site can always change the conventions and then simply convert the previous data to such that it is scaled to the new convention). And the scale should only be very vaguely defined. The real precision that the user should worry about is how the number related to the neighboring resources on the list. So if the user believes, say, a movie to be incredible, and it has a low rating, the user might want to pull it up closer to 1. But if the question is, should it have a 0.6 rating or a 0.9 rating (assuming 1 is the highest score), that should actually only depend on the existing scores of what movies have received scores in about that interval. So the underlying rating should thus be primarily defined in relation to what resources are already rated. And then! If one wants to turn the resulting rating into one where points on the rating axis is more precisely defined, one can then just (and should be able to), upload a translation of that rating, which is basically a conversion function that takes the primary rating and converts all the numbers to the new rating. This `translation' function can then simply be defined by taking a bunch of resources, plotting them in on the list, and then use statistics after that to plot in all the other resources on that new axis (with an updated metric). And by putting a Gaussian ``error'' on all the ``fixed'' resources on this new axis, one can make sure that this process does not run into contradictions. So in short: The normal rating axis that is used when users drag and drop resources to rate them should have very vaguely defined semantics to begin with, and then the users can always translate the resulting axis from all the user activity into something with a more precise meaning, simply by defining a new metric for the axis that moves the resources into new positions on the axis.
%%
%%I also want to mention that when users drag and drop resources, they should be able to dial up and down the number of resources shown on the list as the drag and drop. Here, a setting to show few items in the list could thus only show the most `popular' items, i.e.\ such that an external predicate can be used for defining this setting, other than the predicate that orders the list. The lists should thus also have `filters,' and these filters should have different settings. And if the user can change these settings by hitting some keys, they can basically ``zoom in and out'' in the lists, namely by changing the filter dial to show fewer or more `popular' items, e.g. The user can then be ``zoomed in'' and chose a resource to rate. The user would then start draging it up or down, but since the list is long when ``zoomed in,'' the users might then hit the key to ``zoom out'' while dragging the resource. And when the user find the desired spot to drop it, the user might even not drop it right away, but ``zoom in'' a bit first to find a more precise spot for the resource. 
%%
%%Okay, I think that was it.\,. no, wait, maybe I also want to quickly reiterate something about the subcategories actually being implemented via `compound predicates,' and also that when rating such predicates, the user actually have to rate each atomic predicate individually (such that the `compound predicates' are not meant for rating, but only showing resources in a list.\,. oh, and then if the user wants to filter the list such that only resources of the one category/predicate is shown while rating resources in terms of another predicate, the user then just has to use the `filter' that I just mentioned.\,.).\,. Hm, no, I think that I have already covered these point in my 21--22 notes (in \texttt{main.tex}). So let me just stop again with this subject for now.\,. 
%%
%%\ldots\ Well, let me just mention another thing quickly, namely that the site might also use some automatically generated meta-sentences/relation, such as: ``this resource was uploaded by this user'' or ``this resource was uploaded as a comment to this resource.'' These are thus automatic sentences/relations that the site itself is responsible for applying to all uploads.
%%
%%.\,.\,Oh, and I also intended to mention something else, by the way: I wanted to mention that certain resources, e.g.\ HTML resources (or other markup), might actually get access to the database themselves. For instance, a HTML document might say ``insert a list of the top resources in this category here'' or something like that. More generally these resources might thus be able to query the database when they are viewed and change their appearance after what is contained in the database. (And this way, the site can thus also implement my so-called ``wiki-idea'' from the 21--22 notes.) 
%%
%%\ldots And yeah, all that jazz about `user groups' to distribute trust, and about the user-driven filter algorithms, about rating tags, and about so on and so forth, all that is written about in my 21--22 note collection, I don't want to try to repeat these things now.\,:) %(14:29)
%%
%%%(07.11.22, 10:32):
%%\ldots\ Oh, and I of course also need to mention an important point, and that is: Sure the idea could work as an organization, but if we think about e.g.\ YouTube and Twitch, the commercial part is a big part of what makes those sites work. And by using my ``Economically Sustainable'' (ES) companies instead, the Web 2.0--3.0 site would still be able to give big rewards to the users who create popular content. And on that topic, if I were in charge of such a company, I would try to bring the average user on as soon as possible, given them some vote and some say in how the creators should get paid (how much in total, perhaps, and more importantly: how it should be distributed). I thus envision an e-democracy using the system described above for all the users, where their decisions in this e-democracy will be heard by the company, at least if it is reasonable (and in fact, the company could also be a part of the e-democracy, giving it self a significant weight on its vote, which would then make it easier for the company to keep to its promise of listening to that e-democracy). And of course, since it is an ES company, this e-democracy will be more a representation of the true power over the company, not just power that is ``lend out'' to the users, as long as their decisions does not stray to much from the company's wishes. *(This last sentence does not seem to make a whole lot of sense, but I guess I just needed to point out that if the company is what I am currently calling an 'SRC,' the users will also eventually get that power \emph{within} the company..)
%
%
%%*(26.11.22, 9:01) I mentioned movies at some point above as an example of a category of resources. That does not mean that the site then has to contain all the movies themselves; the resources can simply be reference-type resources (such as kind of movie ID, etc.). And since users should be able to control how resources in different categories are generally viewed, meaning that they can add HTML-wrappers to the resources, they can thus make it so that all movie refernce resources are viewed with potential links to site where they can be viewed or what not (the HTML code can fetch anything that is desired from the database (and/or from the web)). 
%
%
%*(20.12.22) I should also mention, that I imagine that all sentences/relations (formerly known as triplets) should be signed by a private key of the user, which is publicly associated with the (or \emph{is} the) user ID. This way you don't have to trust the particular server when it comes to who uploaded what and when. 






















\end{document}