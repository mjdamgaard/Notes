\documentclass{report}
%\usepackage{style}
\usepackage[utf8]{inputenc}


\usepackage{amssymb}
\usepackage{comment}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{braket}
%\usepackage{listings}
%\lstset{
%	basicstyle=\ttfamily\footnotesize,
%%	literate={~} {$\sim$}{1}
%}

\usepackage{latexsym}

\usepackage{siunitx}
\usepackage{textcomp}

% \usepackage{mathabx}

\usepackage{lipsum}


\newcommand{\bsacc}[3]{#1{\boldsymbol{#2}\hspace{#3em}}\hspace{-#3em}}

\newcommand{\hatbsp}{{\bsacc{\hat}{p}{.15}}}
\newcommand{\dotbsq}{{\bsacc{\dot}{q}{.15}}}
\newcommand{\barbsx}{{\bsacc{\bar}{x}{.05}}}
\newcommand{\barbsq}{{\bsacc{\bar}{q}{.2}}}




%\usepackage{fullpage}
%\usepackage[margin=1.4in]{geometry} % = hvad jeg har i mine main-noter.
%\usepackage[margin=1.0in]{geometry} % = fullpage.
\usepackage[margin=1.0in]{geometry}

\title{QED notes (19.01.22--26.09.22)}
\author{Mads Juul Damgaard}
\date{\today}

\begin{document}
\maketitle

(19.01.22) Read ``Genaral notes$\to$Andre opfølgende noter$\to$Mere om QED'' (in Danish) in the main note set for an understanding of where I am/was at when starting these notes. Except that now I have found out that my strategy for showing that Range$(\hat H \pm i I)$ is dense does not work. (I also already have some plans for how I will write my small paper that I have not written about anywhere. I thus have an overall ``disposition'' in mind, as it is called at least in Danish (i.e.\ an overall structure of the text). But whether it holds I cannot say, especially now that I am not even sure that I can prove the self-adjointness of the operator.)
{\\\centering\noindent
	\vspace{-\baselineskip}
	\hspace{-2.5em}
	{$|$\hspace{\linewidth}\hspace{2.5em}$|$}
}

\chapter[]{Work notes on showing symmetry and self-adjointness of $\hat{H}$}


\section[]{Lad os prøve med et simplificeret $\hat H_I$ \ldots}
(19.01.22) Lad mig prøve at se på en interaktions-$\hat H$, der bare er lig noget simpelt såsom 
\begin{align}
	\hat H_I = \sum \frac{1}{\sqrt{|k_2 - k_1|}}\psi^\iota(k_2)\psi^\kappa(k_1)(a(k_2 - k_1) + a^\dagger(k_1 - k_2)).
\end{align}
Hm, og min fremgangsmåde handler jo så om at udvælge nogle områder af $k$-rummet, som så skal bruges til hele tiden at kvæle alle haler efter et vist punkt.\,. 
%Nå, jeg tror nu lige, jeg går en god eftermiddagstur, for jeg var stort set ikke uden for døren i går...

\ldots Nå nej, lad mig bare se på (endnu mere simpelt)
\begin{align}
\hat H_I = \sum \frac{1}{\sqrt{|k_2 - k_1|}}\psi^\dagger(k_2)\psi(k_1)(a(k_2 - k_1) + a^\dagger(k_1 - k_2)).
\end{align}
til at starte med, og hvor fermionerne altså også bare er 1-spinorer. .\,.\,Hm, og lad mig i øvrigt også lade $\Delta k_{2 1}\equiv k_2 - k_1$ (osv.) fra nu af. %.\,.\,Hm, og ellers kunne man også kalde den %..nvm

Okay, lad mig bare starte med at prøve at konstruere en tilstand, der kan være i $\hat H_I$'s domæne. Hvis vi starter med en en-partikel-tilstand lige omkring $\delta(k_0)$ *(eller $\ket{k_0;\,}$), så vil den blive til en bølgefunktion af en uendeligt stor (non-)tilstand lige omkring
\begin{align}
\begin{aligned}
&\iint \frac{1}{\sqrt{|k - k'|}} \psi^\dagger(k)\psi(k') \big(a(k - k') + a^\dagger(k' - k)\big) \ket{k_0;\,}\,dk\,dk'
=\\
&\int \frac{1}{\sqrt{|k - k_0|}} \psi^\dagger(k) a^\dagger(k_0 - k) \ket{\,}\,dk
=\\
&\int \frac{1}{\sqrt{|k - k_0|}} \ket{k;k_0 - k}\,dk,
\end{aligned}
\end{align}
når man opererer naivt med $\hat H_I$, hvor $\ket{}$ er vakuumtilstanden, og hvor $\ket{p_1, \ldots, p_n ; k_1, \ldots, k_m}$ er en tilstand med $n$ fermioner og $m$ bosoner.\,.

Og ja, $k$ er altid i tre dimensioner; jeg gider bare ikke lige at gøre dem fede. 


Lad os så sige, at jeg gerne vil tilføje en 2-bosons-tilstand til at eliminere halen af denne tilstand helt efter en grænse, lad os kalde den $\lambda$ for nu.\,. 
%Jeg regner ikke med at blive ved med at tilføje disse ligegyldige noter herude i kommentarerne, men jeg har nu lige lyst til at kommentere og sige, at jeg lige føler, jeg har brug for en pause, også selvom jeg ikke som sådan har lavet så meget i dag (udover at gå en god lang tur). Klokken er godt nok allerede halv fem, men jeg stod så også ret sent op.. 

\ldots Okay, jeg behøver vist ikke at gøre så meget ud af det endnu; pointen er bare, at jeg skal lægge en række fler-boson-tilstande (med lige boson-antal) til, som så kan spise hinandens haler/overgangsamplituder. Så vi skal altså have en bølgefunktion på formen,
\begin{align}
\begin{aligned}
\ket{\psi} = &\, \ket{k_0;\,} + \iint \psi_2(k', k'') \ket{k_0 - k' - k''; k', k''} \,dk' \,dk''\\
	&\,+  \iiiint \psi_4(k', k'', k^{(3)}, k^{(4)}) \ket{k_0 - k' - k'' - k^{(3)} - k^{(4)}; k', k'', k^{(3)}, k^{(4)}} \,dk' \,dk''\,dk^{(3)}\,dk^{(4)}\\
	&\,+  \ldots\\
= &\, \ket{\psi_0} + \ket{\psi_2} + \ket{\psi_4} + \ldots,
\end{aligned}
\end{align}
og her skal $\ket{\psi_2}, \ket{\psi_4}, \ldots$ så altså gerne have endelig norm hver især, og deres normer skal også gerne summe til noget endeligt. Og ja, det mener jeg jo godt, kan lade sig gøre. Men lad mig så prøve at se på, om $\hat H_I$ kan være symmetrisk over en mængde af sådan nogle tilstande.

(Lad mig forresten kalde hæve-sænke-operatorerne for fermionerne for noget andet end $\psi$ til den tid. Det kunne f.eks.\ være $v$ og/eller $u$.\,.)

Hm, lad os se på et $\ket{\psi} = \ket{\psi_0} + \ket{\psi_2} + \ket{\psi_4} + \ldots$ og et $\ket{\phi} = \ket{\phi_0} + \ket{\phi_2} + \ket{\phi_4} + \ldots$. .\,.\,Hm, så skal jeg jo lige overveje i første omgang, hvordan f.eks.\ $\hat H_I \ket{\psi}$ ser ud.\,. Jamen det vil jo så bare være det, man vælger at lade stå tilbage, når f.eks.\ $\ket{\psi_2}$ spiser halen fra $\ket{\psi_0}$'s overgangsamplituder til 1-boson-rummet. Så vi har vel 
\begin{align}
\begin{aligned}
	\hat H_I \ket{\psi} = \ket{\psi_1} + \ket{\psi_3} + \ldots,
\end{aligned}
\end{align}
hvis vi vælger at kalde dem det. Og så vil vi så ikke få noget fra et indre produkt med $\ket{\phi}$, hvis dette er en tilsvarende tilstand. Men hvis det er en tilstand, der tager udgangspunkt i f.eks\ldots\ Hm, hvis nu jeg havde kaldt $k_0$ for $p_0$ i stedet, så kunne jeg lade $\ket{\phi}$ tage udgangspunkt i  $\ket{p_0 - k\ldots;}$\ldots\ Hm, eller måske var det egentligt fint bare at bruge $k$'er.\,. Ok, så udgangspunkt i: $\ket{k_0 - k_1; k_1}$.\,. Så vil
\begin{align}
\begin{aligned}
	\braket{\phi| H_I \psi} = \braket{\phi| H_I \psi_0}  + \braket{\phi| H_I \psi_2}. 
\end{aligned}
\end{align}
Her er $\braket{\phi| H_I \psi_0}$ så givet på forhånd, men $\braket{\phi| H_I \psi_2}$ afhænger af, hvor meget vi har valgt, at $\ket{\psi_2}$ skal spise af $\ket{k_0 - k_1; k_1}$-tilstanden.\,. .\,.\,Hov nej, nu glemmer jeg, at $\ket{\phi}$ jo ikke skulle være lig $\ket{k_0 - k_1; k_1}$, men bare tage udgangspunkt i tilstanden, ligesom at $\ket{\psi}$ gør for $\ket{k_0; \,}$.\,.
%Hm, jeg tror nu bare, jeg vender tilbage i morgen. Det virker ikke som så meget, jeg fik nået i dag, men sådan er det jo bare. Jeg summer dog nok lige lidt over problemet her i aften, for det er sikkert meget klogt..

%(20.01.22)
Okay, lad mig for nu sige
\begin{align}
\begin{aligned}
	\hat H_I \ket{\psi} =&\, \ket{\psi_1'} + \ket{\psi_3'} + \ldots\,,\\
	\hat H_I \ket{\phi} =&\, \ket{\phi_0'} + \ket{\psi_2'} + \ket{\psi_4'} \ldots\,.
\end{aligned}
\end{align}
Så vil 
\begin{align}
\begin{aligned}
	\braket{\phi| \hat H_I \psi} = \braket{\phi_1| \psi_1'}  + \braket{\phi_3| \psi_3'} + \ldots\,, 
	\label{phi.hpsi}
\end{aligned}
\end{align}
og
\begin{align}
\begin{aligned}
	%(\hat H_I \ket{\phi})^\dagger \ket{\psi} 
	\braket{\hat H_I \phi| \psi} = \braket{\phi_0'| \psi_0}  + \braket{\phi_2'| \psi_2} + \braket{\phi_4'| \psi_4} + \ldots\,.
	\label{hphi.psi}
\end{aligned}
\end{align}

.\,.\,Hm, konvergerer dette så faktisk ikke altid, eller er det bare mig? Og hvis det gør, vil det så ikke blive umuligt for $\hat H_I$ ikke at være symmetrisk.\,.\,? .\,.\,Jamen det vil de jo, for alle vektorerne i de fire rækker vil jo have aftagende norm nok til, at den samlede norm konvergerer, og pr.\ Cauchy-Schwarz har vi jo så, at de to udtryk her konvergerer.\,. Jeg skal lige tænke over det en gang, men så har jeg umiddelbart svært ved at se, hvordan $\hat H_I$ så ikke kan være symmetrisk over mængden af sådanne tilstande. Og hvis $\hat H_I$ så faktisk er symmetrisk på hele den mængde af tilstande, hvor den \emph{kan} være defineret, så vil dette da umiddelbart være et rigtigt godt tegn!\,.\,. .\,.\,Og ja, den må jo være symmetrisk, hvis begge de to rækker her lige ovenfor konvergerer; så kan de jo ikke andet end at blive det samme. Ej, hvor spændende! Nu har jeg allerede lyst til at åbne Hall op og stirre lidt på, hvad Dom$(A^*)$ og $A^*$ så mon bliver. .\,.\,:\texttt D\,.\,. 

.\,.\,Okay, det vil være et rigtigt godt tegn, for se så på proposition 9.4 og (ikke mindst) dets bevis. Så vil.\,. Ja, $\mathrm{Dom}(A) \subset \mathrm{Dom}(A^*)$, men kan $\mathrm{Dom}(A^*)$ være større end $\mathrm{Dom}(A)$?\,.\,. .\,.\,Ah, om ikke andet, så vil det vel stride imod, at $A^*$'s graf skal være lukket, hvis $\mathrm{Dom}(A^*)$ kunne indeholde en vektor, der.\,. .\,.\,Ah ja, for idet $\mathrm{Dom}(A)$ er tæt i \textbf{H} (hvad jeg i øvrigt skal vise), så vil der findes en Cauchy-serie *(-følge*), der nærmer sig $\phi$ (/$\ket{\phi}$), men.\,. Ja, men denne serie vil så også findes i $\mathrm{Dom}(A^*)$, og.\,. .\,.\,Hm.\,. Vil billedet af denne serie så altid kunne gå imod uendelig.\,.\,? .\,.\,Sorry, jeg mener `følge,' ikke `serie' (hvilket jo er det engelske term for `række' (og så oversættes `følge' i øvrigt med `sequence')).\,. .\,.\,Hm ja, det må gælde.\,. Og så kan $\mathrm{Dom}(A^*)$ altså ikke indeholde vektoren, for så vil dette stride mod, at $A^*$ skal have en lukket graf på $\mathrm{\textbf{H}} \times \mathrm{\textbf{H}}$. .\,.\,\texttt:\texttt)  

Okay, tænkt sig, hvis dette holder.\,.\,\texttt{:)} Nu skal jeg så lige bruge lidt tid på lige at glatte de paradokser ud, der ellers tilsyneladende har poppet lidt frem, når man ligesom har så meget magt til at kvæle alle disse haler.\,. Så det vil jeg gøre.\,.
%..He, jeg kan mærke, at jeg ikke helt kan fatte, at jeg allerede måske fundet bevisstrategien (på nær at jeg lige skal genoverveje, hvordan jeg skal vise, at Dom(A) er tæt)..x) (He, man min hjerne skal nok nå at fatte det på et tidspunkt..^^) *(He, og det var så også foruftigt af min hjerne ikke at glæde sig for tidligt..x)^^)


%(21.01.22) *(Jeg er forresten stået vildt sent op alle disse dage: Imellem elleve og tolv. (I dag stod jeg op lidt over elleve.))
(21.01.22) Okay, der er nu stadig problemer. Paradokserne kunne ikke glattes ud. Og nu kan jeg se, at jeg nok har været for hurtigt til at sige, at ligninger (\ref{phi.hpsi}) og (\ref{hphi.psi}) viste, at $\hat H_I$ var symmetrisk. For se bare, f.eks.\ hvis man kvæler alle boson-produktions-amplituder helt, så vil kun $\braket{\phi_0'|\psi_0}$ stå tilbage i ligning (\ref{hphi.psi}), og ingenting vil stå tilbage for ligning (\ref{phi.hpsi}). .\,.\,Ja, og det var jo så dette eksempel, der fik mig til dengang i slut '17 at konkludere, at den ikke kunne være symmetrisk (fordi jeg så ikke kom i tanke om, at man ikke behøver at kvæle hele produktionen; i start '19 kom jeg jo så frem til, at det hele gik, hvis man bare undlod at kvæle amplituder i områder, som blev brugt af andre (tidligere) tilstande i det domæne, man konstruerer).\,. .\,.\,Hm, og hvis det passer, at $\hat H_I$ ikke er symmetrisk på hele dette relativt omfattende domæne, så må det vel komme sig af, at man i summen i lign.\ (\ref{phi.hpsi}) og (\ref{hphi.psi}) hele tiden ligesom får grupperet de led, der ellers ville forsage divergens, men som så hele tiden spiser hinanden.\,. .\,.\,Ja, og der snakker vi jo lige præcis de to led, som alle $\psi'$'erne (og $\phi'$'erne) er opbygget af, nemlig det led, der kommer fra $\hat H_I \psi_{n-1}$, og det, der kommer fra $\hat H_I \psi_{n+1}$. .\,.\,Hm, så nu skal jeg vel så se på, præcis hvornår domænet kan tillade $\hat H_I$ at være symmetrisk.\,. 

.\,.\,Så lad mig lige prøve at dele $\psi'$'erne (og $\phi'$'erne) mere eksplicit op i de to led.\,. Lad mig i første omgang lige indføre $\hat H_I = \hat H_I^+ + \hat H_I^-$, bare så det er af vejen.\,. .\,.\,Hm, kunne jeg så ikke lade
\begin{align}
\begin{aligned}
	\ket{\psi_n'} = \ket{\psi_n^+} + \ket{\psi_n^-}, \quad 
		\ket{\psi_n^\pm} \equiv \hat H_I^\pm \ket{\psi_{n\mp 1}}\,?
\end{aligned}
\end{align}
Jo, det siger vi.\,. 

Så bliver lign.\ (\ref{phi.hpsi}) og (\ref{hphi.psi}) til
\begin{align}
\begin{aligned}
	\braket{\phi| \hat H_I \psi} = \braket{\phi_1| \psi_1^+} + \braket{\phi_1| \psi_1^-} + \braket{\phi_3| \psi_3^+} + \braket{\phi_3| \psi_3^-} + \ldots\,, 
	\label{pm-dotp1}
\end{aligned}
\end{align}
og
\begin{align}
\begin{aligned}
	\braket{\hat H_I \phi| \psi} = \braket{\phi_0^-| \psi_0}  + \braket{\phi_2^+| \psi_2} + \braket{\phi_2^-| \psi_2} + \braket{\phi_4^+| \psi_4} + \braket{\phi_4^-| \psi_4} + \ldots\,.
\label{pm-dotp2}
\end{aligned}
\end{align}

Og bliver pointen mon så ikke, at disse rækker ikke nødvendigvis konvergerer.\,.\,? .\,.\,Hm, bemærk, at de bør være ens, hvilket er hvorfor, $\hat H_I$ netop bør være symmetrisk, hvis disse (ækvivalente) rækker konvergerer. .\,.\,Hm, så er det jo i øvrigt ret oplagt at sætte dem lige oven over hinanden:
\begin{align}
\begin{aligned}
	\braket{\phi| \hat H_I \psi} =&\, \braket{\phi_1| \psi_1^+} + \braket{\phi_1| \psi_1^-} + \braket{\phi_3| \psi_3^+} + \braket{\phi_3| \psi_3^-} + \ldots\,, \\
	\braket{\hat H_I \phi| \psi} =&\, \braket{\phi_0^-| \psi_0}  + \braket{\phi_2^+| \psi_2} + \braket{\phi_2^-| \psi_2} \,+ \braket{\phi_4^+| \psi_4} + \braket{\phi_4^-| \psi_4} + \ldots\,.
\label{pm-dotp}
\end{aligned}
\end{align}

Jeg ved jo, at det vil konvergerer så snart man samler hver andet term igen, så konvergensen må jo afhænge af.\,. hm, hvilken forskel dette ligesom gør.\,. .\,.\,Hm ja, man må kunne sige, at rækken konvergerer, hvis og kun hvis følgerne,
\begin{align}
\begin{aligned}
	(\braket{\phi_n| \psi_n^+})_{n\in{\{1,2,\ldots\}}}, \:\:
	(\braket{\phi_n| \psi_n^-})_{n\in{\{1,2,\ldots\}}}, \:\:
	(\braket{\phi_n^+| \psi_n})_{n\in{\{1,2,\ldots\}}}, \:\:
	(\braket{\phi_n^-| \psi_n})_{n\in{\{1,2,\ldots\}}}, 
\end{aligned}
\end{align}
alle konverger, hvilket de gør, hvis bare én af dem gør det. 

Og min strategi fra førhen var så netop bare at sørge for, at hvis $\phi$ allerede er en del af domænet, så skal $\psi_n$ vælges, så $\psi_{n-1}^-$ er nul overalt, hvor $\phi_{n-1}$ ikke er det. Det var altså sådanne domæner, jeg fandt på der i start '19, og som jeg altså har haft i tankerne for $\hat H$ siden da.\,. 

.\,.\,Hm, selvfølgelig kan man godt så slække på denne restriktion, for man kunne f.eks.\ bare vælge en hvis $n$, fra hvor dette skal gælde, i stedet for at sige, at det skal gælde på alle $n$ stort set.\,. 

.\,.\,Det gode er så, at de paradokser, jeg har i tankerne, også forsvinder, så vidt jeg kan se, når man har sådanne domæner.

Ok, så mere generelt kan vi vel sige, at vi altså er ude efter domæner, hvor $\braket{\phi_n|\psi_n^-}$ går imod 0 for $n$ gående mod uendelig for alle $\psi, \phi \in \mathrm{Dom}(\hat H)$?\,. Ja, og det kan man vist sagtens konstruere, medmindre jeg tager meget fejl. 

Ok, så nu vil jeg så se på $\mathrm{Dom}(A^*)$ og $A^*$ igen (hvor jeg igen lige skifter fra $\hat H$ til $A$, fordi det lige er lidt nemmere, når jeg tager udgangspunkt i Hall).\,. 

.\,.\,Hm, vil mit tidligere relativt brede domæne (hvorpå $\hat H_I$ så ikke var symmetrisk alligevel) mon være et underset af $\mathrm{Dom}(A^*)$.\,.\,? .\,.\,Hm, uh ha.\,. Dette kan da ende med at blive et stort problem.\,. Lad mig nu lige se.\,. 

.\,.Jo, det kan jo næsten ikke rigtigt være anderledes, end at $\mathrm{Dom}(A^*)$ som minimum altid vil være mit ``brede domæne'' fra før, hvor restriktionen om, at 
\begin{align}
\begin{aligned}
	\lim_{n\to\infty}\braket{\phi_n| \psi_n^-} = 0
	\label{DomA-restriction1}
\end{aligned}
\end{align}
for alle $\psi, \phi \in \mathrm{Dom}(A)$, ikke er sat på.\,. .\,.\,Hm, jeg skulle egentligt til at sige noget med, om det så var spørgsmålet, om $A$ kunne være essentially self-adjoint, men inden jeg når til det, så lad mig lige kigge lidt mere på $\braket{\phi_n| \psi_n^-}$-følgen en gang.\,. .\,.\,Hvad skal til, for at denne ikke går imod 0.\,.\,? .\,.\,Hm, hvis nu 
\begin{align}
\begin{aligned}
	\psi^- \equiv \psi_1^- + \psi_3^- + \ldots
\end{aligned}
\end{align}
er en vektor --- hvor $\psi$ altså er en vektor med kun lige antal bosoner i --- så vil $\braket{\phi_n| \psi_n^-}$ da gå imod 0.\,. Så hvad skal der til, før den er det.\,.\,? .\,.\,Ja, og den behøver umiddelbart ikke nødvendigvis at være en vektor.\,. .\,.\,Nå ja, $\psi_n^-$'erne vil jo være disse bølgefunktioner med uendelig stor norm, så never mind at se på, hvornår $\psi^-$ kan være en vektor.\,. 

Hm, okay lad mig lige gå over til at se på, om det brede domæne, som altså ikke har lign.\ (\ref{DomA-restriction1})-restriktionen, ikke kunne være lukningen af Dom$(A)$, for det ville så umiddelbart være et ret godt tegn (eller, rettere, det vil nok være et dårligt tegn, hvis ikke dette er tilfældet.\,.).\,.

.\,.\,Hm, proposition 9.8(.2) er god for.\,. hm, eller.\,. .\,.\,Tja jo, det kan den meget vel blive, men lad mig nu bare starte med at se på, hvad lukningen af Dom$(A)$ er (og altså ikke lukningen af $A$; den kan vente).\,. .\,.\,Hm, nå nej, det er nok lukningen af $A$, jeg skal kigge på fra starten af.\,. 

.\,.\,Hm, hvis jeg bruger mit tidligere Dom$(A)$, hvor tilstandene vælges så $\braket{\phi_n| \psi_n^-}$-følgen bare er konstant lig 0 efter et vist $n$, så vil vi jo vel ikke kunne nærme mig et punkt i.\,. Hm, lad mig egentligt kalde den ikke-symmetriske operator, defineret på ``det brede domæne,'' for $B$ (B for `brede,' kan man så sige.\,.), og så kan jeg kalde ``det brede domæne'' for Dom$(B)$ i stedet.\,. (.\,.\,Og indtil videre tror jeg så altså på, at $\mathrm{Dom}(B) \subset \mathrm{Dom}(A^*)$.\,.) .\,.\,Hvis vi så ser på en vektor, $\psi$, i Dom$(B)$, med $B\psi = \chi$.\,. Hm, kan vi så for det første nærme os denne (altså $\psi$) via en følge i Dom$(A)$?\,.\,. .\,.\,Hm tja, Dom$(A)$ skal jo gerne være tæt, så det skal man jo gerne kunne.\,. .\,.Hm, og når man konstruerer Dom$(A)$, så kan man starte med at definere vektorer, der tager udgangspunkt i alle impuls-egenvektorerne, og når man så har gjort det, så starter med så forfra og definerer nogen, der ligger endnu tættere på disse egenvektorer (altså dem de hver især tager udgangspunkt i), og hvor man stadig sørger for, at restriktion (\ref{DomA-restriction1}) gælder for alle tidligere vektorer, også dem i de nedre trin. Og ja, på denne måde må man kunne definere en tæt Dom$(A)$.\,. .\,.\,Uh uh,\footnote{Som i: Uh! Uh! (Og ikke som i: U-uh.)} så må det jo næsten handle om \emph{ikke} at bruge mit gamle Dom$(A)$, men netop om at finde et Dom$(A)$, hvor man kan få mulighed for også at nærme sig $\chi = B \psi$.\,.\,!\,.\,. Hm, eller lad mig lige se engang.\,. .\,.\,Vi skal jo rigtignok gerne have, at $B \subset A^{cl}$, skal vi ikke?\,.\,. (Hvilket så er ækvivalent med at $A^{cl}=B$.\,.) .\,.\,Hov, eller jeg mener selvfølgelig \emph{graferne} af $B$ og $A^{cl}$.\,. .\,.\,Jo, for grafen af $A^{cl}$ skal gerne blive lig Dom$(A)$, hvilket jeg altså tror, må være en overmængde (og forhåbentligt også lig) Dom$(B)$. 

.\,.\,Hm, og vil man ikke faktisk lige præcis kunne definere en Dom$(A)$, hvor man.\,. hm, måske lader $n_{max}$, eller hvad jeg skal kalde den (måske $\lambda$, hvis jeg ikke bruger dette ellers, eller.\,. ja, det kan jeg jo bare tænke over), som betegner fra hvornår man skal lade $\psi_n^-$'erne undvige $\phi_n$'erne helt, stige for hvert trin i konstruktionen af (det tætte) Dom$(A)$.\,.\,?(.\,.\,:\texttt).\,.) .\,.\,Ej, hvor spændende.\,.(!\,.\,.)

.\,.\,Ej shit; det er lige før, jeg begynder at tro, at det holder.\,.\,!\,.\,. (Så altså et positivt sagt `shit.') .\,.\,Ej, det ville være så godt.\,.(!\,.\,.)

.\,.\,Uh, og nu kom jeg lige i tanke om, at det jo netop i så fald vil være fra højere og højere ``trin'' i dette domæne, hvorfra man skal tage sine vektorer, hvis man.\,.\, alt andet end lige.\,. vil lave en følge, der konvergerer imod en vektor, $\psi$, for med den konstruktion, jeg lagde op til, vil hvert trin jo gå mere og mere imod den ortogonale impuls-basis.\,. Hm, jeg ved ikke, om dette egentligt bliver betydende, men sikkert værd lige at notere sig.\,.\,:) (.\,.\,For det kunne måske godt være, at jeg får brug for at vise.\,. hm, at man kun kan vælge en (Cauchy-)følge, hvis billede konvergerer mod det samme $\chi$, ville jeg sige, men jeg kom så lige i tanke om, at en symmetrisk operator pr.\ prop.\ 9.8 i Hall altid vil være lukkelig (closable), så det bliver nu nok ikke nødvendigt.\,.\,:)) 


Yes! $A^{cl}$ \emph{må} altså, som jeg kan se det, være lig $B$.\,.\,! Og hvis det passer, så er dette et super godt tegn! Så mangler jeg bare, formentligt, at vise, at $\mathrm{Dom}(A^*) = \mathrm{Dom}(B)$, og vil jeg så ikke nærmest være i mål herved?\,.\,.\,!\,.\,. 

.\,.\,Hm, og ellers kunne man jo også sigte efter at bruge sætning 9.21, men lad mig nu lige se.\,. 

.\,.\,Hm, åh nej, bare man ikke løber ind i problemer ved, at $B$ jo nok ikke kan være symmetrisk, men hvis $A^{cl}=B$, og $A^{cl}$ er self-adjoint (eller selvadjungeret), så giver dette vel en modstrid, for så skal $A^{cl}$ (og dermed også $B$) vel netop også være symmetrisk.\,.(?) .\,.\,Ja, alle selvadjungerede operatorer er symmetriske, så det skal $A^{cl}$ også være, hvis $A$ skal være essentially self-adjoint.\,. 


Nå, lad mig lige skrive det op her, hvorfor Dom$(B)$ må eller ikke nødvendigvis må være en undermængde af Dom$(A^*)$.\,. For ethvert $\phi\in\mathrm{Dom}(B)$ gælder, at for alle $\psi\in \mathrm{Dom}(A)$ er
\begin{align}
\begin{aligned}
	\braket{\phi| A \psi} =&\,
		\braket{\phi_0| A^- \psi_1} + \braket{\phi_1| A^+ \psi_0} + \braket{\phi_1| A^- \psi_2} + \braket{\phi_2| A^+ \psi_1} + \braket{\phi_2| A^- \psi_3} + \ldots \\
		=&\,
		\braket{A^+ \phi_0| \psi_1} + \braket{A^- \phi_1| \psi_0} + \braket{A^+ \phi_1| \psi_2} + \braket{A^- \phi_2| \psi_1} + \braket{A^+ \phi_2| \psi_3} + \ldots \\
		=&\,
		\braket{B^+ \phi_0| \psi_1} + \braket{B^- \phi_1| \psi_0} + \braket{B^+ \phi_1| \psi_2} + \braket{B^- \phi_2| \psi_1} + \braket{B^+ \phi_2| \psi_3} + \ldots \\
		=&\,
		\braket{B \phi| \psi},
	\label{phi.Apsi=Bphi.psi}
\end{aligned}
\end{align}
er det ikke.\,.\,? .\,.\,Hm, og dermed vil vi så have, at
\begin{align}
\begin{aligned}
	\braket{\phi| A \psi} =
	\braket{B \phi| \psi} \leq |B \phi| |\psi| \equiv C_{\phi} |\psi|
\end{aligned}
\end{align}
for alle $\psi$.\,. Og hvis dette holder vand, så \emph{må} Dom$(B)$ rigtignok være en undermængde af Dom$(A^*)$.\,. 

.\,.\,Hm, og skal $A^*$ så ikke også være lig $B$ på Dom$(B)$?\,.\,. .\,.\,Jo. For $A^*$ er pr.\ Hall den \emph{unikke} operator, der opfylder ligning (\ref{phi.Apsi=Bphi.psi}) for alle $\phi \in \mathrm{Dom}(A^*)$ og $\psi \in \mathrm{Dom}(A)$. Og dermed må $A^* = B$ på Dom$(B)$. 

Hov vent, det skaber da et paradoks, hvis.\,. Hm.\,. 

.\,.\,Hm, lad os se på en følge, $(\psi_n)_{n\in\mathbb N}$, i Dom$(A)$, som vi gerne vil have til at konvergere imod et $\psi \in \mathrm{Dom}(B) \setminus \mathrm{Dom}(A)$.\,. .\,.\,Hm, lad os bare sige for nu, at vi rigtignok altid kan konstruere dette, og at $(\psi_n)_{n\in\mathbb N}$ altså gør dette.\,. .\,.\,Okay, lad mig så se på et $\phi$ i $\mathrm{Dom}(B)$, og måske endda også i $\mathrm{Dom}(B) \setminus \mathrm{Dom}(A)$, hvis dette bliver brugbart. Så har vi ifølge ligning (\ref{phi.Apsi=Bphi.psi}), at
\begin{align}
\begin{aligned}
	\lim_{n\to \infty} \braket{\phi| A \psi_n} =&\, 
		\lim_{n\to \infty}\braket{B \phi| \psi_n}.\,.
\end{aligned}
\end{align}
Hm, og kan vi så tage grænsen så $\psi_n\to\psi$ i dette udtryk.\,.\,? .\,.\,Hm, ja for $B\phi$ er en vektor, hvilket betyder at 
\begin{align}
\begin{aligned}
	\braket{B \phi| \psi_n} = \braket{B \phi| \psi} - \bra{B \phi}(\ket{\psi} - \ket{\psi_n})
\end{aligned}
\end{align}
vil gå imod $\braket{B \phi| \psi}$, fordi $|\ket{\psi} - \ket{\psi_n}|$ vil gå imod 0. Så er
\begin{align}
\begin{aligned}
	\lim_{n\to \infty} \braket{\phi| A \psi_n} =
	\lim_{n\to \infty}\braket{B \phi| \psi_n} = \braket{B \phi| \psi}.\,.
\end{aligned}
\end{align}
.\,.\,Hm, og måske skal vi også se på en følge, $(\phi_n)_{n\in\mathbb N}$, i Dom$(A)$, som konvergerer til $\phi$.\,. Så har vi ifølge ligning (\ref{phi.Apsi=Bphi.psi}), at
\begin{align}
\begin{aligned}
	\lim_{n,m\to \infty} \braket{\phi_m| A \psi_n} 
		=&\,
		\lim_{n,m\to \infty}\braket{B \phi_m| \psi_n} \\
		=&\, \lim_{n,m\to \infty} \braket{B \phi| \psi} 
			- \bra{B \phi}(\ket{\psi} - \ket{\psi_n}) 
			- (\bra{B \phi} - \bra{B \phi_m})\ket{\psi_n} \\
		=&\, \lim_{n\to \infty} \braket{B \phi| \psi} 
			- \bra{B \phi}(\ket{\psi} - \ket{\psi_n}) \\
		=&\, \braket{B \phi| \psi}.
\end{aligned}
\end{align}
.\,.\,Ah, men hvis så $A$ er symmetrisk, så må man vel også kunne starte med $\braket{\phi_m| A \psi_n} $ i stedet (og altså forvente det samme resultat), men så udlede $\braket{\phi|B \psi}$ i sidste ende, ikke.\,.\,?

.\,.\,Hm, jo for det er vel en del af definitionen af et indre produkt, at $\braket{\phi|\psi}^*=\braket{\psi|\phi}$, og dermed vil 
\begin{align}
\begin{aligned}
	\braket{A \phi_m|\psi_n} = \braket{\psi_n|A \phi_m}^* 
	\:\stackrel{eq.\: (\ref{phi.Apsi=Bphi.psi})}{=}\:
	\braket{B \psi_n| \phi_m}^* = \braket{\phi_m| B\psi_n}.
\end{aligned}
\end{align}
Og ved så at bruge det samme trick får vi, at
\begin{align}
\begin{aligned}
	\braket{B \phi | \psi} = 
	\lim_{n,m\to \infty} \braket{\phi_m | A \psi_n} = 
	\lim_{n,m\to \infty} \braket{A \phi_m | \psi_n} =
	\braket{\phi | B \psi},
	\label{B-seemingly-symmetric}
\end{aligned}
\end{align}
hvilket pludselig viser, at $B$ må være symmetrisk givet de antagelser, jeg har lavet.\,. (Hvilket altså netop strider imod nogle af de antagelser, jeg har lavet.\,.)

Så ja, der er et paradoks, som viser, at jeg har gjort/tænkt noget galt. Jeg kan nok godt arbejde lidt mere her i aften, men ellers må jeg jo bare på et tidspunkt holde fyraften og så håbe på, at jeg kan løse det i morgen.\,. 

Jeg har ikke lige kunne finde noget i Hall, der siger det, men må der ud fra ovenstående udregninger så ikke altid gælde, at $A^{cl}$ er symmetrisk, givet at $A$ er symmetrisk? For vi kan vel bare erstatte $B$ med $A^*$ alle vegne i disse udregninger.\,.\,? .\,.\,Jo, det må der jo.\,. 

Hov, men har jeg ikke kun brugt, at Dom$(B)$ er lukningen af Dom$(A)$, og ikke at grafen for $B$ er lukningen af grafen for $A$, eller er det bare mig.\,.\,? .\,.\,Nå nej, for jeg har jo netop brugt, at $A\psi_n$ og $A\phi_n$ konvergerer, så dette er, som det bør være.\,. 


Nå, jeg håber jo ikke, svaret i sidste ende bare bliver, at Dom$(B)$ og/eller Dom$(A^*)$ er skarpt større end, hvad Dom$(A)$ kan være, men det må tiden jo vise. 

Det næste spørgsmål bliver så nok at se endnu nærmere på, hvad følger i Dom$(A)$ (altså med restriktion (\ref{DomA-restriction1})) kan konvergere til, eller rettere hvad deres billeder kan konvergere til.\,.

Hm, lad os igen antage, at vi har en følge, $(\psi_n)_{n\in\mathbb N}$, der konvergerer mod en vektor, $\psi$, som ligger i $\mathrm{Dom}(B) \setminus \mathrm{Dom}(A)$. Hvad vil billedet af denne så være? Vi har, at 
\begin{align}
\begin{aligned}
	\lim_{n\to \infty} \braket{\phi| A \psi_n} =
	\lim_{n\to \infty}\braket{B \phi| \psi_n} = 
	\lim_{n\to \infty}\braket{B \phi| \psi} - \bra{B \phi}(\ket{\psi} - \ket{\psi_n}) =
	\braket{B \phi| \psi}
\end{aligned}
\end{align}
for alle $\phi \in \mathrm{Dom}(B)$, så det vil vel sige, at 
\begin{align}
\begin{aligned}
	\lim_{n\to \infty} \ket{\psi_n} =
	 B^* \ket{\psi},
\end{aligned}
\end{align}
vil det ikke.\,.\,? (.\,.\,Og jeg blander jo lidt notationen her; jeg kunne også have droppet ketterne her i den sidste ligning.\,.) .\,.\,Hm, for er $\braket{B \phi| \psi}$ ikke lig $\braket{\phi| B^*\psi}$.\,.\,? .\,.\,Nej, det kan man ikke nødvendigvis, og heller ikke med $A^*$ i stedet for $B$ i øvrigt.\,. .\,.\,Nå jo, måske godt alligevel, for så snakker vi jo også bare $A^{**}$.\,. Hm.\,. 

.\,.\,Hov, har jeg forresten ikke lavet en fejlantagelse i ligning (\ref{phi.Apsi=Bphi.psi}), for er jeg ikke kommet til at antage, at $A^+$ og $A^-$ er.\,. hm, eller at f.eks.\ $A^+\phi_n$ eksisterer som en vektor.\,. Der er i hvert fald noget, der virker lidt uldent.\,. .\,.\,Lad mig lige kopiere den ned her (så jeg ikke skal scrolle op efter den):
\begin{align}
	\begin{aligned}
	\braket{\phi| A \psi} =&\,
		\braket{\phi_0| A^- \psi_1} + \braket{\phi_1| A^+ \psi_0} + \braket{\phi_1| A^- \psi_2} + \braket{\phi_2| A^+ \psi_1} + \braket{\phi_2| A^- \psi_3} + \ldots \\
		=&\,
		\braket{A^+ \phi_0| \psi_1} + \braket{A^- \phi_1| \psi_0} + \braket{A^+ \phi_1| \psi_2} + \braket{A^- \phi_2| \psi_1} + \braket{A^+ \phi_2| \psi_3} + \ldots \\
		=&\,
		\braket{B^+ \phi_0| \psi_1} + \braket{B^- \phi_1| \psi_0} + \braket{B^+ \phi_1| \psi_2} + \braket{B^- \phi_2| \psi_1} + \braket{B^+ \phi_2| \psi_3} + \ldots \\
		=&\,
		\braket{B \phi| \psi}.
\end{aligned}
\end{align}
Hm, men hvad hvis jeg samler det til
\begin{align}
\begin{aligned}
\braket{\phi| A \psi} =&\,
%\braket{\phi_0| \psi_0^-} + \bra{\phi_1} \big(\ket{\psi_1^+} + \ket{\psi_1^-}\big) + \bra{\phi_2} \big(\ket{\psi_2^+} + \ket{\psi_2^-}\big) + \ldots \\
\braket{\phi_0 | \psi_0'} + \braket{\phi_1 | \psi_1'} + \braket{\phi_2 | \psi_2'} + \ldots \\
=&\, \:.\,.
\end{aligned}
\end{align}
Hm, så forsvinder fidusen ligesom.\,. Nå, jeg må kigge videre på det i morgen.\,. 


Nå, nu kunne jeg ikke lige lade være med at vende tilbage (det er stadig aften). Det ville jo faktisk være et rigtigt godt tegn, hvis ligning (\ref{phi.Apsi=Bphi.psi}) ikke holder, for så forsvinder alle disse fartruende sætninger, som jeg har kæmpet med.\,. Ja, så vil jeg jo komme helt tilbage til det punkt, hvor det hele så lovende ud.\,. .\,.\,Og forhåbentligt kan ligning (\ref{B-seemingly-symmetric}) så netop blive et bevis på, at Dom$(B)$ ikke kan være en undermængde af Dom$(A^*)$.\,. .\,.\,Åh, totalt deja vu, fik jeg lige.\,. .\,.\,Nå, men det var vist bare netop det.\,. 

.\,.\,Hm, ja ligning (\ref{B-seemingly-symmetric}) må da netop blive bevis for, at ligning (\ref{phi.Apsi=Bphi.psi}) ikke kan være rigtig.\,.\,!\,.\,. 

Hm, lad mig lige se igen på følger af $\psi_n, \phi_n \in \mathrm{Dom}(A)$, som henholdsvis konvergerer imod $\psi$ og $\phi$, begge vektorer i Dom($B$). Så har vi, at
\begin{align}
\begin{aligned}
%	\lim_{n,m\to \infty} 
	\braket{\phi_m | A \psi_n} 
		=&\,
			\braket{\phi_m | B \psi_n} \\
		=&\,
			\braket{\phi | B\psi} 
				- \bra{\phi}(\ket{B \psi} - \ket{B \psi_n}) 
				- (\bra{\phi} - \bra{\phi_m})\ket{B \psi_n},
\end{aligned}
\end{align}
hvilket viser, at $\lim_{m\to\infty}\braket{\phi_m | A \psi_n}$ eksisterer og må være givet ved 
\begin{align}
\begin{aligned}
	\lim_{m\to \infty} \braket{\phi_m | A \psi_n} 
		=&\,
			\lim_{m\to \infty} \braket{\phi | B\psi} 
				- \bra{\phi}(\ket{B \psi} - \ket{B \psi_n}) 
				- (\bra{\phi} - \bra{\phi_m})\ket{B \psi_n} \\
		=&\,
			\braket{\phi | B\psi} 
				- \bra{\phi}(\ket{B \psi} - \ket{B \psi_n}) .
	\label{m-to-infty}
\end{aligned}
\end{align}
Hm, og hvis $B\psi_n$ konvergerer mod $B \psi$, så vil jeg også kunne tage grænsen for $n\to\infty$ både før og efter, at $m\to\infty$, og have fået det samme, nemlig $\braket{\phi | B\psi}$.\,. Så spørgsmålet er, om $B\psi_n$ konvergerer mod $B \psi$.\,. .\,.\,Hm, for så vil grafen for $A^{cl}$ jo være lig grafen for $B$, vil den ikke.\,.\,?

.\,.\,Og $B\psi_n$ må vel konvergere mod $B \psi$, for da $B$ er linear, må vi have, at
\begin{align}
\begin{aligned}
	\ket{B \psi} - \ket{B \psi_n} = B (\ket{\psi} - \ket{\psi_n}),
\end{aligned}
\end{align}
så 
\begin{align}
\begin{aligned}
	\lim_{n\to\infty} \ket{B \psi} - \ket{B \psi_n} = \lim_{n\to\infty} B (\ket{\psi} - \ket{\psi_n}).\,.
\end{aligned}
\end{align}
Hm.\,. Normen af denne vektor går ikke nødvendigvis mod 0, men hvis vi nu putter $\bra{\phi}$ tilbage på.\,. Så har vi
\begin{align}
\begin{aligned}
\lim_{n\to\infty} \bra{\phi}(\ket{B \psi} - \ket{B \psi_n}) = \lim_{n\to\infty} \bra{\phi} B (\ket{\psi} - \ket{\psi_n}).\,.
\end{aligned}
\end{align}
Hm, som vel egentligt heller ikke nødvendigvis går imod 0, eller er det bare mig.\,.\,? .\,.\,Hm nej, jeg føler da godt, jeg kan finde på nogle modeksempler.\,. 

.\,.\,Hm, og hvad med $(\bra{\phi} - \bra{\phi_m})\ket{B \psi_n}$, hvis jeg lige går tilbage og ser på ligning (\ref{m-to-infty}) igen.\,.\,? Her foregår der ikke helt det samme; vi har en konstant vektor prikket med en vektor, der punktvist går imod 0.\,. .\,.\,(Og uniformt.\,.) .\,.\,Ja, og her skal det gå imod 0, for det fortæller Cauchy-Schwarz os.\,. .\,.\,Men ja, det samme kan jo ikke umiddelbart siges om $\bra{\phi} B (\ket{\psi} - \ket{\psi_n})$, og jeg føler som sagt, man sagtens kan finde modeksempler.\,. .\,.\,Ja, og dette er simpelthen fordi $B (\ket{\psi} - \ket{\psi_n})$'s norm jo slet \emph{ikke} behøver at konvergere; tvært imod kan den endda vokse ligeså meget, det skal være, hvis $B$ ikke er begrænset.  

Okay, og dette er jo rigtigt godt, for så er grafen for $A^{cl}$ netop \emph{ikke} nødvendigvis (altså umiddelbart) være lig grafen for $B$, hvad jeg ellers frygtede.\,.\,:).\,.

Nå, nu er klokken lidt i elleve, så jeg må nok snart hellere holde (hvis jeg skal kunne sove.\,.).\,.\,x) 

.\,.\,Hm, jeg er virkeligt ristet nu, men jeg kom lige til at se, at grænsen af
\begin{align}
\begin{aligned}
\braket{\phi | A \psi_n} = 
	\braket{\phi | B\psi} - \bra{\phi}(\ket{B \psi} - \ket{B \psi_n})
\end{aligned}
\end{align}
netop måske kunne være værd at se på, hvis man vil vise, at Dom$(B) \nsubseteq \mathrm{Dom}(A^*)$.\,. For hvis disse udtryk ikke er begrænsede for $n\to\infty$, så vil dette jo netop vise, at $\phi$ ikke er i $\mathrm{Dom}(A^*)$.\,. .\,.\,Nå, men jeg \emph{skal} snart til at stoppe nu, for nu er jeg ved at blive helt ør i hovedet.\,. 

%(22.01.22) Jeg tænkte lige lidt videre i går nat, inden jeg gik i seng. Jeg kom på, at hvis Dom(A) konstrueres, så den inkluderer tilstande, der har større og større billede, så kunne dette måske være én måde, at vise, at Dom(A^*) \subset Dom(B). Og kort inden jeg gik i seng kom jeg på, at man måske kunne bruge, hvad der svarer til Dom(A^*)'s alternative definition, eksplicit beskrevet under def. 9.1 i Hall, til måske så at vise, at \phi videre skal være en del af Dom(A). Og sengen efterfølgende kom jeg så lidt frem til, at dette måske så kræver, at Dom(A) ligesom er fyldt op til randen, sådan at der altså ikke længere findes vektorer uden for Dom(A), hvor ligning (\ref{DomA-restriction1}) gælder for alle vektorer i Dom(A) (parret med vektoren selv). Så nu vil jeg lige tænke lidt over, hvad jeg vil starte med at regne på og så gøre det..
(22.01.22) Som jeg lige har beskrevet ude i kommentarerne, så overvejer jeg nu, om ikke man først kunne prøve at vise, at $\mathrm{Dom}(A^*) \subset \mathrm{Dom}(B)$, og så bagefter prøve vise, at så skal restriktion (\ref{DomA-restriction1}) gælde, før at der eksisterer et $\chi$, således at $\braket{\phi|A\psi} = \braket{\chi|\psi}$ for alle $\psi\in\mathrm{Dom}(A)$, hvilket er ækvivalent (se teksten under definition 9.1 i Hall) med, at $\phi$ er i Dom$(A^*)$ (og at $\chi$ så er lig $A^*\psi$). 

Lad mig derfor lige prøve at antage, at vi allerede har at $\mathrm{Dom}(A^*) \subset \mathrm{Dom}(B)$, og så prøve at regne på $\braket{\phi|A\psi}$ (og prøve at sammenligne med et muligt $\braket{\chi|\psi}$) for alle $\psi$.\,.

Vi kan i så fald starte med at antage, at $\phi\in\mathrm{Dom}(B)$ og at $\psi\in\mathrm{Dom}(A)$. Hm, så har vi
\begin{align}
\begin{aligned}
	\braket{\phi| A \psi} =&\,
			\braket{\phi_0 | \psi_0'} + \braket{\phi_1 | \psi_1'} + \braket{\phi_2 | \psi_2'} + \ldots \\
		=&\, 
			\braket{\phi_0| \psi_0^-} + \bra{\phi_1} \big(\ket{\psi_1^+} + \ket{\psi_1^-}\big) + \bra{\phi_2}\big(\ket{\psi_2^+} + \ket{\psi_2^-}\big) + \ldots \\
\end{aligned}
\end{align}
og
\begin{align}
\begin{aligned}
	\braket{\chi| \psi} =&\,
	\braket{\chi_0 | \psi_0} + \braket{\chi_1 | \psi_1} + \braket{\chi_2 | \psi_2} + \ldots\,.\,.
\end{aligned}
\end{align}
Hm, lad os lige videre antage, at $A^*=B$ på Dom$(B)$.\,. Så har vi
\begin{align}
\begin{aligned}
	\braket{\chi| \psi} =&\, \braket{B \phi| \psi} \\
		=&\, 
			\braket{\phi_0' | \psi_0} 
				+ \braket{\phi_1' | \psi_1} 
				+ \braket{\phi_2' | \psi_2} + \ldots \\
		=&\, 
			\braket{\phi_0^- | \psi_0} 
				+ \big(\bra{\phi_1^-} + \bra{\phi_1^+}\big)\ket{\psi_1} 
				+ \big(\bra{\phi_2^-} + \bra{\phi_2^+}\big)\ket{\psi_2}.\,.
\end{aligned}
\end{align}

.\,.\,Hm, jeg skal forresten passe på, for nogle af elementerne i $(\braket{\phi_n| \psi_n^-})_{n\in{\{1,2,\ldots\}}}$ må jo umiddelbart godt være uendelig, så at sige; så længe der bare findes et $N$, så at $(\braket{\phi_n| \psi_n^-})_{n\in{\{N,N+1,\ldots\}}}$ går imod 0, så er det fint.\,. 

Hm, jeg kan selvfølgelig ikke bare splitte f.eks.\ $\psi_1'$ op i $\psi_1^- + \psi_1^+$ og antage at disse to led er vektorer i sig selv, hvad man ellers godt kunne tænke, var en antagelse, hvis man så ovenstående ligninger.\,. 
.\,.\,Hm, men hvis det er underforstået, at alle $\braket{\cdot|\cdot}$-integralerne ikke skal tages uafhængigt af hinanden, men skal tages samlet i henhold til, at $\psi'$'erne og $\phi'$'erne skal samles, så kunne man skrive
\begin{align}
\begin{aligned}
	\braket{\phi| A \psi} = &\,
		\Big[
			\braket{\phi_0 | A^- \psi_1} 
				+ \braket{\phi_1 | A^+ \psi_0} 
				+ \braket{\phi_1 | A^- \psi_2} 
				+ \ldots
		\Big]_{spec.\: int.}\,,\\
	\braket{\chi| \psi} = &\,
		\Big[
			\braket{B^+ \phi_0 | \psi_1} 
				+ \braket{B^- \phi_1 | \psi_0} 
				+ \braket{B^+ \phi_1 | \psi_2} 
				+ \ldots
		\Big]_{spec.\: int.}\,.\,.
\end{aligned}
\end{align}
%Nå, jeg vil lige gå en eftermiddagstur i det fine vejr (og tage lidt hævn fra i går, hvor jeg næsten ikke nåede ud i det)... 

%Okay, på min gåtur fandt jeg lidt på, hvad det næste mulige skridt kunne være..
\ldots\ Okay, jeg har lidt en strategi i tankerne, for hvordan jeg fortsætter herfra. I øvrigt kan jeg lige sige, at den ``specielle integration'' jo handler om at lægge funktionerne sammen i samme områder af domænet, inden man integrerer. Og vi har så, at
\begin{align}
\begin{aligned}
	\braket{\phi| A \psi} = &\,
			\Big[
			\braket{\phi_0 | A^- \psi_1} 
				+ \braket{\phi_1 | A^+ \psi_0} 
				+ \braket{\phi_1 | A^- \psi_2} 
				\:\:+\:\: \braket{\phi_2 | A^+ \psi_1} 
				+ \braket{\phi_2 | A^- \psi_3} 
				\:\:+\:\: \ldots
			\Big]%_{sp.i.}
			\\
		=&\,
			\braket{\phi_0 | A^- \psi_1} +
			\big[
				\braket{\phi_1 | A^+ \psi_0} +
				\braket{\phi_1 | A^- \psi_2}
			\big] + \big[
				\braket{\phi_2 | A^+ \psi_1} +
				\braket{\phi_2 | A^- \psi_3} 
			\big]%_{sp.i.}
			+ \ldots\,,\\
	\braket{\chi| \psi} = &\,
			\big[
				\braket{B^+ \phi_0 | \psi_1} +
					\braket{B^- \phi_1 | \psi_0} +
					\braket{B^+ \phi_1 | \psi_2} \:\:+\:\:
					\braket{B^- \phi_2 | \psi_1} +
					\braket{B^+ \phi_2 | \psi_3} \:\:+\:\:
					\braket{B^- \phi_3 | \psi_2} +
					\ldots
			\big]%_{sp.i.}
			\\
		= &\,
\phantom{	\big[
				\braket{B^+ \phi_0 | \psi_1} +			}
				\braket{B^- \phi_1 | \psi_0} +
\phantom{		\braket{B^+ \phi_1 | \psi_2} +
				\braket{B^- \phi_2 | \psi_1} %+
			%		+ \braket{B^+ \phi_2 | \psi_3} 
			%				+ \ldots
			\big]										}
			\\
		&\,
			\big[
				\braket{B^+ \phi_0 | \psi_1} +
\phantom{
				\braket{B^- \phi_1 | \psi_0} +
				\braket{B^+ \phi_1 | \psi_2} \:\:+\:\:	}
				\braket{B^- \phi_2 | \psi_1} %+
		%		+ \braket{B^+ \phi_2 | \psi_3} 
%				+ \ldots
			\big]%_{sp.i.} 
			+ \\
			&\,
%			\big[
\phantom{		\braket{B^+ \phi_0 | \psi_1} +
				\braket{B^- \phi_1 | \psi_0} +			}
			\big[
				\braket{B^+ \phi_1 | \psi_2} \:\:+\:\:
\phantom{		\braket{B^- \phi_2 | \psi_1} +
				\braket{B^+ \phi_2 | \psi_3} \:\:+\:\:	}
				\braket{B^- \phi_3 | \psi_2}
			%				+ \ldots
			\big]%_{sp.i.} 
			+ \ldots\,.
	\label{LaTeX-puslespil}
\end{aligned}
\end{align}
*(Bemærk, at jeg her har udeladt subscripterne på kantparenteserne, men disse er altså underforstået.)
Nå, nu fik jeg lige puslet lidt med \LaTeX, men ja, pointen er altså, at man umiddelbart skal integrere de samme funktioner, men bare forskelligt lagt sammen.\,. Og spørgsmålet bliver jo så, hvornår dette så kan ende med ikke at give det samme, og hvornår det vil give det samme.\,. 

.\,.\,Okay, jeg har lige stirret lidt på $\braket{B^- \phi_1 | \psi_0}$, $\braket{\phi_1 | A^+ \psi_0}$ og $\braket{\phi_1 | A^- \psi_2}$.\,. Måske var det forkert, det der med at bare $(\braket{\phi_n| \psi_n^-})_{n\in{\{N,N+1,\ldots\}}}$ skulle eksistere og gå imod 0: Mon ikke vi rigtigt nok skal kræve, at $(\braket{\phi_n| \psi_n^-})_{n\in{\{1,2,\ldots\}}}$ eksisterer som en følge over $\mathbb{R}$, og som går imod 0?\,. (For alle $\psi,\phi\in\mathrm{Dom}(A)$ i.e.) .\,.\,Lad os sige det.\,. .\,.\,Hm, jeg må forresten lige overveje, om jeg så skal bruge superscripts til f.eks.\ Cauchy-følger, eller noget, for ikke at det bliver helt forvirrende.\,. 

.\,.\,Hm, hvis man nu \emph{kan} ``fylde Dom$(A)$ op til randen,'' som jeg nævnte ude i kommentarerne, lige inden jeg begyndte på den renderede tekst i middags, jamen så kunne man da i princippet bare ændre restriktion (\ref{DomA-restriction1}) til lige præcis at kræve, at $\braket{\phi|A\psi} = \braket{A\phi|\psi}$, men dette virker jo lidt snyd.\,. (Hvilket altså vil sige i praksis, at man jo så bare vil flytte bevisbyrden over på at vise, at man \emph{kan} fylde Dom($A$) op til randen således.\,.) .\,.\,Men jeg føler nu alligevel, at jeg på en eller anden måde er på rette spor med disse tanker alligevel.\,. 

.\,.\,Hm, men lad mig lige vende tilbage til lign.\ (\ref{LaTeX-puslespil}), for hvis vi altså har antaget, at $B$ er en %(ikke nødvendig proper, men det gider man jo af gode gunde ikke at sige hele tiden)
udvidelse af $A^*$ (hvad jeg altså også tror meget vel kan være sandt), og.\,. Hm, lad mig egentligt bare droppe antagelsen om, at $\phi\in\mathrm{Dom}(B)$, om ikke andet så indtil den bliver nødvendig.\,. Men vi antager altså (også), at $\psi\in\mathrm{Dom}(A)$, og hvad ser vi så ud fra lign.\ (\ref{LaTeX-puslespil}).\,.\,? .\,.\,Hm.\,. Nu kom jeg lige i tanke om, at man måske også kunne overveje, en alternativ definition for Dom$(A)$, hvor $\phi$ bare skal være i Dom$(B)$, eller giver det så ikke mening.\,.\,? .\,.\,Hm nej, det er nok for skrapt.\,. 

.\,.\,Hm, lad mig lige se på $\braket{\phi|A^- \psi}$ en gang. Vores (\ref{DomA-restriction1})-restriktion sagde, at 
\begin{align}
\begin{aligned}
		\lim_{n\to\infty}\braket{\phi_n| \psi_n^-} = 0
\end{aligned}
\end{align}
for alle $\psi,\phi\in\mathrm{Dom}(A)$.\,. .\,.\,Så dette må jo i hvert fald gælde i $A^-$'s domæne.\,. .\,.\,Hm ja, men Dom$(A)$ skal være skarpt større end Dom$(A^-)$.\,. 

.\,.\,Nå ok, tilbage til at se på lign.\ (\ref{LaTeX-puslespil}) igen.\,. .\,.\,Okay never mind at fjerne begrænsningen for $\phi$; lad os også antage at $\phi\in\mathrm{Dom}(A^*)\subset \mathrm{Dom}(B)$. Så skal $\chi = B \phi$ nemlig eksistere, og ligeså skal $\braket{\chi|\psi}$ (og dette skal være lig $\braket{\phi|A \psi}$). Specifikt skal $\braket{\chi_0|\psi_0} = \braket{B^-\phi_1|\psi_0}$ eksistere, og kan jeg så vise, at dette vil være lig $\braket{\phi_1| A^+ \psi_0}$? .\,.\,Ja, for integralet må kunne omformes, så det bliver identisk med $\braket{\phi_1| A^+ \psi_0}$. Og da 
\begin{align}
\begin{aligned}
	\braket{\phi_1|A \psi_1} = 
		[
			\braket{\phi_1 | A^+ \psi_0} +
			\braket{\phi_1 | A^- \psi_2}
		]_{sp.i.}
\end{aligned}
\end{align}
også skal eksistere, og siden $\braket{\phi_1 | A^+ \psi_0}$ altså konvergerer på egen hånd, så må $\braket{\phi_1 | A^- \psi_2}$ også konvergere på egen hånd (og altså eksistere for sig selv også). 
Nu kan vi så se ud fra lign.\ (\ref{LaTeX-puslespil}), at dette giver os et puslespil (apropos arbejdet med at opsætte ligningerne), hvor vi hele tiden kan vise den selvstendige eksistens af et nyt matrixelement i ligningerne. Rækken er disse (eksisterende) matrixelementer må så være.\,.:
\begin{align}
\begin{aligned}
	&\braket{B^- \phi_1 | \psi_0}, \\
	&\braket{\phi_1 | A^+ \psi_0}; \\
	&\braket{\phi_1 | A^- \psi_2}, \\
	&\braket{B^+ \phi_1 | \psi_2}; \\
	&\braket{B^- \phi_3 | \psi_2}, \\
	&\braket{\phi_3 | A^+ \psi_2}; \\
	&\quad\:\:\:\ldots
\end{aligned}
\end{align}
Og vi kan se, at vi herved når igennem alle udtryk med lige $n$ for $\psi_n$ og ulige $n$ for $\phi_n$. Og vi kan også se, at vi kunne have startet med $\braket{\phi_0 | A \psi_0} = \braket{\phi_0 | A^- \psi_1} = \braket{B^+ \phi_0 | \psi_1}$ og vist det samme for alle $\psi_n$ og $\phi_n$ med henholdsvis ulige og lige $n$.

Nå, og viser dette så ikke netop, at $\phi$ derfor må være i Dom$(A)$, eller er det bare mig?:) .\,.\,Hm, ikke helt umiddelbart, men tilgengæld viser det jo i første omgang, at $\braket{\phi_n | \psi_n^-}$ (osv.) må eksistere for alle $n$, givet antagelserne. .\,.\,Men fordi der pr.\ de samme antagelser også skal gælde, at $\braket{\phi|A\psi} = \braket{\chi | \psi}$, for alle $\psi\in\mathrm{Dom}(A)$, så.\,. Ah, nej vent. Vi kan jo bare bruge, at alle matrixelementerne skal eksistere, så hvis vi tager hele rækken fra $\braket{\phi|A\psi}$, så skal denne række altså konvergere, hvilket den kun kan, hvis $\braket{\phi_n | \psi_n^-}$ (og også $\braket{\phi_n | \psi_n^+}$) går mod 0. .\,.\,:) 

.\,.\,Hm, vil det så sige, at hvis vi kan vise, at $B$ er en udvidelse af $A^*$, så vil vi være i mål.\,.\,?:) .\,.\,Hm, nå nej, for nu fik jeg jo antaget, at (\ref{DomA-restriction1})-restriktionen ikke bare gælder for alle $\phi,\psi\in\mathrm{Dom}(A)$, men at dette også gælder den modsatte vej.\,. Og så er der netop det med, at dette jo ikke nødvendigvis bare er sådan lige at vise.\,. Nå, men det er da stadig et fint skridt, for hvis sætningen også skal gælde den modsatte vej, og hvis Dom$(A)$ altså skal ``fyldes op til randen,'' jamen så ville jeg alligevel skulle løse dette før noget andet. .\,.\,Hm, og \emph{skal} Dom($A$) være fyldt til randen; hvad hvis det ikke er?\,.\,. .\,.\,Hm, så \emph{vil} en $\phi\notin\mathrm{Dom}(A)$, der alligevel opfylder (\ref{DomA-restriction1})-restriktionen, netop være indeholdt i Dom($A^*$). .\,.\,Ja, det må den jo (i hvert fald hvis $B$ udvider $A^*$.\,.). Så ja, derfor bliver jeg altså alligevel nødt til at løse, at Dom($A$) skal fyldes op til randen, så at sige, og dermed er det bare et rigtigt godt skridt, at jeg nu ved, at dette sandsynligvis (og også lige givet at $B$ udvider $A^*$) kan være nok til, at $A$ så bliver selvadjungeret.\,.\,:) 

.\,.\,Hm, gad vide om opgaven kunne klares bare med en god, gammeldags choice-funktion.\,.\,? (.\,.\,Og så kan det eventuelt lige være, at jeg først skal sikre mig, det med at billedet også bliver større og større, hvis dette altså nu skal til for at vise, at $B$ er en udvidelse af $A^*$.\,.)
%(Grunden til, at jeg lige har overkillet lidt med backup-kopier (har lige kopieret qed20.tex også), er, at jeg er lidt stolt over disse resultater og indsigter for det første, og også fordi jeg nok lige tager en pause nu her, og ikke mindst så fylder de jo ikke noget (sammenlignet med main.tex).;):D^^)

%*(Den var lidt i ni, da jeg startede her igen.)
\ldots\ Okay, det må næsten bare handle om, at bruge aksiomerne for mængdelære, og jeg har en idé til en løsning(svej) i tankerne. Hvis vi nu starter med et Dom($A_0$), som altså opfylder restriktion (\ref{DomA-restriction1}), og så ser på mængden af $\phi\in \mathrm{\textbf{H}} \setminus \mathrm{Dom}(A_0)$, som også opfylder ligningen fra (\ref{DomA-restriction1}) (for alle $\psi\in\mathrm{Dom}(A_0)$), kald denne $X$ (og dennes eksistens er sikret ud specifikation-aksiomskemaet), så findes der en ordnet mængde af vektorer, som udspænder $\mathrm{\textbf{H}} \setminus \mathrm{Dom}(A_0)$, kald den $Y$. Eksempelvis kunne man vælge et specifikt $Y$ ved at tage den funktion, der projekterer vektorer fra \textbf{H} og ind i $X$, og så bruge denne elementvist (axiom schema of replacement) på den ordnede basis af impuls-vektorer i Hilbert-rummet. .\,.\,Okay, og nu skal jeg jo så til at hælde $Y$ over i Dom($A_0$), hvor jeg dog gør det én ad gangen og sorterer ethvert $y\in Y$ fra, der ikke længere overholder restriktion (\ref{DomA-restriction1}).\,. .\,.\,Hm, og hvordan gør man lige det på en smart måde.\,.\,? .\,.\,Nå ja, og vi havde forresten sikkert ikke behøvet at lave $X$ først, for hvis vi alligevel løbende skal sortere vektorer fra i $Y$, så kunne vi ligeså godt bare have startet med en vilkårlig mængde, der udspænder $\mathrm{\textbf{H}} \setminus \mathrm{Dom}(A_0)$, og for den sags skyld også bare som udspænder $\mathrm{\textbf{H}}$. .\,.\,Jeg kunne muligvis bruge (og så kan det faktisk måske være smart at danne $Y$ ud fra $X$, som jeg gjorde.\,.), at restriktion (\ref{DomA-restriction1}) jo kun stopper med at holde for en.\,. hm.\,. Never mind: Det jeg havde i tankerne svarer bare til at starte med et tomt Dom$(A_0)$, hvilket ikke ændrer problemet. .\,.\,Hm, kan vi ikke bare smække specifikations-aksiomet hen over problemet, og så ikke behøve at konstruere sorteringsproceduren selv.\,.\,? Så bør man så starte med, lad mig se.\,. .\,.\,Hm, hvis vi bare starter med potensmængden af $Y$ (som eksisterer pr.\ du-ved-godt-hvilket-aksiom), så kan vi jo bare nøjes med at specificere dette med det samme via en formular, der siger at elementerne i den nye mængde, kald den $Z$, nu alle skal have det sådan, at for hvert (vektor-)element i sig skal der gælde, at der ikke findes en anden vektor i samme mængde (som jo stadig er.\,. hm, jeg skal lige sikre mig, at mængderne i $\mathcal{P}(Y)$ stadig er ordnede, men det kan jeg lige vende tilbage til.\,.) med et lavere indeks, således at lign.\ (\ref{DomA-restriction1}) gælder for dette par a vektorer. Og ja, hvis jeg så altså rigtigt nok definerede $Y$ ud fra $X$, som jeg startede med, så vil ethvert (mængde-)elementer af $Z$ så kunne hældes over i Dom$(A_0)$, hvorved det resulterende Dom($A$) så må blive ``fyldt op'' (hvilket jeg dog lige bør tjekke gælder). Og pr.\ udvalgsaksiomet kan så altid vælge et sådan element fra $Z$. Nå, lad mig så lige tjekke, at enhver vektor, $\phi$, hvor lign.\ (\ref{DomA-restriction1}) gælder for dette nye Dom($A$) så også nødvendigvis må være medlem af Dom($A$) selv.\,. Hm, man mangler vi ikke lige først at sørge for, at alle linearkombinationer fra mængden også bliver tilføjet i Dom($A$).\,.\,? Hm, i så fald kan vi jo bare vælge vores $z\in Z$ (som så er mere på lige fod med $Y$, så jeg skal måske lige finde på nogle andre navne, så.\,.), tage alle linear-kombinationer og \emph{så} forene denne med Dom($A_0$). (Og vi har jo implicit antaget, at Dom($A_0$) selv indeholder alle dets linearkombinationer.) .\,.\,Og vil nævnte udsagn, som med andre ord siger, at Dom($A$) er ``fyldt op,'' så følge af denne konstruktion?\,.\,. .\,.\,Ja, mon ikke man kan starte med at sige, at udsagnet gælder, hvis (og sikkert kun hvis) lign.\ (\ref{DomA-restriction1}) gælder for alle de, vektorer i $Y$, som $\phi$ har en ikke-forsvindende projektion ind på. Så lad os derfor bare se, om lign.\ (\ref{DomA-restriction1}) gælder for enhver af disse. .\,.\,Hm, og enten vil en sådan $y\in Y$ være med i $z$.\,. hov, vi mangler da lige at udvælge en maksimal $z$.\,. .\,.\,Hm, men vil der ikke kun være ét element i $Z$.\,.\,? Nå, nu begynder min hjerne at blive ristet, så jeg holder bare pause her, for jeg kan sagtens samle tråden op igen i morgen (eller senere i aften/nat, hvis jeg ikke kan lade være.\,.). Hm, og ja, jeg kan jo bare lige læse dette igennem igen på sigt, så jeg lige får husket alle hængepartierne.\,.  

\ldots\ Okay, klokken er ti i tolv, og jeg vendte tilbage her for fem minutter siden, fordi jeg lige ville kigge lidt på lign.\ (\ref{LaTeX-puslespil}) og se, om jeg kunne finde frem til noget omkring at vise, at $B$ udvider $A^*$. Og nu fik jeg så lige en interessant tanke, som jeg lige prøver at følge: Hvis $\phi\in\mathrm{Dom}(A^*)$ og $\psi\in\mathrm{Dom}(A)$, så må $\braket{\phi | A \psi}$ eksistere (.\,.\,ej, nu føler jeg mig allerede ristet igen.\,.\,x\texttt)xD)\footnote{.\,.\,nå, men jeg får sikkert svært ved at falde i søvn alligevel, så hva faen.x\texttt{)}} og være lig $\braket{A^* \phi | \psi}=\braket{\psi | A^* \phi}^*$.\,. hm, og her tænkte jeg så at bruge noget med, at $A^*$ udvider $A$, fordi min hjerne lige forudså, at der ville stå noget med $A^*\psi$ her i stedet for $A^* \phi$.\,. Nå, det kan være jeg bare lige må hoppe af tasterne igen og vente til i morgen, når min hjerne er kondenseret til mere fast form igen.\,. 


(23.01.22) Nå, angående at vise, at $B$ udvider $A^*$, hvis jeg lige bliver i den tråd, så kom jeg frem til i går nat i sengen, at det sikkert kunne være værd at se på bølgefunktionerne, når vi vil prøve ligesom at se på, hvad $\braket{A^* \phi_n | \psi_n}$ må være givet $\braket{\phi_n | A \psi_n}$.\,. (.\,.\,Hvor $\psi_n$ altså betegner, det de gør bl.a.\ i lign. (\ref{LaTeX-puslespil}).) For at nå frem til f.eks.\ at $\braket{\phi_n | A^- \psi_{n+1}}= \braket{B^+ \phi_n | \psi_{n+1}}$ i mit forrige (tilsyneladende) bevis, når $\phi\in\mathrm{Dom}(B)$, brugte jeg jo, at man kan omforme integralet, så det bliver identisk med $\braket{B^+ \phi_n | \psi_{n+1}}$. Men dette kan man jo godt, som jeg umiddelbart ser det, stadig gøre, selvom $\phi\notin\mathrm{Dom}(B)$. .\,.\,Så hvis vi nu tillader os selv at skrive.\,. hm, vi kan jo allerede godt skrive $B^+\phi$, også selvom dette ikke er en vektor.\,. Hm, nu tænker jeg lige lidt over, om der mon findes en smart notation, så man kan holde styr på, hvad der er vektorer, og hvad der konvergerer.\,. .\,.\,Ah, men det hele går jo egentligt fint, hvis man bare ikke antager, at den distributive lov gælder for braer og ketter.:) .\,.\,Ja.\,. Stærkt.:) 

Okay, men så har vi jo (medmindre jeg tager meget fejl), at
\begin{align}
\begin{aligned}
	\braket{A^* \phi_n | \psi_{n+1}} = .\,.
\end{aligned}
\end{align}
Hm nej, det går nok ikke.\,. Men måske kan vi sige, at 
\begin{align}
\begin{aligned}
	\braket{A^* \phi | \psi} =&\, \braket{\phi | A \psi} \\
		=&\,
			\braket{\phi_0 | A^- \psi_1} +
			\braket{\phi_1 | A^+ \psi_0} +
			\braket{\phi_1 | A^- \psi_2} +
			\braket{\phi_2 | A^+ \psi_1} +
			\braket{\phi_2 | A^- \psi_3} +
			\ldots\\
		=&\,
			\braket{B^+ \phi_0 | \psi_1} +
			\braket{B^- \phi_1 | \psi_0} +
			\braket{B^+ \phi_1 | \psi_2} +
			\braket{B^- \phi_2 | \psi_1} +
			\braket{B^+ \phi_2 | \psi_3} +
			\ldots\\
		.\,.&
\end{aligned}
\end{align}
Ah, men vent.\,. Kommer vi så ikke allerede i mål her.\,.? For jo, det \emph{kan} vi jo så netop sige, men hvis.\,. Hm.\,. Hov nej, udover at jeg vist også lige tænkte noget forkert, så \emph{kan} man vel ikke nødvendigvis sige dette, eller hvad, for vi kan vel ikke sige, at f.eks.\ $\braket{\phi_1 | A^+ \psi_0}$ konvergerer på egen hånd i, hvad der så burde skrives $\bra{\phi_1} (\,\ket{A^+ \psi_0} + \ket{A^- \psi_2}\,)$.\,.\,? .\,.\,Hm, lad mig lige kopiere lign.\ (\ref{LaTeX-puslespil}) ned her, så jeg ikke skal scrolle op efter den:
\begin{align}
\begin{aligned}
\braket{\phi| A \psi} = &\,
\Big[
\braket{\phi_0 | A^- \psi_1} 
+ \braket{\phi_1 | A^+ \psi_0} 
+ \braket{\phi_1 | A^- \psi_2} 
\:\:+\:\: \braket{\phi_2 | A^+ \psi_1} 
+ \braket{\phi_2 | A^- \psi_3} 
\:\:+\:\: \ldots
\Big]%_{sp.i.}
\\
=&\,
\braket{\phi_0 | A^- \psi_1} +
\big[
\braket{\phi_1 | A^+ \psi_0} +
\braket{\phi_1 | A^- \psi_2}
\big] + \big[
\braket{\phi_2 | A^+ \psi_1} +
\braket{\phi_2 | A^- \psi_3} 
\big]%_{sp.i.}
+ \ldots\,,\\
\braket{\chi| \psi} = &\,
\big[
\braket{B^+ \phi_0 | \psi_1} +
\braket{B^- \phi_1 | \psi_0} +
\braket{B^+ \phi_1 | \psi_2} \:\:+\:\:
\braket{B^- \phi_2 | \psi_1} +
\braket{B^+ \phi_2 | \psi_3} \:\:+\:\:
\braket{B^- \phi_3 | \psi_2} +
\ldots
\big]%_{sp.i.}
\\
= &\,
\phantom{	\big[
	\braket{B^+ \phi_0 | \psi_1} +			}
\braket{B^- \phi_1 | \psi_0} +
\phantom{		\braket{B^+ \phi_1 | \psi_2} +
	\braket{B^- \phi_2 | \psi_1} %+
	%		+ \braket{B^+ \phi_2 | \psi_3} 
	%				+ \ldots
	\big]										}
\\
&\,
\big[
\braket{B^+ \phi_0 | \psi_1} +
\phantom{
	\braket{B^- \phi_1 | \psi_0} +
	\braket{B^+ \phi_1 | \psi_2} \:\:+\:\:	}
\braket{B^- \phi_2 | \psi_1} %+
%		+ \braket{B^+ \phi_2 | \psi_3} 
%				+ \ldots
\big]%_{sp.i.} 
+ \\
&\,
%			\big[
\phantom{		\braket{B^+ \phi_0 | \psi_1} +
	\braket{B^- \phi_1 | \psi_0} +			}
\big[
\braket{B^+ \phi_1 | \psi_2} \:\:+\:\:
\phantom{		\braket{B^- \phi_2 | \psi_1} +
	\braket{B^+ \phi_2 | \psi_3} \:\:+\:\:	}
\braket{B^- \phi_3 | \psi_2}
%				+ \ldots
\big]%_{sp.i.} 
+ \ldots\,.
\end{aligned}
\end{align}
Kan man så bruge samme argument, som jeg brugte i går?\,.\,. Hm, jeg skal tænke på, at ligningerne for $\braket{\chi|\psi}$ jo så ikke længere gælder fra start af (men er noget vi ville skulle vise i så fald). .\,.\,Hm, men vi kan vel skrive
\begin{align}
\begin{aligned}
	\braket{A^* \phi | \psi} =&\, \braket{\phi | A \psi} \\
		=&\,
				\braket{\phi_0 | A^- \psi_1} +
			\big[
				\braket{\phi_1 | A^+ \psi_0} +
				\braket{\phi_1 | A^- \psi_2}
			\big] +
			\big[
				\braket{\phi_2 | A^+ \psi_1} +
				\braket{\phi_2 | A^- \psi_3}
			\big] +	\ldots\\
		=&\,
				\braket{B^+ \phi_0 | \psi_1} +
			\big[
				\braket{B^- \phi_1 | \psi_0} +
				\braket{B^+ \phi_1 | \psi_2}
			\big] +
			\big[
				\braket{B^- \phi_2 | \psi_1} +
				\braket{B^+ \phi_2 | \psi_3}
			\big] + \ldots\,,
\end{aligned}
\end{align}
hvor kantparenteserne har har samme specielle betydning som før.\,. .\,.\,Tja, eller bortset fra, at nu er integrationsvariablene ikke det samme, så det kan man faktisk ikke helt sige.\,. .\,.\,Hm, nå, men jeg må jo nok snart til at se på, så, hvad man mon kan sige om konvergensen, hvis vi så kan variere $\psi$ over hele Dom($A$).\,. 

Forresten kan jeg lige nævne, at jeg kom på i går nat, at det måske vil være smart at sørge for, at Dom($A_0$) fra ovenfor allerede er tæt i \textbf{H}, inden man fylder det videre op ``til randen.'' Bare lige en indskudt note.\,. 

.\,.\,Ah vent, $(\ket{A^+ \psi_0} + \ket{A^- \psi_2})$ er da forresten lig $\ket{\psi_1'}$.\,. Never mind.\,.

.\,.\,Hm, men lad mig dog lige se en gang her først, for det kan da også meget vel lige være værd at notere sig, at $\braket{\chi | \psi}=\braket{A^* \phi | \psi}$ jo også må være givet ved
\begin{align}
\begin{aligned}
	\braket{A^* \phi | \psi} =&\, 
		\bra{A^* \phi} \big(
			\ket{\psi_0} +
			\ket{\psi_1} +
			\ket{\psi_2} +
			\ldots
		\big)\,.\,.
\end{aligned}
\end{align}
.\,.\,Hm, og lad mig lige skrive dette op som følgende en gang:
\begin{align}
\begin{aligned}
	\braket{A^* \phi | \psi} =&\, 
		\braket{\chi_0 | \psi_0} +
		\braket{\chi_1 | \psi_1} +
		\braket{\chi_2 | \psi_2} +
		\ldots\,.
\end{aligned}
\end{align}
.\,.\,Hm, kan vi mon så sige noget i retning af, at (f.eks.) $\braket{\chi_1 | \psi_1} = \bra{\phi_1} (\,\ket{A^+ \psi_0} + \ket{A^- \psi_2}\,)$.\,.\,.? Hov nej, slet ikke, men hvad med $(\,\bra{A^*\phi_0} + \bra{A^* \phi_2}\,) \ket{\psi_1}$.\,.\,.? .\,.\,Det ville jo være rart, men det er jo nok det, vi lige netop ikke rigtigt kan.\,. .\,.\,Nå, nu vil jeg lade ligningerne holde pause og prøve at sætte min hjerne lidt på arbejdet i stedet. Og lad mig bare lige holde en eftermiddagspause (væk fra tasterne) også, hvor jeg så bl.a.\ kan prøve at gøre dette lidt\ldots  


%(Klokken tyve over fem, ca.)
\ldots\ Nå, nu kom jeg endelig på, hvad jeg (selvfølgelig) skal gøre for at vise, at $\mathrm{Dom}(A^*) \subset \mathrm{Dom}(B)$. Hvis $\phi$ ikke ligger i Dom$(B)$, så vil der altså findes et $\phi_n$, hvor $\braket{\phi_n' | \phi_n'} = |\phi_n'|$ ikke konvergerer/eksisterer. Men da Dom($A$) kan antages (og det skal jeg jo lige vise mere eksplicit på et tidspunkt) at være tæt i \textbf{H}, så vil vi kunne danne en følge, $(\psi^m)_{m\in\mathbb{N}}$, over Dom($A$), hvor $\psi^m_n$ konvergerer punktvist imod $\phi_n'$ for $m\to \infty$. Men da $\braket{\phi_n' | \phi_n'}$ jo ikke konvergerer, så må $\braket{\phi_n' | \psi^m_n}$ så heller ikke konvergere for $m\to\infty$. Hm, men viser dette dog, at $\braket{\phi_n' | \cdot}$ så er ubegrænset, eller kan $\braket{\phi_n' | \psi^m_n}$ også bare i princippet oscillere (men inden for en radius af et $C$ ganget med $|\psi^m_n|$)? .\,.\,Ah, nu ved jeg det vist, for hvis det oscillerer, så kan man jo bare stryge nogle andre fortegn ud over $\psi^m_n$, så den resulterende, transformerede $\braket{\phi_n' | \psi^m_n}$ derved kommer til at divergere imod uendelig. Cool. Dette viser altså så, at $\psi \mapsto \braket{\phi_n' | \psi}$ ikke er begrænset over Dom($A$) (i.e.\ $\psi\in\mathrm{Dom}(A)$). .\,.\,Hm, og bemærk at $\phi_n' = \chi_n$ pr.\ den notation, jeg har brugt her ovenfor. .\,.\,Hm, og hvordan følger man så lige dette bevis helt til døren.\,.\,? (.\,.\,For medmindre $\chi_n$ er den eneste ikke-normaliserbare funktion, så kan man vel ikke med det samme sige, at $\braket{\chi | \cdot}$ er ubegrænset, eller.\,.\,?) .\,.\,Men hvis $\chi$ er en vektor.\,. .\,.\,Hov, vent, har jeg ikke glemt at tage højde for, at $|\psi^m_n|$ så også vokser (for voksende $m$)?\,.\,.  .\,.\,Jo.\,. 

.\,.\,Hm, det er da overraskende svært, det her.\,. 

.\,.\,Hm, det burde da næsten være nemt.\,. Gad vide, om jeg skal prøve at læse et bevis for den der, ``Riesz-sætning,'' for det er som om, der er en indsigt, jeg mangler der.\,. 

%(kl. lidt i syv) Nu har jeg læst Riesz-sætningen og beviset for det, men nu er jeg til gengæld blevet lidt træt i hovedet, så jeg holder lige en aftenpause...

%(kl. 19:35):
\ldots\ Ah, nu tror jeg måske, jeg har den.\,. Lad os se, hvis $\chi = A^* \phi$ eksisterer som en vektor, og hvis følgen, $(\psi^m)_{m\in\mathbb{N}}$, over Dom$(A)$ (som antages at være tæt i \textbf{H}) konvergerer imod en meget lokal (delta-agtig, kan vi sige.\,.) funktion.\,. Ja, vi kunne jo sige imod en af (impuls-)basisvektorerne. Så skal 
\begin{align}
\begin{aligned}
	\braket{\chi | \psi^m} = 
		\braket{\chi_0 | \psi^m_0} +
		\braket{\chi_1 | \psi^m_1} +
		\braket{\chi_2 | \psi^m_2} +
		\ldots
\end{aligned}
\end{align}
konvergere for alle $m$, og hvis $\psi^m$ altså går imod $\delta_{n'}(p_1, p_2, \ldots; k_1, k_2, \ldots, k_{n'})$, så må og alle $\braket{\chi_n | \psi^m_n}$ konvergere mod 0 for $n \neq n'$. Samtidigt må $\braket{\chi_{n'} | \psi^m_{n'}}$ så konvergere mod $\chi_{n'}(p_1, p_2, \ldots; k_1, k_2, \ldots, k_{n'})^*$, må det ikke? .\,.\,Jo. .\,.\,Og dermed har vi så
\begin{align}
\begin{aligned}
	\chi_{n'}(p_1, p_2, \ldots; k_1, k_2, \ldots, k_{n'})^* = 
		\lim_{m\to\infty}\braket{\chi | \psi^m} = 
		\lim_{m\to\infty}\braket{\phi | A \psi^m}.\,.
\end{aligned}
\end{align}
(Hm, jeg burde nok have byttet rundt på, hvad skal være super- og subscripter, for det giver mere mening, hvis det er superscripterne, der betegner noget lidt særligt.\,.) .\,.\,Nå, og hvad kan vi så sige om $\braket{\phi | A \psi^m}$, når $m\to\infty$.\,.\,? .\,.\,Hm, det er jeg så ikke lige helt sikker på.\,. .\,.\,Hm, det ville jo være dejligt, hvis vi så kan argumentere for, at integralet må blive lig $\braket{A \phi | \psi^m}$ --- eller bare går mod dette, når $m\to\infty$ --- hvor vi altså her tillader at tage $A$ på $\phi$ også selvom den resulterende funktion (i.e.\ $A\phi$) ikke nødvendigvis bliver normaliserbar (og altså således ikke nødvendigvis ligger i \textbf{H}). .\,.\,Hm, men det må da netop gælde, for hvis det konvergerer, hvad det jo netop skal gøre her, så kan man vel bare omforme integrationen til $\braket{A \phi | \psi^m}$ i stedet. Og hvis vi lader $m\to\infty$, så må vi altså (videre) få
\begin{align}
\begin{aligned}
\chi_{n'}(p_1, p_2, \ldots; k_1, k_2, \ldots, k_{n'})^* = 
	\lim_{m\to\infty}\braket{A \phi | \psi^m} = 
	(A \phi)_{n'}(p_1, p_2, \ldots; k_1, k_2, \ldots, k_{n'})^*.
	\label{forkert1}%(Label tilføjet d. 27/1. Sidste lighed er forkert her (generelt), fordi A\phi netop ikke nødvendigvis er en vektor.)
	%*(31.01.22) Nå ja, og den første lighed er også forkert, for det gælder jo netop kun, når \phi \in Dom(A)..! Ja, fjollet, at jeg først ser det nu.. ..Så hele denne sammensatte ligning var altså håbløs.. 
\end{aligned}
\end{align}
Og hvis dette er sandt, så må vi jo kunne gøre dette for alle koordinater og dermed få, at funktionen, $\chi$, skal være lig funktionen, $A\phi$, for alle koordinater, hvilket er ensbetydende med at $\chi= A\phi$. Men hvis $\phi\notin\mathrm{Dom}(B)$, så vil $A\phi$ ikke være en normaliserbar funktion, hvilket strider imod, at $\chi$ er funktionen for en vektor i \textbf{H}. Derfor holder antagelsen om at $\phi\notin\mathrm{Dom}(B)$ kan ligge i Dom($A^*$), hvilket var, hvad jeg ville vise her. Ej, jeg håber dette holder!\,\textasciicircum\textasciicircum\ Det virker umiddelbart fornuftigt nok, men jeg kan mærke, at jeg lige skal summe lidt mere over det på sigt for at blive mere sikker.\,\textasciicircum\textasciicircum

Det næste skridt bliver jo så, at vise, at $A^*$ er lig $B$ (eller $A$, kan vi nu også sige) overalt på Dom($B$), hvor den selv er defineret. (For så får jeg jo, at $B$ udvider $A^*$, hvilket jo er, hvad jeg gerne vil opnå.) 

.\,.\,Hm, men har mit bevis ikke lige fortalt mig, at funktionen, $A^*\phi$, må være lig funktionen, $A\phi$, overalt hvor $A^*\phi \in\mathrm{\textbf{H}}$.\,.\,? (.\,.\,Hvilket altså måske netop godt kan give mening, nu hvor billedet af $A$ ikke længere antages at være et underrum af \textbf{H}.\,.) (.\,.\,Og hvor Dom($A$) altså nu ikke betegner selve $A$'s egentlige domæne, men bare domænet hvorpå $A$'s billede.\,. hm, ligger indenfor \textbf{H}.\,.) .\,.\,Hm, men, angående det jeg lige skrev i disse parenteser, vil dette udsagn ikke kunne definere.\,. ah, nu ved jeg det: Det var et forkert udsagn. Dette er jo lige præcis $B$ jeg så snakker om, hvilken ikke er symmetrisk. Ja, og derfor burde jeg faktisk have skrevet $B$ og ikke $A$ i ovenstående ligninger, så snart jeg flytter $A$ fra $\psi$ og over på $\phi$, således at $A$ altid vil betegne en \emph{symmetrisk} operator. Hm, og i virkeligheden burde jeg nu nok også finde på et nyt navn i det hele taget, sådan at $B$ heller ikke får \emph{to} domæner, nemlig Dom($B$), for det første, men også hele \textbf{H}. .\,.\,Hm, jeg kunne jo eventuelt gå over til at definere.\,. tja, eller.\,.  .\,.\,Hm jo, lad mig bare kalde den $f_A$ for nu, indtil jeg finder på noget bedre.\,. .\,.\,Hm, eller måske kunne jeg lade $\bar{\bar{A}}$ betegne en slags (kontinuert) matrix, hvor elementerne så giver overgangene i (impuls-)basen, og så kunne $f_{\bar{\bar{A}}}$ måske betegne den funktion, der altså er ligeglad med normaliserbarhed osv.\,.\,? .\,.\,Tja, det kan jeg jo tænke over, men for nu vil jeg nok bare skrive $f_A$.\,. 


\ldots Hm, jeg synes altså det ser ud til at holde (og give god nok mening); at for alle $\phi\in\mathrm{Dom}(A^*)$ må $A^*\phi$ være lig $f_{\bar{\bar{A}}} \phi$ (hvor jeg så alligevel allerede bruger $f_{\bar{\bar{A}}}$ i stedet for $f_A$, fordi dette altså alligevel giver en del mere mening).\,. .\,.\,Og dermed får vi så direkte, at på Dom$(B)$ må $A^*$ være lig $B$, fordi $f_{\bar{\bar{A}}}$ nemlig er lig $B$ på dette. Og som jeg lige argumenterede for, at kan Dom($A^*$) heller ikke være større end Dom($B$), for $A^*\phi = f_{\bar{\bar{A}}}\phi$ er nemlig aldrig normaliserbar, hvis $\phi$ ikke er i Dom($B$) (se Dom($B$)'s definition), hvilket vil stride imod at $A^*\phi = \chi$ er en vektor i \textbf{H}. .\,.\,Og derfor har jeg måske altså opnået, hvad jeg gerne ville i dag.\,.\,:\texttt{)} 

.\,.\,(For så er tanken jo, at mit bevis fra i går så videre kan vise, at hvis $\mathrm{Dom}(A^*) \subset \mathrm{Dom}(B)$, jamen så fortæller lign.\ (\ref{LaTeX-puslespil}) samt lidt puslearbejde os, at hvis $\phi$ ligger i Dom($A^*$), så må $\phi$ også ligge i Dom($A$) (altså hvis jeg så heller ikke har lavet en fejltagelse her).\,.\,:\texttt{)})

.\,.\,Jeg har i øvrigt bl.a.\ et hængeparti (men også andre.\,.) fra i går med at vise, at Dom$(A)$ kan ``fyldes op,'' men dette skal nu nok gå alt sammen.\,. Men ja, det vil jeg dog nok bare vente med at se på til i morgen. .\,.\,Fedt, at jeg nu muligvis --- 7, 9, 13 --- er lykkedes med at outline et bevis for, hvorfor min kære operator kan defineres, så den bliver selvadjungeret.\,.\,:) 


(24.01.22) Jeg har tænkt på, at det jo måske er en overtællelig mængde af vektorer, vi skal hælde over i Dom($A_0$).\,. Og ja, bare dette ikke kommer til at ødelægge det. Det bliver interessant at kigge på, men nu frygter jeg altså, at det alligevel ikke bare lige bliver sådan at løse.\,. 

.\,.\,Hm, men lad mig da lige se på lign. (\ref{DomA-restriction1}) en gang.\,. Lad mig lige kopiere den ned her:
\begin{align}
\begin{aligned}
	\lim_{n\to\infty}\braket{\phi_n| \psi_n^-} = 0.
\end{aligned}
\end{align}
Hvis $\psi_n^-$ var en normaliserbar funktion, var det jo trivielt, men det er den jo lige netop aldrig, eller rettere det er den aldrig for to på hinanden følgende $n$; hvis $\psi_n^-$ \emph{er} normaliserbar, så er $\psi_{n+1}^-$ det ikke. Nå, men min tanke var så lige, hvad når $\phi_n$ er begrænset til et lokalt område?\,.\,. Ikke at det nødvendigvis hjælper mig, men det er måske værd lige at overveje det lidt.\,. .\,.\,Hm, jeg kunne også i stedet gå direkte videre til at overveje, hvad en mængde af $\phi_n$'er (taget fra den samlede Dom($A$)) mon skulle opfylde, før man ikke længere kan finde en ny $\psi$.\,. .\,.\,Hm, og jeg kunne i øvrigt også se på
\begin{align}
\begin{aligned}
\lim_{n\to\infty}\braket{\phi_n^+| \psi_n} = 0.\,.
\end{aligned}
\end{align}

\ldots Hov, jeg læste lige mine argumenter for, at hvorfor at lign.\ (\ref{LaTeX-puslespil})-``puslespillet'' viste, at $\phi \in \mathrm{Dom}(B) \cap \mathrm{Dom}(A^*)$ måtte opfylde restriktion (\ref{DomA-restriction1}), men \emph{har} jeg faktisk ikke lavet en fejltagelse her? For jeg har tilsyneladende sagt, at eksistensen af alle matrixelementerne for rækken af $\braket{\phi|A \psi}$ betyder, at den konvergerer hvis og kun hvis hvert enkle matrixelement går mod nul, men så har jeg vel fejlagtigt antaget, at eksistensen af alle ledene betyder, at man kan ophæve parenteserne, og det passer da ikke, vel? .\,.\,Hm nej, ligningerne viser vel bare, at jeg kan flytte parenteserne til andre par af elementer, men det hjælper vel ikke umiddelbart.\,.\,? 
\ldots Nej, vi kan jo bl.a.\ se (hvis man betragter lign. (\ref{LaTeX-puslespil})), at en række af $1 + [1 - 1] - [1 - 1] + [1 - 1] + \ldots$ vil konvergere i begge tilfælde --- også når man samler nr.\ 1 og 4, nr.\ 3 og 6, nr.\ 5 og 8, nr.\ 7 og 10, nr.\ 9 og 12 osv. (og lader nr.\ 2 stå i starten) --- også selvom rækken altså ikke konvergerer, når man ophæver parenteserne.  

.\,.\,Hm, bare det så ikke vil sige, at $\mathrm{Dom}(A^*) = \mathrm{Dom}(B)$.\,.(?) 

\ldots Oh shit.\,. .\,.\,Hvis $\phi\in\mathrm{Dom}(B)$, så vil $\braket{B\phi | \psi} = \braket{\phi | A \psi}$ for alle $\psi\in\mathrm{Dom}(A)$, hvilket viser, at der eksisterer et $\chi$, nemlig $\chi=B \phi$, sådan at $\braket{\chi | \psi} = \braket{\phi | A \psi}$ for alle $\psi\in\mathrm{Dom}(A)$, hvilket altså betyder (se teksten lige under definition 9.1 i Hall), at $\phi\in\mathrm{Dom}(A^*)$. Og dermed er $\mathrm{Dom}(B) \subset \mathrm{Dom}(A^*)$, og $A$ kan altså ikke blive selvadjungeret, så længe den ikke kan udvides til hele Dom$(B)$ og stadig forblive symmetrisk.\,:(\,.\,. 

Øv!!!


\ldots\ Hm, men er jeg nu også \emph{helt} sikker på, at $\phi\in\mathrm{Dom}(B)$ og $\psi\in\mathrm{Dom}(A)$ medfører $\braket{B\phi | \psi} = \braket{\phi | A \psi}$, for dette bør jo f.eks.\ netop ikke gælde for alle $\psi\in\mathrm{Dom}(B)$.\,.\,? .\,.\,Ah, jeg var da for hurtig, her! For jeg føler da godt, at jeg kan finde på et $\phi\in\mathrm{Dom}(B)$, hvor $\braket{B\phi | \psi} = \braket{\phi | A \psi}$ ikke gælder for alle $\psi\in\mathrm{Dom}(A)$.\,.\,! .\,.\,Åh, hvilken lettelse det vil være!\,.\,. 

.\,.\,Ja, lad os se, om vi ikke kan have en række, hvor det konvergerer for begge de to permutationer, i.e.\ for $a_1 + (a_2 + a_3) + (a_4 + a_5) + (a_6 + a_7) + \ldots$ og for $a_2 + (a_1 + a_4) + (a_3 + a_6) + (a_5 + a_8) \ldots$, men ikke mod det samme.\,. Vi kunne jo eksempelvis have $(a_n)_{n\in\{1, 2, \ldots\}} = (1, -1, 1, -1, \ldots)$.\,. Ja, dette vil konvergere til henholdsvis 1 og $-1$. 

.\,.\,Åh, hvor godt.\,.\,!

Nå, vi har stadigvæk (mener jeg), at $\psi\in\mathrm{Dom}(A)$ medfører, at alle disse $a_n$'er eksisterer, og så vil $\phi$ vil ligge i Dom($A^*$), netop når de to rækker konvergerer til det samme? .\,.\,Ja. .\,.\,Hov, lad mig lige tjekke det med, om $\psi\in\mathrm{Dom}(A)$ rigtignok medfører alle $a_n$'ernes eksistens.\,. .\,.\,Ah jo, for dette kommer sig bare af, at de to rækker skal være lig hinanden, når $\phi\in\mathrm{Dom}(A^*)\subset\mathrm{Dom}(B), \psi\in\mathrm{Dom}(A)$, og mit argument for dette fungerer stadigvæk. .\,.\,Og hvornår konvergerer de to rækker så mod det samme?\,.\,. .\,.\,Ah, der gør de jo netop, når der kommer et punkt for hvert $\varepsilon$, hvorefter resultatet ikke ændrer sig mere end højst det $\varepsilon$, hvis man efter et ulige $n$ trækker sidste element, $a_n$ i rækken fra og ligger $a_{n+1}$ til i stedet. Med andre ord konvergerer de til det samme, netop når $a_{n+1} - a_n$ går imod 0, når man ser på en voksende følge af ulige $n$. .\,.\,Hm, og dette vil med andre ord sige, at de to rækker konvergerer mod det samme, netop når.\,. Ja, hvis vi ser på rækken for $\braket{\phi | A \psi}$, så er
\begin{align}
\begin{aligned}
	(a_n)_{n\in\{1, 2, \ldots\}} = 
	(
		\braket{\phi_0 | A^- \psi_1}, 
		\braket{\phi_1 | A^+ \psi_0}, 
		\braket{\phi_1 | A^- \psi_2}, 
		\braket{\phi_2 | A^+ \psi_1}, 
		\braket{\phi_2 | A^- \psi_3}, 
		\braket{\phi_3 | A^+ \psi_2}, 
%		\braket{\phi_3 | A^- \psi_4}
	\ldots
	).
\end{aligned}
\end{align}
Så de to rækker må konvergere mod det samme, netop når 
\begin{align}
\begin{aligned}
	\lim_{n\to\infty}
		\braket{\phi_{n+1}| A^+ \psi_{n}} -
		\braket{\phi_{n}| A^- \psi_{n+1}}
		= 0.
	\label{DomA*-restriction1}
\end{aligned}
\end{align}

Nå, gad vide om jeg mon så kan ændre Dom($A$)-restriktionen, så den passer med dette.\,.\,? 

.\,.\,Hm, kan vi ikke godt dette, for vil ligning (\ref{DomA*-restriction1}) ikke være nok til at gøre $A$ symmetrisk, hvis den altså gælder for alle $\phi, \psi \in \mathrm{Dom}(A)$? 

.\,.\,Hm, ligning (\ref{DomA*-restriction1}) svarer vel forresten til
\begin{align}
\begin{aligned}
	\lim_{n\to\infty}
		\braket{\phi_{n+1}| \psi_{n+1}^+} - 
		\braket{\phi_{n}| \psi_{n}^-}
		= 0,
	\label{DomA*-restriction2}
\end{aligned}
\end{align}
ikke?\,. .\,.\,Jo, og denne restriktion vil altså følge af min (\ref{DomA-restriction1})-restriktion, men vil ikke umiddelbart nødvendig-vis medføre denne.\,. (Altså medmindre at den faktisk \emph{gør} dette.\,.)

.\,.\,Ah, men hvis jeg vender tilbage til spørgsmålet fra lige før, så.\,. .\,.Hm.\,. .\,.\,Jo, lad os se, hvis $\psi, \phi\in\mathrm{Dom}(B)$, så konvergerer begge de to omtalte rækker, nemlig for $\braket{\phi | B \psi}$ og $\braket{B \phi | \psi}$, og de vil også konvergere til det samme, netop når restriktion (\ref{DomA*-restriction1}) gælder. (.\,.\,!) Så vi bør altså i stedet prøve at bygge Dom($A$) ud fra restriktion (\ref{DomA*-restriction1}) og ikke (\ref{DomA-restriction1}), og hvis det lykkes, og hvis dette domæne altså kan ``fyldes op til randen,'' så bør jeg altså nå i mål.\,.\,:)\,.\,. 

.\,.\,Hm, det må forresten lige præcis være rækker, som ender med $\ldots + (c - c) - (c - c) + (c - c) + \ldots$, hvor $c$ er en eller anden konstant, som vi nu også kan få med i domænet.\,. Hm, eller.\,.\,? .\,.\,Tjo, det kan i hvert fald lige netop være, umiddelbart, at sådanne rækker så også kan forekomme (det ved vi ikke umiddelbart, at de ikke kan).\,.

%Nå, jeg vil lige holde lidt aftenpause, inden jeg (muligvis) går videre.  




(25.01.22) Nå, planen var at fortælle, at jeg i går (aftes/nat) kom frem til, at man måske kunne få ``fyldt Dom$(A)$ op'' ved at sørge for, at alle områder af (impuls-basis-)koordinatsystemet ligesom er brugt til at kvæle en (uendeligt stor) bølgefunktion et niveau nede i en eller anden $\psi\in\mathrm{Dom}(A)$. Men nu, lige her inden jeg åbnede dokumentet op, %(Og den er kvart over tolv nu btw, for jeg står stadig meget sent op (og går sent i seng og falder endnu senere i søvn --- men det går jo også fint nok; jeg får da arbejdet en hel del).)
kom jeg så i tanke om, at man jo nok så altid bare kan finde en ny $\psi$, som ikke er i Dom($A$) hidtil, via en diagonal-argument-procedure.\,. Så det er ikke sikkert, at det bliver vejen at gå. Jeg har dog også stadig den idé med, at prøve at få en mængde $\psi$'er med, hvor deres billeder punktvist nærmer sig de uendeligt store (ikke-kvalte) tilstande a la dem, som basisvektorerne sendes til, men jeg har nu endnu ikke fundet ud af, hvordan dette helt præcist skulle hjælpe (men det virker bare som om, det kunne være en ret naturlig del af en mulig løsning.\,.).\,. .\,.\,Nå, men jeg er løbet lidt tør for mad, %for jeg fik ikke handlet i går, hvor jeg alligevel var ude at gå (og i øvrigt var det også sent der, så jeg trænger til lidt dagslys),
så jeg tror lige, jeg går en tur alligevel (og handler ind på vejen hjem), og så kan jeg jo lige summe 
%(som jeg jo btw altså bruger meget som et ord for at gå med noget i tanker, ofte hvor man tænker over det sådan lidt on and off, og hvor der også bare tildels kører lidt i periferien af hjernen (men hvor man selvfølgelig også nogen gange tager fat og tænker lidt mere fokuseret over tingene..)..)
lidt over disse ting imens. \ldots

Okay, på turen kom jeg på at bruge et map fra de reelle tal og over til, hvilke områder bruges i en $\psi$ til at kvæle $A^+$ billedet fra niveauet under, hvorved man jo altså ikke prøver at starte med en tællelig mængde, men starter med en overtællelig mængde af $\psi$'er. Men så kom jeg jo lidt senere i tanke om, at problemet så bare bliver at få den (overtællelige) mængde, man starter med til at være symmetrisk under $A$.\,. Så nu tror jeg faktisk lige, jeg vil prøve at google på noget i retning af ``infinite sequences with no commen entries after a certain point,'' eller ting i den stil, og så se, om jeg kan finde noget arbejde, der har studeret mængder af disse.\,. 

%(kl. 25 over tre)
\ldots\ Nå, jeg fik søgt en anelse, men jeg tror nu, det bliver for svært for mig at finde. Men nu kom jeg så lige på noget andet interessant. Jeg skrev jo
\begin{align}
\begin{aligned}
	\lim_{n\to\infty}
		\braket{\phi_{n+1}| A^+ \psi_{n}} -
		\braket{\phi_{n}| A^- \psi_{n+1}}
		= 0.
\end{aligned}
\end{align}
i går, men da jeg skrev min gamle restriktion op, så udledte jeg den jo netop, hvor jeg bare antog, at $\psi$ og $\phi$ bestod udelukkende af henholdsvis lige og ulige $\psi_n$'er og $\phi_n$'er (og altså var 0 for alle andre). Så det er selvfølgelig det, der gør forskellen. .\,.\,Hm, og man må vel kunne sige, at et generelt $\psi$, altid kan.\,. splittes op i.\,. hm.\,. .\,.\,Hm nej, jeg kan nok ikke lige konkludere noget her umiddelbart, og selv hvis jeg kunne, så kan dette jo godt så ændre sig, så jeg begynder at drage den frie energi (som man kunne kalde $A^0$ eller $A^{diag}$ eller noget.\,.) ind i billedet.\,. 

.\,.\,Hm, nu kom jeg lige på, at hvis man mikser områderne fra tidligere $\psi$ i Dom($A_0$), så kan dette også være en måde, at sikre sig, at en ny $\psi$ er indeholdt i Dom$(A^*)$, så det giver lige en ekstra dimension på det, som vi også skal bekymre os om.\,. 


.\,.\,Hm, og man kan ikke bare starte med mængde af de reelle tal (til sit map), som allerede er ordnede fra start af.\,. .\,.\,ved måske at konstruere den ud fra en tællelig mængde, der allerede er ordnet, og så på en eller anden må sørge for, at potensmængden stadig er det.\,.\,? (En meget løs tanke, men sådanne kan jo alligevel også ofte være rare netop at skrive ned, når man alligevel sidder ved tasterne.\,.) 

.\,.\,Hm, og noget andet er: Kunne man mon bruge linearkombinationer med uendelig mange ikke-forsvind-ende indgange til at ødelægge diagonal-argument-proceduren.\,.\,? .\,.\,Ah, det var da umiddelbart en ret god idé, for mon ikke man godt kan gøre dette på en måde, så Dom($A$) stadig holdes.\,. ``symmetrisk under'' $A$? 


%(Kl. ti i et:)
Klokken er ti min.\ i et nu (altså om natten til d.\ 26.). Jeg kan måske forklare lidt mere om i morgen, hvordan i aften er gået.\,. Jeg er rimeligt ristet nu, så det kan sagtens være, at det hele er forkert, men nu kom jeg lige frem til, at undermængden af Dom($B$), hvor vi kun har lige og ulige $\psi$'er (så altså enten er 0 for alle $\psi_n$ med lige $n$ eller er det for alle $\psi_n$ med ulige $n$), allerede er ``symmetrisk under'' $B$. Hvis dette passer, så er det virkeligt vildt, for så.\,. Tja, det vil jeg hellere snakke om i morgen, når jeg har lidt mere hjerne.\,. .\,.Lad mig for nu bare lige tænke over den næste ting, jeg havde i tankerne.\,. 

.\,.\,Som var, at.\,. Eller rettere, nu er den nærmere bestemt, at man jo så lige præcis kan danne linearkombinationer.\,. hvilket jo sådan set er nok bare at kunne gøre med vilkårlige \emph{par} af vektorer, fordi mængden jo alligevel er (så bred), som den er.\,. og så burde linearkombinationerne stadig danne en mængde, der er ``symmetrisk under'' $B$.\,. Og hvis dette er rigtigt nok.\,. Jamen så vil dette jo lige præcis blive til hele Dom$(B)$.\,. .\,.Hm, lad mig lige prøve at tænke lidt.\,. .\,.\,Hm, vil to linearkombinations-par altid være ``symmetriske under'' $B$.\,.\,? .\,.\,Ja.\,. Og vil de dog mon virkeligt udgøre hele Dom($B$)?\,.\,. .\,.\,Ja, for det nytter vil nemlig lige præcis ikke noget (.\,.hm, og her skal jeg måske lige sørge for at overveje det endnu nærmere, når den frie energi, $A^{diag}$, kommer med.\,.) at prøve at sætte en ulige og en lige vektor sammen til en vektor i Dom($B$), hvis ikke de begge to er i Dom($B$) i forvejen.\,. Så med det argument bør det rigtigt nok blive til hele $B$. 

Okay, dette er rigtigt spændende, ikke mindst fordi det virkeligt var begyndt at se ud som en hård opgave, at ``fylde Dom($A$) op,'' men det kan jeg måske snakke lidt om i morgen. Men det virker nu alt for tidligt at glæde sig (især med mine seneste fejltagelser, hvor jeg lige fik draget nogle for hurtige konklusioner.\,.).\,. .\,.\,Ja, jeg lader det være, og så er jeg bare spændt på, at tage det frem igen i morgen. 


(26.01.22) Nå, der gik ikke lang tid, efter at jeg skrev det, til at jeg godt kunne se, at, nej, selvfølgelig kan de to rækker godt konvergere til noget forskelligt, også når vi kun snakker bølgefunktioner med lige og ulige bosontal. Nå, jeg tror lige, jeg vil skrive nogle noter om, hvad jeg tænkte i går og i går aftes, ude i kommentarerne og så fortsætte med de vigtige ting her i den renderede tekst. 
%Jeg gik jo i går og tænkte meget på, at jeg skulle "fylde Dom(A) op" af tilstande, hvor de alle brugte forskellige områder i koordinatsystemet (altså for deres \psi_n'er) til at kvæle de uendelige (\psi_{n-1}^+)-bølgefunktioner. Og dette var lidt en hovedpine; faktisk kom jeg frem til, at dette ikke kunne lade sig gøre at løse kontruktivt, for man ville altid i så fald kunne finde mere "hurtigvoksende funktion," hvis man altså betragter problemet ved at nummerere alle områder og så omdanne det til et problem med at finde en mængde af \mathbb{N}\to\mathbb{N}-funktioner, hvor hvert udvalgte par kun må overlappe et endeligt antal gange. Og så kan det nemlig ikke lade sig gøre at inddele disse i mængder.. Hm, jo det kan man måske egentligt godt alligevel.. (..Indele dem i mængder, hvor alle funktioner i samme mængde vokser lige stærkt..) ..Hm, det er da egentligt sådan lidt interessant.. ..Nå, men det er ikke længere vigtigt her, så det må jeg filosofere over i min fritid. Om ikke andet, så kom jeg altså i tanke om i går omkring kl. elleve, at problemet jo mere var, hvis man kvæler områder med en (\psi_n^-), som andre voktorer bruger i deres \phi_n (altså til selv at kvæle (\phi_{n-1}^+)), så er det der, man kan bryde symmetrien (nemlig hvis man bliver ved med dette indimellem for voksende n). Dette giver jo ummiddelbart et andet problem at løse, men jeg havde stadig i tankerne, at der skulle være uendeligt mange områder i brug (fordi jeg stadig havde en forestilling om, at man skulle bruge uendeligt mange vektorer (for jo at sikre sig at mængden bliver tæt i \textbf{H}), men at områder stadig ikke måtte overlappe). Senere fik jeg så den tanke, som jeg ind ovenfor i går omkring et-tiden. Og som sagt fandt jeg hurtigt bagefter ud af, at dette ikke holdt. Og så var det vist sådan, at jeg kvart over eller tyve over to endeligt kom frem til, at områderne \emph{godt} må overlappe. (..!) Jeg mener, det var det, jeg fandt frem til på det tidspunkt.. (Jeg var ret ristet da, så jeg husker det ikke vildt godt (men jeg skrev bare tidspunktet ned på noget avispapir.xD), men det må næsten være det, jeg indså der (det kan vist ikke rigtigt være andet).) Jeg lagde mig så ikke vildt lang tid efter, og i sengen kunne jeg jo heller ikke lade det være, og der kom jeg så (med mindre jeg tager \emph{meget} fejl) frem til, at jeg jo endda så også sagtens kan lave en tæt mængde i \textbf{H}, bare med "de samme områder" hele tiden. For hvert punkt i koordinatsystemet, i.e. for hver basisvektor, kan man altså bare have et designeret område til at kvæle (\psi^+)-funktioner til denne basisvektor. Og så kan man simpelthen bare lave en følge af mængder af tilnærmede basisfunktioner (altså tilnærmet med vektorer i Dom(B)), hvor man simpelthen bare kvæler mindre og mindre af \psi^+ for vektorerne for hver mængde i følgen.! Nå, og så faldt jeg til ro med en tanke om, at man nok så skulle prøve at begrænse de områder, der kan bruges til $psi_n$'erne (ved at sørge for at alle andre områder er kvalte (af \psi_n^-)'er fra andre \psi'er), således at man nærmest kun kan bruge ét "område" i sidste ende for en vektor.. Ja, og så var det først lige inden jeg stod op (og jeg snoozede fra kl. halv elleve til tolv xD), at brikkerne endelig faldt mere på plads, og at jeg kunne se, at dette jo netop så bare er at sørge for altid kun at bruge ét "område" til at kvæle en given basisvektor og så samtidigt sørge for altid at kvæle alle andre områder (..og det bliver jo så minus de områder, man lader stå fra og med nr. m mængde i den nævnte følge (hvori mængderne gerne skulle konvergere mod (impuls-)basen vektorvist)). For således må alle potentielle nye \psi så blive nædt til netop at bruge det ene område for hver basis vektor. Og i løbet af min morgenrutine (muligvis var det i badet) fik jeg lige præciseret lidt, at man jo så nok bare skal bruge en mængde af samtlige vektorer, for hvilke der for hvert \varepsilon eksisterer et N, således at alle \psi_n med n \geq N vil være parallelt med det område.. der er valgt til vores konstruktion.. Hm, jeg skal lige analysere den del lidt mere, hvor at vide, hvordan man præcis skal formulere dette, men det korte af det lange er altså, at jeg godt tror på, at man kan definere sådan en mænge via restriktionsaksiomet, sådan at man når i mål, og at Dom(A) er "symmetrisk under" A, og at enhver vektor, som er "symmetrisk med" alle \psi\in Dom(A), selv må være i Dom(A). Tænk, hvis jeg har ret..!!:D:) 

%Nå, jeg føler for lige at gå en eftermiddagstur (den er lidt over to nu), men så kan jeg jo bare passende gå og summe lidt over disse ting.:) 

%(kl. tyve i fem) Ah, det var godt med god pause, hvor jeg ikke tænkte på fysik rigtigt. Meget kort after, at jeg havde klappet computeren sammen, kom jeg på, at det jeg talte om lige her ovenfor nok skal formuleres (lidt bedre) som, at.. Hm.. ..Tja, jeg tænkte noget med, at hvis man ser på et område i \psi_n, der går til at kvæle en basisvektor i (\psi_{n-1}^+), så skal dette.. område være parallelt med.. den vektor man ligesom i konstruktionen har valgt som standard for at udligne denne basisvektor.. Hm.. ..Jo, det er måske ikke helt dumt formuleret.. ..Nu vil jeg så prøve at tage hul på, at få disse ting formuleret matematisk..

%(tolv min. i fem)
\ldots\ Okay, nu har jeg fået skrevet nogle ting ude i kommentarerne om den seneste udvikling i min tanke gang (imellem denne og forrige paragraf i kildekoden). Og som jeg har forklaret i disse noter, så har jeg altså nu en strategi i tankerne, som jeg tror måske kan føre til en Dom($A$), hvorover $A$ er symmetrisk og selvadjungeret. Og nu vil jeg så prøve at tage hul på at formulere denne strategi matematisk.\,.

Hm, det handler om, at man for hver (impuls-)basisvektor, $e_{\boldsymbol{k}}$, vælger en dedikeret vektor (fra et område i impuls-koordinatsystemet (i.e.\ den samlede mængde af ``$e_{\boldsymbol{k}}$'er''), hvor $e_{\boldsymbol{k}}^+$ ($= A^+ e_{\boldsymbol{k}}$) er ikke-forsvindende) som skal bruges som standard til at slukke $e_{\boldsymbol{k}}$, når denne indgår i en $\psi_n^+$, hvor man gerne vil kvæle denne i området for $e_{\boldsymbol{k}}$. .\,.Hm, og hvad når  $e_{\boldsymbol{k}}$ selv bruges i.\,. nå ja: Når $e_{\boldsymbol{k}}$.\,. Hm nej, vent lige.\,. .\,.\,Ah, jeg kan i hvert fald spørge om, hvad der sker, når en vektor så selv skal tage udgangspunkt i $e_{\boldsymbol{k}}$?\,.\,. .\,.\,Ja, men her skal man jo så bare huske ikke at kvæle den pågældende vektor, lad mig kalde den $V(e_{\boldsymbol{k}})$, og så skal alle.\,. hm, lad mig egentligt kalde $e_{\boldsymbol{k}}$ for $e^n_{\boldsymbol{k}}$ i stedet (også fordi jeg jo egentligt heller vil til at bruge superscripter til sådanne $n$ i stedet for subscripter).\,. Og så skal alle $e^{n+1}_{\boldsymbol{k'}}$'er fra $A^+ e^n_{\boldsymbol{k}}$, som er ortogonale på $V(e^n_{\boldsymbol{k}})$, så jo altså kvæles med deres egne $V(e^{n+1}_{\boldsymbol{k'}})$, som ligger et niveau længere oppe.\,. .\,.\,Ja, og nu fik jeg så også nævnt det næste, som var at $V(e^n_{\boldsymbol{k}})$'erne som standard ikke selv må kvæles. Dette burde give os en symmetrisk mængde af vektorer under $A$ (og for nu vil jeg stoppe igen med at putte anførselstegn, når jeg siger ``symmetrisk under'' (en operator), for det har jeg gjort så meget nu, så nu bør man forstå, hvad det handler om). Desuden kan vi så også lave en følge af mængder ud fra denne, hvor vi fjerner flere og flere $V(e^n_{\boldsymbol{k}})$'er, sådan at vektorerne i hver mængde kommer tættere og tættere på de basisvektorer, de bygger på, for hvert led i følgen. Min pointe er så, at man simpelthen bare burde, som jeg kan se, være i stand til at tilføje foreningsmængden af hele denne følge til Dom($A_0$) og stadig altså opnå en Dom($A_0$), der er symmetrisk under $A$ --- og som nu også er tæt i \textbf{H}. Men vi er ikke færdige endnu, for der findes også flere vektorer, som er ``symmetriske med'' alle vektorer i Dom($A_0$) ``under $A$'' (så her har jeg forresten også lige en selvopfundet sprogbrug, som jeg også fra nu af vil begynde at undlade anførselstegn for). Men mit håb er så, at man kan udfylde de resterende huller i Dom($A_0$) ved at medtage, og nu skal jeg nok snart lige tænke lidt, alle vektorer, hvor der.\,. for hvert $\varepsilon$ findes et $N$, således at.\,. Hm, og det er så her, jeg tænker noget i retning af at sige, at det der så svarer til $V(e^n_{\boldsymbol{k}})$ i den nye vektor, $\phi$, som vi gerne vil tilføje til Dom($A_0$) (eller rettere, vi vil jo gerne tilføje hele mængden af alle sådanne $\phi$ på én gang),\,.\,. kald det.\,. $V'_{\phi}(e^n_{\boldsymbol{k}})$,\,.\,. der skal $\braket{V'_{\phi}(e^n_{\boldsymbol{k}}) | V(e^n_{\boldsymbol{k}})}$ så gerne gå imod $\|V'_{\phi}(e^n_{\boldsymbol{k}})\| \|V(e^n_{\boldsymbol{k}})\|$.\,. ja, eller rettere forskellen af disse to udtryk skal altså være inden for $\varepsilon$ for alle $n\geq N$. Mit håb er altså umiddelbart, at dette allerede vil være nok til at ``fylde Dom($A$) op'' (således at ingen nye $\phi$ kan findes, som ikke allerede er i Dom($A$)). 


%(kl. sytten over elleve)
\ldots\ Øv! Nu er jeg lidt kommet frem til, at min nævnte strategi heller ikke virker. For som jeg ser det nu, kan potentielle nye $\psi$'er stadig bryde ud af deres fængsler så at sige.\,. .\,.\,Nå, jeg gider ikke lige prøve at forklare det nærmere nu. Jeg vil hellere prøve så at se lidt nærmere på, hvornår to tilstande i Dom($B$) er ikke symmetriske under $B$. Det er det jo, når restriktion (\ref{DomA-restriction1}) ikke holder, hvis vi lige ser på udelukkende lige eller ulige bosontal for vektorerne.\,. Og nu vil jeg så gerne prøve at se lidt på, hvad man kan sige om matrixelementerne i denne række, i hvert fald hvis de kommer fra tilstande, som følger min måde at konstruere tilstande i Dom($B$) på.\,. 

Hvis jeg bruger min $\psi'$-notation fra tilbage i starten af denne sektion, så må vi have.\,.
\begin{align}
\begin{aligned}
	A^- \phi_n + A^+\phi_{n-2} = \phi_{n-1}' \Longrightarrow
	A^- \phi_n = \phi_{n-1}' - A^+\phi_{n-2},
\end{aligned}
\end{align}
og hvis vi så indfører, at $A^-_n$ er den del af $A^-$, der opererer på en $\phi_n$, så får vi for det fleste $n$, at
\begin{align}
\begin{aligned}
	\phi_n = (A^-_n)^{-1} (\phi_{n-1}' - A^+\phi_{n-2}).
	\label{reduce_phi_n1}
\end{aligned}
\end{align}
Dette har jeg så tænkt mig at bruge i:
\begin{align}
\begin{aligned}
	\braket{\phi_n | \psi_{n}^-} = \braket{(A^-_n)^{-1} (\phi_{n-1}' - A^+\phi_{n-2}) | A^- \psi_{n+1}}.\,.
\end{aligned}
\end{align}
.\,.\,Og vi kan så også reducere ketten til
\begin{align}
\begin{aligned}
	\braket{\phi_n | \psi_{n}^-} = \braket{(A^-_n)^{-1} (\phi_{n-1}' - A^+\phi_{n-2}) | 
		\psi_{n}' - A^+\psi_{n-1}}.\,.
\end{aligned}
\end{align}
.\,.\,Hm, og lad mig også lige opskrive 
\begin{align}
\begin{aligned}
	A^- \phi_n = \phi_{n-1}' - A^+\phi_{n-2}
\end{aligned}
\end{align}
og
\begin{align}
\begin{aligned}
	A^+\phi_{n-2} = \phi_{n-1}' - A^- \phi_n.\,.
\end{aligned}
\end{align}
.\,.\,Hm, og jeg kunne vel også have skrevet
\begin{align}
\begin{aligned}
	\braket{\phi_n | \psi_{n}^-} =&\, 
		\braket{(A^-_n)^{-1} (\phi_{n-1}' - A^+\phi_{n-2}) | 
			A^-_{n+1} (A^-_{n+1})^{-1} (\psi_{n}' - A^+\psi_{n-1})}.\,. \\
	=&\, 
		\braket{(A^-_n)^{-1} (\phi_{n-1}' - A^+\phi_{n-2}) | 
			\psi_{n}' - A^+\psi_{n-1}}.\,. \\
\end{aligned}
\end{align}
.\,.\,Ja, det ser rigtigt nok ud.\,. 

.\,.\,Hm, jeg kan vist godt se, nogenlunde hvad dette leder hen til, hvis man bliver ved med at reducere med lign.\ (\ref{reduce_phi_n1}).\,. Men det kommer ikke til at give mig noget umiddelbart, hvis jeg prøver at fortsætte med dette i nat, så jeg må jo bare lige tænke lidt over det (måske), og så ellers se på det i morgen igen. 


(27.01.22) Mit argument om at $\mathrm{Dom}(A^*) \subset \mathrm{Dom}(B)$ holder ikke. Jeg tror jeg kom til at bruge, at $A$ var selvadjungeret, men det går jo ikke, for så er $\mathrm{Dom}(A^*)$ trivielt undermængde af $\mathrm{Dom}(B)$. Ja, det har været lidt dumt gjort i så fald (men lad mig lige læse mit argument igen.\,.) .\,.\,Ah, det er sidste lighed i lign.\ (\ref{forkert1}), det går galt. Den gælder nemlig ikke generelt, når $A\phi$ jo ikke nødvendigvis er en vektor i \textbf{H} i den sammenhæng. Grunden til, at jeg kan se dette nu, er at jeg i går nat kom på et modeksempel. Jeg kom nemlig til at overveje, hvad der sker, hvis man bare konstruerer en tæt mængde af vektorer, som alle sendes til 0 af $A$ (hvad man nemlig bør kunne). Dette domæne vil så overholde de krav, jeg prøver at opfylde nu og har prøvet de sidste par dage, men den resulterende operator vil tydeligvis få $\mathrm{Dom}(A^*) = \mathrm{\textbf{H}}$ og $A^* = \psi \mapsto 0$. 

Hm, hvad er $B$'s adjungerede egentligt? .\,.\,Hm, jeg tror faktisk, den er $\{0\}$, hvilket sådan set virker meget fornuftigt.\,. .\,.\,Eller rettere Dom($B^*$) er lig $\{0\}$.

\ldots Men ja, så det er jo lidt ærgerligt, at jeg ingen gang kan vide, at jeg er i mål, hvis jeg opfylder de krav, jeg har har arbejdet på nu her.\,. 


.\,.\,Hm, og nu kom jeg lige i tanke om noget andet.\,. Jeg prøver lige at tænke over, hvor $\braket{\phi | A \cdot}$ er begrænset, for hvis vi kun arbejder på ligesom at begrænse tilstandede i henhold til deres haler --- deres boson-produktioner og tilhørende boson-boson-bølgefunktioner til at kvæle disse osv.\ --- så kan man vil lige netop potentielt set komme ud for, at man altid kan konstruere et $\psi$, således at $\braket{\phi | A \psi}$ kan komme til at bryde enhver given $C$.\,.(?) .\,.\,Hm, nå nej, måske ikke.\,. \ldots Hm jo, hvis man f.eks.\ fjerner flere og flere $V(e)$'er og altså inkludere tilstande med større og større billeder, som jeg havde tænkt mig her sidst, så vil man da i hvert fald kunne bryde $C$ altid, vil man ikke?\,.\,. \ldots Hm, men så burde min strategi fra i går middags vel så heller ikke give en symmetrisk $A$, eller der må vel gå et eller andet galt.\,.\,? \ldots Hm, kunne det evt.\ være noget med, at symmetrien bliver brudt, når man tilføjer alle linearkombinationer (fra Dom($A_0$)) til Dom($A_0$).\,.\,?
\ldots\ Nå nej, når man husker at $\phi$ er fastholdt (hvad jeg vist ikke lige gjorde), så kan man vist ikke få $\braket{\phi | A \cdot}$ til at være ubegrænset --- i hvert fald nok ikke på den måde, jeg lige tænkte.\,. 

.\,.\,Hm, jeg kan mærke, at jeg snart får brug for en pause fra fysikken igen, hvis jeg ikke lige kommer nogen vegne, ikke mindst fordi jeg ikke føler, at jeg kan blive ved med at bruge tid på det meget længere, hvis ikke snart jeg får mål i sigte igen (hvad jeg jo dog har følt jeg har haft nærmest hver dag på det sidste; det har i hvert fald været meget (hurtigt) op og ned.\,.).\,. (.\,.\,Og jeg kan mærke, at jeg ikke er vildt oplagt på opgaven i dag.\,. .\,.\,Også selvom jeg egentligt føler mig ok frisk; jeg har bare ikke vildt meget mod på opgaven lige nu.\,.)

%(kl. fem over seks)
\ldots\ Jeg fik en tanke i går nat (udover den/dem, jeg allerede har nævnt), som egentligt kan medføre, at min tanke om, at en ny potentiel $\psi$ kan ``bryde ud af fængslet,'' som jeg formulerede det, i min løsning, som jeg skrev om i går middags, ikke nødvendigvis er rigtig.(!) Men det var først nu her, da jeg var ude at gå (jeg er nemlig lige kommet jeg nu fra en eftermiddagsgåtur), at jeg tænkte videre over denne tanke (bl.a.\ fordi jeg fik min tanke omkring at definere Dom($A$) til at være alle de $\psi$, hvor $A \psi = 0$, kort efter og så tænkte over disse ting i stedet). Men nu fik jeg altså endeligt vendt tilbage til den, og jeg kan altså ikke helt afskrive min løsning fra i går endnu.\,:)\,.\,.

Okay, lad mig prøve at se på det.\,. Lad os sige, at vi har bygget min omtalte løsning for Dom($A$) og så ser på et $\phi$, som også opfylder restriktion (\ref{DomA*-restriction1}) (eller måske ligefrem restriktion (\ref{DomA-restriction1}), især hvis vi nøjes med at se på bølgefunktioner med udelukkende lige eller ulige bosontal). .\,.\,Hm, ja lad os bare sige udelukkende lige eller ulige bosontal (for nu).\,. .\,.\,For en given $\phi_{n}$ skal $\phi^+_{n+1}$ så kvæles mere og mere for voksende $n$, i hvert fald hvis man ser på normen.\,. .\,.\,Hm, så lad os slå ned i et område af $\phi_{n}$, kald det.\,. hm, jeg ville have kaldt det $\phi_n'$, men det bruger jeg jo allerede.\,. .\,.\,Hm, det bliver lidt forvirrende, men jeg skal jo nok alligevel holde mig fra at bruge den gamle mærke-notation, så lad mig faktisk bare kalde det $\phi_n'$ her (og så huske ikke at bruge dem gamle notation for nu, medmindre jeg genintroducerer den). Min tanke er så nu, at udvælge et $\phi_n'$ og et $\phi_{n+1}^+.\,.'$.\,. hov, det duer ikke rigtigt, for jeg kan ikke sætte to superscripter.\,. .\,.\,Hm, kunne jeg ikke bruge en accent i stedet?\,.\,. .\,.\,Hm nej, lad mig bare sætte parenteser for nu og så altså lade mærket betegne en vis projektion, som er forklaret i sammenhængen. Så vi vælger et $\phi_n'$ og en tilhørende $(\phi^+_{n+1})'$, hvor $(\phi^+_{n+1})'$ kommer fra $A^+ \phi_n'$, og hvor $(\phi^-_{n+1})'$ på samme område stort set spiser $(\phi^+_{n+1})'$.\,. .\,.\,Nu tager vi så et $\psi$ fra Dom($A$) med modsat paritet, hvor $\psi_{n+1}$ har en ikke forsvindende bølgefunktion på samme område, og lad os bare så snakke specifikt om $\psi_{n+1}'$ på dette område. .\,.\,Hm, eller vi kan faktisk specifikt vælge en $\psi$, der tager udgangspunkt i en basisvektor fra dette område.\,. hov nej, vi skal lige bruge hele området, men det er også okay: $\psi$ kan bare være en linearkombination af vektorer, der tager udgangspunkt i dette område. Så vil.\,. .\,.\,Hm lad mig egentligt bare kalde hele den del af $\phi$, der involverer $\phi_n'$ for $\phi'$.\,. Så vil
\begin{align}
\begin{aligned}
	\braket{\phi'| A \psi} = 
		\braket{\phi'_{n}   | A^- \psi_{n+1}} + 
		\braket{\phi'_{n+2} | A^+ \psi_{n+1}} + 
		\braket{\phi'_{n+2} | A^- \psi_{n+3}} + 
		\braket{\phi'_{n+4} | A^+ \psi_{n+3}} + 
		\ldots
\end{aligned}
\end{align}
og
\begin{align}
\begin{aligned}
	\braket{A \phi'| \psi} = 
		\braket{A^+ \phi'_{n}   | \psi_{n+1}} + 
		\braket{A^- \phi'_{n+2} | \psi_{n+1}} + 
		\braket{A^+ \phi'_{n+2} | \psi_{n+3}} + 
		\braket{A^- \phi'_{n+4} | \psi_{n+3}} + 
		\ldots\,.\,.
\end{aligned}
\end{align}
Hm.\,. \ldots Hm, jeg har stadig en nogenlunde idé om, hvor jeg gerne vil hen med dette, men jeg tror lige jeg holder en aftenpause %(.\,.som det snart er ved at være i min bog; jeg tænker hen af sekstiden, så har vi aften) 
(og så måske bare summer lidt over det imens).\,. 

%(kl. 25 min. i syv)
\ldots\ Okay, nu fik jeg lige tænkt lidt mere. Idéen er nu, at jeg håber på at kunne komme frem til, at $\braket{\phi'_{m} | A^- \psi_{m+1}}$ kun kan være aftagende for voksende $m$, og at den kun aftager, når $V_{\psi}(\psi_{m-2})= \psi_{m}$ og.\,. lad mig lige se.\,. .\,.\,Hm.\,. .\,.\,Ah, er det ikke, når $\phi_m$ er ikke-ortogonal på.\,. hm.\,. .\,.\,Hm, det virker faktisk lidt kompliceret.\,. Naivt kunne man sige, at det var, når $\phi'_m$ var ikke-parallel med $V_0(\phi'_{m-2})$, hvor $V_0$ er vores standard for konstruktionen, og hvor f.eks.\ $V_\psi$ (som jeg kaldte $V'_\psi$ før) altså godt kan være forskellig fra $V_0$ (som jeg bare kaldte $V$ før), selvom $\psi\in\mathrm{Dom}(A)$, hvis bare det altså ligesom stopper med at være forskellige efter et vist punkt.\,. Men det antager jo, at $A^- \psi_{m+1}$ \emph{aldrig} spiser noget af $V_0(\phi'_{m-2})$, og er det nu også rigtigt, eller hvad?\,.\,. .\,.\,Hm nå, men kan jeg nu alligevel ikke bare påstå i stedet, at det må være, når $\phi_m$ er ikke-parallel med $V_\psi(\phi'_{m-2})$.\,.\,? .\,.\,Hm nej, for hvad betyder det overhovedet?\,. .\,. (For $\psi$ har jo modsat paritet af $\phi$.) .\,.\,Hm nej, lad mig lige gå tilbage til spørgsmålet, om $A^- \psi_{m+1}$ altid skal lade $V_0(\phi'_{m-2})$ være.\,.(?) .\,.\,Nej, det kan jo ikke være tilfældet.\,. 
%(He, den her type tænkeri sætter virkeligt min hjerne på prøvelse..x) Det er et rigtig spændende felt, jeg har valgt at specialisere mig i, men man bliver godt nok tvunget til at sætte de grå arbejde..x) ..Det er sådan en abstrakt form for tænkeri, hvor man skal tænke meget i billeder og virkelig holde tungen lige i munden for at prøve at overskue det.. He..)
\ldots Hm, eller måske giver det faktisk lidt mening at skrive $V_\psi(\phi'_{m-2})$, for så kunne man måske bare for den modsatte paritet sige, at $V_\psi$ så betegner den del af koordinatsystemet for niveauer med denne paritet, der \emph{ikke} bliver spist af $\psi^-$'er.\,:)\,.\,.(?) .\,.\,Hm, det synes jeg lyder meget klogt --- selvfølgelig kan man altid finde en anden notation også (man kunne f.eks.\ kalde det $U_\psi$ i stedet), men jeg synes det virker klogt at fremhæve denne del.\,. 

.\,.\,Og så kan jeg altså forhåbentligt komme frem til, at $\braket{\phi'_{m} | A^- \psi_{m+1}}$-følgen kun aftager, og netop kun når $\phi'_m$ altså er ikke-parallel med.\,. .\,.\,Hm jo, lad mig bare bruge $V_\psi(\phi'_{m-2})$ for nu.\,. *(Ja, og det er sikkert meget klogt endda; det bliver sikkert også smart, når nu vi på et tidspunkt skal til at ophæve paritet-udelukkelsen.) .\,.\,Og hvis dette passer.\,. Hm ja, lad mig lige tænke over, hvad man mon så kan nå frem til.\,. .\,.\,Jo, lad mig lige sige, at pointen for to $\phi$ og $\psi$ som begge er i Dom($A$), er at både $\phi_m = V_\phi(\phi_{m-2})$ og $V_\psi(\phi_{m-2})$ begge på et tidspunkt skal gå mod $V_0(\phi_{m-2})$, hvorved $\braket{\phi_{m} | A^- \psi_{m+1}}$ altså vil aftage mere og mere derfra.\,. .\,.\,Hm, jeg tænkte lige, om dette så endda kunne være en for stærk antagelse, men det.\,. .\,.\,Tja, det må jeg jo bare se nærmere på til den tid. .\,.\,Og hvis vi så går tilbage til vores $\braket{\phi'_{m} | A^- \psi_{m+1}}$, hvor $\phi'$ altså bare vides også at skulle overholde restriktion (\ref{DomA-restriction1}).\,.\,? .\,.\,Ah, jamen så kan vi jo altid finde en $\psi$, eller måske skulle man rettere sige en $V_\psi$, som ikke har nogle områder tilfældes med $\phi'$, hvis og kun hvis.\,. hm.\,. hvis $\phi'$ ikke har en hale, der har overlap med $V_0$'s hale.\,. Hm ja, så der er måske noget der, hvor det ikke lige kommer til at gå helt, som jeg ville have haft håbet på, men det må jeg jo lige se på.\,. (Jeg er jo også langt fra sikker på endnu, at min antagelse omkring, hvordan $\braket{\phi'_{m} | A^- \psi_{m+1}}$ er aftagende, holder.\,.) 
%..Hm, dette kunne gå hen og blive et problem.. ..Men nu tror jeg lige, jeg holder en pause igen.. 

%(klokken ni)
\ldots\ Okay ja, så nu håber jeg vel egentligt mere på at nå frem til, $\braket{\phi'_{m} | A^- \psi_{m+1}}$ mere bare er lig med, hvor meget $V_\phi'(\phi'_{m-2})$ og $V_\psi(\phi'_{m-2})$ er parallelle med hinanden.\,. (Så at man altså godt til hver en tid kan bryde symmetrien i de to rækker igen.\,.) .\,.\,Hm, eller mener jeg ikke, hvor meget de er ortogonale på hinanden.\,.\,? .\,.\,Nå nej, lig.\,. (Hm, jeg håber jo lidt på nu, at jeg kan svare oplagt på dette (med "jo, det to ting er lige netop lig hinanden"), men lad mig nu lige se ad en gang.\,.) .\,.\,Hm, men det følger jo, så vidt jeg kan se, direkte af, hvordan jeg har defineret $V_\psi$ og $V_\phi'$, så.\,. spørgsmålet er nok nærmere, hvad jeg lige mangler, før dette også bliver tilfældet.\,. .\,.\,Hm ja, på en måde er spørgsmålet vel nu --- eller i hvert fald ét af dem (men nok et stort et af dem.\,.) --- om man altid vil kunne vække $\braket{\phi'_{m} | A^- \psi_{m+1}}$ til live igen for et givent $m$.\,.\,? .\,.\,Ved altså at have et $V_\psi$ og et $V_\phi'$, der stopper med at være parallelle.\,. måske for passende områder ift.\ de specifikke $\phi$ og $\psi$.\,. .\,.\,Hm, men angående det sidste, så er hele pointen (som jeg så småt begyndte at indse fra i går nat af), at de to ikke kan undslippe hinanden, da de hver især kun er herre over hver deres paritet, men hvor de samtidigt hver især "fylder det hele" i den modsatte paritet (nemlig i form af at f.eks.\ $A^+ \phi_n$ "fylder det hele" på næste niveau --- og nemlig lige præcis der, hvor $\psi_{n+1}$ har "frihed" til at vælge område for sin placering, men så altså ikke kan "undslippe" $A^+ \phi_n$).\,. .\,.\,Hm, men jo, mon så ikke det faktisk passer, at man lige nøjagtigt kan finde en $\psi\in\mathrm{Dom}(A)$, der ikke er symmetrisk med $\phi$, hvis og kun hvis $V_\phi$ har en sammenhængende følge af basisvektorer, hvor den næste vektor i denne følge altså hele tiden ligger i $A^+$-produktionen af den forrige, hvor $V_\phi$ ikke konvergerer til $V_0$?\,.\,.

.\,.\,Hm, men hvad så med.\,. Man kan jo sige, at rækkerne umiddelbart konvergerer til det samme, hvis bare $V_\phi(\phi_{m})$ konvergerer til $V_0$ for alle lige $m$, men hvad så med alle de ulige $m$? Dette skulle jo gerne på én eller anden måde følge af det andet, men hvordan.\,.\,? .\,.\,Tja, det umiddelbare svar vil vel være, at ellers kan rækkerne ikke konvergere, men lad mig nu lige se.\,. .\,.\,Hm, men er $\braket{\phi'_{m+1}   | A^+ \psi_{m}}$ nu også lig.\,. .\,.\,Hm, er specifikt $A^+ \psi_m$ lig $V_\psi(\psi_{m-1})$.\,.\,? .\,.\,Hm nej, det giver ikke mening.\,. 
%..Nå, jeg håber virkeligt, at dette (altså det fra forrige paragraf) holder..!^^ Men nu begynder jeg at føle mig en smule ristet, så jeg holder pause igen (og måske fri). ..Men ja: spændende!..:) 


(28.01.22) Okay, der er sket en del ting siden i går aftes. For det første kom jeg frem til kort tid efter, at jeg stoppede på tasterne, at det nok alligevel gælder, det med at $\braket{\phi'_{m} | A^- \psi_{m+1}}$ nok af aftagende. Klokken to om natten (ja, mit døgn er jo stadig rykket (og jeg er også rigtigt lang tid om at falde i søvn --- men til gengæld får jeg tænkt i sengen)) kom jeg så også frem til en stor ting, som jeg har overset indtil nu. $A^-$ kan jo godt absorberer andre bosoner end den, der ligesom blev emitteret senest så at sige. Dette betyder ikke rigtigt noget for f.eks.\ $\psi_2$, hvis $\psi$ tager udgangspunkt i en 0-boson-vektor, for det tilføjer bare en endelig tilstand i 1-boson-rummet for billedet af $\psi_2$. Men for f.eks.\ $\psi_4$ begynder det faktisk at give problemer, for så vil absorption af både den fjerde (som planlagt) men også den anden boson bidrage til $\psi_3^-$ med uendeligt store tilstande. Dette er ret betydende! Hvis jeg har tænkt dette før, så har jeg glemt det igen (hvilket måske kan være, hvis jeg ikke anså problemet som vigtigt, hvad der kan give god nok mening, hvis jeg dengang tænkte, at $\hat H$ nok skulle vise sig at være selvadjungeret for hele, hvad jeg kalder Dom$(B)$ nu.\,.). Nå, men er dette godt eller skidt? Tja, da jeg kom på det i går nat, der tænkte jeg, ``sikke en hovedpine, det så vil blive at løse denne opgave.'' Men hvad jeg senere kom frem til i sengen, er, at hvis ellers det kommer til at gå fint med at danne vektorer i Dom($B$), så kan det potentielt set gøre opgaven nemmere. Så det må jeg jo lige se på. Samtidigt kom jeg der også frem til, at jeg egentligt har tænkt for meget på fermionen, når jeg har forestillet mig tilstandene. I virkeligheden bør jeg bare se bølgefunktionerne som værende over en følge af $k-$ (og ikke $\Delta k$!) koordinater, og så faktisk være ret ligeglad med fermionens impuls (i hvert fald så længe, der kun er én). Så ja, det bliver rigtigt godt for mig lige at prøve at stille de bølgefunktioner op, og så arbejde med at få en tilstand til at konvergere efter operation med $A$. Ok, men i badet i.\,. ja, i middags, var det jo så (omkring kvart i tolv), kom jeg pludselig på en ny, rimelig.\,. halv-genial tanke, og det var, at hvis $\braket{\phi'_{m} | A^- \psi_{m+1}}$ virkeligt er aftagende, jamen så er der måske alligevel råd, for måske kan man så bare inkludere en slags mængde i Dom($A$) af alle vektorer, som nærmer sig $V_0$ for halvdelen af alle $m$-niveauer eller mere efter et vist $M$. Jeg gik så ud på en middagstur (for mig nærmest en slags morgentur, kan man sige.\,.) kort efter min morgenrutine ligesom. Her kom jeg på frem til.\,. for forinden havde jeg nemlig fået øje på problemet, ``jo tak, men hvad så med de vektorer, hvor det er præcis halvdelen, der nærmer sig $V_0$?'' Men fordi vi altid snakker intervaller af endeligt mange diskrete niveauer, jeg tror jeg på, at denne strategi \emph{kan} lade sig gøre. Jeg nåede så dog at komme i tanke om, at vi jo også så vil kunne finde vektorer, der kun overlapper \emph{præcis} halvt med $V_0$, og så får man samme problem igen. Men efter lidt tid, da jeg var nået til Stensø, kom jeg så i tanke om, at (impuls-)koordinatsystemet jo også antages at være diskret (og det gør jeg i forvejen, for de matematiske sætninger siger at \textbf{H} gerne skal være separabel, og det er også helt fint, at se på et endeligt $L$ (altså længden af ``universet'' i teorien)), og så kan dette problem altså også nok godt løses.\,.\,! Nå, men alt dette vil ikke nødvendigvis blive relevant, for jeg ved jo bl.a.\ endnu ikke, hvordan det kommer til at gå med det nye Dom($B$)-vektorer, men det må jeg jo bare begynde at se på nu her. Og som jeg ser det, er der altså en lille sandsynlighed for, at dette nye faktisk kan komme til at gøre, at at $V_0$ på et tidspunkt skal låses til det samme for alle niveauer, hvilket jo umiddelbart ville være storartet.\,.\,!\,.\,. Men ja, ingenting er sikkert; jeg må bare lige se lidt på det.

Som sagt vil jeg begynde at være ligeglad med fermion-impulsen, og så vil jeg altså bare skrive $\psi_n$ som en funktion af $n$ $k$-koordinater. .\,.\,Hm ja, og så vil $\psi_0$ netop være en basisvektor af en fermion med en vis impuls (og med 0 bosoner).\,. eller rettere $\psi_0$ vil være parallel med denne. Og ja, da $A$ er impulsbevarende, behøver vi ikke at bekymrer os om andet end én sådan start-impuls-basisvektor ad gangen. 

$A^+\psi_0$ er så givet på forhånd, og $\psi_2(k_1, k_2)$ skal så være givet, så at $A^- \psi_2(k_1, k_2)$ kommer til at tilnærme sig $-A^+\psi_0$, hvilket vil sige, at de kun må afvige med en endelig forskel (ift.\ differencens vektornorm). 

.\,.\,Hm, jeg burde næsten prøve at begynde at lave superscripter i stedet.\,. .\,.\,Hm, eller hvad? Er det egentligt alligevel ikke bedre bare at bruge to subscripter, når/hvis vi på et tidspunkt skal bruge en følge af dem? .\,.\,Det tror jeg næsten. Ok. .\,.\,Okay, definer så.\,. $V_1(k): \mathbb{R}^3 \to (\mathbb{R}^3 \to \mathbb{C})$, og lad.\,. $\psi_2 = (k_1, k_2) \mapsto \psi_1^+(k_1) V_1(k_1)(k_2)$, således at $A^- \psi_2(k_1) = \psi_2^-(k_1)=$.\,. .\,.\,$= \int dk \bar{A}(k)(\psi_1^+(k) V_1(k)(k_1) + \psi_1^+(k_1) V_1(k_1)(k))$. Og her har jeg altså ladet $A = A^- + A^+ = \int dk \bar{A}(k) a^-(k) + \int dk\bar{A}(k)^* a^+(k)$.\,. .\,.\,Ja, lad mig lige skrive dette op en gang: Vi har
\begin{align}
\begin{aligned}
	A^- \psi_2(k_1) = \psi_2^-(k_1) = 
		\int dk\, \bar{A}(k)(\psi_1^+(k) V_1(k)(k_1) + \psi_1^+(k_1) V_1(k_1)(k))
	\label{V_1:1}
\end{aligned}
\end{align}
og 
\begin{align}
\begin{aligned}
	A = A^- + A^+ = 
		\int dk\, \bar{A}(k) a^-(k) + \int dk\, \bar{A}(k)^* a^+(k).
\end{aligned}
\end{align}
.\,.\,Og her er lign.\ (\ref{V_1:1}) altså potentielt bare midlertidig; her forsøger jeg mig frem med at skrive en løsning op (hvorimod ligningen for $A$ er en definition, jeg bare regner med at bruge fra nu af).

Okay, og her er det så, at $\int dk \bar{A}(k)\psi_1^+(k) V_1(k)(k_1)$ (første led i lign.\ (\ref{V_1:1})) gerne skulle blive endelig, ikke?\,.\,. .\,.\,Hm, lad os se, vi skulle gerne have, at
\begin{align}
\begin{aligned}
	\iint  |\psi_2(k_1, k_2)|^2\,dk_1\,dk_2 = \iint |\psi_1^+(k_1)|^2 |V_1(k_1)(k_2)|^2 \,dk_1\,dk_2 
\end{aligned}
\end{align}
er endelig.\,. \ldots Hm, men det giver os ikke lige umiddelbart noget svar på det spørgsmål.\,. .\,.\,Nej, der skal jeg måske nok tage et mere konkret eksempel, før man ville kunne se dette.\,. 


\ldots Hm, jeg tager lige en pause udledningerne, men nu så jeg lige lidt på det, og vil lige bemærke, at vi jo sådan set altid bare for en $\psi_1^+(k)$ lagt til, hver gang $A^+$ opererer.\,. Og ja, så kan jeg altså ikke lade være med at tænke, at $V_m$ ret meget må konvergere til en konstant funktion.\,. .\,.\,Hm tja, men jeg kan jo ikke være sikker overhovedet, før jeg regner mere på det.\,. Men ellers er det gode jo også, at jeg alligevel nu tror, at der kan findes en strategi, selv hvis dette ikke er tilfældet.\,. (.\,.\,Altså den nævnte strategi med at lade Dom$(A)$ bestå af alle de $\psi$, hvor $V_\psi$ ``konvergerer halvt eller mere'' til $V_0$. (.\,.\,Hvilket vil sige, lidt løst sagt (og tanken er jo også bare en smule løs indtil videre), at den efter et punkt vil tilnærme sig $V_0$ for halvdelen af alle basisvektorer/koordinater eller mere.\,.)) 

.\,.\,Men lad mig nemlig også lige nævne, at hvis bare jeg lige akkurat kan få tiltro nok til, at min nye strategi kan lede mig frem til en løsning, så overvejer jeg nu bare at udgive det i en form, hvor selvadjungeret-sektionen bare er udeladt, og hvor jeg bare henviser til, at jeg selv så småt føler, at jeg arbejder mig frem mod en løsning, men at andre skal være velkommen til at joine problemet (og hvor folk også skal være velkomne til at spørge til mine resultater indtil videre).\,. .\,.\,Jeg føler faktisk, at dette kunne være en ret fed måde at gøre det på. Men det kræver desværre bare lige, at jeg selv har stor nok tiltro på, at problemet kan løses.\,. .\,.\,Ikke at det absolut \emph{skal} kunne løses, men jeg skal ligesom sikre mig, at det vil være en spændende nok opgave med nok kød på, til at den er værd at give videre til en større mængde mennesker.\,. 

.\,.\,Tja, eller på den anden side, så behøver jeg måske ikke være vildt sikker på, at der bliver kød på opgaven, for det er jo et væsentligt problem i fysikken uanset hvad; problemet afhænger jo ikke af, at jeg har tilføjet et Coulomb-potentiale til teorien.\,. Hm.\,.\,? (.\,.\,Nå ja, det skal jeg forresten også huske, skal inkluderes i $A$ på sigt.\,.) .\,.\,Men angående, hvor sikker jeg skal være på, at der er kød på.\,.\,? .\,.\,Hm, jeg kan ikke rigtigt tro på, at der findes en velkendt løsning.\,. .\,.\,Så spørgsmålet er vel mere bare, om jeg mener problemet har god chance for at være traktabelt.\,. .\,.\,Ja, men det kan jeg forhåbentligt også snart nå frem til, om jeg synes, det har. Så lad mig lige overveje problemet lidt mere, og hvis jeg mener, at chancen for tractability er stor nok, så tror jeg nemlig så, jeg vil skifte tilbage til at skrive udgivelsespapirer (inkl.\ om QED, hvor jeg så bare lader selvadjungeret-problemet stående åbent). 


%(klokken fem i syv)
\ldots\ Hm jo, pointen med $V_1$ er jo netop, at når man integrerer $\psi_2$ over første variabel, så skal det rigtigt nok gerne give noget endeligt, men hvis man integrerer anden variabel, så skal det tilnærme sig $\phi_1^+$.\,. .\,.\,Eller rettere når man integrerer $\bar{A}(k_1)V(k_1)(k_2)$.\,. (I øvrigt kunne jeg godt tage og kalde det $c(k)$ i stedet for $\bar{A}(k)$.\,. .\,.\,Måske.\,.\,:)) .\,.\,Hov nej, det var rigtigt nok, for jeg skrev $\psi_2$ og ikke $V_1$.\,.\,x) %(..Har åbnet en juleøl og tager den bare lidt med ro..;)) 

\ldots Ej, det tegner altså meget godt.\,. (.\,.\,Det tegner af, at $V_n$, eller $V_{\psi\,n}$ (/$V_{\psi, n}$) kunne vi også sige, skal blive overvejende konstant.\,.) 

.\,.\,Hm, er det ikke lige før $V_3$ \emph{skal} være lig $V_1$ allerede (osv.), eller er det bare mig.\,.\,? \ldots Hm, vil det så godt nok være pr.\ egen antagelse om, at $\psi_2$ skal integrere til en endelig vektor over første variabel, så det må jeg lige huske på.\,.


%(tyve i ti)
\ldots\ Lad mig lige prøve en gang at antage, at 
\begin{align}
\begin{aligned}
	\psi_4(k_1, k_2, k_3, k_4) = \psi_2(k_1, k_2) v(k_3, k_4).
	\label{psi_4_seperabel}
\end{aligned}
\end{align}
Så har vi
\begin{align}
\begin{aligned}
%	A^- \psi_4(k_1, k_2, k_3, k_4) =&\, \psi_1^+(k_3)\psi_2(k_1, k_2) \stackrel{(vend\ om)}{\Longrightarrow}\\
	A^- \psi_4(k_1, k_2, k_3) =&\, -\psi_1^+(k_1)\psi_2(k_2, k_3) \stackrel{(vend\ om)}{\Longrightarrow}\\
%	\psi_1^+(k_3)\psi_2(k_1, k_2)  =&\, 
	-\psi_1^+(k_1)\psi_2(k_2, k_3)  =&\, 
%		A^- (\psi_2(k_1, k_2) v(k_3, k_4)) \\%\Longrightarrow\\
		A^- (\psi_2 v)(k_1, k_2, k_3) \\%\Longrightarrow\\
%	\psi_1^+(k_3)\psi_2(k_1, k_2)  
%	=&\, A^- \psi_2(k_1, k_2) v(k_3, k_4) + \psi_2(k_1, k_2) A^- v(k_3, k_4) \\
	=&\, A^- \psi_2(k_1) v(k_2, k_3) + \psi_2(k_1, k_2) A^- v(k_3) \\
%	=&\, \psi_1^+(k_1) v(k_2, k_3) + \psi_2(k_1, k_2) A^- v(k_3, k_4) \\
	=&\, \psi_1^+(k_1) v(k_2, k_3) + \psi_2(k_1, k_2) A^- v(k_3).\,. \Longrightarrow .\,.
\end{aligned}
\end{align}
Hm, måske skal jeg lige putte nogle kantparenteser på, eller noget, til eksplicit at gøre bølgefunktionerne symmetriske i $k$-variablene.\,. .\,.\,Og det skal så også på i lign.\ (\ref{psi_4_seperabel}).\,. .\,.\,Ah, men hvad sker der så, når $v = \psi_2$?\,. Så får vi noget, der kan give mening! (Umiddelbart.:)) Lad mig se.\,. .\,.\,Ah, vi skal for det første lige huske et fortegn fra, at $A^- \psi_2$ skal være lig $-\psi_1^+$ i virkeligheden (eller rettere nærmest lig.\,.), og ikke $\psi_1^+$. Så får vi i stedet
\begin{align}
\begin{aligned}
	-\psi_1^+(k_1)\psi_2(k_2, k_3) =
		-\psi_1^+(k_1) v(k_2, k_3) + \psi_2(k_1, k_2) A^- v(k_3).
\end{aligned}
\end{align}
.\,.\,Hm, ah, skal vi så ikke bare have $v = \psi_2 / 2$?\,\texttt{:D} .\,.\,Det lugter jo i hvert fald lidt i den retning.\,.\,;) 


\ldots\ Lad mig lige sige, at $u(k_1, k_2) \equiv \psi_2(k_1, k_2)/2 - v(k_1, k_2)$. Og når vi altså husker, at VHS'en og RHS'en altid skal symmetriseres, så får vi 
\begin{align}
\begin{aligned}
%	-\psi_1^+(k_1)\psi_2(k_2, k_3) =
%		-\frac{1}{2} \psi_1^+(k_1) \psi_2(k_1, k_2) + \psi_1^+(k_1) u(k_2, k_3) 
%			-\frac{1}{2}\psi_2(k_1, k_2) \psi_1^+(k_1) + \psi_2(k_1, k_2) A^- u(k_3). \Longrightarrow\\
	0 = \psi_1^+(k_1) u(k_2, k_3) - \psi_2(k_1, k_2) A^- u(k_3).
	\label{u_lign1}
\end{aligned}
\end{align}
Og det er klart, at $u = k \mapsto 0$ løser denne ligning, men spørgsmålet er så, hvad eller løser den. .\,.\,(Og så skal jeg stadigvæk også huske, at jeg indtil videre bare har antaget, at $\psi_4$ kan separeres på den måde, som jeg skrev i lign.\ (\ref{psi_4_seperabel}).\,.) .\,.\,Hm, men dette arbejde handler dog om at analysere Dom($B$), hvilket også kan være vigtigt/nødvendigt, men dette er faktisk ikke helt sikkert (som jeg lige kan se det i dette sekund), for det kan jo også godt være, at jeg bare kan nøjes med at se på, om andre vektorer kan være symmetriske under $A$ med en mængde vektorer med bølgefunktioner som dem ovenstående ligninger her lægger op til at bygge.\,:)\,.\,.


(29.01.22) Jeg har her til middag tænkt over, om det ikke bliver et problem, når $\hat H_I$ udvides med, at fermionerne bliver Dirac-spinorer osv. Men jeg er så kommet frem til, at hvis vi impuls-tilstande, hvor spinorerne ikke er ændret i forhold til 0-impuls-tilstandende, så får vi det samme dejlige billede, hvor $\psi_1^+(k)$ (nu med fire spinor-indgange) bliver den samme for alle sådanne impuls-tilstande. Og når jeg skal konjugere positron-tilstandene, så gør jeg det jo lige præcis på en måde, så det gøres i henhold til 0-impuls-spinorerne (uagtet den faktiske impuls), så derfor tror jeg altså, at billede også bliver ca.\ det samme her.\,.\,:)   


\ldots Nå, planen nu er, at jeg vil gå i gang med at se på, om det kan lade sig gøre for $\psi_2$ at integrere til en undelig stor vektor over begge funktionsvariable hver især samtidigt, eller om (og det håber jeg altså på) $\psi_2$ kun vil kunne dette med hensyn til én parameter. .\,.\,Så lad os sige, vi har, at
\begin{align}
\begin{aligned}
	\int dk_1\, \bigg|\int dk_2\, \psi_2(k_1, k_2)\bigg|^2 = \infty,
\end{aligned}
\end{align}
og at
\begin{align}
\begin{aligned}
	\iint dk_1\, dk_2\, \big| \psi_2(k_1, k_2)\big|^2 \neq \infty.
\end{aligned}
\end{align}
\ldots Hm, og bemærk, at for alle $k_1$ har vi, at 
\begin{align}
\begin{aligned}
	\int dk_2\, \psi_2(k_1, k_2) \neq \infty.\,.
\end{aligned}
\end{align}
.\,.\,Hm, men vent, for vi kan jo altid definere.\,.\, hm, okay to ting: Vi kan altid definere $\psi_2' = (k_1, k_2) \mapsto \psi_2(k_1, k_2) + \psi_2(k_2, k_1)$ for det første, og det andet er så, at dette skal vi jo netop også altid gøre på en måde, for $\psi_2$ skal jo allerede være symmetrisk i dets variable! D'oh.\textasciicircum\textasciicircum\ Ha, så never mind meget af dette. Hm, hvad kan jeg så sige.\,:)\,.\,.\,?

.\,.\,Hm, lad os bytte om og sige $\psi_2(k_1, k_2) = \psi_2'(k_1, k_2) + \psi_2'(k_2, k_1)$.\,. Så er
\begin{align}
\begin{aligned}
	A^-\psi_2(k_1) = 
		\int dk\, \bar{A}(k)( \psi_2'(k_1, k) + \psi_2'(k, k_1) ).\,.
\end{aligned}
\end{align}
.\,.\,Hm, og vi kan i øvrigt videre skrive
\begin{align}
\begin{aligned}
	\psi_1^+(k_1) \simeq A^-\psi_2(k_1) = 
		\int dk\, \bar{A}(k)( \psi_2'(k_1, k) + \psi_2'(k, k_1) ).
\end{aligned}
\end{align}
.\,.\,Ah, nu søgte jeg lige på ``symmetrization of functions'' og så lige en sætning, der minder lidt om, at ``alle funktioner kan skrives.\,.''.\,. Hov, endnu bedre: Nu så jeg den faktiske sætning, som den forrige sætning mindede mig om, nemlig at ``enhver funktion kan skrives som en sum af en symmetrisk og antisymmetrisk (/``skew-symmetric'') funktion.'' Så ja, min klokke ringede rigtigt. Og dette kan nemt ses, hvis man både symmetriserer og antisymmetriserer en funktion og derefter lægger de to ting sammen; så får man sin funktion tilbage. .\,.\,Hm, men vent, for dette var jo egentligt ikke det, jeg var ude efter.\,. Jeg var mere ude efter noget omkring separable udgaver.\,. Hm, lad mig se, om man også kan gøre noget med at symmetrisere/antisymmetrisere funktioner via multiplikation.\,. 

.\,.\,Hov, men skal vi bare bruge, at 
\begin{align}
\begin{aligned}
	\int  dk_2\, \psi_2(k_1, k_2) = \int  dk_1\, \psi_2(k_1, k_2)
\end{aligned}
\end{align}
medfører, at
\begin{align}
\begin{aligned}
	A^-\psi_2(k_1) = 
		\int dk\, \bar{A}(k)( \psi_2(k_1, k) + \psi_2(k, k_1) ) = 
			2 \int dk\, \bar{A}(k)\psi_2(k_1, k)?\,.
\end{aligned}
\end{align}
Bum.\,. .\,.\,Ja, det er jo klart.\,.\,;)\,\texttt{xD}. (.\,.\,Og jeg burde forresten hellere, som foreslået tidligere, bruge f.eks.\ $c(k)$ frem for $\bar{A}(k)$.\,.)

.\,.\,Ja, så dette betyder jo egentligt bare, at jeg kan antage, at $\psi_2$ har formen, som jeg lagde op til i lign.\ (\ref{V_1:1}).\,. (Og altså ikke, at $\psi_2$ ligefrem er separabel nødvendigvis.\,.)
.\,.\,Nå ja, og det kan vist forresten heller ikke være anderledes, for ellers kan normen af $\psi_2$ nok ikke gøres endelig.\,. .\,.\,Hm, men er det ikke også bare nærmest det, jeg skal bruge, før jeg så kan få et rigtigt gavnligt resultat, mon.\,.\,?\,.\,. 

.\,.\,Hm, jeg så lige lidt på lign.\ (\ref{u_lign1}), som så godt nok skal omdannes til en (sikkert meget tilsvarende) udgave, der ikke antager sparabilitet, og jeg tror nu godt, man må kunne finde ikke-trivielle løsninger til denne, desværre.\,. 


%(klokken tyve over fem)
\ldots\ Ah, det er jo nok sådan, hvis vi kigger på ligning (\ref{u_lign1}), at 
\begin{align}
\begin{aligned}
	\lbrack A^- u \rbrack_{sym} = 
		\bigg[(k_1, k_2, k_3) \mapsto 
			\frac{\psi_1^+(k_1) u(k_2, k_3) }{ \psi_2(k_1, k_2)}\bigg]_{sym}
	\label{u_lign2}
\end{aligned}
\end{align}
jo faktisk nok vil være en endelig, eller rettere normaliserbar, bølgefunktion, også selvom vi har $\psi_1^+(k_1)$ på højrehåndssiden. Og hvis dette er sandt, jamen så vil en ikke-triviel $u$ jo bare tilføje noget endeligt til $A^- \psi_4$.\,. (Og det har vi jo allerede frihed til i forvejen.\,.) .\,.\,Hov, på nær at jeg jo netop også dividerer med $\psi_2(k_1, k_2)$.\,.\,? .\,.\,Hm nå, så kan jeg altså ikke lige umiddelbart sige dette alligevel.\,. 


(30.01.22) Okay, jeg tror faktisk jeg holder pause med fysikken igen nu her, når jeg lige har skrevet denne statusopsummerende tekst. For jeg er nemlig lige præcis nu nået til et punkt, hvor jeg bestemt tror på, at jeg sandsynligvis vil kunne finde en løsning, der holder, hvis bare jeg lige får tiden til det. Og jeg tror faktisk ikke, jeg har langt igen, men når man alligevel skal tage højde for alle delene af hele teorien, så skal der sikkert nok alligevel opstå nogle små problemer hist og her, selv hvis min nuværende løsningsstrategi ellers rimeligt meget holder, som jeg forestiller mig den. Det er så der, jeg har overvejet tanken om, bare at udgive det i første omgang, hvor jeg udelader og udskyder sektionen, hvor jeg viser selvadjungerethed. Men når først jeg går i gang med hovedsektionerne, så er jo næsten sikker på, at der også vil dukke tilsvarende små issues op hist og her, der lige vil kræve nogle dage at løse. Og nu har jeg her i går indset en måde, jeg kan lave min første udgivelse på, så jeg føler mig rimeligt tryk ved, at det kommer til at gå glat (og at det ikke ligesom eksploderer på en uhensigtsmæssig måde, hvor det bare kommer til at implodere hurtigt igen efterfølgende, og hvor jeg så får svært ved at samle energien op igen og altså misser chancen for at ride på en positiv energi.\,.).\,. .\,.\,Jeg tror nemlig bare, jeg så vil udgive min blockchain-opdagelse og så bare lægge op til, og tease lidt, at jeg også har i sinde at udgive mere inden for en kort tid, bl.a.\ en QED-teori, hvor jeg opgiver en Hamilton-operator, som jeg mener at være meget tæt på at vise, er Lorentz-invariant. (.\,.\,Pointen er lidt at holde informationen så sparsom, så folk generelt ikke bare vil affeje det (for så ikke at vende tilbage og lytte igen, når jeg får lappet fejlene og forstærket mit bevis).\,.) .\,.\,Men ja, det skal også lige præcis have så meget kød på, at folk vil være interesserede i at vende tilbage og se, når jeg endelig udgiver det. Og ja, det tror jeg altså sagtens (7, 9, 13) kan lade sig gøre. Så det er min hensigt nu, og lad mig så lige slutte af med nogle flere ord om, hvad min løsningsstrategi er, når jeg skal forsætte med dette igen o lidt tid.

Selvom min nye indsigt stadig i princippet kunne have potentiale til at låse $V$'erne, så tror jeg det ikke. Jeg har kigget lidt på, og jeg tror altså, at følgen af $V$'er (i.e.\ $V_1, V_3, \ldots$ for lige bølgefunktioner med min seneste notation (den var anderledes før (men jeg ville gerne undgå at bruge $V_0$, for den har jeg jo givet en speciel betydning)) og $V_2, V_4$ for ulige bølgefunktioner (mht.\ bosontal)) altid vil have frihed til at.\,. lade sig afvige med ``en endelig del'' så at sige.\,. Hm, men nu fik jeg lige en tanke, så det er jeg ikke helt sikker på. Okay, lad mig lige kigge lidt på ligningerne en gang, bare lige for at se ad, men ellers er pointen altså, at jeg alligevel jo mener, at jeg kan løse det, selv hvis de bare har fuld frihed.\,. \ldots Hm tja.\,. Jeg er ikke helt sikker på, at de får fuld frihed, men det kan jeg jo evt.\ bare begynde at se nærmere på, når jeg tager emnet op igen. Og pointen er jo, at som jeg ser det, vil det kun komme mig til gode, at der bliver en sådan begrænsning på $V$'erne. Og selv hvis der ikke er nogen begrænsning, så mener jeg altså at kunne løse det. Og min løsningsstrategi er altså at starte med en mængde (Dom($A_0$) om man vil), hvor alle vektorer har $V_1 = V_2 = V_3 = \ldots = V_0$, og hvor $V_0$ \emph{kun} undlader at kvæle den del af $\psi_1^+$, der ikke bruges til.\,. lad mig nu lige se en gang.\,. .\,.\,Hm ja, der er noget jeg har overset, for det med ``kun at kvæle alt det, der ikke bruges til at selv kvæle (de uendelige bølgefunktioner) i de bølgefunktioner i mængden med den modsatte paritet,'' det giver jo ikke mening, hvis man bygger vektorerne op, så $V$'erne.\,. nå nej, de skulle jo lige netop heller \emph{ikke} være separable.\,. .\,.\,Ah, nu tror jeg, jeg ved det nogenlunde.\,. .\,.\,Hov, nu kom jeg lige for første gang i tanke om den finte med altid bare at definere bølgefunktionerne kun over den del af koordinatsystemet, hvor $k_1\leq k_2 \leq \ldots$\,\texttt{xD}\textasciicircum\textasciicircum\ Sjovt, at jeg ikke har tænkt på det før nu!\,\texttt{xD} .\,.\,Hm, nå tilbage til spørgsmålet for hånden en gang.\,. .\,.\,Hm, jeg pønser på en gåtur sammen med en ven, så jeg tror egentligt bare, jeg holder den pause nu, og så vender tilbage senere. \ldots 


%(klokken kvart i seks)
(01.02.22) Nå, der er alligevel sket en del ting, siden jeg skrev her sidst, og jeg føler det som om, der er en del, der skal skrives. Men jeg må jo bare tage det én ting ad gangen. For det første kan jeg nævne, at jeg jo fik tænkt lidt over, hvordan bølgefunktionerne i Dom($B$) kan konstrueres. Hvis man ser på en følge, $(k_1, k_2, \ldots, k_n)$, der repræsenterer en basisvektor, der skal spises/kvæles af et område af $\psi_{n+1}$, gives ved $k_{n+1} \mapsto \psi_{(k_1, k_2, \ldots, k_n)}(k_{n+1})$, så kan man altså vælge $\psi_{(k_1, k_2, \ldots, k_n)}$ til at være ikke-forsvindende på et område, hvor $k_{n+1}$ (i.e.\ input-variablen) er (som regel meget) større end $k_n$ (som i øvrigt er større end alle de forrige $k$'er, da jeg altså kigger på symmetriske funktioner, hvor input-følgen altid er ordnet i voksende rækkefølge). Og jeg kom frem til, at man så bare skal sørge for, at $\psi_{(k_1, k_2, \ldots, k_n)}$ virkeligt varierer meget som funktion af subscript-$k$'erne, således at man kan opnå, at bølgefunktionen, der fremkommer ved at integrere $\psi_{n+1}$ (sammen med en faktor af $\bar{A}(k)$) over én af alle $k$'erne fra $k_1$ til $k_n$, bliver noget endeligt i alle tilfældende, og hvor man altså kun får en uendelig bølgefunktion, netop når man integrerer $\psi_{n+1}$ (ganget med $\bar{A}(k_{n+1})$) over $k_{n+1}$ (og altså ingen af de andre $k$-variable). For hvis $\psi_{(k_1, k_2, \ldots, k_n)}$ bare varierer tilstrækkeligt meget i disse subscript-$k$'er, så vil det ikke betyde meget, om man absolut-kvadrerer før eller efter, man integrerer over en sådan $k$-variabel. Og hvis man kvadrerer først, skal det jo netop gerne give en endelig bølgefunktion, da $\psi_{m+1}$ jo gerne skal være endelig i sig selv. Det var lidt rodet forklaret, men således er jeg altså ret overbevist om, at man kan konstruere sine vektorer i Dom$(B)$. 

Så langt se godt.\,. Jeg kom også frem til, at mit argument, som jeg nævte på et tidspunkt, hvor jeg brugte at \textbf{H} var separabel, nok ikke holder (fordi ``områderne'' vokser for voksende $n$). Men jeg kom så på, at man her godt sagtens kan bruge udvalgsaksiomet til for hver $\psi$, hvor $V_\psi$ kun konvergerer til $v_0$ på halvdelen af ``områderne,'' at vælge, om det enten er $\psi$ og alle andre funktioner med tilsvarende hale som denne, eller om det er mængden af de modsatte funktioner, så at sige, hvilke altså konvergerer til $V_0$ på de modsatte halvdele af områderne, der skal med i Dom($A$). Igen lidt rodet forklaret, men dog formentligt (og forhåbentligt) meningsfuldt (hvis man bare lige læser det nok gange.\,.).\,. 

Disse to punkter kom jeg henholdsvis frem til om aftenen og om natten d.\ 30/01 (eller d.\ 31.\ om natten, om man vil, men jeg plejer nu mere at tælle natten efter kl. 12 med som samme dag (indtil man går i seng og får sovet)).

I går, d.\ 31., (medmindre jeg kom frem til noget af det søndag nat også; det kan jeg ikke lige huske, men det er jo også lige meget) kom jeg så frem til et paradoks i, at grafen for $A$ skal være lukkelig, og at $(A^{cl})^*$ bør være lig $A^*$, for med min løsning der, hvor jeg tager ``alle funktioner, der konvergerer halvt eller mere til $V_0$,'' (eller rettere næsten alle, for jeg tager kun halvdelen af dem, der kun netop konvergerer halvt), så burde alle vektorer i Dom($B$) alligevel ligge i lukningen af denne operator.\,. Og det er nu nok lidt et generelt problem, hvis man prøver med den løsningsstrategi, for det nytter ikke rigtigt noget, at man kun ser på halen, når man skal udvælge vektorer til Dom($A$). For hvis man gør det, så må man, som jeg ser det, altid kunne finde en følge i Dom($A$), der konvergerer imod enhver vektor, $\phi$, i Dom($B$), og hvor billedet også konvergerer imod $B\phi$. 

Jeg fandt også et andet grimt resultat: For hver følge af $\psi^n$'er i Dom($A$), som konvergerer imod en basisvektor, $e_m$, med bosontal $m$, skal der være grænse for.\,. Hm, hvordan skal jeg lige formulere dette.\,.\,? %..Hm, jeg holder lige en pause...

(02.02.22) .\,.\,Okay, lad mig prøve at formulere det sådan her. Jeg (troede og) håbede på, at man for ethvert par af basisvektorer, kald dem $e_1$ og $e_2$, hvor $\bar{\bar{A}}$ har ikke forsvindende overgangsamplituder imellem dem, kunne få det sådan, at man altid kunne finde en følge i Dom$(A)$, hvor følgen nærmer sig de to basisvektorer, og hvor matrixelementet over følgen (med $A$), kald det $\braket{\phi^n| A \psi^n}$ kunne gå imod $\bar{\bar{A}}(e_1, e_2)$. Men tvært imod: Dette matrixelement bliver faktisk nødt til at forsvinde (stort set) for alle basisvektorpar udover lige et muligt afgrænset område (måske inden for en vis ``radius'' af $e_1$). For ellers så kan man, som jeg ser det nu, for en enhver følge $\phi^n$, der nærmer sig $e_1$, bygge en vilkårlig lille vektor ud af.\,. ja, ud af $e_2$'er, kunne man nærmest sige, som dog kan få et vilkårligt stort matrixelement, for en vis $\phi^N$. Men så kan $\phi^N$ jo ikke være i Dom($A^*$) pr.\ definition 9.1 i Hall, hvilket enten betyder, at $A$ ikke er symmetrisk, eller at $\phi^N$ ikke kan være i Dom($A$), hvilket ville være et totalt håbløst resultat. Så det kom jeg altså også frem til der i forgårs (er det nu). Og det er virkeligt ikke et resultat, jeg bryder mig om (altså at $\phi$'er omkring $e_1$ kun kan have ikke-forsvindende matrixelementer med $\psi$'er omkring $e_2$'er (løst sagt) i et meget afgrænset område). Det er ikke et resultat, der \emph{nødvendigvis} er et problem, men jeg kan nu bare mærke, at der gnider mig lidt den forkerte vej. Men ja, meget mere har jeg ikke at sige om dette, andet end at man selvfølgelig så gør klogt i at tage højde for dette, når man vil prøve at finde et gangbart Dom($A$). I øvrigt kan jeg også lige nævne angående mit forrige punkt, at hvis man nu finder et Dom($A$), hvor alle vektorer har et ikke forsvindende billede, og at særligt alle ``tilnærmede basisvektorer'' har et stort billede i næste niveau, så tegner det godt, for så kan man ikke umiddelbart (det kan jeg i hvert fald ikke umiddelbart) nemt finde en måde, hvor man kan tilnærme sig både en vilkårlig vektor i Dom($B$) og dens billede (for hvis man så tilnærmer sig vektoren med disse ``tilnærmede basisvektorer,'' så får man hele tiden et større og større billede).\,.

Nå, i går (nu) d.\ 1/2 stod jeg så op af sengen med en ny idé. Jeg havde lign.\ (\ref{forkert1}) i tankerne og tænkte, at det jo ville være rart, hvis man kunne få denne til at holde --- samt også få det sådan, at $\mathrm{Dom}(A)\subset\mathrm{Dom}(B)$ --- således at man igen opnåede en situation, hvor man bare stod med opgaven om at ``fylde Dom($A$) op til randen.'' Jeg havde på det tidspunkt (måske i forgårs eller dagen før) allerede tænkt, at man nok kunne opnå $\mathrm{Dom}(A)\subset\mathrm{Dom}(B)$, hvis bare man sørger for, at Dom($A_0$) for alle basisvektorer bare har nogle få.\,. ja, hvis jeg skal fortsætte med det løse sprog fra før, så kunne jeg sige ``nogle få $e_2$'er, hvor deres matrixelement tilnærmelsesvist er lig $\bar{\bar{A}}(e_1, e_2)$. .\,.\,Hm, vent en gang, for holder dette egentligt?\,.\,. .\,.\,Hm, eller skulle man ikke netop til dette argument bruge, at mængden af $e_2$'er med ikke forsvindende $\bar{\bar{A}}(e_1, e_2)$ (løst sagt, for i virkeligheden taler vi jo om ``tilnærmende vektorer'' til $e_1$ og $e_2$) er ubegrænset.\,.\,? Lad mig lige se.\,. .\,.\,Ej øv, argumentet holder nok ikke, som jeg lige kan se det. Så er der fare for, at den løsningsstrategi, som jeg havde lyst til at præsentere, som jeg kom på i går, heller ikke rigtigt holder.\,. Det var ellers et virkeligt godt sted at stoppe; med en idé til en løsningsstrategi, der var værd at fortsætte med (men hvor jeg også kunne se, at det ville tage for meget arbejde til, at det var værd at gøre lige nu.\,.).\,. .\,.\,Nå lad mig lige tænke over det hele en gang for at se, om jeg kan redde den.\,. 

(03.02.22) Nå, det blev lige en længere pause, men jeg synes, jeg fik tænkt over de ting, jeg gerne ville i går, og kom altså frem til nogle ting, jeg føler, jeg kan runde godt af med for nu. 

Jeg er ikke hundred på, at det holder, men jeg har en idé til en $A_0$, så at sige, der måske har nogle gode egenskaber. Tanken er at have.\,. .\,.\,Hm, vent, lad mig lige tænke mig om en gang.\,. \ldots Jo, det burde nok holde, og hvis ikke, så gør det heller ikke så meget. Men jeg føler, at det er værd at nævne dette. Tanken er at have en Dom($A_0$), hvor alle basisvektorer tilnærmes på en måde, så ikke bare de områder, som selv bruges til at kvæle bølgefunktioner et niveau nede, bliver ladt være, men at mere og mere af hele koordinatsystemet bliver ``ladt være'' (svarende til, at det, jeg engang kaldte $\psi'_n$'er, bliver større og større). Dette svarer vel egentligt forresten til, hvad jeg foreslog der d. 26.; der ville jeg også lade ``$\psi'_n$'erne'' blive større og større.\,. Nå, jeg kom så frem til i går, at man måske nok godt kan vise, at vektorer indeholdt i $\mathrm{\textbf{H}} \setminus \mathrm{Dom}(B)$ ikke kan være indeholdt i Dom($A_0^*$). For hvis vi ser på vektorer indeholdt i Dom($B$), så må matrixelementet med en vektor bygget af (linearkombinationer af) vektorer i Dom($A_0$), vist forsvinde, når man bygger dem af vektorer, der lader større og større $\psi'_n$'er være --- nå ja, og hvor man altså kun tager vektorer i områder som vektoren i Dom($B$), kald den $\phi$, selv kvæler (i dennes $\phi'_n$'er). Men pointen er så, at hvis $\phi$ ikke er i $B$, så gælder dette ikke, og man vil altså kunne få ikke-forsvindende matrixelementer i sådan en konstruktion. Og jeg tror så umiddelbart, at man også vil finde frem til, at man kan få ubegrænset store matrixelementer herved. Og hvis dette passer, så vil definition 9.1 i Hall fortælle os, at $\phi$ ikke kan være i Dom($A_0^*$). Ok, og det var altså, hvad jeg nåede lidt at komme frem til i går. Og for så at fortsætte tanken, som jeg stod op med i forgårs (er det nu), så overvejede jeg altså lign.\ (\ref{forkert1}), som jeg lige kan kopiere ind her. Mit dengang forkerte resultat var, at
\begin{align}
\begin{aligned}
	\chi_{n'}(p_1, p_2, \ldots; k_1, k_2, \ldots, k_{n'})^* 
		=&\,
			\lim_{m\to\infty}\braket{\chi | \psi^m} = 
			\lim_{m\to\infty}\braket{\phi | A \psi^m} \\
		%\chi_{n'}(p_1, p_2, \ldots; k_1, k_2, \ldots, k_{n'})^* 
		=&\, 
			\lim_{m\to\infty}\braket{A \phi | \psi^m} \\
		=&\, 
			(A \phi)_{n'}(p_1, p_2, \ldots; k_1, k_2, \ldots, k_{n'})^*.
\end{aligned}
\end{align}
De to sidste linjer holdt ikke da, men hvis vi ved, at $\phi$ ligger i Dom($B$), så skal vi dog kun lægge et ekstra led til udtrykket i anden linje. Og dette led vil så lige præcis være forskellen på $\braket{\phi | A \psi^m}$ og $\braket{A \phi | \psi^m}$. Og fordi $A \phi$ så også her vil være en vektor i \textbf{H}, så vil sidste linje også holde, hvis vi bare stadig husker $(\braket{\phi | A \psi^m} - \braket{A \phi | \psi^m})$ lagt til. Så vi får, at
\begin{align}
\begin{aligned}
	\chi_{n'}(p_1, p_2, \ldots; k_1, k_2, \ldots, k_{n'})^* =
		(A \phi)_{n'}(p_1, p_2, \ldots; k_1, k_2, \ldots, k_{n'})^* 
		+ \lim_{m\to\infty}(\braket{\phi | A \psi^m} - \braket{A \phi | \psi^m}).
		\label{chi-formel_lig_A_phi-formel1}
\end{aligned}
\end{align}
Og min idé var så, at hvis Dom($A_0$) indeholder en følge af $\psi^m$'er, som lader mere og mere være af billedet, så vil $\braket{\phi | A \psi^m}$ gå imod $\braket{A \phi | \psi^m}$ for alle $\phi\in\mathrm{Dom}(B)$. Og hvis dette holder, så opnår jeg jo den samme situation, som jeg troede, jeg havde før, hvor formularen for $A^*$ bliver nødt til at være den samme som for $A$ for hele dens domæne --- og altså også hvor $\mathrm{Dom}(A^*) \subset \mathrm{Dom}(B)$. Dette er en situation, jeg ret godt kan lide. Så handler det på en måde bare om at ``fylde Dom($A$) op til randen'' (også selvom man finder en anden løsning til at bestemme $A$ (i.e.\ på en mere direkte måde)). Og som jeg ser det, så virker mine to punkter, om hhv.\ at lukningen af $A$ ikke må kunne blive $B$, og at man ikke må kunne konstruere ubegrænsede matrixelementer for $\psi$ i Dom($A$) med linearkombinationer af andre vektorer fra Dom($A$), heller ikke så faretruende med et sådant $A_0$. 

Jeg kan lige nævne hurtigt, at jeg stadig er ret åben for muligheden for rent faktisk at konstruere Dom($A$) ved at ``fylde det op.'' Jeg er jo blevet rimeligt meget tilhænger af matematisk konstruktivisme selv, så det er på en måde en ret oplagt tanke for mig, og som jeg ser det, kunne det altså også godt være en potentiel løsningsmulighed. Der skal helt sikkert også være andre løsningsmuligheder, men noget andet er så også, at det også ville være et vildt godt resultat at få, hvis man kunne vise, at man bare kan ``fylde symmetriske operatorer op'' på denne måde, for så ville man jo også kunne generalisere til alle mulige andre symmetriske operatorer også. .\,.\,Nå lad mig egentligt bare fortsætte i dette spor, også selvom jeg kom på nogen af disse tanker i går, og så kan jeg bare slutte af med, hvad jeg også kom frem til i forgårs. Men ja, for at fortsætte omkring dette emne, så betyder det så dog, at det måske slet ikke bliver nødvendigt med nævnte resultat, hvor $A^*$ får samme formel overalt som $A$.\,. Tja, og dog, det \emph{skal} den jo have alligevel, hvis den skal være selvadjungeret.\,. Never mind; det er sikkert et meget godt sted at starte (altså med en Dom($A_0$), der opfylder det, jeg lige nævnte her ovenfor) uanset hvad.\,. .\,.\,Men ja, om ikke andet så ser jeg stadig en lille chance for, at løsningsmuligheden, \emph{hvis} den altså holder, hvilket slet ikke er sikkert overhovedet, kan være så kraftig, at man ingen gang behøver at tænke på andet end at danne en $A_0$, der bare er symmetrisk (og defineret på et tæt domæne i \textbf{H}). Men uanset, om løsningsmuligheden holder i sidste ende, så synes jeg bare, det er vildt rart at kunne runde af for nu, hvor jeg stadig har bare én mulighed i sigte, som jeg kan fortsætte med, når jeg tager det op igen. Og samtidigt kan jeg med ro sige, at jeg ikke har tid til at forfølge den lige nu, for jeg kan nemlig se, at den kræver, at jeg faktisk sætter mig grundigt ind i en masse (tilsyneladende halvtung) matematik, for at jeg kan begynde at overveje den grundigere. Pointen er nemlig, at jeg vil tage en konstruerbar model af ZFC-mængdelære, hvori alle de samme sætninger så skal gælde (men hvor man bare putter `kontruerbar' ind i alle definitioner og sætninger). Denne model kan man så behandle inden i en ydre model af ZFC (muligvis en, hvor man antager antager eksistensen af $\omega^\omega$-kardinalen, hvis der er behov for det.\,.). I den ydre model kan man så definere et $A$ (og særligt det tilhørende Dom($A$)), som så er fyldt op.\,. Dette er måske lidt nemmere sagt end gjort, men jeg tror på, at det må kunne lade sig gøre; det skulle undre mig meget andet. Nu kommer de svære så lidt, for man må ikke antage, at Dom($A$) så eksisterer i den indre model. For det vil det ikke nødvendigvis gøre (nemlig hvis man har ``fyldt Dom($A$) op'' ét element ad gangen i en \emph{tælleligt} uendelig mængde (hvilket nemlig kræver en antagelse, som strider imod at Dom($A$) så kan eksistere i modellen (pga.\ diagonal-argumentet))). 
Og så bliver arbejdet altså, som jeg ser det, at gå igennem alle sætninger derfra, der kan lede til spektral-sætningen, og altså tjekke, at de godt stadig kan holde, også selvom Dom($A$) ikke eksisterer i den indre model, og med andre ord at \textbf{H} ikke længere er komplet i den ydre model. Så det er altså min plan, men det betyder, at jeg skal gennemgå en masse matematik --- en masse sætninger og også en masse definitioner, som jeg ikke er vant til og derfor også lige skal bruge tid på at læse om og forstå. (Jeg tror heldigvis det meste, jeg skal bruge, allerede står i Hall.) Så det bliver altså det punkt, jeg runder af på (for nu).\,:) 

Nå, og det andet jeg kom på i forgårs (aften).\,. Hov nej, tre dage siden d.\ 31.\,. Hm, lad mig lige hurtigt se en gang.\,. Ah ja, mine andre datoer/tidspunkter er vist rigtige nok, men det var d.\ 31/1, jeg kom frem til følgende, nemlig at der jo faktisk er kød nok på min teori, selv hvis jeg ikke havde/har udsigt til at kunne vise selvadjungeretheden.(.\,!) For problemet har jo netop lige præcis ikke noget at gøre med mit Coulomb-potentiale-led (hvad jeg også har haft indset før, men nu indså jeg det lige igen (der for tre dage siden)). Så bare det at jeg har en teori, hvor at det er sådan, at \emph{hvis} man kan vise selvadjungerethed og/eller at den opfører sig ordentligt i det hele taget, jamen så vil teorien var Lorentz-invariant (også selvom den altså indeholder mit dejlige Coulomb-potentiale-led). Så derfor \emph{kan} jeg altså sagtens udbrede mig om idéerne, selv på det stadie, de har nu!\,\texttt{:D}\,\, Og det har jeg altså tænkt mig at gøre.\,:) 

(06.02.22) Nå ja, og en anden løsningsmulighed er jo også, at regne på det hele og så se, om jeg kan finde en version af min idé omkring at tage ``alle funktioner, der konvergerer halvt eller mere til $V_0$,'' der holder. Dette vil så i første omgang nok kræve, at jeg regner mere på det hele for at finde ind til præcis, hvorfor min første løsning ikke var symmetrisk, \emph{hvis} den altså ikke var det (hvad jeg jo tror, den ikke var, fordi lukningen grafen for den ser ud til at blive lig grafen for $B$). På nogen måde virker denne løsningsstrategi næsten mere sandsynlig end den anden, men selvfølgelig vil den anden stadig altid være værd at forfølge uanset hvad, for \emph{hvis} den nu skulle vise sig faktisk at du, så er det jo en løsning, der meget vel ville kunne generaliseres til andre operatorer med symmetriske formularer også. 

(11.02.22) Jeg læste lidt om matematikken her i forgårs og i går aftes, men i går aftes (sent) kom jeg i tanke om at ``another counterexample'' omkring $-x^4$-potentialet jo bl.a.\ er et godt eksempel på, hvorfor symmetriske formularer ikke altid kan tillade selvadjungerede operatorer. Det skulle i hvert fald undre mig, hvis et så studeret eksempel ville tillade det. Og derfor vil min løsningsmulighed omkring at force sætningerne ind på en indre model, hvorved en operator, hvor $\mathrm{Dom}(A^*) = \mathrm{Dom}(A)$, nok kan dannes, men hvor vektorrummet (i den ydre model) så ikke længere er komplet, så altså garanteret ikke virke. Så jeg bør altså hellere fortsætte med mere gængse løsningsstrategier, men jeg har dog lovet mig selv, at jeg først vil udgive det andet, jeg arbejder på, inden jeg fortsætter med dette. 





\section{Fortsat omkring selvadjungerethed (22.02.22)}
Bemærk at denne sektion er startet dagen efter, at jeg startede næste sektion omkring at gøre klar til en udgivelse (hvilket jeg altså gjorde i går). Men i går nat (på vej i seng og i sengen) kom jeg på nogle idéer omkring at vise selvadjungerethed, som jeg bestemt ikke lige kan lade være med at følge op på først. Jeg kom nemlig på, at vi jo nok gerne vil finde frem til et domæne, hvor alle ``veje'' ift.\ at vælge, hvad jeg hidtil ofte har tænkt på som ``områder,'' er taget netop én gang, således at man ikke kan komme med en ny vektor til domænet, uden at den bryder symmetrien. Og så kom jeg videre på, at det måske ville være rigtigt gavnligt, hvis man tog alle sine mulige vektorer til at kvæle produktioner fra nedre niveauer og Gram-Schmidt-ortogonaliserede dem. Og så kunne man måske også på en eller anden måde Gram-Schmidt-ortogonalisere de vektorer, som lades være, og som altså ikke kvæles. I badet her i morges.\,. eller her til formiddag er nok mere rigtigt at sige.\,.\textasciicircum\textasciicircum\ fik jeg så suppleret sidstnævnte tanker en anelse ved at tænke på, at man måske bare kunne opdele det i vektorer, der kvæler hinanden helt, og så vektorer, der lader hinanden være helt.\,. Det skal jeg lige tænke lidt mere over. Men ja, så tanken er altså lidt noget i retning af, at vi så måske får en mængde af, hvad kan mappes til/fra en mængde af uendelige følger af (ubegrænsede) naturlige tal, og at man måske, når man har netop én af hver af disse følger, så kan ende der, hvor man gerne vil være. Men dette er bare lige den umiddelbare tanke; det kan godt være, at det er en hel anden mængde, som domænet skal mappe til (og det kan også selvfølgelig være, at det slet ikke kommer til at give mening). Men det er altså de tanker, jeg vil arbejde videre på nu. Så nu vil jeg nærmere bestemt bruge noget tid til at stirre på de rækker, som ovenstående tekst handler meget om, og så vil jeg prøve at overveje, hvad man mon kan gøre. \ldots 

Hm, jeg har også nogle andre tanker, men nu kom jeg lige i tanke om, at det ikke er sikkert, at man kan Gram-Schmidt-ortogonalisere vektorerne, og at de så stadig kvæler det, de skal kvæle.\,. \ldots\ Men tja, hvem siger også, at det lige er det, man præcist er ude efter.\,.\,?\,. .\,. 

\ldots\ Hm, nu kom jeg også i tanke om en måde, hvor man måske kan bruge den der $V_0$-strategi, jeg havde fat i, men hvor man måske kan sørge for, at lukningen af grafen over domænet ikke bliver lig grafen for $B$.\,. Hm, også værd at tænke lidt over.\,. (Og dette handler om at være ``blid'' mod alle vektorer, der har fulgt $V_0$ længe, men være mere og mere ``hård'' mod vektorer, der har brudt $V_0$ for nyligt, hvor jeg med `blid' og `hård' tænker på det, ift.\ hvor meget skal efterlades (ifølge $V_0$) i næste niveau --- og dermed altså hvor stort billede bliver, hvis den følger $V_0$ derfra (og hvor ``hård imod'' altså betyder, at den skal have et stort billede).\,.) .\,.\,Ja, så en vektor (hvis vi lige fortsætter fra forrige parentes her), der bryder $V_0$ i lang tid, vil ligesom få et større og større billede.\,. 

\ldots Hm, denne seneste idé her fra forrige paragraf er jo selvsagt ret interessant (også), for selvom jeg jo endnu ikke helt er klar over, præcis hvad gik galt i min forrige løsning, så ser det i det mindste ikke ud til med denne nye løsning, at jeg længere har noget argument for at konkludere, at løsningen ikke holder.\,. 

\ldots Hm, lad mig derfor lige prøve at kigge argumenter og formodne propositioner igennem ovenfor, der handler om at nå frem til symmetri og selvadjungerethed\ldots 

%Klokken tyve i fem (efter lidt tænkeri, en tænke-gåtur og så lidt mere tænkeri):
\ldots\ Okay, den bliver altså mere og mere interessant denne løsningsidé.\,. I pausen, siden jeg slap tasterne sidst, er jeg kommet lidt frem til, at man måske med denne løsning så ikke behøver noget med, at løsningerne bare skal konvergere halvt til $V_0$, men i stedet bliver de (måske; hvis det altså holder) nødt til at konvergere (helt) mod $V_0$ (nok med en vis nedre begrænset asymptotisk fart endda.\,.), hvis de ikke skal få et divergerende billede.\,. Og jeg er også lidt kommet frem til, at $V_0$ også så kan styre vektorene i domænet, så de sørger for at ``lade visse områder være'' og sådan, hvilket jeg jo lidt kom frem til sidst, før jeg slap (der omkring d. 3/2 nærmere bestemt), nok vil blive nødvendigt, hvis domænet skal være symmetrisk, og netop hvis altså funktionalet fra def.\ 9.1 i Hall skal være begræset på selve Dom($A$), bare.\,. 

\ldots Okay, så det er lige før, jeg vil erklære det en ny løsningsstrategi.\,. tjo tja, men også kun lige før; jeg bliver nødt til lige at gennemgå argumenterne mere grunddigt, før jeg vil begynde at sige noget om, hvor meget jeg tror på den. Men strategien, som jeg har i tankerne nu, og som jeg altså bør undersøge, det er at definere en $V_0$ (som jeg har kaldt den før; altså en procedure, der givet en impuls-basisvektor giver et område, hvormed produktionen fra denne vektor skal kvæles --- hvis vektoren altså \emph{skal} kvæles (og eller kan omtalte område bare være f.eks.\ $\emptyset$)), der er mere og mere ``hård'' mod alle basisvektorer, der har lige har ``brudt'' $V_0$'s procedure, så at sige, hvis man kigger på dens følge af $k$'er. Og samtidigt skal dette $V_0$ måske også på en måde lade større og større områder ``være,'' men det må jeg lige se på. Og strategien som jeg så har i tankerne derfra, er at bruge det, jeg kom frem til der d.\ 3/2 (eller måske op til, men som jeg altså skrev om der), hvor at jeg mente, at man nok kunne vise at $\mathrm{Dom}(A^*) \subset \mathrm{Dom}(B)$, hvis man kan finde følger i $\mathrm{Dom}(A) \subset \mathrm{Dom}(B)$, der nærmer sig enhver given impuls-basisvektor, og som også ``lader mere og mere af billede være.'' Jeg er slet ikke 100 på, at dette argument holder, men hvis det gør, så kunne man derved nok måske gå videre til at vise, at.\,. .\,.\,Hm, nå ja, for det første, at.\,. Hm.\,. %...Nå, jeg kommer ikke udenom en pause..

\ldots\ Ja, og næste skridt kunne så netop være, hvis argumentet her også holder vand, at bruge lign.\ (\ref{chi-formel_lig_A_phi-formel1}) til at vise, at $A^*$ har samme formel som $A$ på Dom($B$).\,. (For mon ikke man kan finde sådanne $\psi^m$-følger i Dom($A$), der lader mere og mere af deres billede (eller rettere billedet af den basisvektor, de tilnærmer sig) være?\,.) Og hvis dette altså også holder, så kunne man vel nok gå videre til prøve at vise, at det kun er vektorer fra selve Dom($A$), der er ``symmetriske under $A$'' med alle (andre) vektorer fra Dom($A$). For jeg kom jo også frem til, at dette må gælde for alle vektorer i Dom($A^*$), hvis formularen af $A^*$ er lig formularen for $A$ på Dom$(B)$. Så hvis dette sidste argument også holder, og hvis man altså kan vise, at alle andre vektorer i Dom($B$) (som altså ikke er i Dom($A$)) vil bryde symmetrien af $A$, så må vi vel dermed nå i mål og få vist, at $A$ er selvadjungeret med omtalte valg af Dom($A$).\,. .\,.\,Og grunden til at jeg formoder, at det kan være rigtigt, at ingen andre vektorer end dem fra Dom($A$) selv er symmetriske med Dom($A$) under $A$, er altså, at jeg har en idé om, at alle vektorer der kun ligesom konvergerer delvist til $V_0$'s forskrift, så at sige, de vil ikke være i Dom$(B)$, og alle dem der bare slet ikke konvergerer til $V_0$'s forskrift, der mener jeg, at man må kunne finde mindst én vektor i Dom($A$), som ikke er symmetrisk med pågældende vektor uden for Dom($A$), hvor de to ikke er ``symmetriske under $A$,'' som jeg kalder det her i disse noter. .\,.\,All right, det bliver spændende at forfølge denne løsningsstrategi-idé.\,. Nu er det bare spørgsmålet, hvornår jeg skal gøre dette, og hvad min plan i det hele taget er nu?\,.\,. .\,.\,Hm ja, det må jeg jo lige tænke over en gang, evt.\ bare her i løbet af i aften, og så kan jeg vende tilbage i morgen. .\,.\,Hm, hvor kunne det bare være fedt (btw), hvis det viser sig, at jeg har fat i noget her.\,:)\,.\,. 

.\,.\,Hm okay, måske bliver planen faktisk, at jeg lige prøver at gå igennem de nævnte argumenter, og at jeg måske endda også kigger på, om det med, at ingen andre vektorer fra Dom$(B)$ er symmetriske under $A$ med alle vektorer i Dom($A$), nu også holder for den Dom($A$), jeg har i tankerne.


(23.02.22) Jeg tænkte lidt videre over løsningsidéen i går aftes, og indtil videre synes jeg altså, at den giver ret god mening --- jeg er i hvert fald ikke \emph{endnu} kommet frem til nogen fejl i den.\,.\,!\,:)\,.\,. Og desuden er jeg også kommet i tanke om noget, jeg manglede at overveje med min gamle løsningsidé omkring at ``konvergere mod $V_0$ halvt eller mere.'' For jeg har førhen nemlig gået og tænkt det lidt som om, at hver vektor, $\psi$, der bruger en vis $V_\psi$, nødvendigvis også skal kvæle alle områder, der ikke er i $V_\psi$, men det giver jo ikke mening overhovedet. Så der er altså noget der i mine tidligere tanker, der ikke holder, og som man ville skulle forsøge at lappe. Men i mellemtiden er jeg jo kommet frem til, at denne løsning ikke må kunne holde (fordi grafen bliver lig $B$'s graf), og det kan så være, at dette simpelthen bare kommer sig af, at man altså ikke kan lappe dette hul. Det ville dog kræve en del mere arbejde, hvis jeg skal forstå præcist, hvad der gik galt med den løsning. Men fordi der altså er et hul i argumenteringen her, så gør dette jo kun en alternativ teori, der ikke har det hul umiddelbart, og som ikke umiddelbart kan ses at måtte fejle heller, væsentlig mere sandsynlig, må man sige.\,. 

Nå, lad mig prøve at forklare, hvorfor løsningsidéen umiddelbart virker til at holde, når det kommer til at dele Dom($B$) over i to, hvor $A$ er symmetrisk over den ene del, men hvor en tilføjelse af enhver anden vektor fra den anden del til Dom($A$) vil bryde denne symmetri. Lad $V_0$ være en funktion, der tager basisvektorer (eller sammensatte vektorer) og fortæller, hvilke nogle begrænsede områder i de højere niveauer må/skal bruges til at kvæle denne basisvektor (helt, delvist eller slet ikke (hvorved området så i sidste tilfælde altså er forsvindende)). Vi starter så med en mængde af alle vektorer, som efter et vist punkt følger $V_0$ til punkt og prikke, ikke mindst når det kommer til, hvilke områder de skal undlade at kvæle selv. Ja, sidstnævnte er faktisk det vigtige her, og man skal altså gerne have en mængde, hvor for hvert område uden for de områder, som $V_0$ peger på, kvæles helt vektorer i denne mængde. Hvilke vektorer kan man så tilføje til denne mængde, uden at det bryder symmetrien af $A$? Tjo, hver gang en vektor undlader at rette sig efter $V_0$ på et vist punkt, og altså holde en hvis $\psi_n$ inden for $V_0$ begrænsninger, så vil den del af $\psi_n$, der ligger uden for blive kvalt af visse andre vektorer i mængden. Og når de sker, så har vi en potentiel kilde til asymmetri imellem disse vektorer. Dette må derfor nødvendigvis kureres igen, hvis vektorerne skal være symmetriske under $A$, ved at de områder, der bruges til at kvæle produktioner fra.\,. ``udbryderdelen'' af $\psi_n$, igen på et tidspunkt må falde mere og mere inden for $V_0$. Dog kan vi godt i princippet have, at ``udbryderens''.\,. ja, lad os næsten kalde det dens ``haler''.\,. Hm ja, det passer også med, hvordan jeg har brugt ``haler'' i denne sammenhæng tidligere. Vi kan altså godt have at dennes haler igen bryder væk fra $V_0$ i princippet, og vi kan også godt have, at de aldrig kommer helt ind i $V_0$ på samme punkt, men at visse dele af halerne bare nærmer sig $V_0$ på forskellige tidspunkter.\,. Men ved så netop at sørge for, at $V_0$ er meget ``hård'' (og mere og mere ``hård'' ikke mindst) ved udbryder-vektorer, der skal prøve at nærme sig $V_0$ igen, så mener jeg altså, at man kan opnå, at man sikrer sig, at de skal nærme sig $V_0$ igen ret.\,. uniformt.\,. hvis deres billede ikke skal divergere. .\,.\,Ja, for alle dele af halerne skal nærme sig $V_0$ igen, hvis symmetrien skal bevares. Men man kan altså konstruere $V_0$ således at dette får billede til at divergere, hvis ikke halerne også nærmer sig $V_0$ (uniformt) i en vis asymptotisk fart. (Og billede må altså nemlig ikke divergere, hvis vi allerede ved, at vektorerne skal være i Dom($B$), for det er jo definitionen af Dom($B$), nemlig at vektorernes billede mht.\ $A$ konvergerer.) Og når først halerne uniformt har nærmet sig $V_0$, så kunne man spørge, kan de så ikke bryde ud igen derefter? Men nej, for dette vil man jo bare straffe igen med det samme. Så halerne skal altså på et eller andet tidspunkt nærme sig $V_0$ og blive der, hvis ikke billedet skal divergere, altså antaget at vektorerne ikke bryder symmetrien heller. Okay, og tanken er jo dermed altså at vælge Dom($A$), så.\,. Ah, lad mig lige præcisere noget først en gang, for jeg bør nok forklare nærmere, hvad det vil sige, at ``$V_0$ er (mere og mere) hård mod udbrydere.'' Det vil i bund og grund sige, at den for basisvektorer, der jo forresten kan ses som bestående af en følge af stigende $k$'er, tager og ser på, om de sidste $k$'er i denne følge passer med $V_0$'s forskrift for disse niveauer hidtil. Og hvis den sidste (og største) $k$ altså ikke passer med forskriften, så vil $V_0$ altså vælge et begrænset område to niveauer oppe til at kvæle produktionen fra denne vektor (ét niveau oppe), men vælge et formindsket område, der altså lader en god del af produktionen være i billedet. Og for stigende niveauer vel den lade mere og mere af billedet være på denne måde, hvis altså ikke det sidste $k$ i rækken passer med forskriften. Men hvis det sidste $k$ derimod passer med forskriften, så vil $V_0$ vælge et stort område, således at meget af vektorens billede kan kvæles, og således at vektorer, der følger $V_0$'s forskrift efter et punkt altså vil have et endeligt, konvergerende billede. Ok, og tanken er altså så at vælge Dom($A$), så den ligesom inkluderer alle disse vektorer, der konvergerer mod, hvad $V_0$ foreskriver, og som altså gør det hurtigt nok til at have et endeligt billede mht.\ (eller hvilken præposition man nu plejer at bruge her) $A$. Øhm, og vil denne mængde så ikke selv være symmetrisk under $A$?\,.\,. .\,.\,Ja, det vil den jo netop, alt efter hvad jeg kan se.\,:) 

Hvor er det altså fedt, at jeg fik denne idé.\,.\,! Selv hvis nu den viser sig ikke at holde helt, så kan jeg ikke lade være med at føle, at det virkeligt er et skridt i den rigtige retning. Ja, selv endda hvis det skulle vise sig, at operatoren i sig selv faktisk ikke er selvadjungeret, så virker det stadig som et vigtigt skridt i den rigtige retning til at analysere det. .\,.\,Jeg har med andre ord en fornemmelse af, at denne idé vil være vigtig uanset hvad.\,. He, og jeg vil også lige nævne, at det jo er lidt sjovt, hvordan jeg i går startede et helt andet sted så at sige, og at idéen så bare pludselig kom lidt fre højre og langsomt begyndte at tage al opmærksomheden.\texttt{:D}\textasciicircum\textasciicircum\ 


%Klokken halv seks:
\ldots\ Nå, nu kom jeg lige til at overveje, om det nu også er helt sandt, at alle ``udbrydende'' haler nu også vil bryde symmetrien nødvendigvis, medmindre altså de efterfølgende nærmer sig $V_0$ igen. For man kunne jo godt måske forestille sig udbryder-vektorer, som måske alligevel var ortogonale på de mere standard haler på en eller anden måde\ldots \ldots Selvfølgelig kunne man muligvis så sørge for at konstruere den indledende mængde, så at vektorerne i den kvæler forskellige områder og lader andre være.\,. .\,.\,Hm ja, mon ikke man får eller kan få det sådan.\,.\,?\,.\,. .\,.\,Hm jo, den Dom($A$), jeg har i tankerne, vil jo også indeholde alle mulige vektorer, der kvæler nogen områder uden for $V_0$'s områder og lader andre være. Så udbryder-vektorer vil vel dermed altid bryde symmetrien under $A$ med én eller anden vektor fra Dom($A$), hvis ikke at ``udbryderne'' altså nærmer sig $V_0$'s forskrift igen.\,.(?\,.\,.) .\,.\,Ja, det må vist være sådan, og jeg kom så også lige til at tænke på: Hvad med de vektorer, der kvæler lidt af $V_0$'s områder. Men her må man jo bare behandle dette som en slags udbryder-vektorer også, hvor man altså også bare skal være mere og mere ``hård'' mod sådanne.\,. .\,.\,Ja, er det ikke bare sådan (lad mig lige tænke en gang).\,.\,? .\,.\,Ah, men det har jeg jo allerde taget højde for, for her vil $V_0$ jo som nævnt bare pege på et forsvindende område, hvorved alle vektorer, der alligevel kvæler pågældende vektor, så selvsagt vil være ``brudt ud'' af dette (forsvindende) område. .\,.\,Ja, så min løsningsidé ser altså stadigvæk umiddelbart ud til at holde indtil videre. 


(24.02.22) I går aftes fik jeg lige tænkt nogle flere tanker omkring dette emne. For det første skal man også overveje den parproduktion, der bliver både fra foton-elektron-positron-(Dirac-)interationen og fra Coulomb-.\,. Ah, eller måske \emph{burde} jeg lige netop kalde den noget andet (såsom gauge-interaktionen), når den netop også inkluderer andet end Coulomb-interaktionen. Den inkluderer nemlig også par-produktion. Ok, nå men man skal også lige tage højde for parproduktionen. Her kan jeg dog ikke se, hvorfor man ikke skulle kunne bruge helt den samme strategi, når man inddrager disse, for at nå frem til et symmetrisk domæne under $A$, som altså heller ikke kan rumme andre vektorer, uden at det bryder symmetrien. Så hvis min løsning altså bare holder, så er jeg ikke så bekymret for, at man ikke også sagtens kan føre løsningen videre til at inddrage parproduktionen. .\,.\,Ah vent, når det kommer til parproduktionen fra gauge-interaktionen, så er det jo faktisk lidt et andet billede fordi.\,. Hov nej, der er generelt et andet billede, for.\,. Hm, lad mig lige tænke over det en gang.\,. (Jeg har i øvrigt også noget fra i går aftes, jeg skal huske at nævne omkring, at $V_0$ måske kun skal være mere og mere hård som funktion af niveau og ikke af $k$-størrelse (måske for at Dom$(A^*)\subset\mathrm{Dom}(B)$-argumentet kan holde), men det vender jeg bare tilbage til efterfølgende.\,.) 

.\,.\,Hm, uanset hvilken vektor vi ser på ellers, så vil der blive en konstant parproduktion-amplitude fra $\hat H$. Spørgsmålet er så for det første, om ikke man kan kvæle denne produktion med.\,. Ah vent, man behøver jo ingen gang at kvæle den med parproduktionsvektorer i højere niveauer (hvor annihilation giver den $\psi_n^-$, der skal til for at kvæle ($\psi_n^+$-)produktionen); man kunne sikkert også bare bruge foton-absorption til at kvæle produktionen.\,. .\,.\,Hm, men ja, det giver et andet billede, for de vektorer, der skal bruges til at kvæle (den uendelige hale af) parproduktionen, de kommer jo så bare til at indgå i vektoren, og deres egne haler vil så altid kun have med foton-emission og -absorption at gøre. Jamen ok. Så parproduktion gør bare, at alle vektorer skal tilføjes en ekstra hale (af rene 0-impulstilstande btw), som selvfølgelig kan gøres arbitrært lille (også for gauge-parproduktionen.\,. hm, eller lad mig forresten lige tjekke dette en gang.\,.).\,. .\,.\,Ah jo, jeg behøver faktisk ikke at tjekke dette, for selv hvis det viser sig, at man ikke kan bruge annihilation til at kvæle, så kan man jo som nævnt altid bare bruge foton-absorption i stedet (med det samme). .\,.\,Og ville løsningen så altså dermed let kunne føres videre til, når $\hat H$ inkluderer parproduktionen?\,.\,. .\,.\,Hm ja, løsningen vil jo så bare, som jeg i hvert fald kan se, være helt den samme. 

Ok, lad mig så vende tilbage til det med, at $V_0$ måske kun skal være mere og mere hård som funktion af niveau (eller som funktion af partikelantal, kunne man også sige). Tanken kommer sig af, at mit løsningsforslag der fra d.\ 3/2 af nok også kræver, at de tilnærmede basisvektorer, som man bygger den vektor af, hvis matrixelement med $\mathrm{\textbf{H}} \setminus \mathrm{Dom}(B)$-vektoren skal gå imod uendelig, gerne også skal have billeder af begrænsede størrelser (for det niveau man er på), således at funktionalet fra def.\ 9.1 i Hall kan gå imod uendelig, uden at $\|\psi\|$ gør det. Og lad mig så lige prøve at forklare nærmere, hvad tanken bag dette potentielle bevisskridt så er. Den er, at jeg mener, at en vektor i $\mathrm{\textbf{H}} \setminus \mathrm{Dom}(B)$ må have mindst ét lille område (medmindre det er den frie energi, der får vektoren til at konvergere, men mon ikke også man sagtens kan finde en måde at trække alle $\|\hat H_0 \psi \|= \infty$-vektorer fra i første omgang.\,.\,?\,.\,.).\,. hvis produktioner ikke kvæles tilstrækkeligt, og som altså giver en uendeligt stor vektor i næste niveau, når $A^+$ opererer på den.\,. \ldots Hm, der er nu også andre måder, hvorpå man kan få uendelige billeder; man kan f.eks.\ få uendelig store vektorer fra fotonabsorption af endelige vektorer.\,. 

\ldots\ Ah, det er faktisk nemt at skille $\|\hat H_0 \psi \|= \infty$-vektorerne fra, for vi må jo have $\mathrm{Dom}((H_0 + H_1 + \ldots)^*) = \mathrm{Dom}(H_0^*) \cap \mathrm{Dom}(H_1^*) \cap \dots$ for alle operatorer, $H_0, H_1, \ldots$, og hvis så $H_0$ i øvrigt er selvadjungeret, så kan vi skrive dette videre om til $\mathrm{Dom}(H_0) \cap \mathrm{Dom}(H_1^*) \cap \dots$. Så på den måde\ldots\ Hov, det er måske forkert, for så ville summen to selvadjungerede operatorer jo altid bare være selvadjungeret. Så ja, der kan jo nok godt være tilfælde, hvor funktionalet i def.\ 9.1 godt kan være ubegrænset for én eller begge af $H_0$ og $H_1$ for en vis $\phi$, men hvor det altså faktisk er begrænset for summen.\,. .\,.\,Ja, klart nok.\,. .\,.\,Hm, men man kan nu sikkert godt vise, at dette ikke vil være tilfældet for $\hat H_0$ og $\hat H_{DI} + \hat H_{GI}$ (overvejer jeg nu lidt at kalde, hvad jeg nedenfor før (f.eks.\ for tre dage siden) har kaldt $\hat H_I$ og $\hat H_C$). For man må kunne vise, at man altid kan splitte Hilbert-rummet op i lige og ulige vektorer (mht.\ partikelantallene i Fock-underrummene) og så bruge kvaliteterne, at $\hat H_0$ altid lader partikelantallet være uændret, og at interkations-$\hat H$'erne altid ændrer partikelantallet. Så man kan altså herved ikke få en situation, hvor den ene operator pludselig gør det omtalte funktionale begrænset, når den ellers ikke var det for den anden operator. Okay, så langt, så godt. Og hvad så med de andre måder at opnå uendelige billeder på.\,.\,? .\,.\,Hov, to sekunder, for det er vel ikke sådan, at den allestedsnærværende parproduktion kan ødelægge det faktum, at man kan splitte det op i lige og ulige funktioner.\,.\,? .\,.\,Hm nej, det kan det ikke rigtigt gøre.\,. .\,.\,Tja, eller det kan jo måske gøre argumentet mere besværligt.\,. .\,.\,Hov, nu kom jeg også lige i tanke om, at gauge-interaktions-parproduktionen jo faktisk også gør min løsningsidé lidt mere kompliceret, for nu skal man jo, så vidt jeg kan se, også tage højde for, at produktioner også \emph{kan} kvæles helt eller delvist ved brug af elektron-positron-annihilationer i stedet for rent af foton-absorptioner.\,. 

Okay, så det korte af det lange er lidt, at der altså er en del mere at tænke over, før man kan løse problemet helt, men jeg mener dog stadig, at der er god sandsynlighed for, at jeg er på rette vej med min seneste idé her. Og indtil videre tror jeg faktisk på, at jeg har argumenter, som dur, hvis bare man lige holder gauge-parproduktionen (og annihilationen særligt.\,. tja, og nu vi er inde på det, så kan man jo sige det samme om Dirac-interaktions-annihilationen.\,.).\,. og Dirac-parproduktionen ude af billedet til at starte med, og hvis man også lige (for det har jeg heller ikke lige overvejet, hvad det kan betyde) glemmer, at.\,. Hm, jeg skulle til at sige, ``at fotonabsorption også kan give uendeligt store billeder,'' men lad mig dog faktisk lige overveje, hvad dette kan betyde en gang.\,. (.\,.\,Hm, og lad mig nu også lige tænke lidt over, hvad annihilationerne kan betyde for $V_0$-løsningen, inden jeg altså sætter dette problem på pause og begynder at fokusere mere rent på artikelskrivning.\,.) .\,.\,Ah, måske kan man bruge nogenlunde samme strategi, for at visse at sådanne tilstande ikke kan være i Dom($A^*$). Lad mig nu lige se.\,. .\,.\,Min tanke er altså, at man kan bruge tilnærmede basisvektorer, der hver især lader det billede være, hvor fotonabsorptionerne kommer fra (og hvor $V_0$ så også vil tillade (pr.\ konstruktion) at en linearkombination af sådanne vektorer godt kan få et begrænset billede).\,. .\,.\,Og hvad vil matrixelementet/funktionalet så blive?\,.\,. .\,.\,Ah, jamen det vil netop blive uendeligt (hvilket endda er nemmere at se end for i første tilfælde, hvor vi så på en vektor med uendeligt stort billede pga.\ foton\emph{emission}).\,:) .\,.\,Og ja, jeg bør i øvrigt også sætte nogle flere ord på, hvorfor jeg mener, at man kan få / får et ubegrænset funktionale i emissionstilfældet.\,. I dette tilfælde er tanken, at man konstruerer en vektor af en linearkombination af vektorer i områderne hvor $\phi$ har uendelig stor emission til, som alle selv lader $\phi$'s områder være (også altså ikke kvæler dem), hvor denne emission kommer fra. Og igen skal $V_0$ så pr.\ konstruktion altså tillade en sådan linearkombination, uden at pågældende individuelle vektorer i denne bliver ``straffet hårdere og hårdere'' af $V_0$, og hvor man altså godt kan inkludere flere og flere af dem, uden at deres billede nødvendigvis divergerer (for husk at disse vektorer skal tages fra Dom($A$), og at deres haler dermed på et tidspunkt skal konvergere til at følge $V_0$'s forskrift). Og vil dette så kunne give et uendeligt stort funktionale? .\,.\,Det mener jeg jo umiddelbart, for jeg mener, at $\phi$ så, siden emissionerne giver en uendeligt stor vektor må mangle hale-vektorer (to niveauer oppe) til at kvæle denne emission igen. Hvis den nu havde dette, så vil disse hale-vektorer selv bidrage i matrixelementet / det indre produkt med de indgående vektorer i den konstruerede linearkombination, og man vil komme frem til, at hvor $\phi$ kvæler sin produktion helt, der vil bidraget til matrixelementet (/ det indre produkt) være 0. Dette bør jeg i øvrigt lige tænke over en ekstra gang og tjekke, om det også passer, men lad os lige antage, at jeg har ret i dette for nu. Og tanken er så videre, at når $\phi$ derimod ikke har sådanne hale-vektorer til at kvæle dens emissionsvektorer, så vil bidragene til matrixelementet altså \emph{ikke} forsvinde her, og man vil tilmed så altid (mener jeg umiddelbart, men dette er også noget, man bør overveje nærmere) kunne opnå et arbitrært stort matrixelement via disse bidrag.\,. %Nå, selvom det var planen at fortsætte artikelarbejdet i dag, så kan jeg mærke, at jeg sikkert bare kommer til at bruge resten af i dag til lige at tænke over de to ting, jeg har nævnt i denne paragraf af ting, jeg lige kan/bør tænke over nu her. Så lad mig derfor bare tage det stille og roligt med dette. Og nu vil jeg således også gå mig en eftermiddagstur og så (muligvis) summe lidt over det.

%Klokken kvart i fire:
\ldots Jeg tog lige en lille gåtur nu her, og på vejen hjem, lige her for kort tid siden, fik jeg tænkt lidt over, om omtalte Dom$(A^*)\subset\mathrm{Dom}(B)$-argument holder, det virkede altså sådan, så jeg gik lidt videre til at tænke over, hvad man gør med $V_0$ og annihilationen. Men her kom jeg så hurtigt frem til, at man jo bare skal se annihilationsområderne som en del af de mulige områder $V_0$'s forskrift kunne pege på. Og hvis den så måske ikke gør dette, så skal den ``indledende mængde,'' som jeg snakkede om (for illustrationens skyld), og selvfølgelig så også hele Dom($A$), jo indeholde vektorer, som kvæler disse områder helt. Og så følger det ellers bare mit ovenfor beskrevne argument derfra, hvor vektorer, der alligevel lever på disse områder, så bliver nødt til at have haler derfra (samt alle andre steder fra), der konvergerer til, hvad $V_0$ foreskriver. Så ja, denne del af det hele bør faktisk ikke udgøre nogen ekstra problemer for løsningen, som jeg kan se det.\,:) .\,.\,Men ja, jeg skal dog lige vende tilbage til det andet emne også, for selvom det på min gåtur så ud til at give mening umiddelbart, så er der dog lige nogle dele af det, jeg mangler at overveje nærmere.\,. \ldots Okay, argumentet for vektorerne, der har et uendeligt stort billede via absorption (i.e.\ mht.\ $A^-$), giver altså rigtig god mening.\,. Og for emissionstilfældet.\,.\,? \ldots Ja, og her er argumentet jo altså, at $\phi$ så ikke vil have nok vektorer to niveauer oppe, hvorved vi forresten altså kunne tale om et $\phi_n$ og et $\phi_{n+2}$, til at modarbejde det arbitrært store bidrag, man kan opnå fra $\braket{\phi_n | A^- \psi_{n+1}}$.\,. .\,.\,Hm, nu kom jeg lige til at tænke på, om det egentligt ikke er et problem, at dette specifikke bidrag også kan blive arbitrært stort for en $\phi$, der ligger i Dom($A$), for bør rækken ikke konvergere, når man samler matrix-elementer med samme $n$ i $\phi_n$ til venstre.\,.\,? .\,.\,Hm, jeg skal dog også huske, at der ikke er nogen, der siger, at man skal kunne tage en uendelig række af $\psi$'er i Dom($A$) og så forvente, at denne stadig ligger i Dom($A$).\,. hm, men er det så ikke bare det, der løser dette ``problem''.\,.\,? Og argumentet, jeg har gang i, bruger jo ikke, at $\braket{\phi_n | A^- \psi_{n+1}}$ skal kunne \emph{blive} uendeligt, men bare at det er ubegrænset (samt så at hverken $\braket{\phi_{n+2} | A^+ \psi_{n+1}}$ eller matrixelementer fra niveauer højere oppe kan udligne det).\,. .\,.\,Jo, intet problem der, og jeg tror altså også, at mit argument her må vise sig at holde.\,. 7, 9, 13.\,.\,:) 

.\,.\,Nå, men det er da lige før, nu jeg er kommet så langt, at jeg så også lige skal gå tilbage og se på, om man kan argumentere for, at de andre kilder til, at billederne mht.\ $\hat H$ (.\,.\,eller rettere mht.\ dennes formular) kan blive uendeligt store, ikke vil ødelægge min løsning.\,. Lad mig se, hvad drejer det sig så om? .\,.\,Ah, men mangler vi så ikke stort set bare at argumentere for, at $\mathrm{\textbf{H}} \setminus \mathrm{Dom}(\hat H_0)$ kan skilles fra for Dom($A^*$) (eller Dom($\hat H^*$) rettere (da $A$ og $\hat H$ altså er det samme her))?\,:)\,.\,. .\,.\,Tja, eller det er jo selvfølgelig for tidligt at sige rigtigt, men ift.\ de ting, jeg er kommet i tanke om, vil det så ikke se ud til at holde, hvis bare jeg får dette med (eller var der også andre hængepartier, som jeg har fået øje på).\,.\,? .\,.\,Hm, tja nej, man skal nu nok gå igennem alle de andre mulige kilder til uendelige billeder hver for sig, og sikre sig, at de ikke er i Dom($A^*$), før man kan slå fast at Dom$(A^*)\subset\mathrm{Dom}(B)$.\,. .\,.\,Ah, men kan man ikke bare bruge helt samme strategi til også at vise, at annihilation og parproduktion, der fører til uendelige billeder, heller ikke kan være med i Dom($A^*$).\,.\,!\,? .\,.\,Hm, ligesom at der var nemmest at se for absorption, så må det i så fald også være nemmest først at se for annihilation.\,. .\,.\,Hm jo, det er jo helt det samme billede, vi har her.\,. (.\,.\,Altså som i at det er helt samme situation, vi har med at gøre; jeg snakker ikke om et funktions-/operator-billede her.\,x)) .\,.\,Ja, der bør ikke være forskel på, om man snakker fotonabsorption/-emission eller om man snakke annihilation/parproduktion, her når det kommer til halerne. Der bør gælde de samme ting, og de samme argumenter må kunne bruges. Og hvis dette så er rigtigt, jamen så \emph{mangler} vi vel faktisk bare at håndtere de mulige uendelige billeder fra $\hat H_0$, umiddelbart.\,.\,?\,:) .\,.\,Hm, man kunne vel i princippet godt tænke sig, at $\hat H_I$ på en måde kunne redde en $\|\hat H_0 \psi \|= \infty$-vektor fra at divergere\ldots\ .\,.\,Hm, men måske ikke en med vektor, der ligger i min foreslåede Dom($A$) (og ja, undskyld at jeg blander $A$ og $\hat H$).\,.\,?\,.\,. .\,.\,Hm ja, og her tænker jeg jo så faktisk på, hvis man starter med at løse for $\hat H_I$ ($= \hat H - \hat H_0$) alene, således at $A$ i Dom($A$) her altså bare er synonym med $\hat H_I$ i stedet.\,. .\,.\,Og spørgsmålet er altså så, om man til sidst så kan lægge $\hat H_0$ til og stadig få en selvadjungeret (samlet) operator.\,.\,? .\,.\,Ah, men man \emph{kan} stadig gøre noget, der er helt tilsvarende til at dele vektorer op i ``lige og ulige.'' .\,.\,Hov, eller kan man.\,.(?) \ldots Nå, jeg holder altså lige en pause, og så kan jeg jo summe over dette.

%Kl. tyve i otte:
\ldots\ Jeg er ikke helt kommet frem til endnu, hvad jeg gør for $\hat H_0$, men jeg tænker nu, at det bliver også at have den med i $A$ fra start og så prøve at vise, at vektorer uden for $\hat H_0$'s domæne ikke kan være med i Dom($A^*$). Men noget andet jeg så er kommet i tanke om, er at der også er en anden kilde til uendelige billeder fra $\hat H_I$, og det er, når produktionerne bare ikke kvæles mere og mere nok for højere niveauer, til at summen af disse (hver især endelige) ikke-kvalte produktioner bliver endelig. Man kunne så tænke, at man bare kunne gøre noget tilsvarende (med at konstruere sine vektorer med større og større matrixelement med $\phi$), bare fordelt over flere niveauer, men så kan det jo dog være et problem, hvis $V_0$ jo ``straffer hårdere og hårdere'' som funktion af niveauerne. Men nu kom jeg så til at tænke på, om dette virkeligt overhovedet er nødvendigt for $V_0$ at gøre? Er det mon ikke nok, hvis den bare ``straffer'' alle udbrydere ca.\ lige meget (og altså med en fast begrænsning på ``afstraffelsen''), for vil det så ikke stadig være sådan, at vektorer, der bliver ved med at ``bryde ud,'' også så vil få et større og større billede heraf (hvis de altså hele tiden skal konvergere tilbage til $V_0$ igen for hvert ``udbrud'')? .\,.\,Hm ja, jeg tror da, jeg har fat i noget her.\,. .\,.\,He, jeg håber, jeg har fat i noget her, men det må jeg jo bare lige tænke lidt over.\,:) For så vil jeg nemlig i mellemtiden gå tilbage til at tænke over, hvad man kan gøre for vektorer, der afbilledes til noget uendeligt af $\hat H_0$.\,. .\,.\,Hm, og løsningen bliver ikke bare noget med at tage en følge af vektorer, der tilnærmer sig $\phi$ selv, og så vise, at en sådan følge vil kunne føre til et større og større matrixelement (altså i def.\ 9.1-funktionalet, selvfølgelig).\,.\,? .\,.\,Hm, det lyder da også umiddelbart lovende.\,.\,:)\,.\,. (Men lad mig bare lige holde for i dag ved tasterne og så (muligvis) bare summe over disse muligheder til i morgen.\,:))


(25.02.22) Det er ikke $\phi$ selv, man skal tilnærme sig nødvendigvis for at gøre matrixelementet større og større, men der vil findes en vektor (hvis $\|\hat H_0 \phi \| = \infty$), man kan tilnærme sig for at opnå dette (nemlig en vektor, der minder om $\phi$ men som måske har langsommere aftagende hale (ift.\ normen), når man ser på $\hat H_0$-basisvektorer med stigende energi/egenværdi). Og ja, jeg kan ikke se, hvorfor man ikke skulle kunne tilnærme sig denne med en følge fra Dom($A$), som ikke forhindrer matrixelementet i at blive større og større. Selvom man måske godt \emph{kan} finde en følge (hvad ved jeg umiddelbart?), der forhindre dette, så er pointen jo bare, at man også må kunne finde en, der ikke forhindre et større og større matrixelement. Og dermed mener jeg altså sagtens, man må kunne inddrage $\hat H_0$ (i ``$A$'') og så stadig bevise, at $\mathrm{Dom}(A^*) \subset \mathrm{Dom}(B)$.

Jeg vil gerne gå videre med artikel arbejdet nu her i dag (og gerne allerede nu her til middag), %klokken er tyve over elleve nu btw (kom lidt sent i gang).
men lad mig lige først tænke en lille smule over, om min idé omkring en konstant ``straffende'' $V_0$ ser ud til at virke (det tror jeg umiddelbart, den gør), og om min løsning så ser ud til (umiddelbart) at kunne holde nu.\,. 

\ldots Hm ja.\,. .\,.\,Jeg kan ikke rigtigt konkludere andet, end at jeg altså tror, der er en vis sandsynlighed, for at jeg faktisk har fundet løsning her.\,.\,:) 

Det bliver rigtigt spændende at arbejde videre med denne løsning og prøve at tjekke den mere grundigt, men nu vil jeg altså dog lige lave en artikel først, hvor jeg bare introducerer min teori. Så jeg vil putte et bogmærke i dette arbejde for nu, og hvis jeg er heldig, så kan det være, når jeg kommer tilbage til det igen, at jeg så måske har andre interesserede med, der kunne have lyst til også at arbejde på at tjekke denne løsning (og tjekke teorien generelt).\,:) Man kan da i det mindste håbe, at det går så vel.\textasciicircum\textasciicircum\ 







\chapter{Notes leading to a publication without self-adjointness}

\section{Going through the relevant arguments (21.02.22)}
%\section{Gennemgang af de relevante argumenter}


Let us see, we begin with the Hamiltonian of the theory (in the $k$-space), which is given by something like
\begin{align}
\begin{aligned}
	\hat H = .\,.
\end{aligned}
\end{align}
Hm, should I just begin with the discretized version.\,.\,? .\,.\,Probably not, because we would want to integrate rather than sum the multidimensional Gaussian.\,. .\,.\,Hm, something like (\ldots)
\begin{align}
\begin{aligned}
	\hat H = \hat H_{0} + \hat H_{I} + \hat H_{C},
\end{aligned}
\end{align}
\begin{align}
\begin{aligned}
	\hat H_{0} = \int d\boldsymbol{k}\, |\boldsymbol{k}| 
		\hat a^\dagger_{\boldsymbol{k}} \hat a_{\boldsymbol{k}} + 
		\sum_{s=1}^2 \int d\boldsymbol{p}\, E_{\boldsymbol{p}} (
			\hat a^\dagger_{s \boldsymbol{p}} \hat a_{s \boldsymbol{p}} + 
			\hat b^\dagger_{s \boldsymbol{p}} \hat b_{s \boldsymbol{p}}
		),
\end{aligned}
\end{align}
\begin{align}
\begin{aligned}
	\hat H_{C} = \sum_{i=1}^4\sum_{j=1}^4 \iint d\boldsymbol{p}\, d\boldsymbol{p}'\, e %(e'et her er indsat efterfølgende (ligesom de nedenstående e'er.)
%		\frac{
%			\braket{\boldsymbol u_{i \boldsymbol{p}} | \boldsymbol u_{j \boldsymbol{p}'}}_{\mathbb{C}^4}
%		}{|\boldsymbol{p}' - \boldsymbol{p}|^2} 
		\frac{\boldsymbol u_{i \boldsymbol{p}}^* \cdot \boldsymbol u_{j \boldsymbol{p}'}}
			{|\boldsymbol{p}' - \boldsymbol{p}|^2} 
%		\hat \psi^\dagger_{i \boldsymbol{p'}} \hat \psi_{j \boldsymbol{p}},
		\hat \chi^\dagger_{i \boldsymbol{p'}} \hat \chi_{j \boldsymbol{p}},
\end{aligned}
\end{align}
\begin{align}
\begin{aligned}
	\hat H_{I} = \sum_{i=1}^4\sum_{j=1}^4 \iint d\boldsymbol{p}\, d\boldsymbol{k}\, 
		\frac{e}{\sqrt{2 |\boldsymbol{k}|}}(
			\mathcal{A}_{i j p k}^* \hat a^\dagger_{\boldsymbol{k}}	
%				\hat \psi^\dagger_{i \boldsymbol{p}} \hat \psi_{j \boldsymbol{p}} +
				\hat \chi^\dagger_{i \boldsymbol{p} - \boldsymbol{k}} \hat \chi_{j \boldsymbol{p}} +
			\mathcal{A}_{i j p k} \hat a_{\boldsymbol{k}}
				\hat \chi^\dagger_{i \boldsymbol{p} + \boldsymbol{k}} \hat \chi_{j \boldsymbol{p}}
		)\ldots
	\label{H_I_form_01}
\end{aligned}
\end{align}
I don't know if this makes 100 \% sense, but $\hat H_I$ should probably have pretty much this form.\,. And here we have defined $\hat \chi_{i \boldsymbol{p}} = \hat a_{i \boldsymbol{p}}$ for $i=1,2$ and $\hat \chi_{i \boldsymbol{p}} = \hat b^\dagger_{(i-2) (-\boldsymbol{p})}$ for $i=3,4$ *(i.e.\ for the antiparticles).\,. *(Hm, there can also be sign errors in eq.\ (\ref{H_I_form_01}) if the $\chi$'s should have a different order in one of the two terms.\,.) Perhaps I should clean up the subscripts by lifting the momentum indexes up as functional inputs, or something like that.\,. 

The $\boldsymbol u$'s are the 4-spinors %-vectors %No. 4-spoinors, not 4-vectors..
(where, by the way, $\boldsymbol u_{i \boldsymbol{p}}^* \cdot \boldsymbol u_{j \boldsymbol{p}'} = \delta_{i j}$ whenever $\boldsymbol{p}' = \boldsymbol{p}$) coming from the solutions of the free Dirac equation.

Okay, so I should look into now what $\hat H_{I}$ should be more precisely.\,. 

\subsection{Finding what $\hat H_I$ should be more exactly}
\ldots\ Okay, let us see.\,. If we have the field integral in $k$-space.\,. .\,.\,Then $\hat H_I$ should give us the term that becomes what we can call $\mathcal{L}_I$.\,. .\,.\,Hm, an aside: Couldn't it be kinda cool to name $\hat H_C$ as $\hat H_G$ instead, where G then stands for gauge.\,.\,?\,:)\,.\,. .\,.\,Perhaps, but if I indeed unveil it as the Coulomb Hamiltonian from the beginning, then $\hat H_C$ would of course also be very appropriate. .\,.\,Okay, but back to $\hat H_I$ and $\mathcal{L}_I$.\,. .\,.\,So we should look into what the Fourier-transformed $\mathcal{L}_I$ is and then probably read $\hat H_I$ off of that.\,.\,? 

.\,.\,Hm, if we look at the general path integral (I'm looking at my old QED notes *(namely at p.\ 11 of \texttt{QED paper03\_MadsD.pdf})), then $V(\boldsymbol{q})$ should now just turn into a four-by-four matrix, which have off-diagonal terms exactly when it comes to $\mathcal{L}_I$.\,. .\,.\,Hm, and is it then still trivial to Fourier-transform $V$?\,.\,. .\,.\,Hm, I would think so, because for any $\boldsymbol{q}$, we should be able to write $V(\boldsymbol{q})$ as a sum of Fourier components, right.\,.\,? .\,.\,Yes, and these will then show us how $\hat V(\boldsymbol{q})$ works on the $k$-space.\,. .\,.\,Okay, so far, so good.\,. .\,.\,Hm, and do we want to expand in terms of sine and cosine components as I have preferred in the past, or is it better to simply expand in terms of the complex exponential functions?\,.\,. .\,.\,Hm well, expanding in terms of the complex exponentials would then require a restriction on the coefficients (since $V(\boldsymbol{q})$ should be strictly real everywhere).\,. .\,.\,Hm, but that actually shouldn't really matter, right.\,.\,? .\,.\,Hm no, for any $\boldsymbol{q}$, $V(\boldsymbol{q})$ can be expanded in terms of complex exponentials and from this we can read off what $\hat V$ should be over the $k$-space.\,. .\,.\,Right? .\,.\,Hm, or rather, we can read what $\hat V$ should be as a function of $\boldsymbol{q}$, but what about as a function of $\tilde{\boldsymbol{q}}$?\,.\,. .\,.\,Well, we would probably get the expected answer to this question, and it will be easily obtainable, just be writing up the formula and transforming from $\boldsymbol{q}$ to $\tilde{\boldsymbol{q}}$. Okay, so expanding in terms of the complex exponentials (such as everyone else\,xD)\footnote{But doing it differently did yield me my phase operator, back in the day, so I'm glad I did it.\,\texttt{:D}\textasciicircum\textasciicircum} is probably the best course. 

.\,.\,And what do we get for $\hat V$ then?\,.\,. .\,.\,Don't we just get the $\hat V$ (or rather the contribution to it coming from the interaction part of the Dirac term) with matrix elements of 
\begin{align}
\begin{aligned}
	\bra{\boldsymbol{u}_{i \boldsymbol{p}}} 
		\hat H_{I, Dirac}|_{A_\mu \to \sim (a^\dagger_{\mu\, -\boldsymbol{k}} + a_{\mu \boldsymbol{k}})} 
	\ket{\boldsymbol{u}_{j\, \boldsymbol{p} + \boldsymbol{k}}},
\end{aligned}
\end{align}
or something like that.\,.\,? .\,.\,Ah yes, I think so.\,. \ldots Ah yes, and I can probably just Fourier transform in terms of the ladder operators. Okay, I think it will be pretty easy and give exactly the result one would expect. 

\ldots\ All right. So we should get an $\hat H_I$ on the form
\begin{align}
\begin{aligned}
	\hat H_{I} = \sum_{i=1}^4\sum_{j=1}^4 \iint d\boldsymbol{p}\, d\boldsymbol{k}\, 
		\frac{e}{\sqrt{2 |\boldsymbol{k}|}}(
			\mathcal{A}_{i j p k}^* \hat a^\dagger_{-\boldsymbol{k}}	
%				\hat \psi^\dagger_{i \boldsymbol{p}} \hat \psi_{j \boldsymbol{p}} +
				\hat \chi^\dagger_{i \boldsymbol{p} + \boldsymbol{k}} \hat \chi_{j \boldsymbol{p}} +
			\mathcal{A}_{i j p k} \hat a_{\boldsymbol{k}}
				\hat \chi^\dagger_{i \boldsymbol{p} + \boldsymbol{k}} \hat \chi_{j \boldsymbol{p}}
		),
	\label{H_I_form_02}
\end{aligned}
\end{align}
where the $\mathcal{A}$ coefficient should come from the 
$\bra{\boldsymbol{u}_{i \boldsymbol{p}}} 
\hat H_{I, Dirac, A_{\perp \pm\boldsymbol{k}}} 
\ket{\boldsymbol{u}_{j\, \boldsymbol{p} + \boldsymbol{k}}}$ 
matrix element. And the first thing I should do, when I continue on, is probably to make the gauge elimination in reverse. 


(23.02.22) No, I shouldn't make the arguments in reverse. I should just write up the Hamiltonian to begin with but then go on to write the field integral and make all the steps from their to get the proposed Hamiltonian. Afterwards I can then go on to explain why the field integral is Lorentz-invariant. 

(25.02.22) Well, deriving the path integral is often more natural to do by starting from the Hamiltonian, so in a way, the most natural way to derive the theory might be to go back and forth a bit (like I of course did). But anyway, I think I am actually just going to write up as many of the relevant formulas and equations I can now figure out now. And then afterwards I can try to nail down the arguments and all the steps.\,. 




%\subsection{The field/path integral I should begin from (23.02.22)} %Or 24. if I continue tomorrow instead..
\subsection{The field/path integral formulas and relevant equations (25.02.22)}
I'm not going to write to much explaining text in this subsection *(or try to keep it very neat in general *(at all; not that these notes are generally very neat.\,x))).

\subsubsection{The terms of the Hamiltonians}
\begin{align}
\begin{aligned}
	\hat H = \hat H_{0} + \hat H_{I} = \hat H_{0 Ph} + \hat H_{0 D} + \hat H_{I D} + \hat H_{I G},
\end{aligned}
\end{align}
\begin{align}
\begin{aligned}
	\hat H_{0} = \hat H_{0 Ph} + \hat H_{0 D} = 
%		\sum_{s=1}^2 \int d\boldsymbol{k}\, |\boldsymbol{k}| 
		\sum_{s=1}^2 \int d\boldsymbol{k}\, k
			\hat a^\dagger_{s \boldsymbol{k}} \hat a_{s \boldsymbol{k}} + 
		\sum_{s=1}^2 \int d\boldsymbol{p}\, E_{\boldsymbol{p}} (
			\hat a^\dagger_{s \boldsymbol{p}} \hat a_{s \boldsymbol{p}} + 
			\hat b^\dagger_{s \boldsymbol{p}} \hat b_{s \boldsymbol{p}}
		),
	\label{H_0_01}
\end{aligned}
\end{align}
\begin{align}
\begin{aligned}
	\hat H_{I D} = \sum_{s=1}^2 \sum_{\mu=1}^4\sum_{\nu=1}^4 \iint d\boldsymbol{p}\, d\boldsymbol{k}\, 
%		\frac{e}{\sqrt{2 |\boldsymbol{k}|}} \mathcal{A}_{s \mu \nu \boldsymbol{p} \boldsymbol{k}} (
		\frac{e}{\sqrt{2 k}} \mathcal{A}_{s \mu \nu \boldsymbol{p} \boldsymbol{k}} (
			\hat a^\dagger_{s\,-\boldsymbol{k}}	
				\hat \chi^\dagger_{\nu \boldsymbol{p} + \boldsymbol{k}} \hat \chi_{\mu \boldsymbol{p}} +
			\hat a_{s \boldsymbol{k}}
				\hat \chi^\dagger_{\nu \boldsymbol{p} + \boldsymbol{k}} \hat \chi_{\mu \boldsymbol{p}}
		),
	\label{H_ID_01}
\end{aligned}
\end{align}
\begin{align}
\begin{aligned}
	\hat H_{I G} = \sum_{\mu=1}^4\sum_{\nu=1}^4 \iint d\boldsymbol{p}\, d\boldsymbol{p}'\, 
		\frac{e}{|\boldsymbol{p}' - \boldsymbol{p}|^2} 
%		(\boldsymbol u_{i \boldsymbol{p}}^* \cdot \boldsymbol u_{j \boldsymbol{p}'})
		(\psi_{\mu \boldsymbol{p}}^\dagger \psi_{\nu \boldsymbol{p}'})
		\hat \chi^\dagger_{\nu \boldsymbol{p'}} \hat \chi_{\mu \boldsymbol{p}},
	\label{H_IG_01}
\end{aligned}
\end{align}
where %$\hat \chi_{i \boldsymbol{p}} = \hat a_{i \boldsymbol{p}}$ for $i=1,2$ and $\hat \chi_{i \boldsymbol{p}} = \hat b^\dagger_{(i-2) (-\boldsymbol{p})}$ for $i=3,4$,
\begin{align}
\begin{aligned}
	\hat \chi_{\mu \boldsymbol{p}} = 
		\begin{cases}
			\hat a_{\mu \boldsymbol{p}} & \mu=1,2\\
			\hat b^\dagger_{(\mu-2) (-\boldsymbol{p})} & \mu=3,4
		\end{cases},
\end{aligned}
\end{align}
%
%\begin{align}
%\begin{aligned}
%	\mathcal{A}_{s \mu \nu \boldsymbol{p} \boldsymbol{k}} = 
%		\bra{\boldsymbol{u}_{\mu \boldsymbol{p}}} 
%%		\gamma^0 \boldsymbol\gamma \cdot \boldsymbol{\hat{A}}_{\perp \pm\boldsymbol{k}}
%%		\gamma^0 \boldsymbol\gamma \cdot \boldsymbol{e}_{\perp s\, \pm\boldsymbol{k}}
%		\gamma^0 \boldsymbol\gamma \cdot \boldsymbol{e}_{\perp s \boldsymbol{k}}
%		\ket{\boldsymbol{u}_{\nu\, \boldsymbol{p} + \boldsymbol{k}}}
%\end{aligned}
%\end{align}
%Indskudt tænkeri: Hm, jeg skal have besluttet navne til både Dirac-4-spinor-løsningsvektorerne og til \boldsymbol{\hat{A}}_{\perp \pm\boldsymbol{k}}-vektorerne (hvilke jeg nemlig også har kaldt u i mine gamle noter).. ..Hm, jeg kunne jo godt kalde sidstnævnte for e, men er det nok, eller skal jeg også finde et bedre navn til Dirac-u'erne?.. Hm, og jeg kan ikke bare kalde dem \psi? ..Hm, jo det kan jeg da godt; er det ikke bare det, jeg gør så..? ..Hm, men skal jeg bruge dem i bold (fed) udgave, eller..? 
%... Hm, lad mig bare kalde dem for.. ..Hm, jeg kunne måske kalde dem for \psi_{0 D} eller noget i den stil.. 
%$\psi_{0 D}$
%..Ja, lad mig bare gøre det for nu.
%...Hm nej, det ser ikke så godt ud.. ..Hm, måske vil jeg bare bruge \boldsymbol for 4-spinorer (men ikke for 4-vektorer).. ..Hm, eller man skulle ikke bare bruge en \bar..? ..Nej.. ..Hm, nu tror jeg simpelthen bare jeg kalder dem for \psi lige ud for nu.. 
\begin{align}
\begin{aligned}
	\mathcal{A}_{s \mu \nu \boldsymbol{p} \boldsymbol{k}} = 
		\psi_{\mu \boldsymbol{p}}^\dagger
%		\gamma^0 \boldsymbol\gamma \cdot \boldsymbol{\hat{A}}_{\perp \pm\boldsymbol{k}}
%		\gamma^0 \boldsymbol\gamma \cdot \boldsymbol{e}_{\perp s\, \pm\boldsymbol{k}}
		(\gamma^0 \boldsymbol\gamma \cdot \boldsymbol{e}_{\perp s \boldsymbol{k}})
		\psi_{\nu\, \boldsymbol{p} + \boldsymbol{k}},
	\label{mathcal_A_01}
\end{aligned}
\end{align}
and where $\psi_{\mu \boldsymbol{p}}$, $\mu \in \{1, 2, 3, 4\}$, are the four (normalized) eigensolutions to the free Dirac equation (in just the (4-spinor) single-particle Hilbert space) with a given momentum $\boldsymbol{p}$.


%Path integral for a general $\hat H = \hat H_0 + \hat H_I$\ldots:

\subsubsection{Writing $\hat H_{0 Ph}$ in terms of $\hat P$s and $\hat X$s}
\begin{align}
\begin{aligned}
	\hat H_{0 Ph} = 
		\sum_{s=1}^2 \int d\boldsymbol{k}\, k
			\hat a^\dagger_{s \boldsymbol{k}} \hat a_{s \boldsymbol{k}} =
		\sum_{s=1}^2 \int d\boldsymbol{k}\, \big(
			\frac{1}{2} \hat P_{s \boldsymbol{k}}^2 + \frac{1}{2} k^2 \hat X_{s \boldsymbol{k}}^2
		\big),
	\label{H_0Ph(P,X)_01}
\end{aligned}
\end{align}
where $k$ is of course the norm of $\boldsymbol{k}$.\,. Let me in fact change that above as well.\,. 

\ldots Hm, I wonder if it would make sense to try to write up the equivalent theory of the extended Hilbert space (with the special solutions for $A_\parallel$ and $V$) before I even write up the path integral.\,.\,? 

\ldots Hm, that sounds reasonably enough to do.\,. Let me try.\,.


\subsubsection{Extending the Hilbert space and writing up an equivalent theory here}
\begin{align}
\begin{aligned}
	\hat H_{0 Ph} \to \int d\boldsymbol{k}\,
		\sum_{\mu=0}^3 \frac{1}{2} \hat P_{\mu \boldsymbol{k}}^2 +
		\sum_{\mu=1}^2 \frac{1}{2} k^2 \hat X_{\mu \boldsymbol{k}}^2 -
		(\pm i?) k (\hat X_{3\, \pm? \boldsymbol{k}}) \hat P_{0 \boldsymbol{k}} -
		(\pm i?) k (\hat X_{0\, \pm? \boldsymbol{k}}) \hat P_{3 \boldsymbol{k}}\,\ldots
\end{aligned}
\end{align}

%Klokken tyve i otte:
\ldots\ Let me postpone finding out what factors should be exactly. But $\hat H_{0 Ph}'$ might look something like that, i.e.\ like
\begin{align}
\begin{aligned}
	\hat H_{0 Ph}' = \int d\boldsymbol{k}\, \Big(
		\sum_{\mu=0}^3 \frac{1}{2} \hat P_{\mu \boldsymbol{k}}^2 +
		\sum_{\mu=1}^2 \frac{1}{2} k^2 \hat X_{\mu \boldsymbol{k}}^2 -
		i k (\hat X_{3 \boldsymbol{k}}) \hat P_{0 \boldsymbol{k}} -
		i k (\hat X_{0\boldsymbol{k}}) \hat P_{3 \boldsymbol{k}}
	\Big).
	\label{H_Ph'_01}
\end{aligned}
\end{align}

.\,.\,And the point is then that
\begin{align}
\begin{aligned}
	\bra{\psi} e^{-i \hat H t} \ket{\psi} = \bra{\psi'} e^{-i \hat H' t} \ket{\psi'}
\end{aligned}
\end{align}
when $\psi'$ is an extension of $\psi$ where for all\ldots\ \ldots Let me also postpone this part for a bit and try to write up $\hat H_I'$ first.\,. We should have.\,. Oh right, we should just have $\hat H_I' = \hat H_{ID}$ ($= \hat H_I - \hat H_{IG}$).\,. .\,.\,Yes, and from there, we should be able to obtain the Lorentz invariant path integral that one might start from in a more natural, motivated derivation (and that I indeed started from). But the big steps lie in showing the $\psi'$ solutions do not break the Lorentz symmetry if it already exists and in showing that the above equation holds.\,. (And first of all, I also need to define the $\psi'$ solutions formally.\,.) %..And I will look into this tomorrow..


(26.02.22) Ah, $\hat H_{Ph}'$ should actually have the form of eq.\ (\ref{H_Ph'_01}).\,. .\,.\,Hm, maybe it \emph{is} actually best to just Fourier transform in terms of sine and cosine, and then transform the space again once the Hamiltonian (i.e.\ $\hat H'$) is obtained.\,. .\,.\,Yeah, it seems more clean that way, even if it is possible to use expontentials in the field integral to begin with.\,. 

Okay, so I can actually just use my old approach (and I might even start from there to \emph{derive} the theory more (i.e.\ in more motivated way)) in which I obtain (with $\xi = 1$)
\begin{align}
\begin{aligned}
%	\hat H_{0 Ph}' = \sum_{\sigma\in\{1, -1\}}\int_{\mathbb{R}_{+}^{3}} d\boldsymbol{k}\, \Big(
	\hat H_{0 Ph}' = \sum_{\sigma=\pm 1}\int_{\mathbb{R}_{+}\times \mathbb{R}^{2}} d\boldsymbol{k}\, \Big(
		\sum_{\mu=0}^3 \frac{1}{2} \hat P_{\mu \boldsymbol{k} \sigma}^2 +
		\sum_{\mu=1}^2 \frac{1}{2} k^2 \hat X_{\mu \boldsymbol{k}  \sigma}^2 +
		\sigma k (\hat X_{3 \boldsymbol{k} -\sigma}) \hat P_{0 \boldsymbol{k} \sigma} +
		\sigma k (\hat X_{0\boldsymbol{k} -\sigma}) \hat P_{3 \boldsymbol{k} \sigma}
	\Big)
	\label{H_Ph'_02}
\end{aligned}
\end{align}

%Hm, bare jeg ikke har glemt \sigma-(/s-)fortegnet, når jeg har fundet frem til, at mine specielle løsninger også \emph{er} løsninger.. ..Nå nej, pyh; det er jo noget med, at jeg kun får bidrag fra cosinusfunktionerne.. Ok.. ..Ej, sikke et vejr, det er blevet!.. Hm.. ..Nå, det giver da forresten ikke mening at transformere over til exponentielfunktionerne, før jeg laver min gauge-elimination, for jeg vil jog netop gerne ende med at udskille alle cosinusfunktionerne her. Ja, så det er nok bedre, at vente med den transfomation til sidst, når jeg skal opnå min endelige $\hat H$. ..Hm, jeg brænder virkeligt for at komme ud i det her vejr; kan jeg ikke retfærdiggøre det, hvis jeg kan tage problemet med, hvordan jeg lige adskiller cosinusfunktionerne med mig..? ..Jeg kan i øvrigt også lige tænke over, hvordan vi får båret Dirac-Hamiltonianen med i felt-/sti-integralet.. ..Hm ja, og så kan jeg ellers tænke over, hvad jeg ellers kan tænke over;) ; nu smutter jeg altså ud i det vejr. 

%Kl. tyve i to:
\ldots\ Never mind the $\hat \chi$s; I don't think I will necessarily need them! I should be able to just use.\,. .\,.\,Hm, or maybe I will actually stick to them (but perhaps call then $\hat c$ instead.\,.), but otherwise, one could also make use of $\hat \psi_{\boldsymbol{p}} =\sum_{s=1}^2 (\hat a_{s \boldsymbol{p}} + \hat b^\dagger_{s -\boldsymbol{p}})$. And then I have also realized that I can just use $w$ instead of $\psi$/$\psi_{0 D}$/$\boldsymbol\psi$/$\boldsymbol u$.\,:) So eq.\ (\ref{mathcal_A_01}) becomes
\begin{align}
\begin{aligned}
	\mathcal{A}_{s \mu \nu \boldsymbol{p} \boldsymbol{k}} = 
		w_{\mu \boldsymbol{p}}^\dagger
		(\gamma^0 \boldsymbol\gamma \cdot \boldsymbol{e}_{\perp s \boldsymbol{k}})
		w_{\nu \boldsymbol{p} + \boldsymbol{k}}.
	\label{mathcal_A_02}
\end{aligned}
\end{align}

*[And eq.\ (\ref{H_IG_01}) becomes (.\,.\,Hm, let me actually try to rewrite the inner product.\,.)
\begin{align}
\begin{aligned}
	\hat H_{I G} = \sum_{\mu=1}^4\sum_{\nu=1}^4 \iint d\boldsymbol{p}\, d\boldsymbol{p}'\, 
		\frac{e}{|\boldsymbol{p}' - \boldsymbol{p}|^2} 
%		(w_{\mu \boldsymbol{p}}^\dagger w_{\nu \boldsymbol{p}'})
		\braket{w_{\mu \boldsymbol{p}} | w_{\nu \boldsymbol{p}'}}_{\mathbb{C}^4}
		\hat \chi^\dagger_{\nu \boldsymbol{p'}} \hat \chi_{\mu \boldsymbol{p}}.
	\label{H_IG_02}
\end{aligned}
\end{align}
And then eq.\ (\ref{mathcal_A_02}) could also be written as
\begin{align}
\begin{aligned}
	\mathcal{A}_{s \mu \nu \boldsymbol{p} \boldsymbol{k}} = 
		\bra{w_{\mu \boldsymbol{p}}}
		\gamma^0 \boldsymbol\gamma \cdot \boldsymbol{e}_{\perp s \boldsymbol{k}}
		\ket{w_{\nu \boldsymbol{p} + \boldsymbol{k}}}_{\mathbb{C}^4}.
	\label{mathcal_A_03}
\end{aligned}
\end{align}
.\,.\,I like that.\,.]

Oh, I actually have a clash between $\hat a_{s \boldsymbol{k}}$ for photons and fermions since both have two indices.\,. .\,.\,Ah, how about making sure to always put the spin index after the momentum index for photons.\,.\,? .\,.\,Hm, funny that Lancaster and Blundell does/do this (but maybe that's why I chose to do so in my old notes).\,. But it would probably be more conventional, to just use $a$, $b$ and $c$, and then perhaps use $c$ for the bosons.\,. .\,.\,Okay, let me put a pin in these thoughts for now. *Oh, but I could then perhaps use $\hat \psi_{\mu \boldsymbol{p}}$ instead of $\hat \chi_{\mu \boldsymbol{p}}$, just to note.\,. *[.\,.\,Hm, and I could also perhaps just write $\hat H_{0 D}$ as
\begin{align}
\begin{aligned}
	\hat H_{0 D} = 
		\int d\boldsymbol{p}\, E_{\boldsymbol{p}} \Big(
			\sum_{\mu=1}^2 \hat \psi^\dagger_{\mu \boldsymbol{p}} \hat \psi_{s \boldsymbol{p}} + 
			\sum_{\mu=3}^4 \hat \psi_{\mu -\boldsymbol{p}} \hat \psi^\dagger_{\mu -\boldsymbol{p}}
		\Big).\,.
	\label{H_0D_02}
\end{aligned}
\end{align}
No, then it is better to just define $a$ and $b$ but then just shift the names to $b$ and $c$.\,. Okay.\,.]

I might just argue for my special solutions (for $V$ and $A_\parallel$) from the path integral, like how I have always done it to myself.\,. 


%... Klokken 25 i seks: 
%Lad mig lige indsætte nogle q'er (altså koblingskonstanter) ovenfor, som jeg ellers har glemt *(hm, det bliver nok e'er i stedet, i hvert fald for alle formler, der specifikt har med QED at gøre..), og lad mig også lige kopiere følgende tekst ind her i kommentarnoterne, som er taget fra main.tex:
	%"(06.12.21) Okay, i går aftes kom jeg endelig frem til argumentet igen, og kom vist også på en god måde at formulere det på. Hvis man nemlig starter med vilkårlig start-tilstand for V og A_\parallel, så har man i første omgang en fase på denne i henhold til løsningsdomænet. Denne fase svarer til \exp(-i phi(\sum x_{fermions})), hvor denne phi er identisk med den, man skal lægge til nul- ((V=0, A_\parallel=0)-) tilstanden for at komme til den vilkårlige tilstand. Når vi specifikt lægger en phi til nul-tilstanden med \square^2 phi = 0, så vil den transformerede vilkårlige tilstand (som jeg har kaldt (V', A')) blive til en slut-tilstand, som svarer til den transformerede nul-tilstand, bare centreret om et andet punkt, og nu med en fase på, der afhænger af phi(\sum x_{fermions}_{fin}). Min argumentations-idé (hvilket jeg jo nok i sidste ende bare oversætter til matematik, hvis jeg kan) er så, at man ser på en transformeret base af slut-tilstanden, så slut-fasen, der afhænger af phi(\sum x_{fermions}_{fin}) altid bare går ud med denne base-transformation. Nå, hvis vi så går lidt tilbage, er vi altså frie til at lægge en \square^2 phi = 0 -bølge til nul-tilstanden, hvis.. Hm, \emph{skal} jeg mon ikke transformere basen i begge ender for det mest overskuelige argument?.. Tja nej, måske skal jeg egentligt bare argumentere med, at slut-tilstanden bliver den samme bare forskudt og med en fase på \exp(-i (phi(X_{fin}) - phi(X_{init})), men at man så i første omgang også samler \exp(-i phi(X_{init})) op pga., hvordan den samlede start-tilstand ser ud (og altså pga. løsningsdomænet). Så i sidste ende får man en slut-tilstand, der bare er forskudt (i henhold til (V', A') og til \square^2 phi=0 -bølgen (som også afhænger af (V', A'))) og som altså får en fase på sig oveni, lig \exp(-i phi(X_{fin})) (fordi de to andre faser spiste hinanden), hvor phi er i form af \square^2 phi=0 -bølgen. Og når jeg siger "centreret," så behøver det altså slet ikke at være der, hvor slut-tilstanden er størst omkring eller noget. Vi kan med andre ord vælge nul-tilstandens "modpart" frit, og kan altså vælge (V=0, A=0) her også. Det vil sige at dette "center-punkt" vil forskydes med phi-bølgen (og kun denne) i det Lo.-transformerede tilstandsrum også. Dette vil sige at den samlede sluttilstand vil være en sum, eller et integrale rettere, af en masse næsten identiske tilstande bare centrerede om forskellige punkter og med en fase hver især som den eneste forskel, som er lig \exp(-i phi(X_{init})), hvor \partial^\mu phi = A^\mu = "centerpunktet" for det pågældende slut-tilstands-bidrag. Det kan godt være, at jeg bare vil argumentere matematisk, men intuitivt kan man så herfra argumentere med, at vi kan lave et baseskift af sluttilstanden, som går fra løsningsdomænet og til \hat P_V = \hat P_{A_\parallel} = 0 -løsninger, hvorved dette så for alle slut-tilstands-bidrag vil spise vores \exp(-i phi(X_{init})). Så nu har vi altså bare en masse identiske slut-tilstande, bare centrerede om forskellige (V, A_\parallel)-punkter, lagt sammen til den endelige slut-tilstand (efter Lorentz-transformationen). Og så skal man bare lige vise, at determinanten af Jacobianten fra phi_{init} til phi_{fin} er 1 for sådanne \square^2 phi = 0 -bølger, og herved får man så, at slut-tilstands-bidragenes "centerpunkter" vil være fordelt jævnt over hele tilstandsrummet, og herved får man, når man summer/integrerer dem samme, en samlet slut-tilstand, der ikke afhænger af V eller af A_parallel. Til sidst skal vi så lige transformere slut-basen tilbage, og så opnår vi altså en løsning indeholdt i vores løsningsdomæne. Fedt! Rart endelig at have styr på den del af beviset (det tog godt nok lidt længere, end jeg havde regnet med ^^). ^^" 
%
%Kl. ti i syv: 
%...Hov, var det ikke noget med, at \hat\psi skulle konjugeres mht. positionsbasen i stedet..!?.. ..Jo, det var det jo.. Hm, jeg holder lige pause igen (fik godt nok ikke nået meget i dag indtil videre, men det er også ok).. Det kan så godt være, at jeg bare lige summer over tingene til i morgen.. 


%Klokken tyve i et; har sovet meget længe i dag (gik godt nok tidligt i seng, men jeg lå vågen en del i mroges, inden jeg faldt i søvn igen (følte, jeg havde brug for :))). Nu er jeg forhåbentligt langt om længe frisk og klar til at få styr på tingene:
(27.02.22) Ah, I \emph{should} probably use the ``$(\square^2\phi = 0)$-wave argument'' (as I have called it) both for showing Lorentz invariance of the solutions \emph{as well} as showing that they are indeed solutions. .\,.\,Hm, but isn't there actually a circularity in the argument if I use $\hat P_0 \psi = 0$ holds for the solutions to show that it \emph{is} a solution? I therefore perhaps need to show that $\hat P_0 \psi = 0$ holds first, or.\,.\,? 

Aside: I should maybe structure the article such that I first derive the ``naive'' (though I will definitely not call it that) Hamiltonian by eliminating the gauge symmetry in a simple way (that breaks the Lorentz invariance for all I know) and getting $\hat H = \hat H_0 + \hat H_{I D}$. Now the whole problem is motivated and understood (generally, I think) and I can then go back and do the elimination a more careful way. .\,.\,I really like this idea; I think it will be much easier to understand when the readers can compare to the more ``naive'' (so to (not) say) approach.\,. 

Another.\,. Oh, I can see that I might be using that term wrongly; I should write `side note' instead: Another side note: I should make sure that the Yukawa potential in conventional QED is thought to arise from the equations \emph{after} the gauge symmetry is eliminated. If this is true, then my theory is sure to be \emph{different} and not just be a different way to cast a known theory (which will still show us some new insights about it). (I'm pretty convinced that it's a new theory, but checking said thing will assure this if it's true.) *Of course the gauge elimination happens before the Yukawa potential is derived since everything is calculated from the Feynman diagrams. And the no-photon pair production coming from my $\hat H_{IG}$ also has to be something that is not seen before. \ldots Oh, by the way, maybe my theory will actually predict something new about the probabilities/amplitudes of pair productions.\,.\,! Let me mention that below in my text structure plan as well.\,.

Okay, back to the $(\square^2\phi = 0)$-wave argument and such.\,. .\,.\,Hm, or maybe it should just be divided into two arguments, where in the first argument, we start by setting $V=0$ everywhere and then show that the $(P_3 \sim e k^{-1})$-solutions solve it.\,. 

Side note: Maybe I should use $\hat P$ and $\hat Q$ (rather than $\hat X$) for lattices/fields and then use $\hat p$ and $\hat x$ for fermionic particles (if need be). .\,.\,Yes, I will probably do that. .\,.\,Oh, but if I use.\,. Oh, wait.\,.\,! Let me use $\hat p$ and $\hat q$ for operators and $\boldsymbol{p}$ and $\boldsymbol{q}$ for their eigenvalues and then just talk about the general case for the path integral, where they do not necessarily represent lattice momentum/amplitude. And when I get specific about talking about a lattice(/field), I can then just change the names to $P$ and $Q$.\,:) 

\ldots\ Hm, is it not a bit paradoxical-sounding that the $(A_\mu + \partial_\mu \phi)$ gauge symmetry is present, when $V$ is counteracted everywhere by the energy from $k V \hat P_{A_\parallel}$.\,.\,?\,?\,.\,.
%..Nå, selvom det jo er tidligt for mig ift., hvornår jeg stod op, så går jeg lige en eftermiddagstur i den sol, der også er fint fremme i dag. Sjovt, at jeg bliver ved med at glemme og skulle genfinde argumenterne for denne løsning. (Jeg forbinder meget gåture i Herestedøster med, når jeg før har tænkt over (og løst) dette problem, så det kan være, jeg også vil gå derhen nu, og prøve at gå lidt i mine gamle fodspor så at sige.^^)


%Klokken 25 i syv:
%Ah, jeg tror jeg er ved at have den nu. Jeg gik en god gåtur tidligere, hvor jeg fik tænkt nogle ting. For det første kan jeg lige nævne, at jeg fik tænkt lidt over, hvor fedt det altså bare er, at man bare kan argumentere med (som jeg nævnte (og kom frem til igen) i mine main.tex-noter), at integralerne i Trotter-expansionen *(eller i 'sti-integralet,' kunne jeg måske rettere have sagt her..) må kunne påføres et cutoff *(på alle k-integrationsvariablene), så hvis Hamilton-operatoren bare er selvadjungeret. For det vil jo sige, at vi kan tilnærme dymamikken arbitrært godt (og for en arbitrær stor periode) med en begrænset (bounded) Hamilton-operator. Og de fleste af de opslitninger, man så kan lave af denne begrænsede operator vil så også være i form af en sum af begrænsede operatorer, og dette vil sige, at så længe disse bare er symmetriske, så vil de trivielt også være selvadjungerede (og man kan derfor bare Trotter'e derudaf på fuld hammer). Der er så dog lige den caveat, at min $\hat H'$ nok måske alligevel kan have ubegrænsede led i sig, hvilket også er derfor jeg lige sørger for at nævne dette, for jeg vil nemlig så altså sætte mig for lige at være opmærksom på dette, når jeg skal til arbejde med den, og hvis det bliver relevant at tage højde for. Nå, men jeg kom også frem til, at man må kunne lave et ret fint bevis for, at mine løsningsrestriktioner er bevaret i tid, hvis man laver en lille Trotter-ekspansion, hvor man adskiller den frie foton-del, Dirac-delen minus eV-leddet og så resten, nemlig eV-leddet og V- og A_\parallel-felt-delen. Men nu her efter jeg kom hjem igen, så har jeg kigget på L-inv.-beviset, og jeg blev lige lidt bekymret for, om jeg rigtignok har overset $k V \hat P_{A_\parallel}$-delen, som måske bryder gauge-symmetrien. Men så har jeg lige husket nu her, at man jo i dette bevis ser på det delvise sti-integrale, hvor A_\mu-feltet er gjort klassisk. Herved vil man altså så kun have Langange-funktionen fra A_\mu-feltet og så Dirac-Hamiltonianen ovenpå. Og her \emph{vil} der altså være den omtalte gauge-symmetri. Og nu, lige inden jeg begyndte her på tasterne igen, kom jeg så også lidt frem til, at dette bevis godt både kan bruges til at vise, at restriktionerne er bevaret i tid (så man ikke behøver mit andet lille Trotter-bevis (hvor man btw argumenterede ved at vise, at hver lille U(\delta t)-enhed i expansionen bevarer restriktionerne over \delta t eksakt *(og hvor man så lavede et tilsvarnede argument som i mit \square\phi-argument ovenfor, bare hvor man inden da kunstigt har opnået V=0 (fordi denne del er separeret fra over i en anden del af U(\delta t)), og hvor man derfor kun skal koncentrere sig om at argumetere for A_\parallel))), og samtidigt også at de er bevaret efter en Lorentz-transformation. ..Inden jeg så lige svarer på mit hængende $k V \hat P_{A_\parallel}$-spørgsmål i den renderede tekst, så vil jeg lige overveje en gang, om argumenterne vil blive rigide, også selvom $\hat H'$ jo som nævnt ikke nødvendigvis er begrænset længere (selvom den er en udvidelse er en begrænset $\hat H$ (fordi vi altså med det samme laver vores ultraviolette cutoff på $\hat H$, før vi gør noget andet)).. 
%...Hm, og man kan ikke bare også lave et cutoff fra starten på A_\mu-amplituderne og så bære dette med sig på en måde..? ..Jo..(?..) ..Hm, hvor man måske så starter med at cutoff på A_\perp og så fra starten af bare sætter det samme cutoff på A_\parallel og V, når man omskriver til $\hat H'$..?.. ..Hm, men det er måske ikke så smart, for det kommer måske så til at karambolere med, når man skal L.-tranformere osv.. ..Hm, på den anden side, så gør det måske ikke noget, at man har sådan et cutoff, og så bare måske kan vise, at enhver given Lorentz-transfomation(-cyklus) vil være gyldig (og give det samme), hvis bare man lader cutoff'et gå imod uendeligt.. ..Hm, ja.. Ja, sgu! Jo, og hermed \emph{kan} man altså nok opnå, det jeg gerne vil opnå, hvilket nemlig bare er at have et argument for, hvorfor integralerne konvergerer (og altså hvorfor hver omkrivning gælder). Og det var jo bare det, jeg lige ville sikre mig. Og når så man ved, at alle integraller osv. konvergerer, når man lader cutoffs'ne gå imod uendeligt, jamen så \emph{kan} man også bare til hver en tid sætte grænserne til uendeligt (og altså fjerne cutoff'et igen), overalt hvor det giver mening. ..Og ja, det vil, så vidt jeg lige kan se, nok egentligt give mening nærmest altid, for jeg kan ikke komme på nogen formler/ligninger, hvor der ikke findes en uendelig udgave (så længe man jo altså bare lige ved, at pågældende integraler og/eller summer også vil konvergere, når de gøres uendelige). Ok, så jeg tror altså, der i bund og grund vil blive rimeligt (og måske totalt) kofrit ude på isen, når det kommer til diverse omskrivninger, man har lyst til at lave, \emph{hvis} altså bare man først lige sikrer sig (eller antager i mit tilfælde), at man starter med en selvadjungeret Hamilton-operator..:) 

\ldots\ No, because in my ($\square^2\phi = 0$) argument, we look at the classical fields in the (partial) path integral, so $k \hat V \hat P_{A_\parallel}$ isn't there.\,. 

Okay, with my comments (in Danish) in the source code in this subsection, I think I have the steps pretty much under control now. So I think I will make a (following) subsection now, where I go through all the formulas and equations in the order of the text structure I have in mind now. This text structure is to start by introducing my $\hat H$. Then I will derive a generalized path integral (with what could be a fermionic opartor on top), starting with a general self-adjoint Hamiltonian. I will apply then read off $\hat H'$ that gets us the sought for path integral for QED. *(Oh, and should just assume that there is a cutoff on $\hat H'$ here, so that it is ensured to be self-adjoint.) I think I will then try to see if I can make a naive gauge eliminetion to get $\hat H - \hat H_{I G}$. Then I will go back and suggest my plane wave solutions for $V$ and $A_\parallel$. I will show that the proposed restrictions are conserved in time with the special case of my $(\square^2\phi = 0)$ argument and I will also show that they are Lorentz-invariant this way. I will start by making the argument for the theory where the positron-$\hat\psi$s are \emph{not} conjugated, and then afterwards, I will argue that it follows that the actual theory, where they \emph{are} conjugated, is also Lorentz invariant. *(And for this argument, I can use an assumption that the theory converges when all cutoffs go to infinity.) From these solutions, the desired $\hat H$ should emerge. *(Oh, but not before we transform from sine/cosine ladder operators to the momentum ladder operators.\,.) By then assuming that this Hamiltonian is self-adjoint, we can then justify the assumptions that the cutoffs can be sent to infinity. And we can then go back to the path integral started with (when deriving the $\hat H'$ of interest) and argue that the theory will then indeed be Lorentz-invariant. Now, is $\hat H$ self-adjoint? That question remains to be answered --- perhaps in a later version of the article. It is not self-adjoint if we define it as broadly as possible, but I am working on a possible solution, where I hope to show that it is self-adjoint on a certain (dense) domain. I would like, however, to get some other eyes on that solution before I/we publish it (hopefully with a rigorous proof behind it).\,. I will then go on to discuss the qualities of the theory (i.e.\ that it meets all expectations and then some (in terms of making a certain common approximation approach more likely to be.\,. good (i.e.\ better than what would otherwise be the case.\,.))).\,. I plan on also mentioning a certain double-slit experiment (that I am personally quite interested in).\,. *(I should also mention something about just how neat the theory will be, if the proposed Hamiltonian is indeed self-adjoint.) *(Oh, and I should of course also talk about the previous wisdom about Yukawa potentials and how my theory seems to say something different here.\,.) And lastly I should go on to talk about that my approach might, for all I know, be able to give new results for other gauge symmetric quantum theories when applied to these (perhaps yielding other spherically symmetric potentials (not carried by particle interactions)).\,. So that's my planned text structure at this point.\,:) *I should also mention (what I just realized) %(d. 28/2)
that my theory might predict something new about pair production probabilities/amplitudes.\,\texttt{:D}


(28.02.22) Oh, but there is still the matter of conjugating the positron modes the right way. I have previously arrived at the thought/belief that this should be done wrt.\ the position basis somehow. But this is probably not true; it should probably be done the more trivial/natural way.\,. I think I have also written somewhere, that $\int d\boldsymbol{p}\, \hat \psi_{\mu \boldsymbol{p}} \propto \hat \psi_{\mu \boldsymbol x}$, or something to that extend, but this is not true. $\int d\boldsymbol{p}\, \hat \psi_{\mu \boldsymbol{p}}$ \emph{is} very localized, however, but only when we see $a= L/2\pi k_{max}$ as very small.

.\,.\,But the fact that $\int d\boldsymbol{p}\, \hat \psi_{\mu \boldsymbol{p}}$ still \emph{is} more and more localized when $k_{max}$ grows means that I am pretty confident that my proof/argument (if I can't just make a reference to somewhere) will work. But we will (probably) see in the next subsection.




\subsubsection{Formula-/equation-focused pre-draft}


So the Hamiltionan I believe I will end up with is
\begin{align}
\begin{aligned}
	\hat H = \hat H_{0} + \hat H_{I} = \hat H_{0 P} + \hat H_{0 D} + \hat H_{I D} + \hat H_{I G},
\end{aligned}
\end{align}
\begin{align}
\begin{aligned}
	\hat H_{0} = \hat H_{0 P} + \hat H_{0 D} = 
		\sum_{\lambda=1}^2 \int d\boldsymbol{k}\, k
			\hat a^\dagger_{\boldsymbol{k}\lambda} \hat a_{\boldsymbol{k}\lambda} + 
		\sum_{s=1}^2 \int d\boldsymbol{p}\, E_{\boldsymbol{p}} (
			\hat b^\dagger_{s \boldsymbol{p}} \hat b_{s \boldsymbol{p}} + 
			\hat c^\dagger_{s \boldsymbol{p}} \hat c_{s \boldsymbol{p}}
		),
	\label{H_0_03}
\end{aligned}
\end{align}
\begin{align}
\begin{aligned}
	\hat \psi_{\mu \boldsymbol{p}} = 
		\begin{cases}
			\hat b_{\mu \boldsymbol{p}} & \mu=1,2\\
			\hat c^\dagger_{\mu-2\, -\boldsymbol{p}} & \mu=3,4
		\end{cases},
\end{aligned}
\end{align}
\begin{align}
\begin{aligned}
	\hat H_{I D} = \sum_{\lambda=1}^2 \sum_{\mu=1}^4\sum_{\nu=1}^4 \iint d\boldsymbol{p}\, d\boldsymbol{k}\, 
%		\frac{e}{\sqrt{2 |\boldsymbol{k}|}} \mathcal{A}_{s \mu \nu \boldsymbol{p} \boldsymbol{k}} (
		\frac{e}{\sqrt{2 k}} \mathcal{A}_{\mu \nu \boldsymbol{p} \boldsymbol{k} \lambda} (
			\hat a^\dagger_{-\boldsymbol{k} \lambda}	
				\hat \psi^\dagger_{\nu \boldsymbol{p} + \boldsymbol{k}} \hat \psi_{\mu \boldsymbol{p}} +
			\hat a_{\boldsymbol{k} \lambda}
				\hat \psi^\dagger_{\nu \boldsymbol{p} + \boldsymbol{k}} \hat \psi_{\mu \boldsymbol{p}}
		),
	\label{H_ID_03}
\end{aligned}
\end{align}
\begin{align}
\begin{aligned}
	\mathcal{A}_{\mu \nu \boldsymbol{p} \boldsymbol{k} \lambda} = 
		\bra{w_{\mu \boldsymbol{p}}}
		\gamma^0 \boldsymbol\gamma \cdot \boldsymbol{e}_{\perp \boldsymbol{k} \lambda}
		\ket{w_{\nu \boldsymbol{p} + \boldsymbol{k}}}_{\mathbb{C}^4}.
	\label{mathcal_A_04}
\end{aligned}
\end{align}
\begin{align}
\begin{aligned}
	\hat H_{I G} = \sum_{\mu=1}^4\sum_{\nu=1}^4 \iint d\boldsymbol{p}\, d\boldsymbol{p}'\, 
		\frac{e}{|\boldsymbol{p}' - \boldsymbol{p}|^2} 
		\braket{w_{\mu \boldsymbol{p}} | w_{\nu \boldsymbol{p}'}}_{\mathbb{C}^4}
		\hat \psi^\dagger_{\nu \boldsymbol{p'}} \hat \psi_{\mu \boldsymbol{p}}.
	\label{H_IG_03}
\end{aligned}
\end{align}
I'll get back to $\boldsymbol e$ and $w$.



And now on to the generalized path integral.

Just to note:
\begin{align}
	\hat I = 
		\int d^N \boldsymbol q\, \ket{\boldsymbol q}\bra{\boldsymbol q} = 
		\int d^N \boldsymbol p\, \ket{\boldsymbol p}\bra{\boldsymbol p},
\end{align}
and 
\begin{align}
\begin{aligned}
	\braket{\boldsymbol q | \boldsymbol p} =
		(2 \pi)^{-\frac{N}{2}} e^{i \boldsymbol p \cdot \boldsymbol q}.
\end{aligned}
\end{align} 


Hm, let me try to derive a corollary the Trotter product formula.\,. The formula says that
\begin{align}
\begin{aligned}
	\lim_{M\to \infty} (e^{i \hat A t / M} e^{i \hat B t / M})^M \ket{\psi} = 
		e^{i (\hat A + \hat B) t} \ket{\psi}.\,.
\end{aligned}
\end{align} 
*(No, this is ambiguous. But in the ``norm topology,'' the limit is as according to this equation.) And it follows that
\begin{align}
\begin{aligned}
	\lim_{M, m, n \to \infty} (
		(e^{i \hat C t / M n} e^{i \hat D t / M n})^n
		(e^{i \hat E t / M m} e^{i \hat F t / M m})^m
	)^M \ket{\psi} = 
		e^{i (\hat A + \hat B) t} \ket{\psi}.\,.
\end{aligned}
\end{align} 
Hm no, that's not what I want.\,. \ldots Hm, I guess (for bounded operators) I only need to find an identity similar to the one in exercise 20.7-2. in Hall to show a generalized version.\,. %But let me take an afternoon break now..

\ldots\ Ah, for bounded operators, the formula actually extends itself pretty much, since each factor in the product will converge uniformly on \textbf{H}.  

\ldots\ I'm by the way gonna denote the ultra violet cutoff by $\Lambda$ and write 
\begin{align}
	\hat I_\Lambda = \hat P_{\Lambda} =
		\int_\Lambda d^N \boldsymbol q\, \ket{\boldsymbol q}\bra{\boldsymbol q} = 
		\int_\Lambda d^N \boldsymbol p\, \ket{\boldsymbol p}\bra{\boldsymbol p}\,.\,.
\end{align}
*(Here $\hat P_\Lambda$ is a projection operator, not a momentum operator.) Hm, where $N$ is the number of dimensions in the Hilbert space.\,. should I call it $\boldsymbol\Lambda$.\,.\,? Or $\mathrm{\textbf{H}}_\Lambda$.\,.\,? .\,.\,And then $\hat I_{\mathrm{\textbf{H}}_\Lambda}$.\,.\,? .\,.\,Hm no, let me just call it $\hat I_\Lambda$ in that case.\,. .\,.\,Or what about $\hat I_{\boldsymbol\Lambda}$?\,.\,. \ldots Hm, or how about we just start with a \textbf{H} that is equal to ``$\mathrm{\textbf{H}}_\Lambda$,'' and where $\Lambda$ is just given by $1/2\pi a$? That sounds better.\,. .\,.\,Hm, but shouldn't I still explicitly denote that $\boldsymbol p$ and $\boldsymbol q$ are restricted to a subset of $\mathbb{R}^N$, namely to a certain $[-A_{max}, A_{max}]^N$.\,.(?) .\,.\,Hm, couldn't I then just let $\Lambda$ denote this also?\,.\,. Hm, but how do you even Fourier transform bounded functions correctly.\,.\,? .\,.\,Hm well, if the bound is on the absolute-square integral of the function\ldots .\,.\,Hm, that might actually be pretty neat.\,.\,!\,.\,. (Maybe.\,.) .\,.\,Oh no, it will not be very neat in some ways.\,. \ldots\ Hm, maybe I should just try not to put restrictions on the field amplitudes.\,. .\,.\,Or could I perhaps put restrictions on $\boldsymbol q$ but not on $\boldsymbol p$.\,.\,? .\,.\,And then we would have
\begin{align}
\begin{aligned}
	\hat I_\Lambda \equiv &\,
		\int_\Lambda d^N \boldsymbol q\, \ket{\boldsymbol q}\bra{\boldsymbol q} = \\
	\hat I_\Lambda \hat I = &\,
		\hat I_\Lambda \int d^N \boldsymbol p\, \ket{\boldsymbol p}\bra{\boldsymbol p}\,.\,.
\end{aligned}
\end{align}
.\,.\,That actually sound pretty promising.\,. But then I should choose another name, rather than $\Lambda$.\,. .\,.\,Unless I just wanna gather all cutoffs under one name.\,. .\,.\,But I already have the coordinate space cutoffs built into the fact that the Hilbert space is.\,. Hm, I was about to say $N$-dimensional.\,. .\,.\,Yeah no, it's infinite dimensional, and is in fact equal to $L^2([-q_{max}, q_{max}]^N)$.\,. .\,.\,Hm, should I name $[-q_{max}, q_{max}]^N$ as $E_q^N$.\,.\,? (As in the eigenspectrum of $\hat q$.\,.) .\,.\,Sure, why not.\,. .\,.\,Or maybe I'll just choose a simpler name, but let's see.\,. \ldots Oh, the Hilbert space should be $L^2(\mathbb{R}^N)$, not $L^2([-q_{max}, q_{max}]^N)$. But $\hat I_\Lambda$, or what I will call it, is the projection operator onto $L^2([-q_{max}, q_{max}]^N)$.

Okay, I actually think this will make pretty good sense. Let me just write $\boldsymbol \Lambda$ for now, such that $\boldsymbol \Lambda$ can be seen as a tuple $(\Lambda, L, Q_{max})$ of the cutoffs and restrictions on the space. I might very well change this notation again at some point, but let me just work through the equations now with this.

.\,.\,Or let me actually see if I can read a bit about the imaginary Gaussian integral first.\,. 


\ldots\ Hm, I just realized that my $\boldsymbol p$ also needs to be bounded if we want to make sure to have bounded operators of the Hamiltonians.\,.(!) And this comes just when I am wondering if I should actually discretize $\boldsymbol q$ and $\boldsymbol p$ as well.\,. But maybe it will make the Gaussian integration a bit ugly.\,.\,?\,.\,. .\,.\,Hm, this idea actually sounds pretty good still.\,. 

\ldots Oh, I'm actually really starting to like this picture. I figure now that we shouldn't actually look at a discretized Hilbert space when it comes to $\boldsymbol q$ and $\boldsymbol p$, but we should instead define a subset of \textbf{H} with step-like functions, $\ket{\boldsymbol{q}}$s and $\ket{\boldsymbol{p}}$s and define $\hat H_{\boldsymbol{\Lambda}}$ such that it maps functions of said subset into functions the same subset. So we can see both $k_{max}$ and the dicretizing restrictions on the $\ket{\boldsymbol{q}}$ and $\ket{\boldsymbol{p}}$ vectors can be seen strictly as bounds that changes $\hat H$, but actually leaves the Hilbert space itself (i.e.\ \textbf{H}) unchanged.\,. 

(01.03.22) I really like this idea, actually.\,:) It's so nice that I don't have to argue about two theories on different Hilbert spaces and that one get more and more similar to the other in a certain limit. Now I can instead just show it mathematically. Even though it is really the same argument in both cases, it just becomes much simpler to think about (or so I think), when.\,. Yeah, when you don't \emph{have} to think, so to speak: you just have to look at the math. And we now get that the Hamiltonian terms are bounded in all the inner points of the derivation. And also the matrix elements in the derivation always actually exist.\,xD\,\textasciicircum\textasciicircum

Okay, on with the genralized path integral! First of all, we have
\begin{align}
\begin{aligned}
	\lim_{M \to \infty} \Big\|
		e^{-i (\hat A + \hat B + \hat C + \hat D) t } \ket{\psi} - (
%		e^{-i (\hat A + \hat B + \hat C + \hat D) t } \psi - (
			e^{-i \hat A t / M } e^{-i \hat B t / M}
			e^{-i \hat C t / M } e^{-i \hat D t / M}
		)^M \ket{\psi}
%		)^M \psi
	\Big\| = 0,
	\label{Trotter_four_terms_01}
\end{aligned}
\end{align} 
where $\| \ket{\psi} \|$ is the vector norm of vector $\ket{\psi}$. .\,.\,The ket notation is by the way useful since it allows us to denote the vectors by other than just their wave function, namely also by the symbols that we also use to denote their eigenvalues wrt.\ certain operators, such as with $\ket{\boldsymbol q}$. So essentially $\ket{\boldsymbol q}$ would otherwise be written as e.g.\ $\psi_{\boldsymbol{q}}$. Oh, and by the way, since I'm letting the Hilbert space be explicitly defined (as $L^2(something)$.\,.) (.\,.\,unlike what is often the case in physics literature), we have that $\psi$ (outside of a ket) is \emph{also} a vector, and thus we simply have $\ket{\psi} = \psi$ (and could interchange them anywhere in the equations *(well, of course unless it is used in an index.\,. oh, and we thus shouldn't for instance allow ourselves to change $\ket{\psi}$ to $\ket{\ket{\psi}}$.\,x))) in the cases where $\psi$ represent the wave function. But in these sections (of the article), I'm going to write $\ket{\psi}$ rather than $\psi$ for consistency. 

Anyway, let me try to argue for eq.\ (\ref{Trotter_four_terms_01}) by using the Trotter product formula as well as the fact that our operators here are bounded.\,. When they are bounded, we should know that\ldots\ Well, first of all, let us note that we have\ldots\ .\,.\,No wait, let me think a bit.\,. 
\ldots Well, when they are bounded, can't we use that for instance.\,. .\,.\,Hm, no.\,. 
%\begin{align}
%\begin{aligned}
%	\Big\|
%		e^{-i (\hat A + \hat B) t } \ket{\psi} - (
%%		e^{-i (\hat A + \hat B + \hat C + \hat D) t } \psi - (
%			e^{-i \hat A t / M } e^{-i \hat B t / M}
%		)^M \ket{\psi}
%%		)^M \psi
%	\Big\| = \varepsilon
%\end{aligned}
%\end{align} 
\ldots Ah, maybe I just need to show the corresponding version of eq.\ (20.5) i Hall (the one for which exercise 20.7-2. is used) and then follow that proof from there.\,. .\,.\,Oh, the proof in Hall is actually more complicated than what I anticipated.\,. .\,.\,Hm, maybe, since they are bounded, we can just argue simply from the expansion of $\exp(-i \hat A t)$.\,.  \ldots Oh wait, can't I do something like
\begin{align}
\begin{aligned}
	&\lim_{M, m, n \to \infty} (
		(e^{i \hat C t / M n} e^{i \hat D t / M n})^n
		(e^{i \hat E t / M m} e^{i \hat F t / M m})^m
	)^M \ket{\psi} = \\
	&\lim_{M \to \infty} (
		(e^{i \hat C t / M^2} e^{i \hat D t / M^2})^M
		(e^{i \hat E t / M^2} e^{i \hat F t / M^2})^M
	)^M \ket{\psi},
\end{aligned}
\end{align} 
and then introduce $Z=M^2$ to write this as
\begin{align}
\begin{aligned}
	\lim_{Z \to \infty} (
		(e^{i \hat C t / Z} e^{i \hat D t / Z})^{Z/M}
		(e^{i \hat E t / Z} e^{i \hat F t / Z})^{Z/M}
	)^{Z/M} \ket{\psi}?\,.\,.
\end{aligned}
\end{align} 
Hm.\,. (.\,.\,Maybe I can choose something else for $n$ and $m$ if it suits better, but let's see.\,.)
\ldots Hm, let me try to write
\begin{align}
\begin{aligned}
	&\lim_{M, m \to \infty} (
		(e^{i \hat C t / M m} e^{i \hat D t / M m})^m
		(e^{i \hat E t / M m} e^{i \hat F t / M m})^m
	)^M \ket{\psi} = \\
	&\lim_{m \to \infty} (
		(e^{i \hat C t / m^3} e^{i \hat D t / m^3})^m
		(e^{i \hat E t / m^3} e^{i \hat F t / m^3})^m
	)^{m^3} \ket{\psi}
\end{aligned}
\end{align} 
instead, or something like that.\,. \ldots Hm, I almost feel like there must be something I am missing.\,. Let me try to rewrite it like this instead (where we define all limits by the norm topology by the way):
\begin{align}
\begin{aligned}
	&\lim_{M \to \infty} (
		e^{i (\hat A + \hat B) t / M} e^{i \hat C t / M}
	)^M \ket{\psi} \\
	=\,
	&\lim_{M \to \infty} (
			(e^{i (\hat A + \hat B) t})^{1/M} e^{i \hat C t / M}
	)^M \ket{\psi} \\
		=\,
	&\lim_{M, m \to \infty} (
			(e^{i \hat A t / m} e^{i \hat B t / m})^{m/M} e^{i \hat C t / M}
		)^M \ket{\psi}.\,.
\end{aligned}
\end{align} 
Oh, and with $m=M$!\,.\,.\,? We get
\begin{align}
\begin{aligned}
	&\lim_{M \to \infty} (
		e^{i (\hat A + \hat B) t / M} e^{i \hat C t / M}
	)^M \ket{\psi} \\
	=\,
	&\lim_{M \to \infty} (
			e^{i \hat A t / M} e^{i \hat B t / M} e^{i \hat C t / M}
		)^M \ket{\psi}.\,.
\end{aligned}
\end{align} 
Ah, finally! Okay, so that Trotter product formula does indeed extend itself; I was just slow to see how. (Because we can keep repeating this if for instance $\hat A = \hat X + \hat Y$ and so on.) This argument works because.\,. Oh wait, maybe I should say that the \emph{Lie} product formula generalizes itself.\,. (.\,.\,Well, for the Lie product formula, it is (now) a trivial matter, since the proof is just a simple calculation. And we \emph{can} by the way actually show that our operators with the cutoffs behave exactly like matrices (on the $\hat I_\Lambda$ subspace) so we could actually just use the Lie product formula if it turns out to be easier.\,.) .\,.\,Hm, and I am pretty convinced we can use the above argument for bounded operators as well, but let me just see for a moment.\,. .\,.\,Oh well, never mind, I actually don't care very much about this. In a lot of ways, it will surely be nice just to show that the operators (with cutoffs) behave exactly like matrices, so that everything is just on easy mode from there (also if someone perhaps want to show something else than what I do (with my work as a starting point, so to say)). Okay. Let me take a an afternoon break and then move on.

\ldots\ Okay, let $\boldsymbol{\Lambda} = (\Lambda, L, \Lambda', L', \Pi, \Gamma)$\ldots 
%$\delta k_1, \delta k_2, a_1, a_2, \delta p, \delta q) = \\
% (2 \pi  L_1, 2 \pi  L_2, a_1, a_2, \delta p, \delta q)$
\ldots Let also $N=\lfloor 2 \Lambda / (2\pi / L)\rfloor = \lfloor\Lambda L / \pi \rfloor$.\,. No, assume $\Lambda L / \pi$ is an integer and thus that $\Lambda = N \pi / L$, where we also have the definition for $N$. .\,.\,Hm, with this definition, we will get $N^3$ everywhere instead of $N$, though.\,. .\,.\,Oh well, that's probably for the best, actually.\,. \ldots Hm, let $\Pi = K \pi / \Gamma$, where $K$ is also an integer (I want to preserve $M$ for the temporal discretization).\,. .\,.\,And then we can also simply define $a$, $\delta k$, $\delta q$ and $\delta p$ as $L/N$, $2\Lambda / N$, $\Gamma / K$ and $2\Pi / K$, respectively. (And we can define $N', a', \delta k'$ similarly to $N, a, \delta k$.) Okay.\,. (.\,.\,And we could also call it $\delta x$ instead of $a$.\,.) .\,.\,Yeah, let me actually do that: Let me call it $\delta x$ instead of $a$ (for more consistency). .\,.\,I could also think about, whether I actually want to use capital $\Delta$s instead.\,. .\,.\,Yeah, that might look better.\,. $\Delta x, \Delta k, \Delta q, \Delta p$.\,. Yeah, I like that better (they are much more visible that way).\,. .\,.\,Oh, but do I then call it $\Delta t$ instead of $\delta t$ when I get to that?\,.\,. .\,.\,Hm, now I kinda prefer small $\delta$s again.\,. Okay, small deltas it is (for now at least). 

Okay, so the step function $\ket{\boldsymbol q}$s almost define themselves. I'll let each $q_i$ run from $-L/2$ to $L/2$ in steps of $\delta q$ (and thus the step functions will have a width of $\delta q$). .\,.\,Hm, but then $N$ is actually equal to $L/ \delta q + 1$.\,. Hm, should I let them run from $\delta q$ to $L$ instead.\,.\,?\,.\,. %..Let me take a break.. 

%Klokken tyve over seks (og gik på pause kl. fem over fem, btw):
\ldots\ Ah, the $q_i$s should take values of the midpoints, so they should of course run from $-L/2 + \delta q /2$ to $L/2 - \delta q / 2$ instead. *(No, from $-\Gamma/2 + \delta q /2$ to $\Gamma/2 - \delta q / 2$.)

But $L$ should actually just be constant throughout (though $\Gamma$ should not). So I think I can actually just use $(\Lambda, \Pi, \Gamma)$ instead.\,. We'll then still assume $\Lambda = N \pi / L$ and $\Pi = K \pi / \Gamma$. And we'll have $(\delta x, \delta k, \delta q, \delta p) = (L/N, 2\Lambda / N, \Gamma / K, 2\Pi / K)$. The $q_i$ eigenvalues run from $-\Gamma/2 + \delta q /2$ to $\Gamma/2 - \delta q / 2$ as mentioned, and we probably won't really need the $x_i$ values for anything. The $k_i$ values run from either $-\Lambda/2 + \delta k /2$ or from $\delta k$ to $\Lambda/2 - \delta k / 2$ depending on the type of Fourier transform used. But I will use the cosine/sine version for the most part, in which case case the $k_i$ values run from $\delta k / 2$ to $\Lambda/2 - \delta k / 2$. The $p_i$ values, however, will run from $-\Pi/2 + \delta p / 2$ to $\Pi/2 - \delta p / 2$, as I will use the complex-exponential version. Hm, I actually made a mistake here, but isn't this actually much nicer, namely when we let the momentum values run from $\sim -\Lambda / 2$ to $\sim \Lambda / 2$, such that $\Lambda/2$ is actually the ultraviolet cutoff rather than $\Lambda$?\,.\,. .\,.\,Hm, or maybe not.\,. .\,.\,Okay, never mind. Let the $k$ values run from $\delta k / 2$ to $\Lambda - \delta k / 2$ and let the $p$ values run from $-\Pi + \delta p /2$ to $\Pi - \delta q / 2$. 

.\,.\,Hm, maybe we could call our ``set of bounds'' $\boldsymbol B=(\Lambda, \Gamma, \Pi)$ (and keep $L$ of it since it is a bound on the full Hilbert space as well). And then we can can write e.g.\ $\hat I_{\boldsymbol B}$ and $\hat H_{\boldsymbol B}$ and so on.\,. .\,.\,Yes, that sounds good. 

So then each $\ket{\boldsymbol{p}}$, $\boldsymbol{p} = (p_{11}, p_{12}, \ldots, p_{1N^3}; p_{21}, \ldots p_{2N^3}; \ldots, p_{D N^3})$, is given by
%\begin{align}
%\begin{aligned}
%	\ket{\boldsymbol{p}} = \frac{1}{\sqrt{N^3 K^D}} \sum_{j = 1}^{K} \prod_{d=1}^{D} \prod_{n=1}^{N^3}  e^{i p_{d n} q(k)} \ket{text}
%\end{aligned}
%\end{align} 
\begin{align}
\begin{aligned}
%	\ket{\boldsymbol{p}} = \frac{1}{\sqrt{N^3 K^D}} \sum_{d=1}^{D} \sum_{n=1}^{N^3}
%	\ket{\boldsymbol{p}} = \frac{1}{\sqrt{N^3 K^D}} \sum_{\boldsymbol{q}\in \textbf{H}_B}^{D}
%	\ket{\boldsymbol{p}} = \frac{1}{K^{D N^3 / 2}} \sum_{\boldsymbol{q}\in E_q}
%	\ket{\boldsymbol{p}} = K^{-D N^3 / 2} \sum_{\boldsymbol{q}\in E_q}
%	\ket{\boldsymbol{p}} = \frac{1}{\sqrt{K^{D N^3}}} \sum_{\boldsymbol{q}\in E_{\hat{\boldsymbol{q}}}}
%	\ket{\boldsymbol{p}} = \frac{1}{\sqrt{K^{D N^3}}} \sum_{\boldsymbol{q}\in \textbf{H}_{1\boldsymbol{B}}}
	\ket{\boldsymbol{p}} = \frac{1}{\sqrt{K^{D N^3}}} \sum_{\boldsymbol{q}\in Q}
		e^{i \boldsymbol{p} \cdot \boldsymbol{q}} \ket{\boldsymbol{q}}.\,.
\end{aligned}
\end{align} 
.\,.\,Alright.\,. \ldots Hm yeah, maybe I should use just $Q$ instead of, say, $E_{\boldsymbol{q}}$ or $E_{\hat{\boldsymbol{q}}}$. I think I will (for now at least). .\,.\,Hm I should, however, keep in mind that it might be better to just start of with something simpler if possible, where for instance $DN^3$ might just be $N$ instead. But maybe it \emph{will} just be better to do this more special case to begin with --- let us just wait and see. 

(02.03.22) Of course I should just do the simple version of the path integral derivation and then just reinterpret the coordinate vectors afterwards. (Like I did back in the day, but where said coordinates are now also discrete and bounded.) 
But Let me go back to the Lie/Trotter formula for a moment. Last night I realized that my argument wasn't rigorous enough for this purpose and then I had an idea for changing and mending the proof, so I will try that out now. Let me take the Trotter product formula and note that (when we assume that all the relevant sums are self-adjoint)
\begin{align}
\begin{aligned}
	\lim_{M \to \infty} \Big\|
		e^{-i (\hat A + \hat B + \hat C) t } \ket{\psi} - (
			e^{-i \hat A t / M } e^{-i (\hat B + \hat C) t / M}
		)^M \ket{\psi}
	\Big\| = 0,
\end{aligned}
\end{align} 
and
\begin{align}
\begin{aligned}
	\lim_{M \to \infty} \Big\|
		(e^{-i (\hat B + \hat C) t})^{1/M} \ket{\phi} -
		\,.\,.\,
%		)^M \ket{\psi}
	\Big\| = 0\,.\,.
\end{aligned}
\end{align} 
.\,.\,Hm wait, let me assume that the operators are bounded.\,. .\,.\,Then going from
\begin{align}
\begin{aligned}
	e^{-i (\hat A + \hat B + \hat C) t } \ket{\psi} \to
		(e^{-i \hat A t / M } e^{-i (\hat B + \hat C) t / M})^M \ket{\psi}
\end{aligned}
\end{align} 
costs us an error of $\hat \varepsilon_1(M)\ket{\psi}$. And going from 
\begin{align}
\begin{aligned}
	e^{-i (\hat B + \hat C) t } \ket{\psi} \to
		(e^{-i \hat B t / M } e^{-i \hat C t / M})^M \ket{\psi}
\end{aligned}
\end{align} 
costs us an error of $\hat \varepsilon_2(M)\ket{\psi}$\ldots\ .\,.\,Oh, and going from
\begin{align}
\begin{aligned}
	(e^{-i (\hat B + \hat C) t })^{1/M} \ket{\psi} \to
		e^{-i \hat B t / M } e^{-i \hat C t / M} \ket{\psi}
\end{aligned}
\end{align} 
will then give us an error of $\hat \varepsilon_2(M)^{1/M} \ket{\psi}$.\,.\,!\,.\,. .\,.\,And you could also have defined it the other way around, which would probably make this easier to see.\,. .\,.\,Okay so going from
\begin{align}
\begin{aligned}
	(e^{-i \hat A t / M } e^{-i (\hat B + \hat C) t / M})^M \ket{\psi} \to
		(e^{-i \hat A t / M }  e^{-i \hat B t / M } e^{-i \hat C t / M})^M \ket{\psi}
\end{aligned}
\end{align} 
will give us a total error of $\sum_{m=1}^{M} \hat \varepsilon_2(M)^{1/M} \ket{\psi_m}$, where $\ket{\psi_m} = (e^{-i \hat A t / M }  e^{-i \hat B t / M } e^{-i \hat C t / M})^{m-1} \ket{\psi}$, and thus all $\ket{\psi_m}$s have the same norm. Okay, since the operator are bounded, $\hat \varepsilon_1(M)$ and $\hat \varepsilon_2(M)$ are bounded as well, which means there are an upper bounds, call them $\varepsilon_1$ and $\varepsilon_2$, on their eigen.\,. Hm, there eigenvalues are all 1, so should I talk about.\,. no wait, they are not ones.\,. The operators are neither unitary nor symmetric.\,. .\,.\,Hm, oh well, they can be bounded nonetheless.\,. .\,.\,Are but the $\hat \varepsilon$s will always be \emph{bounded}, so that's not the quality I'm looking for.\,. .\,.\,Hm, ah, instead I am looking to use that their bounds decreases for increasing $M$.\,. \ldots Ah, dang. Why is this so hard for me? .\,.\,Let me try searching for an answer again (maybe try another search engine than Google's.\,.).\,. .\,.\,No, it doesn't give me anything, regardless.\,. .\,.\,Hm, I was right about the $\hat \varepsilon_2(M)^{1/M} \ket{\psi}$ error above.\,. (I just forgot my argument for a moment (even though this is one sitting\,x)).\,.) %..I need a break and then I'll continue with something else.. (Klokken 25 over et.)

%(Kl. tre):
Ha! I actually won't even need any other then the regular Trotter formula! So never mind all that!\,:D (I actually think, by the way, that my $\hat \varepsilon_2(M)^{1/M} \ket{\psi}$ error argument \emph{was} bad, but again: Never mind all that!)

So let me move on (and show why we only need the regular Trotter formula).\,:) I think now that I ought to divide the Hilbert space (bounded or unbounded) in three parts. .\,.\,Hm, how should I denote the different vectors then.\,.\,? .\,.\,Hm, let me just denote them with superscripts. So we have.\,. Oh wait, why not just use a (first) subscript. OK. So we can write
\begin{align}
\begin{aligned}
	\textbf{H} = \textbf{H}_1 \otimes \textbf{H}_2 \otimes \textbf{H}_3,
\end{aligned}
\end{align} 
\begin{align}
\begin{aligned}
	\ket{\boldsymbol{p}_i} = \frac{1}{\sqrt{N_i^{D_i}}} \sum_{\boldsymbol{q}_i\in Q_i}
		e^{i \boldsymbol{p}_i \cdot \boldsymbol{q}_i} \ket{\boldsymbol{q}_i}
	\label{ket_pi_01}
\end{aligned}
\end{align} 
for $i\in{1, 2}$ and with e.g.\ $\boldsymbol{p}_i = (p_{i1}, p_{i2}, \ldots, p_{iD_i})$ and so on. .\,.\,Hm, and let $\{\ket{\psi_n} \,|\, n\in \{1, 2, \ldots, N_3^{D_3}\}\}$ be a similar set to the sets of $\ket{\boldsymbol{q}_1}$s and $\ket{\boldsymbol{q}_2}$s, i.e.\ a set of step functions that from an orthogonal basis of a subspace of (in this case) $\textbf{H}_3$. Let us then (for all $\boldsymbol{q}_i$s and $\boldsymbol{p}_i$s) define vectors
\begin{align}
\begin{aligned}
	\ket{\boldsymbol{p}_1, \boldsymbol{q}_2} =&\, \ket{\boldsymbol{p}_1} \otimes \ket{\boldsymbol{q}_2},\\
	\ket{\boldsymbol{q}_1, \boldsymbol{p}_2} =&\, \ket{\boldsymbol{q}_1} \otimes \ket{\boldsymbol{p}_2},
\end{aligned}
\end{align} 
which are then all vectors in $\textbf{H}_1 \otimes \textbf{H}_2$. .\,.\,Hm, and we can also add $\psi_n$s in the mix, e.g.\ as in $\ket{\boldsymbol{p}_1, \boldsymbol{q}_2, \psi_n}$.\,. 

Okay, next up is the path integral derivation (where we'll also have to use what values the $p$s and $q$s take, but I'll just get to that.\,.).\,. 

.\,.\,Oh wait, let me just make clear that all these vectors form orthogonal basis for subspaces of \textbf{H}. So let us define these as 
\begin{align}
\begin{aligned}
	\textbf{H}_B = \textbf{H}_{1B} \otimes \textbf{H}_{2B} \otimes \textbf{H}_{3B}.
\end{aligned}
\end{align} 
Let also $\hat I_B$ be the projection operator from \textbf{H} into $\textbf{H}_B$. %Okay, before I move on, let me take a break again. (Kl. fire)

%(Kl. halv fem):
Oh, I should define the $q$ and $p$ values immediately because otherwise eq.\ (\ref{ket_pi_01}) isn't defined. .\,.\,Oh, never mind that's not true.\,. .\,.\,Hm, I think I am actually just gonna let them run from $-\Gamma$ (not $\Gamma/2$) to $\Gamma$ and from $-\Pi$ to $\Pi$.\,. Yeah, okay. (Or rather from $-\Gamma + \delta q / 2$ to $\Gamma - \delta q / 2$ and so on, and then we have $N = 2\Gamma/\delta q = 2\Pi / \delta p$.) .\,.\,Hm, and do I then put $i$ indices on all these.\,.\,? .\,.\,Hm, let me just do that for now.\,.

For all $i\in \{1, 2\}$, $j\in\{1, 2, \ldots, D_i\}$ define $\hat P_{ij}$ by
%\begin{align}
%\begin{aligned}
%	\hat P_{ij} \ket{\boldsymbol{p}_i} = p_{ij} \ket{\boldsymbol{p}_i}
%\end{aligned}
%\end{align} 
%for all $\boldsymbol{p}_i$, where, as we recall, $p_{ij}$ is the $j$th entry of $\boldsymbol{p}_i$. We'll also define $\hat Q_{ij}$ similarly by
%\begin{align}
%\begin{aligned}
%	\hat Q_{ij} \ket{\boldsymbol{q}_i} = q_{ij} \ket{\boldsymbol{q}_i}.
%\end{aligned}
%\end{align} 
\begin{align}
\begin{aligned}
	\hat P_{ij} = \sum_{\boldsymbol{p}_i \in P_i} p_{ij} \ket{\boldsymbol{p}_i} \bra{\boldsymbol{p}_i} 
\end{aligned}
\end{align} 
where, as we recall, $p_{ij}$ is the $j$th entry of $\boldsymbol{p}_i$. We'll also define $\hat Q_{ij}$ similarly by
\begin{align}
\begin{aligned}
	\hat Q_{ij} = \sum_{\boldsymbol{q}_i \in Q_i} q_{ij} \ket{\boldsymbol{q}_i} \bra{\boldsymbol{q}_i}.
\end{aligned}
\end{align} 
And let me see, since 
\begin{align}
\begin{aligned}
	\braket{\boldsymbol{q}_i| \boldsymbol{p}_i} = 
		(N_i^{D_i})^{-1/2} e^{i \boldsymbol{p}_i \cdot \boldsymbol{q}_i},
\end{aligned}
\end{align} 
we have
%\begin{align}
%\begin{aligned}
%	\hat Q_{ij} \hat P_{ij} =&\,  
%		\sum_{\boldsymbol{p}_i \in P_i} \sum_{\boldsymbol{q}_i \in Q_i} 
%			q_{ij} p_{ij} 
%			\ket{\boldsymbol{q}_i} 
%				\braket{\boldsymbol{q}_i | \boldsymbol{p}_i} 
%			\bra{\boldsymbol{p}_i} \\
%		=&\,
%		\sum_{\boldsymbol{p}_i \in P_i} \sum_{\boldsymbol{q}_i \in Q_i} 
%			(N_i^{D_i})^{-1/2} e^{i \boldsymbol{p}_i \cdot \boldsymbol{q}_i} q_{ij} p_{ij} 
%			\ket{\boldsymbol{q}_i} 
%			\bra{\boldsymbol{p}_i}
%\end{aligned}
%\end{align} 
\ldots 
\begin{align}
\begin{aligned}
	\ket{\boldsymbol{q}_i} = \frac{1}{\sqrt{N_i^{D_i}}} \sum_{\boldsymbol{p}_i\in P_i}
		e^{- i \boldsymbol{p}_i \cdot \boldsymbol{q}_i} \ket{\boldsymbol{p}_i} .\,.\,?
	\label{ket_qi_01}
\end{aligned}
\end{align} 
\begin{align}
\begin{aligned}
	\frac{1}{\sqrt{N_i^{D_i}}} \sum_{\boldsymbol{p}_i\in P_i}
		e^{- i \boldsymbol{p}_i \cdot \boldsymbol{q}_i} \ket{\boldsymbol{p}_i} =&\,
	\frac{1}{N_i^{D_i}} 
		\sum_{\boldsymbol{p}_i\in P_i} \sum_{\boldsymbol{q}_i'\in Q_i}
		e^{- i \boldsymbol{p}_i \cdot \boldsymbol{q}_i}
		e^{i \boldsymbol{p}_i \cdot \boldsymbol{q}_i'} 
		\ket{\boldsymbol{q}_i'} \\ 
	=&\,
	\frac{1}{N_i^{D_i}} 
		\sum_{\boldsymbol{p}_i\in P_i} \sum_{\boldsymbol{q}_i'\in Q_i}
		e^{i \boldsymbol{p}_i \cdot (\boldsymbol{q}_i - \boldsymbol{q}_i')}
		\ket{\boldsymbol{q}_i'} \\ 
	=&\,
	\frac{1}{N_i^{D_i}} 
		\sum_{\boldsymbol{q}_i'\in Q_i}
		N_i^{D_i}
		\delta_{\boldsymbol{q}_i', \boldsymbol{q}_i}
		\ket{\boldsymbol{q}_i'} \\
	=&\,
	\ket{\boldsymbol{q}_i},
\end{aligned}
\end{align} 
so yes, eq.\ (\ref{ket_qi_01}) applies. 

And so
\begin{align}
\begin{aligned}
	\hat P_{ij} \hat Q_{ij}  =&\,  
		\sum_{\boldsymbol{p}_i \in P_i} \sum_{\boldsymbol{q}_i \in Q_i} 
			q_{ij} p_{ij} 
			\ket{\boldsymbol{q}_i} 
				\braket{\boldsymbol{q}_i | \boldsymbol{p}_i} 
			\bra{\boldsymbol{p}_i} \\
		=&\,
		\sum_{\boldsymbol{p}_i \in P_i} \sum_{\boldsymbol{q}_i \in Q_i} 
			(N_i^{D_i})^{-1/2} e^{i \boldsymbol{p}_i \cdot \boldsymbol{q}_i} q_{ij} p_{ij} 
			\ket{\boldsymbol{q}_i} 
			\bra{\boldsymbol{p}_i} \\
		=&\,
		\sum_{\boldsymbol{p}_i \in P_i} \sum_{\boldsymbol{p}_i' \in P_i} 
		\sum_{\boldsymbol{q}_i \in Q_i} 
			(N_i^{D_i})^{-1} e^{i (\boldsymbol{p}_i - \boldsymbol{p}_i') \cdot \boldsymbol{q}_i} q_{ij} p_{ij} 
			\ket{\boldsymbol{p}_i'} 
			\bra{\boldsymbol{p}_i}\,.\,.
\end{aligned}
\end{align}
.\,.\,And
\begin{align}
\begin{aligned}
	\hat Q_{ij} \hat P_{ij} 
		=&\,
		\sum_{\boldsymbol{p}_i \in P_i} \sum_{\boldsymbol{q}_i \in Q_i} 
			(N_i^{D_i})^{-1/2} 
			e^{- i \boldsymbol{p}_i \cdot \boldsymbol{q}_i} q_{ij} p_{ij} 
			\ket{\boldsymbol{p}_i} 
			\bra{\boldsymbol{q}_i} \\
		=&\,
		\sum_{\boldsymbol{p}_i \in P_i} \sum_{\boldsymbol{p}_i' \in P_i} 
		\sum_{\boldsymbol{q}_i \in Q_i} 
			(N_i^{D_i})^{-1} 
			e^{i \boldsymbol{p}_i \cdot (\boldsymbol{q}_i' - \boldsymbol{q}_i)} q_{ij} p_{ij} 
			\ket{\boldsymbol{q}_i'} 
			\bra{\boldsymbol{q}_i}\,.\,.
\end{aligned}
\end{align}
Hm, let me actually sum over all $q_{ik}, k\neq j$.\,. Then we have
\begin{align}
\begin{aligned}
	\hat P_{ij} \hat Q_{ij}  
	=&\,
	\sum_{\boldsymbol{p}_i \in P_i} \sum_{\boldsymbol{p}_i' \in P_i} 
	\sum_{\boldsymbol{q}_i \in Q_i} 
		(N_i^{D_i})^{-1} 
		e^{i (\boldsymbol{p}_i - \boldsymbol{p}_i') \cdot \boldsymbol{q}_i} q_{ij} p_{ij} 
		\ket{\boldsymbol{p}_i'} 
		\bra{\boldsymbol{p}_i} \\
	=&\,
	\sum_{\boldsymbol{p}_i \in P_i} \sum_{p_{ij}'} \sum_{q_{ij}} 
		(N_i^{D_i})^{-1} N_i^{D_i - 1}
		e^{i (p_{ij} - p_{ij}')  q_{ij}} q_{ij} p_{ij} 
		\ket{(p_{i1}, \ldots, p_{i j-1}, p_{ij}', p_{i j+1}, \ldots)} 
		\bra{\boldsymbol{p}_i} \\
	=&\,
	\sum_{\boldsymbol{p}_i \in P_i} \sum_{p_{ij}'} \sum_{q_{ij}} 
		N_i^{-1}
		e^{i (p_{ij} - p_{ij}')  q_{ij}} q_{ij} p_{ij} 
		\ket{(p_{i1}, \ldots, p_{i j-1}, p_{ij}', p_{i j+1}, \ldots)} 
		\bra{\boldsymbol{p}_i} \,.\,.
\end{aligned}
\end{align}
.\,.\,Hm, and let me try to expand $\hat Q_{ij} \hat P_{ij}$ the other way.\,. We have
\begin{align}
\begin{aligned}
	\hat Q_{ij} \hat P_{ij} 
		=&\,
		\sum_{\boldsymbol{p}_i} \sum_{\boldsymbol{q}_i} 
			(N_i^{D_i})^{-1/2} 
			e^{- i \boldsymbol{p}_i \cdot \boldsymbol{q}_i} q_{ij} p_{ij} 
			\ket{\boldsymbol{p}_i} 
			\bra{\boldsymbol{q}_i} \\
		=&\,
		\sum_{\boldsymbol{q}_i} \sum_{\boldsymbol{p}_i} \sum_{\boldsymbol{p}_i'} 
			(N_i^{D_i})^{-1} 
			e^{i (\boldsymbol{p}_i' - \boldsymbol{p}_i) \cdot \boldsymbol{q}_i} q_{ij} p_{ij} 
			\ket{\boldsymbol{p}_i} 
			\bra{\boldsymbol{p}_i'} \\
		=&\,
		\sum_{q_{ij}} \sum_{\boldsymbol{p}_i} \sum_{p_{ij}'} 
			N_i^{-1} 
			e^{i (p_{ij}' - p_{ij}) q_{ij}} q_{ij} p_{ij} 
			\ket{\boldsymbol{p}_i} 
			\bra{(p_{i1}, \ldots, p_{i j-1}, p_{ij}', p_{i j+1}, \ldots)}
\end{aligned}
\end{align}
.\,.\,Hm, as we should, since their product should be a symmetric operator.\,. .\,.\,Hm, let's see, the contribution when $p_{ij}' = p_{ij}$ is given by 
\begin{align}
\begin{aligned}
	\sum_{\boldsymbol{p}_i \in P_i} \sum_{q_{ij}} 
		N_i^{-1}
		q_{ij} p_{ij} 
		\ket{\boldsymbol{p}_i} 
		\bra{\boldsymbol{p}_i}
\end{aligned}
\end{align}
for both operators.\,. .\,.\,Hm, I don't like that very much.\,. .\,.\,I should probably try in one dimension first.\,. .\,.\,Or better yet, see if I can read about it somewhere.\,. %..Or better yet, take a break..


(03.03.22) I have a couple of things to say. First of all, I looked up the integral for $\int x \sin(kx) dx$ and that's how you get the commutator. But it means it isn't true in this discrete case. So all this doesn't matter anyway. I'm sure the definitions here are as they should be.

Another thing I realized last evening is that I of course don't need to split $\textbf{H}_1$ and $\textbf{H}_2$ up in two. I somehow (partly) forgot (as has happened before) that my $\sum_i \hat C_i \hat p_i$ consists of commuting pairs of operators. Which is very nice of course. (So we won't need all those $i$s.)

And then in bed last night (very late; %(most of the realizations happend after three (and I want to bed a little after twelve))
took me long time to fall asleep) I realized several things. I realized that we could let one part of the Hamiltonian remain unbounded throughout but I'm not sure that I will need this. I realized that by discretizing the fermion wave functions, it might be easier to argue for the gauge eliminating plane-wave solutions since it will put an upper bound on the field momentum needed. I also thought about the fact that discretizing this might mean that one could use the Dirac sea more directly, but I might not use that as well.\,. I by the way consider actually making my Trotter argument first, before the $\square^2\phi$ argument.\,. And then I also realized something really nice, which is that we don't need e.g.\ $\delta q$ and $\delta p$ to be restricted by $\Gamma$ and $\Pi$. .\,.\,Hm, it might change eq.\ (\ref{ket_pi_01}) and (\ref{ket_qi_01}) but I think I can work it out.\,. And when these are each independent and unrestricted, it just makes it a lot nicer, I think, when we get to the gauge eliminating plane-wave solutions. .\,.\,solution.\,. .\,.\,Hm, GEPS for short.\,.\,? .\,.\,Hm, no because they are not plane waves, actually.\,. Right.\,.\,? .\,.\,Or maybe they are.\,. .\,.\,Hm no, they are not.\,. .\,.\,Well, then we can just call it a gauge-eliminating wave solution.\,. Anyway.\,. So now I should try to derive the generalized path integral with discretized (or `simplified,' one could say.\,.) operators where $\delta q$ and $\delta p$ are not restricted by $\Gamma$ and $\Pi$. .\,.\,Hm, and since I'm changing names anyway, let me just call them $L/2$ and $\Lambda$ here instead.\,.

Okay, so instead we'll have
\begin{align}
\begin{aligned}
	\textbf{H} = \textbf{H}_1 \otimes \textbf{H}_2.
\end{aligned}
\end{align} 

Hm, and let me think about, what we can do for the $\ket{\boldsymbol{p}}$s and $\ket{\boldsymbol{q}}$s, and about what we'll need for the gauge elimination.\,. \ldots Hm, maybe I would actually like the $\ket{\boldsymbol{p}}$s not to be equally spaced in terms of their $p$-values.\,. \ldots Hm, or do I just want to take the limit $\delta p \to 0$ directly (when dealing with the gauge elimination).\,.\,? .\,.\,Yeah, I think that's the idea.\,. .\,.\,Hm no, I need to think some more.\,. .\,.\,Maybe I should just use the fact that the real $\hat P$ will keep approximated $\ket{\boldsymbol{p}}$s approximately constant (apart from the phase change) (or rather $\exp(-i \hat P t)$ will).\,. .\,.\,Hm yeah, and that way, the argument will work with $\hat P_{\boldsymbol{\Lambda}}$ as well (in the right limit).\,. .\,.\,Yeah, that's the strategy.\,. .\,.\,Nice.\,. 

Oh, good. Then it seems that I can just use the nice $\ket{\boldsymbol{p}}$s and $\ket{\boldsymbol{q}}$s with $\delta q$ and $\delta p$ (and thus with equal spacing) restricted by $\Gamma$ and $\Pi$, or whatever I choose to call them. Cool. .\,.\,Ah, I think I can make a pretty rigorous argument for the gauge elimination if I'm lucky, but let's see when we get there. I hope it will be possible --- and not too hard.\,.\,:) 

So we can define
%\begin{align}
%\begin{aligned}
%	\hat Q_{\boldsymbol{\Lambda} i} =&\, \sum_{\boldsymbol{q} \in Q_{\boldsymbol{\Lambda}}^D} 
%		q_{i} \ket{\boldsymbol{\Lambda}; \boldsymbol{q}} \bra{\boldsymbol{\Lambda}; \boldsymbol{q}} \\
%	\hat P_{\boldsymbol{\Lambda} i} =&\, \sum_{\boldsymbol{p} \in P_{\boldsymbol{\Lambda}}^D} 
%		p_{i} \ket{\boldsymbol{\Lambda}; \boldsymbol{p}} \bra{\boldsymbol{\Lambda}; \boldsymbol{p}},
%\end{aligned}
%\end{align} 
%where $q_i$ and $p_i$ are understood as the $i$th entry of $\boldsymbol{q}$ and $\boldsymbol{p}$ respectively. 
%\begin{align}
%\begin{aligned}
%	\hat Q_{\Lambda i} =&\, \sum_{\boldsymbol{q} \in Q_{\Lambda}^D} 
%		q_{i} \ket{\Lambda; \boldsymbol{q}} \bra{\Lambda; \boldsymbol{q}} \\
%	\hat P_{\Lambda i} =&\, \sum_{\boldsymbol{p} \in P_{\boldsymbol\Lambda}^D} 
%		p_{i} \ket{\Lambda; \boldsymbol{p}} \bra{\Lambda; \boldsymbol{p}},
%\end{aligned}
%\end{align} 
%\begin{align}
%\begin{aligned}
%	\hat Q_{\boldsymbol{B} i} =&\, \sum_{\boldsymbol{q} \in Q_{\boldsymbol{B}}^D} 
%		q_{i} \ket{\boldsymbol{B}; \boldsymbol{q}} \bra{\boldsymbol{B}; \boldsymbol{q}} \\
%	\hat P_{\boldsymbol{B} i} =&\, \sum_{\boldsymbol{p} \in P_{\boldsymbol{B}}^D} 
%		p_{i} \ket{\boldsymbol{B}; \boldsymbol{p}} \bra{\boldsymbol{B}; \boldsymbol{p}},
%\end{aligned}
%\end{align} 
\begin{align}
\begin{aligned}
	\hat Q_{B i} =&\, \sum_{\boldsymbol{q} \in Q_{B}^D} 
		q_{i} \ket{B; \boldsymbol{q}} \bra{B; \boldsymbol{q}}, \\
	\hat P_{B i} =&\, \sum_{\boldsymbol{p} \in P_{B}^D} 
		p_{i} \ket{B; \boldsymbol{p}} \bra{B; \boldsymbol{p}},
\end{aligned}
\end{align} 
where $q_i$ and $p_i$ are understood as the $i$th entry of $\boldsymbol{q}$ and $\boldsymbol{p}$ respectively. \ldots I how dropped the boldness of $B$, which is fine because I can just call it an `ordered set.' .\,.\,Or just call it a tuple, why not?\,. 
Here $\ket{B; \boldsymbol{q}}$ is defined as normalized step functions on intervals $[-L/2 + (n-1) \delta q, -L/2 + n \delta q]$, where $n$ takes integer values from 1 to $N$. By the restrictions of $B$ we have $N \delta q = L$, by the way. .\,.\,Well actually, this is when $D=1$, and for $D>1$, the step functions just become multidimensional step functions. And $\boldsymbol{q}$ take the discrete values that are the midpoints in these multidimensional step functions.\,. *(These values are the elements of $Q_B^D$ by the definition of $Q_B$, by the way.) .\,.\,We then define the $\ket{\boldsymbol{p}}$s by
\begin{align}
\begin{aligned}
	\ket{B; \boldsymbol{p}} = \frac{1}{\sqrt{N^{D}}} \sum_{\boldsymbol{q}\in Q_B^D}
		e^{i \boldsymbol{p} \cdot \boldsymbol{q}} \ket{B; \boldsymbol{q}},
	\label{ket_pB_01}
\end{aligned}
\end{align} 
where each entry of $\boldsymbol{p}$ takes values %in $[-\Lambda + (n-1) \delta p, -\Lambda + n \delta p]$. 
%where each entry of $\boldsymbol{p}$ takes values in $[-\Lambda + (n-1) \Delta p, -\Lambda + n \Delta p]$. %..Hm, let me try to change from \delta to \Delta in the above text.. ..Hm, I think it looks better..
%.\,.\,Okay, I have just changed $\delta$ to $\Delta$ in the above text from just now and I think it looks better. So I'll keep it this way for now. %..Hm, or maybe not.. I can't decide, but I'll actually change it back for now..
of $-\Lambda + n \delta p/2$ with $n\in \{1, 2,\ldots, N\}$ (and where we have $N \delta p = 2\Lambda$). 

One can then show
\begin{align}
\begin{aligned}
	\ket{B; \boldsymbol{q}} = \frac{1}{\sqrt{N^{D}}} \sum_{\boldsymbol{p}\in P_B^D}
		e^{- i \boldsymbol{p} \cdot \boldsymbol{q}} \ket{B; \boldsymbol{p}}.
	\label{ket_qB_01}
\end{aligned}
\end{align} 
(See above for how to do this. (Even though I have yet to argue for the ($N$ times) delta-valued summation, if I want to do so.\,.)) 

Okay, and let us then finally define $\hat H_B$ by
\begin{align}
\begin{aligned}
	\hat H_B = \hat H_{B1} \otimes \hat I_2 + \hat I_1 \otimes \hat H_{B2}
	\label{H_B_01}
\end{aligned}
\end{align} 
with
\begin{align}
\begin{aligned}
	\hat H_{B1} =  
		\sum_{j=1}^D \frac{1}{2} \hat P_{B j}^2 + 
		\hat V_B + 
		\sum_{j=1}^D \hat C_{B j} \hat P_{B j},
	\label{H_B1_01}
\end{aligned}
\end{align} 
where $\hat V_B$ and $\hat C_{B j}$ for all $j$ have the forms
\begin{align}
\begin{aligned}
	\hat V_B = \sum_{\boldsymbol{q} \in Q_{B}^D} 
		V(\boldsymbol{q}) \ket{B; \boldsymbol{q}} \bra{B; \boldsymbol{q}}
	\label{V_B_01}
\end{aligned}
\end{align} 
and
\begin{align}
\begin{aligned}
	\hat C_{B j} = \sum_{\boldsymbol{q} \in Q_{B}^D} 
		C_{j}(\boldsymbol{q}) \ket{B; \boldsymbol{q}} \bra{B; \boldsymbol{q}}
	\label{Cj_B_01}
\end{aligned}
\end{align} 
with $V$ and the $C_j$s all being %smooth,
real-valued functions on $\mathbb{R}^D$ that are bounded on any bounded subset of the domain (such that $\hat V$ and $\hat C_{B j}$ are all bounded). 
%Let me take a break and go for a walk in this lovely spring weather..

\ldots\ On the full Hilbert space, all these operators can be written with an extra label $\psi_n$, and with a sum over all $n$, where each $\psi_n$ represent vectors in an orthogonal basis of $\textbf{H}_2$. .\,.\,Or rather, $\ket{B; \psi_n}$ represent just an orthogonal \emph{set} (not necessarily spanning), that is a subset of $\textbf{H}_2$.

The Trotter product formula (whether $\hat H_{B2}$ is bounded or not, actually) then gives us
\begin{align}
\begin{aligned}
	\bra{\phi', \psi'}
		e^{-i \hat H_{B} t}
	\ket{\phi, \psi} =
	\lim_{M \to \infty} 
	\bra{\phi', \psi'}
		(e^{-i (\sum_{j=1}^D \hat P_{B j}^2 / 2 + \,.\,.\,) \delta t} e^{-i (\hat V_{B} + \,.\,.\,) \delta t})^M
	\ket{\phi, \psi},
\end{aligned}
\end{align} 
where $\delta t$ implicitly depends on $M$, being given by $\delta t = t/M$. .\,.\,Hm, don't I actually need a three-part Trotter expansion.\,.\,? .\,.\,Hm, by the way, there must be a way to get rid of that $B$ everywhere.\,. .\,.\,Maybe just by defining a function $B(\boldsymbol{q})$.\,. .\,.\,Or define both $B_q(\boldsymbol{q})$ and $B_p(\boldsymbol{p})$.\,. *(Or maybe it should just be how it is now, but I can think about that another time.) Okay, but back to the Trotter problem.\,. .\,.\,Ah, wait! Couldn't I divide the $CP$ term, as well as the $V$ and $P$ term all in two!? .\,.\,Nice! .\,.\,Oh, that was actually just what I \emph{was} doing before in a way, except that now I know that I don't need to mix them up (in e.g. $\ket{\boldsymbol{q}_1, \boldsymbol{p}_2}$).\,. 

Hm, so maybe I should just go back to 
\begin{align}
\begin{aligned}
	\textbf{H} = \textbf{H}_1 \otimes \textbf{H}_2 \otimes \textbf{H}_3
\end{aligned}
\end{align} 
and so on, and then define
\begin{align}
\begin{aligned}
	\hat V_{Bi} = \sum_{\boldsymbol{q} \in Q_{B}^{D_i}} 
		V(\boldsymbol{q}_i) \ket{B; \boldsymbol{q}_i} \bra{B; \boldsymbol{q}_i}
	\label{V_Bi_01}
\end{aligned}
\end{align} 
and so on.\,.(?\,.\,.) .\,.\,Hm, but isn't it a hundred times easier just to define $D_1$ and $D_2$ and then let $D = D_1 + D_2$?\,.\,. .\,.\,Yeah, let's definitely just do that, and then I can always rearrange the dimensions afterwards if something else suits better. OK. So going back to 
\begin{align}
\begin{aligned}
	\textbf{H} = \textbf{H}_1 \otimes \textbf{H}_2
\end{aligned}
\end{align} 
again (and so on), we can write 
\begin{align}
\begin{aligned}
	\bra{\phi', \psi'}
		e^{-i \hat H_{B} t}
	\ket{\phi, \psi} =
	\lim_{M \to \infty} 
	\bra{\phi', \psi'}
		(e^{-i  (\hat H_{B11} + \hat H_{B21}) \delta t} e^{-i (\hat H_{B12} + \hat H_{B22}) \delta t})^M
	\ket{\phi, \psi},
%	\lim_{M \to \infty} 
%	\bra{\phi', \psi'}
%		(e^{-i (\sum_{j=1}^{D_1} (\hat P_{B j}^2 / 2 + \hat C_{B j} \hat P_{B j}) + \,.\,.\,) \delta t} e^{-i (\hat V_{B} + \,.\,.\,) \delta t})^M
%	\ket{\phi, \psi},
\end{aligned}
\end{align} 
where now, all the operators are operators of the full Hilbert space (which is why we can just add them together). And here I have defined
\begin{align}
\begin{aligned}
	\hat H_{B11} =  
		\sum_{j=1}^{D_1} \frac{1}{2} \hat P_{B j}^2 + 
		\,.\,.\, +%\hat V_B + 
		\sum_{j=1}^{D_1} \hat C_{B j} \hat P_{B j}\,.\,.
	\label{H_B11_01}
%	\lim_{M \to \infty} 
%	\bra{\phi', \psi'}
%		(e^{-i (\sum_{j=1}^{D_1} (\hat P_{B j}^2 / 2 + \hat C_{B j} \hat P_{B j}) + \,.\,.\,) \delta t} e^{-i (\hat V_{B} + \,.\,.\,) \delta t})^M
%	\ket{\phi, \psi},
\end{aligned}
\end{align} 
Hm no, let me then redefine $\hat H_{B1}$ as
\begin{align}
\begin{aligned}
	\hat H_{B1} =&\, \hat H_{B11} + \hat H_{B12} \\=&\,
		\sum_{j=1}^{D_1} \big(
			\frac{1}{2} \hat P_{B j}^2 + 
			\hat V_{Bj} + 
			\hat C_{B j} \hat P_{B j}
		\big) +
		\sum_{j=D_1+1}^{D} \big(
			\frac{1}{2} \hat P_{B j}^2 + 
			\hat V_{Bj} + 
			\hat C_{B j} \hat P_{B j} 
		\big)\\=&\,
		\sum_{j=1}^{D} \big(
			\frac{1}{2} \hat P_{B j}^2 + 
			\hat V_{Bj} + 
			\hat C_{B j} \hat P_{B j} \,.\,.
		\big)
	\label{H_B1_02}
\end{aligned}
\end{align} 
*(This form is actually wrong; see below instead.) Hm, I need to get rid of those $B$s. They have to just be implicit in $\hat H$ instead. .\,.\,Hm, should I get rid of them in the kets (and bras) as well? .\,.\,Yes, I think so.\,. 

So remove all labels of $B$ in the above equations. In other words, let's write *(and I think I might just write all operators on the full Hilbert space to begin with.\,.)
\begin{align}
\begin{aligned}
	\textbf{H} = \textbf{H}_1 \otimes \textbf{H}_2
\end{aligned}
\end{align} 
\begin{align}
\begin{aligned}
	\hat Q_{i} =&\, \sum_{\psi \in \Psi} \sum_{\boldsymbol{q} \in Q^D} 
		q_{i} \ket{\boldsymbol{q}, \psi} \bra{\boldsymbol{q}, \psi}, \\
	\hat P_{i} =&\, \sum_{\psi \in \Psi} \sum_{\boldsymbol{p} \in P^D} 
		p_{i} \ket{\boldsymbol{p}, \psi} \bra{\boldsymbol{p}, \psi},
\end{aligned}
\end{align} 
\begin{align}
\begin{aligned}
	\ket{\boldsymbol{p}, \psi} = \frac{1}{\sqrt{N^{D}}} \sum_{\boldsymbol{q}\in Q^D}
		e^{i \boldsymbol{p} \cdot \boldsymbol{q}} \ket{\boldsymbol{q}, \psi},
	\label{ket_p_01}
\end{aligned}
\end{align} 
\begin{align}
\begin{aligned}
	\ket{\boldsymbol{q}, \psi} = \frac{1}{\sqrt{N^{D}}} \sum_{\boldsymbol{p}\in P^D}
		e^{- i \boldsymbol{p} \cdot \boldsymbol{q}} \ket{\boldsymbol{p}, \psi},
	\label{ket_q_01}
\end{aligned}
\end{align} 
\begin{align}
\begin{aligned}
	\hat H = \hat H_{1} + \hat H_{2},
	\label{H_B_02}
\end{aligned}
\end{align}
\begin{align}
\begin{aligned}
	\hat H_{1} = 
		\sum_{j=1}^{D} \big(
			\frac{1}{2} \hat P_{j}^2 + 
			\hat C_{j} \hat P_{j} +
			\hat V_{j} 
		\big) 
%	\\ =&\, 
%		\sum_{j=1}^{D_1} \big(
%			\frac{1}{2} \hat P_{B j}^2 + 
%			\hat C_{B j} \hat P_{B j}
%		\big) +
%		
%		\sum_{j=D_1+1}^{D} \big(
%			\frac{1}{2} \hat P_{B j}^2 + 
%			\hat V_{Bj} + 
%			\hat C_{B j} \hat P_{B j} 
%		\big)
	\label{H_1_01}
\end{aligned}
\end{align} 
\begin{align}
\begin{aligned}
	\hat H_{11} = 
		\sum_{j=1}^{D_1} \big(
			\frac{1}{2} \hat P_{j}^2 + 
			\hat C_{j} \hat P_{j}
		\big) + 
		\sum_{j=D_1+1}^{D}
			\hat V_{j} 
	\label{H_11_01}
\end{aligned}
\end{align} 
\begin{align}
\begin{aligned}
	\hat H_{12} = 
		\sum_{j=D_1+1}^{D} \big(
			\frac{1}{2} \hat P_{j}^2 + 
			\hat C_{j} \hat P_{j}
		\big) + 
		\sum_{j=1}^{D_1}
			\hat V_{j} 
	\label{H_12_01}
\end{aligned}
\end{align} 
\begin{align}
\begin{aligned}
	\hat H_{1} = \hat H_{11} + \hat H_{12}.
	\label{H_1_02}
\end{aligned}
\end{align} 
We'll also assume that $\hat H_{2}$ can be written as
\begin{align}
\begin{aligned}
	\hat H_{2} = \hat H_{21} + \hat H_{22},
%	\label{H_2_01}
\end{aligned}
\end{align}
where $\hat H_{21}$ commutes with $\hat H_{11}$ and $\hat H_{22}$ commutes with $\hat H_{12}$ (i.e.\ $[\hat H_{21}, \hat H_{11}] = [\hat H_{22}, \hat H_{12}] = 0$).

%(Kl. fem i syv:)
\ldots\ And now we can write (from Trotter)
\begin{align}
\begin{aligned}
	\bra{\phi', \psi'}
		e^{-i \hat H t}
	\ket{\phi, \psi} =&\,
	\lim_{M \to \infty} 
	\bra{\phi', \psi'}
		(e^{-i  (\hat H_{11} + \hat H_{21}) \delta t} e^{-i (\hat H_{12} + \hat H_{22}) \delta t})^M
	\ket{\phi, \psi}. %\\=&\,
%	\lim_{M \to \infty} 
%	\bra{\phi', \psi'}
%		(e^{-i  \hat H_{B11} \delta t} 
%		e^{-i  \hat H_{B21} \delta t}
%		e^{-i  \hat H_{B12} \delta t} 
%		e^{-i  \hat H_{B22} \delta t})^M
%	\ket{\phi, \psi}.
\end{aligned}
\end{align} 

Hm, I am also going to assume that $\hat H_2$ can be written as
\begin{align}
\begin{aligned}
	\hat H_{2} = \hat H_{21} + \hat H_{22} =
		\sum_{j=1}^{D_1} \hat V_{j} \hat H_{21j} +
		\sum_{j=D_1+1}^{D} \hat V_{j} \hat H_{22j} \,.\,.
\end{aligned}
\end{align}
.\,.\,Oh wait, I need the kinetic part of $\hat H_2$ as well.\,. .\,.\,Oh, but I can't get this to commute with $\hat V$ at all, can I?\,.\,. .\,.\,No.\,. .\,.\,Hm no, I simply need a three-part Trotter expansion.\,. 

\ldots Hm, let me try to derive it again.\,. 
We have.\,. 
\begin{align}
\begin{aligned}
	\bra{\phi} e^{-i (\hat A + \hat B + \hat C) t } \ket{\psi} =&\,
		\lim_{m \to \infty}
			\bra{\phi} (e^{-i \hat A t / m } e^{-i (\hat B + \hat C) t / m})^m \ket{\psi} \\
	=&\,
		\lim_{m \to \infty} \lim_{n \to \infty}
			\bra{\phi} (
				e^{-i \hat A t / m } 
				(e^{-i \hat B t / n} e^{-i \hat C t / n})^{n/m}
			)^m \ket{\psi}.\,.
\end{aligned}
\end{align} 
\ldots Ah, maybe we \emph{can} make a good argument, that they can grow simultaneously. Let me see.\,. First we choose a big $m=M$ in the RHS of the first line. So
\begin{align}
\begin{aligned}
	\bra{\phi} e^{-i (\hat A + \hat B + \hat C) t } \ket{\psi} 
	\approx&\,
	\bra{\phi} (e^{-i \hat A t / M } e^{-i (\hat B + \hat C) t / M})^M \ket{\psi} 
\end{aligned}
\end{align} 
with some error, call it $\varepsilon_1(M)$.\,. And then
\begin{align}
\begin{aligned}
	\bra{\phi} (e^{-i \hat A t / M } e^{-i (\hat B + \hat C) t / M})^M \ket{\psi} \approx&\,
		\bra{\phi} (
			e^{-i \hat A t / M } 
			(e^{-i \hat B t / N} e^{-i \hat C t / N})^{N/M}
		)^M \ket{\psi}
\end{aligned}
\end{align} 
with some error, let us see.\,. .\,.\,Hm.\,. \ldots Hm, I just realized, that apart from the fact, that it might seem a bit dumb, I actually don't need $M$ to grow at the same rate as $N$.\,. .\,.\,Hm, and in some ways, that might actually be a more neat approach, because then we are not relying on our operators to be bounded and/or finite-dimensional (which is what I would have been fine with before if I was able to derive it only for such). .\,.\,Okay, so maybe I should actually just go through with this skew kind of Trotter expansion. It does the job, it uses only well-know formulae and it doesn't need as many requirements, which is nice if you want to reuse the same approach for other theories in the future. Ok.\,.\,:) .\,.\,And I actually don't even need to prepare the readers for it; I can just go a head and do it in several steps, where I then just use the Trotter formula two times.\,.\,:) 

%(Klokken tyve over ni:)
\ldots\ Wait, of course the kinetic part of the Dirac Hamiltonian commutes with the field operators. He.\,x) .\,.\,And then I \emph{can} write
\begin{align}
\begin{aligned}
	\hat H_{2} = \hat H_{20} + \hat H_{21} + \hat H_{22},
%	\label{H_2_01}
\end{aligned}
\end{align}
where $\hat H_{20}$ commutes with.\,. Oh, but it doesn't commute with $\hat H_{21}$ and $\hat H_{22}$, though.\,. ($\hat H_{20}$ is supposed to become the kinetic Dirac Hamiltonian.\,.) .\,.\,Okay, so I may indeed need a three-part expansion.\,. 


%(04.03.22) Kort efter jeg skrev ovenstående i går og stoppede for aftenen, kom jeg frem til, hvordan man nemt kan argumentere for, hvordan hele Trotter-ekspansionen må konvergere (for den "skæve" ekspansion), når N går imod uendeligt. Men det kommer jeg til. ..Hov nej, det må jeg forresten hellere nævne med det samme.
(04.03.22) I found a good argument last night, why we have
\begin{align}
\begin{aligned}
	\bra{\phi} (e^{-i \hat A t / M } e^{-i (\hat B + \hat C) t / M})^M \ket{\psi}
	=
	\lim_{N \to \infty}
		\bra{\phi} (
			e^{-i \hat A t / M } 
			(e^{-i \hat B t / N} e^{-i \hat C t / N})^{N/M}.
		)^M \ket{\psi} 
\end{aligned}
\end{align}
It is simply that for each of the $M$ operators, we can choose a big enough $N_m$, where $N_m$ is the large number of the inner Trotter expansion of the $m$th operator, such that the error compared to operating with the original $m$th operator from the LHS, i.e. $e^{-i (\hat B + \hat C) t / M}$, has a norm less than $\varepsilon/M$ for $N_m$ and all numbers greater than that, where $\varepsilon$ is the maximal error we are trying to achieve in total. Note that $N_m$ can then each be chosen depending on the approximated $(e^{-i \hat A t / M } e^{-i (\hat B + \hat C) t / M})^m$ (in this case) that hits it. By a general triangle inequality, that means we'll get an error with norm less than $\varepsilon$. Finally we can then increase all $N_m$s to their maximal value in the set, which cannot increase any of the $M$ errors because of how the $N_m$s were chosen. And this shows that for any $\varepsilon$, there is a large enough number (i.e.\ said maximal value), such that the error of the expansion will be less than $\varepsilon$ for this number and all greater numbers than that.

I by the way think that this skew kind of expansion only will make the following proofs easier, but let's see.\,:) (.\,.\,I am of course going to choose $\hat A = \hat H_2$.)

Okay. So with the equations above from eq.\ (\ref{H_1_02}) and up, we then go on to write (.\,.\,changing the order of the expansion so it looks better.\,.)
\begin{align}
\begin{aligned}
	\bra{\phi', \psi'} e^{-i \hat H t} \ket{\phi, \psi} 
	=&\,
	\lim_{M \to \infty} \lim_{N \to \infty} 
		\bra{\phi', \psi'} (
			(e^{-i  \hat H_{11} t / N} e^{-i \hat H_{12} t / N})^{N/M}
			e^{-i  \hat H_{2} t / M}
		)^M
		\ket{\phi, \psi}.
\end{aligned}
\end{align} 
We can also rewrite this by defining $\delta t_1 = t / N$, $\delta t_2 = t / M$ and $K = N/M$ such that we get
\begin{align}
\begin{aligned}
	\bra{\phi', \psi'} e^{-i \hat H t} \ket{\phi, \psi} 
	=&\,
	\lim_{M \to \infty} \lim_{K \to \infty} 
		\bra{\phi', \psi'} (
			(e^{-i  \hat H_{11} \delta t_1 } e^{-i \hat H_{12} \delta t_1})^{K}
			e^{-i  \hat H_{2} \delta t_2}
		)^M
		\ket{\phi, \psi}.
	\label{Trotter_H_01}
\end{aligned}
\end{align} 
Note that this equation might also be true if we set $K$ as a constant $\geq 1$, but we haven't proven that here. And note that we are of course free to let $K$ grow with integer values in this expression. 

.\,.\,Let me see this with big $\Delta$s instead.\,.
\begin{align}
\begin{aligned}
	\bra{\phi', \psi'} e^{-i \hat H t} \ket{\phi, \psi} 
	=&\,
	\lim_{M \to \infty} \lim_{K \to \infty} 
		\bra{\phi', \psi'} (
			(e^{-i  \hat H_{11} \Delta t_1 } e^{-i \hat H_{12} \Delta t_1})^{K}
			e^{-i  \hat H_{2} \Delta t_2}
		)^M
		\ket{\phi, \psi}.
\end{aligned}
\end{align}
.\,.\,Hm, that also doesn't look so great. Oh well, I'll just keep the small deltas.\,. 

.\,.\,I'm not gonna do the derivations here, but it's easy to see that
\begin{align}
\begin{aligned}
	\hat H = \hat I_Q \hat H = \hat H \hat I_Q, \quad *(wrong)
\end{aligned}
\end{align}
where
\begin{align}
\begin{aligned}
	\hat I_Q = \hat I_P = 
		\sum_{\boldsymbol{q} \in Q^D} \ket{\boldsymbol{q}}\bra{\boldsymbol{q}} =
		\sum_{\boldsymbol{p} \in P^D} \ket{\boldsymbol{p}}\bra{\boldsymbol{p}}
\end{aligned}
\end{align}
is the projection operator onto the subspace spanned by the $\ket{\boldsymbol{q}}$s (and by the $\ket{\boldsymbol{p}}$s). (I have chosen $\hat I$ instead of $\hat P$ as to not confuse it with the momentum operator). 

We can now rewrite the matrix element in the RHS of eq.\ (\ref{Trotter_H_01}) (assuming that $K$ is a positive integer).\,. Hm wait, will it work with.\,. .\,.\,Hm, I might actually have to split $\hat H_2$ up as well.\,. .\,.\,Hm, in that case we will just get
\begin{align}
\begin{aligned}
	\bra{\phi', \psi'} e^{-i \hat H t} \ket{\phi, \psi} 
	=&\\%=&\,
	\lim_{M \to \infty} \lim_{K_1,K_2 \to \infty} 
		\bra{\phi', \psi'} &(
			(e^{-i  \hat H_{11} \delta t_1 } e^{-i \hat H_{12} \delta t_1})^{K_1}
			(e^{-i  \hat H_{21} \delta t_2 } e^{-i \hat H_{22} \delta t_2})^{K_2}
		)^M
		\ket{\phi, \psi}.
	\label{Trotter_H_02}
\end{aligned}
\end{align} 
instead.\,. .\,.\,Alright, fine. 

.\,.\,Oh, it's easy to \emph{see} (from direct calculation) that 
\begin{align}
\begin{aligned}
	\hat H_1 = \hat I_Q \hat H_1 = \hat H_1 \hat I_Q,
\end{aligned}
\end{align}
but we'll \emph{assume} (and show it later when we define it) that
\begin{align}
\begin{aligned}
	\hat I_Q \hat H_2 = \hat H_2 \hat I_Q.
\end{aligned}
\end{align}
And we should by the way also note that this will then also apply respectively for $e^{-i  \hat H_1 t }$ and $e^{-i  \hat H_2 t }$. This means that we can generate $\hat I_Q$s from e.q.\ $e^{-i  \hat H_{11} t }$ in the above matrix element and distribute them everywhere we want to within it (if we want to argue this way). So we can put a $\hat I_Q$ between every factor and at the ends of the Trotter expansion, i.e.\ in our 
\begin{align}
\begin{aligned}
	\bra{\phi', \psi'} &(
		(e^{-i  \hat H_{11} \delta t_1 } e^{-i \hat H_{12} \delta t_1})^{K_1}
		(e^{-i  \hat H_{21} \delta t_2 } e^{-i \hat H_{22} \delta t_2})^{K_2}
	)^M
	\ket{\phi, \psi}
\end{aligned}
\end{align} 
expression. .\,.\,Okay and now to figure out what $\hat I_Q$s.\,. Ah yeah, this argument (or an equivalent one) is exactly what we need (and no more) to go on from here, because $\hat I_Q$s and $\hat I_P$s are exactly what we \emph{should} insert to rewrite it. Okay, and then what $\hat I_Q$s and $\hat I_P$s goes where.\,.\,? .\,.\,Hm, we should just insert them at the ends of the two inner parentheses, preferably. .\,.\,Hm, and it might be best (and at least it's as good) to write $\hat I_Q$s to the right, such that we get
\begin{align}
\begin{aligned}
	\bra{\phi', \psi'} &(
		(\hat I_P e^{-i  \hat H_{11} \delta t_1 } e^{-i \hat H_{12} \delta t_1} \hat I_Q)^{K_1}
		(\hat I_P e^{-i  \hat H_{21} \delta t_2 } e^{-i \hat H_{22} \delta t_2} \hat I_Q)^{K_2}
	)^M
	\ket{\phi, \psi}
\end{aligned}
\end{align} 
We can then look at the two inner operators and see that we have
\begin{align}
\begin{aligned}
	\hat I_P e^{-i  \hat H_{11} \delta t_1 } e^{-i \hat H_{12} \delta t_1} \hat I_Q
	= \,.\,.
\end{aligned}
\end{align} 
Oh wait, before that, let me just ask myself, why on earth should I need to expand $e^{-i  \hat H_{2} \delta t_2}$ again? .\,.\, Hm well, because.\,. let's see.\,. .\,.\,Hm no, I just said that it commutes with $\hat I_Q$.\,. Well, and does it actually do this.\,.\,? .\,.\,Yes, of course.\,. .\,.\,Hm, I feel like the fact that $\hat I_Q = \hat I_P$ confuses me a bit, since.\,. Ah no, the point is that while $\hat H_2$ does not in general commute with $\hat P$ and $\hat Q$, it does commute with $\hat I_Q = \hat I_P$.\,:) Right. 

Okay, so I should go back to (the nicer)
\begin{align}
\begin{aligned}
	\bra{\phi', \psi'} e^{-i \hat H t} \ket{\phi, \psi} 
	=&\,
	\lim_{M \to \infty} \lim_{K \to \infty} 
		\bra{\phi', \psi'} (
			(e^{-i  \hat H_{11} \delta t_1 } e^{-i \hat H_{12} \delta t_1})^{K}
			e^{-i  \hat H_{2} \delta t_2}
		)^M
		\ket{\phi, \psi}
	\label{Trotter_H_03}
\end{aligned}
\end{align} 
and start rewriting the matrix element on the RHS by writing
\begin{align}
\begin{aligned}
	\bra{\phi', \psi'} \hat I_Q 
		(
			(\hat I_P e^{-i  \hat H_{11} \delta t_1 } e^{-i \hat H_{12} \delta t_1} \hat I_Q)^{K}
			e^{-i  \hat H_{2} \delta t_2}
		)^M 
		\hat I_Q
	\ket{\phi, \psi}.
\end{aligned}
\end{align}
We go on to rewrite the first inner operator as
\begin{align}
\begin{aligned}
	\hat I_P e^{-i  \hat H_{11} \delta t_1 } e^{-i \hat H_{12} \delta t_1} \hat I_Q
	=&\,
	\sum_{\boldsymbol{q} \in Q^D}\sum_{\boldsymbol{p} \in P^D}
		\ket{\boldsymbol{p}}\bra{\boldsymbol{p}}
			e^{-i  \hat H_{11} \delta t_1 } 
			e^{-i \hat H_{12} \delta t_1}
		\ket{\boldsymbol{q}}\bra{\boldsymbol{q}} \,.\,.
%	\\=&\,
%	\sum_{\boldsymbol{q} \in Q^D}\sum_{\boldsymbol{p} \in P^D}
%		\ket{\boldsymbol{p}}\bra{\boldsymbol{p}}
%			e^{-i  \hat H_{11} \delta t_1 } 
%			e^{-i \hat H_{12} \delta t_1}
%		\ket{\boldsymbol{q}}\bra{\boldsymbol{q}} 
\end{aligned}
\end{align}
Hm, let's recall that
\begin{align}
\begin{aligned}
	\hat H_{11} = 
		\sum_{j=1}^{D_1} \big(
			\frac{1}{2} \hat P_{j}^2 + 
			\hat C_{j} \hat P_{j}
		\big) + 
		\sum_{j=D_1+1}^{D}
			\hat V_{j} 
\end{aligned}
\end{align} 
\begin{align}
\begin{aligned}
	\hat H_{12} = 
		\sum_{j=D_1+1}^{D} \big(
			\frac{1}{2} \hat P_{j}^2 + 
			\hat C_{j} \hat P_{j}
		\big) + 
		\sum_{j=1}^{D_1}
			\hat V_{j} 
\end{aligned}
\end{align} 
The next step is then to first let $\sum_{j=1}^{D_1} \hat V_{j}$ in $e^{-i \hat H_{12} \delta t_1}$ hit $\ket{\boldsymbol{q}}$ and let $\sum_{j=1}^{D_1} (\hat P_{j}^2 / 2 + \hat C_{j} \hat P_{j})$ in $e^{-i \hat H_{11} \delta t_1}$ hit $\bra{\boldsymbol{p}}$ and let them thereby change to $\sum_{j=1}^{D_1} V_{j}(q_j)$ and $\sum_{j=1}^{D_1} ( p_{j}^2 / 2 + C_{j}(\boldsymbol{q}) p_{j})$. Let's assume that I have already defined the (one-dimensional) function $V_j$ for all $j$.\,. Then we have $\sum_{j=D_1+1}^{D} \hat V_{j}$ left in $e^{-i \hat H_{12} \delta t_1}$ and $\sum_{j=D_1+1}^{D} (\hat P_{j}^2 / 2 + \hat C_{j} \hat P_{j})$ left in $e^{-i \hat H_{12} \delta t_1}$.\,. .\,.\,Oops, this is not what we want. Okay, instead I should rewrite the matrix element as
\begin{align}
\begin{aligned}
	\bra{\phi', \psi'}  
		(
			(
				\hat I_Q 
				e^{-i  \hat H_{11} \delta t_1 } 
				\hat I_P 
				e^{-i \hat H_{12} \delta t_1} \hat I_Q
			)^{K}
			e^{-i  \hat H_{2} \delta t_2}
			\hat I_Q
		)^M 
	\ket{\phi, \psi},
\end{aligned}
\end{align}
and then write
\begin{align}
\begin{aligned}
	&\hat I_Q e^{-i  \hat H_{11} \delta t_1 } \hat I_P e^{-i \hat H_{12} \delta t_1} \hat I_Q
	=\\&
	\sum_{\boldsymbol{q}_1 \in Q^D} \sum_{\boldsymbol{p}_1 \in P^D} \sum_{\boldsymbol{q}_2 \in Q^D} 
		\ket{\boldsymbol{q}_2}\bra{\boldsymbol{q}_2}
		e^{-i  \hat H_{11} \delta t_1 } 
		\ket{\boldsymbol{p}_1}\bra{\boldsymbol{p}_1}
		e^{-i \hat H_{12} \delta t_1}
		\ket{\boldsymbol{q}_1}\bra{\boldsymbol{q}_1}.
\end{aligned}
\end{align}
We then see that 
\begin{align}
\begin{aligned}
	\bra{\boldsymbol{q}_2}
		e^{-i  \hat H_{11} \delta t_1 } 
	\ket{\boldsymbol{p}_1} %\bra{\boldsymbol{p}}
%			e^{-i \hat H_{12} \delta t_1}
%		\ket{\boldsymbol{q}_1}
	=&\,
	\bra{\boldsymbol{q}_2}
		e^{-i  
			(
				\sum_{j=1}^{D_1} 
					(
						\frac{1}{2} \hat P_{j}^2 + 
						\hat C_{j} \hat P_{j}
					) + 
				\sum_{j=D_1+1}^{D} \hat V_{j}  
			) \delta t_1 
		} 
	\ket{\boldsymbol{p}_1} %\bra{\boldsymbol{p}}
%				e^{-i \hat H_{12} \delta t_1}
%			\ket{\boldsymbol{q}_1}
	\\=&\,
	\bra{\boldsymbol{q}_2}
		e^{-i  
			(
				\sum_{j=1}^{D_1} 
					(
						\frac{1}{2} p_{j}^2 + 
						C_{j}(\boldsymbol{q}) p_{j}
					) + 
				\sum_{j=D_1+1}^{D} V_{j}(q_j)
			) \delta t_1 
		} 
	\ket{\boldsymbol{p}_1}
	\\=&\,
	\braket{\boldsymbol{q}_2 | \boldsymbol{p}_1}
		e^{-i  
			(
				\sum_{j=1}^{D_1} 
					(
						\frac{1}{2} p_{j}^2 + 
						C_{j}(\boldsymbol{q}) p_{j}
					) + 
				\sum_{j=D_1+1}^{D} V_{j}(q_j)
			) \delta t_1 
		},
\end{aligned}
\end{align}
and by similar observation that 
\begin{align}
\begin{aligned}
	\bra{\boldsymbol{p}_1}
		e^{-i  \hat H_{12} \delta t_1 } 
	\ket{\boldsymbol{q}_1} %\bra{\boldsymbol{p}}
%			e^{-i \hat H_{12} \delta t_1}
%		\ket{\boldsymbol{q}_1}
	=&\,
	\braket{\boldsymbol{p}_1 | \boldsymbol{q}_1}
%		e^{-i  
%			(
%				\sum_{j=1}^{D_1} 
%					(
%						\frac{1}{2} p_{j}^2 + 
%						C_{j}(\boldsymbol{q}) p_{j}
%					) + 
%				\sum_{j=D_1+1}^{D} V_{j}(q_j)
%			) \delta t_1 
%		},
	\,.\,.
\end{aligned}
\end{align}
.\,.\,Ah, damn.\,. .\,.\,(With this, I get a split-up $V(\boldsymbol{q})$ and $\boldsymbol C(\boldsymbol{q})$.\,.) .\,.\,Time for a break.\,. 

%(Kl. tyve over et:)
\ldots\ I was initially worried (going to break (i.e.\ going for a walk of course in this weather)) that I might need an extra nested Trotter expansion, but I should just go through with is this way. However, I \emph{need} to get rid of this ugly (as it has turned out) division. So I will actually go back to dividing the Hilbert in three essentially, and then I'll of course just write $\ket{\boldsymbol{2_1}, \boldsymbol{q_2}, \psi}$ instead. If the summations limits get too much, I can by the way also always decide to make them minimalistic and implicit.

Okay, so let me just write the formulas once again.\,.
\begin{align}
\begin{aligned}
	\textbf{H} = \textbf{H}_{1} \otimes \textbf{H}_{2} \otimes \textbf{H}_3
\end{aligned}
\end{align} 
\begin{align}
\begin{aligned}
	\hat Q_{ij} =&\, \sum_{\psi \in \Psi} \sum_{(\boldsymbol{q}_1, \boldsymbol{q}_2) \in Q^{D}} 
		q_{ij} \ket{\boldsymbol{q}_1, \boldsymbol{q}_2, \psi} \bra{\boldsymbol{q}_1, \boldsymbol{q}_2, \psi}, \\
	\hat P_{ij} =&\, \sum_{\psi \in \Psi} \sum_{(\boldsymbol{p}_1, \boldsymbol{p}_2) \in P^{D}} 
		p_{ij} \ket{\boldsymbol{p}_1, \boldsymbol{p}_2, \psi} \bra{\boldsymbol{p}_1, \boldsymbol{p}_2, \psi}\,.\,.
\end{aligned}
\end{align} 
.\,.\,Hm.\,. *($i\in\{1,2\}$.\,.) 
.\,.\,Or with more implicit summations *(and let me actually also change $\psi$ to $e_3$.\,.)%$\boldsymbol{e}_3$) %..No.. ..Yes.. ..Or to just $e_3$.. ..Sure..
\begin{align}
\begin{aligned}
	\hat Q_{ij} =&\, \sum_{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3} 
		q_{ij} 
		\ket{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3} 
		\bra{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3}, \\
	\hat P_{ij} =&\, \sum_{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3} 
		p_{ij} 
		\ket{\boldsymbol{p}_1, \boldsymbol{p}_2, e_3} 
		\bra{\boldsymbol{p}_1, \boldsymbol{p}_2, e_3}\,.\,.
\end{aligned}
\end{align} 
.\,. 
\begin{align}
\begin{aligned}
	\ket{\boldsymbol{p}_1, \boldsymbol{p}_2, e_3} = \frac{1}{\sqrt{N^{D_1 + D_2}}} 
		\sum_{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3}
		e^{i \boldsymbol{p}_1 \cdot \boldsymbol{q}_1} 
		e^{i \boldsymbol{p}_2 \cdot \boldsymbol{q}_2} 
%		e^{i \boldsymbol{p}_1 \cdot \boldsymbol{q}_1 + i \boldsymbol{p}_2 \cdot \boldsymbol{q}_2} 
		\ket{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3} ,
%	\label{ket_p_01}
\end{aligned}
\end{align} 
\begin{align}
\begin{aligned}
	\ket{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3} = \frac{1}{\sqrt{N^{D_1 + D_2}}} 
		\sum_{\boldsymbol{p}_1, \boldsymbol{p}_2, e_3}
		e^{-i \boldsymbol{q}_1 \cdot \boldsymbol{q}_1} 
		e^{-i \boldsymbol{q}_2 \cdot \boldsymbol{q}_2} 
%		e^{i \boldsymbol{p}_1 \cdot \boldsymbol{q}_1 + i \boldsymbol{p}_2 \cdot \boldsymbol{q}_2} 
		\ket{\boldsymbol{p}_1, \boldsymbol{p}_2, e_3} ,
\end{aligned}
\end{align} 
\begin{align}
\begin{aligned}
	\hat H = \hat H_{1} + \hat H_{2} + \hat H_3,
%	\label{H_B_02}
\end{aligned}
\end{align}
\begin{align}
\begin{aligned}
	\hat H_{i} = 
		\sum_{j=1}^{D_i} \big(
			\frac{1}{2} \hat P_{ij}^2 + 
			\hat C_{ij} \hat P_{ij}
		\big) +
		\hat V_{i} ,
	\label{H_i_01}
\end{aligned}
\end{align} 
for $i\in\{1,2\}$. .\,.\,Hm, not so bad, actually.\,. (I think I prefer to let these expressions be more expanded this way and slightly more ugly, but to let the formulas speak more for themselves this way (as opposed to defining the operators for the sub- Hilbert spaces, that is.\,.).\,.) .\,.\,Cool. 
.\,.\,Oh, and to write $\hat H_{ij}$ in a better way for when it should appear in exponents, let us write.\,. .\,.\,Hm no, let me get to that later.\,. 
%\begin{align}
%\begin{aligned}
%	\hat H_{i1} = 
%			\frac{1}{2} {\boldsymbol{\hat P}}_{ij}^2 + 
%			\hat C_{ij} \hat P_{ij} +
%			\hat V_{ij} 
%		\big),
%	\label{H_i1_02}
%\end{aligned}
%\end{align} 

We are then interested in rewriting
\begin{align}
\begin{aligned}
	\bra{\psi'} e^{-i \hat H t} \ket{\psi}
	=&\,
	\lim_{M \to \infty} \lim_{K \to \infty} 
		\bra{\psi'} (
			(e^{-i  \hat H_{1} \delta t_1 } e^{-i \hat H_{2} \delta t_1})^{K}
			e^{-i  \hat H_{3} \delta t_2}
		)^M
		\ket{\psi}
%	\bra{\phi_1', \phi_2', \psi'} e^{-i \hat H t} \ket{\phi_1, \phi_2, \psi}
%	=&\,
%	\lim_{M \to \infty} \lim_{K \to \infty} 
%		\bra{\phi_1', \phi_2', \psi'} (
%			(e^{-i  \hat H_{1} \delta t_1 } e^{-i \hat H_{2} \delta t_1})^{K}
%			e^{-i  \hat H_{3} \delta t_2}
%		)^M
%		\ket{\phi_1, \phi_2, \psi}
\end{aligned}
\end{align} 
by writing the matrix element as.\,.
%\begin{align}
%\begin{aligned}
%	\bra{\psi'} 
%		(
%			(
%				\hat I_Q 
%				e^{-i  \hat H_{1} \delta t_1 } 
%				\hat I_P 
%				e^{-i \hat H_{2} \delta t_1} \hat I_Q
%			)^{K}
%			e^{-i  \hat H_{3} \delta t_2}
%			\hat I_Q
%		)^M 
%	\ket{\psi}
%\end{aligned}
%\end{align}
%and noting that
%\begin{align}
%\begin{aligned}
%	&\hat I_Q e^{-i  \hat H_{1} \delta t_1 } \hat I_P e^{-i \hat H_{2} \delta t_1} \hat I_Q
%	= \,.\,. 
%%	=\\& 
%%	\sum_{\boldsymbol{q}_1, \boldsymbol{q}_2,\boldsymbol{p}_1 \boldsymbol{q}_2 \in Q^D} 
%%		\ket{\boldsymbol{q}_2}\bra{\boldsymbol{q}_2}
%%		e^{-i  \hat H_{11} \delta t_1 } 
%%		\ket{\boldsymbol{p}_1}\bra{\boldsymbol{p}_1}
%%		e^{-i \hat H_{12} \delta t_1}
%%		\ket{\boldsymbol{q}_1}\bra{\boldsymbol{q}_1} \,.\,.
%\end{aligned}
%\end{align}
\begin{align}
\begin{aligned}
	\bra{\psi'} 
		(
			(
				\hat I_Q 
				e^{-i  \hat H_{1} \delta t_1 } 
				\hat I_P 
				e^{-i \hat H_{2} \delta t_1} 
%				\hat I_Q
			)^{K}
%			\hat I_Q
			e^{-i  \hat H_{3} \delta t_2}
		)^M 
		\hat I_Q
	\ket{\psi}
\end{aligned}
\end{align}
.\,.\,Better.\,. %Let me take a break again.. (Kl. tyve i tre.)

%(Kvart over tre:)
Let me define.\,. Oh, I actually need $\hat C_{ij}$ to have the property that.\,. Wait. Let me first actually change the above so that $D_1 = D_2 = D$.\,. .\,.\,Done. .\,.\,No, let me actually change it back, but maybe write $D_1 + D_2$ explicitly instead of $D$, and then I should also change eq.\ (\ref{H_i_01}) slightly.\,. .\,.\,Done. And now let me state that\ldots
%\begin{align}
%\begin{aligned}
%	\sum_{j=1}^{D_1}\hat C_{1j} \ket{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3} =&\,
%		\boldsymbol C_1 \cdot \boldsymbol{q_2}, \\
%	\sum_{j=1}^{D_2}\hat C_{2j} \ket{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3} =&\,
%		\boldsymbol C_2 \cdot \boldsymbol{q_1}.
%\end{aligned}
%\end{align}
*No that was wrong, sorry. We should just have
\begin{align}
\begin{aligned}
%	\sum_{j=1}^{D_1}
	\hat C_{1j} \ket{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3} =&\,
		C_{1j}(\boldsymbol{q_2})
		\ket{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3}, \\
%	\sum_{j=1}^{D_2}
	\hat C_{2j} \ket{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3} =&\,
		C_{2j}(\boldsymbol{q_1})
		\ket{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3}
\end{aligned}
\end{align}
instead. (And then we can define $\boldsymbol{C}_1(\boldsymbol{q_2})$ and $\boldsymbol{C}_2(\boldsymbol{q_1})$ the way you would expect.\,.)

*Oh, and by the way, we also have.\,. Wait, I also need to change the formula for $\hat H_{i}$ again. Let me do that now.\,. .\,.\,Done. And with that, I can state that
\begin{align}
\begin{aligned}
	\hat V_{1} \ket{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3} =&\,
		V_{1}(\boldsymbol{q_2})
		\ket{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3}, \\
	\hat V_{2} \ket{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3} =&\,
		V_{2}(\boldsymbol{q_1})
		\ket{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3}.
\end{aligned}
\end{align}

Okay, and now back to $\hat I_Q e^{-i  \hat H_{1} \delta t_1 } \hat I_P e^{-i \hat H_{2} \delta t_1}$.\,. We have
%\begin{align}
%\begin{aligned}
%	&\hat I_Q e^{-i  \hat H_{1} \delta t_1 } \hat I_P e^{-i \hat H_{2} \delta t_1} \hat I_Q
%	=\\& 
%	\sum_{\boldsymbol{q}\mathrm{s}, \boldsymbol{p}\mathrm{s} \mathrm{\ and\ } e\mathrm{s}}%_{\boldsymbol{q}_1, \boldsymbol{q}_2,\boldsymbol{p}_1 \boldsymbol{q}_2 \in Q^D} 
%		\ket{\boldsymbol{q}_2}\bra{\boldsymbol{q}_2}
%		e^{-i  \hat H_{11} \delta t_1 } 
%		\ket{\boldsymbol{p}_1}\bra{\boldsymbol{p}_1}
%		e^{-i \hat H_{12} \delta t_1}
%		\ket{\boldsymbol{q}_1}\bra{\boldsymbol{q}_1} \,.\,.
%\end{aligned}
%\end{align}
\begin{align}
\begin{aligned}
	\bra{\boldsymbol{q}_1', \boldsymbol{q}_2', e_3'} 
		e^{-i  \hat H_{1} \delta t_1 } 
	\ket{\boldsymbol{p}_1, \boldsymbol{p}_2, e_3}
%	=
%	\bra{\boldsymbol{q}_1', \boldsymbol{q}_2', e_3'} 
%		e^{
%			-i 
%			\sum_{j=1}^{D_1} (
%				\frac{1}{2} \hat P_{1j}^2 + 
%				\hat C_{1j} \hat P_{1j} +
%				\hat V_{1j} 
%			)
%			\delta t_1 
%		} 
%	\ket{\boldsymbol{p}_1, \boldsymbol{p}_2, e_3}
	=&\,
	\bra{\boldsymbol{q}_1', \boldsymbol{q}_2', e_3'} 
		e^{
			-i
			\big(
				\sum_{j=1}^{D_1} (
					\hat P_{1j}^2 / 2 + 
					\hat C_{1j} \hat P_{1j}
				) +
				\hat V_1
			\big)
			\delta t_1
		} 
	\ket{\boldsymbol{p}_1, \boldsymbol{p}_2, e_3} 
	\\=&\,
	\bra{\boldsymbol{q}_1', \boldsymbol{q}_2', e_3'} 
		e^{
			-i
			(
				\boldsymbol p_{1}^2 / 2 + 
				\boldsymbol C_{1}(\boldsymbol{q_2}') \cdot \boldsymbol p_{1} +
				V_1(\boldsymbol{q_2}')
			)
			\delta t_1
		} 
	\ket{\boldsymbol{p}_1, \boldsymbol{p}_2, e_3} \,.\,. 
	\label{pppqqppqpqp_01}
\end{aligned}
\end{align}
%Hm, let me take another break.. (Kl. tyve over fire.)

%(Kl. ti over seks:)
\ldots\ Ah, an important thing to note: $\hat H_3$ does commute with $\hat Q_i$ and $\hat V$ and so on, but does not commute with the field momentum operators, $\hat P_j$. .\,.\,Hm, but I don't think I will try to change my expansion for that reason. When I went to break, I had thoughts that maybe it \emph{would} be good to use a non-skew three-part Trotter (-Suzuki) expansion, but no, I actually think this is better. I should just make sure to introduce $\ket{\psi_q}$ and $\ket{\psi_q}$, where it is implicitly understood that $\ket{\psi_q}$ can always be (expanded to and) replaced with $\ket{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3}$ and $\ket{\psi_p}$ can be replaced with $\ket{\boldsymbol{p}_1, \boldsymbol{p}_2, e_3}$. Also, any labels, primes etc.\ should also remain in this replacement, such that for instance  $\ket{\psi_{q ijn}''} = \ket{\boldsymbol{q}_{1 ijn}'', \boldsymbol{q}_{2 ijn}'', e_{3 ijn}''}$ etc. With this, we can for instance write
\begin{align}
\begin{aligned}
	\hat V_{1} \ket{\psi_q} =&\,
		V_{1}(\boldsymbol{q_2})
		\ket{\psi_q}, \\
	\hat V_{2} \ket{\psi_q} =&\,
		V_{2}(\boldsymbol{q_1})
		\ket{\psi_q},
\end{aligned}
\end{align}
and so on. .\,.\,I might also choose to have $\ket{\psi_{q_{ijn}''}} = \ket{\boldsymbol{q}_{1 ijn}'', \boldsymbol{q}_{2 ijn}'', e_{3 ijn}''}$ but let's see.\,. And eq.\ can be written as
\begin{align}
\begin{aligned}
	\bra{\psi_{q'}} 
		e^{-i  \hat H_{1} \delta t_1 } 
	\ket{\psi_p}
	=&\,
	\bra{\psi_{q'}}  
		e^{
			-i
			\big(
				\sum_{j=1}^{D_1} (
					\hat P_{1j}^2 / 2 + 
					\hat C_{1j} \hat P_{1j}
				) +
				\hat V_1
			\big)
			\delta t_1
		} 
	\ket{\psi_p} 
	\\=&\,
	\bra{\psi_{q'}}  
		e^{
			-i
			(
				\boldsymbol p_{1}^2 / 2 + 
				\boldsymbol C_{1}(\boldsymbol{q_2}') \cdot \boldsymbol p_{1} +
				V_1(\boldsymbol{q_2}')
			)
			\delta t_1
		} 
	\ket{\psi_p} \,.\,.
\end{aligned}
\end{align}
.\,.\,Yes, I like it better when the subscripts are nested for e.g.\ $\psi_{q'}$.
.\,.\,Hm, let me use the classical Hamiltonian in a way to write this more neatly.\,. .\,.\,We'll write *(and I'll also start using second indices/labels instead of using primes)
%\begin{align}
%\begin{aligned}
%	\bra{\psi_{q'}} 
%		e^{-i  \hat H_{1} \delta t_1 } 
%	\ket{\psi_p}
%	=&\,
%	\bra{\psi_{q'}}  
%		e^{
%			-i
%			(
%				\boldsymbol p_{1}^2 / 2 + 
%				\boldsymbol C_{1}(\boldsymbol{q_2}') \cdot \boldsymbol p_{1} +
%				V_1(\boldsymbol{q_2}')
%			)
%			\delta t_1
%		} 
%	\ket{\psi_p} 
%	\\=&\,
%	\bra{\psi_{q'}}  
%		e^{
%			-i
%			H_1(\boldsymbol{p}_1, \boldsymbol{q}_2')
%			\delta t_1
%		} 
%	\ket{\psi_p} \,.\,.
%\end{aligned}
%\end{align}
\begin{align}
\begin{aligned}
	\bra{\psi_{q_{m k}}} 
		e^{-i  \hat H_{1} \delta t_1 } 
	\ket{\psi_{p_{m k}}}
	=&\,
	\bra{\psi_{q_{m k}}}  
		e^{
			-i
			(
				\boldsymbol p_{1mk}^2 / 2 + 
				\boldsymbol C_{1}(\boldsymbol{q}_{2 m k}) \cdot \boldsymbol p_{1 m k} +
				V_1(\boldsymbol{q}_{2 m k})
			)
			\delta t_1
		} 
	\ket{\psi_{p_{m k}}} 
	\\=&\, 
	e^{
		-i
		H_1(\boldsymbol{p}_{1 m k}, \boldsymbol{q}_{2 m k})
		\delta t_1
	} 
	\braket{\psi_{q_{m k}} | \psi_{p_{m k}}}
	\\=&\, 
	e^{
		-i
		H_1(\boldsymbol{p}_{1 m k}, \boldsymbol{q}_{2 m k})
		\delta t_1 +
		i \boldsymbol{p}_{1 m k} \cdot \boldsymbol{q}_{1 m k} +
		i \boldsymbol{p}_{2 m k} \cdot \boldsymbol{q}_{2 m k}
	} 
	\delta_{e_{3 m k}, e_{3 m k} \,.\,.} \,.\,. 
\end{aligned}
\end{align}
%and then we'll also get expressions of
.\,.\,Hm, that doesn't exactly work, but maybe we can do something about it, let's see.\,. %..Hm, lad mig holde pause/fri og så bare summe over det..


%(05.03.22) Hm, jeg har en del ting, jeg kom frem til i går aftes, og nu er jeg så lige i gang med at tænke videre over nogle tanker om at vise L.-inv. Jeg har overvejet, om man skulle approksimere fermion-bølgefunktionerne med delta-funktioner i en vis bevisstrategi, men nu kom jeg lige frem til, at det behøver jeg ikke. Men nu blev jeg lige lidt i tvivl igen, så jeg tillader mig lige at gå herind og "tænke lidt på tasterne".. ..Hm, jeg skal bare bruge, at enhver (\omega, k)-bølge giver den samme (fermion-)\psi-bølge til tilstrækkelig god approksimation i begge systemer.. ..Hm ja, så geometriproblemet \emph{handler} faktisk om lattice spacing'en i rum og tid.. ..Hm, men husk at lattice'en er i k-rummet.. Hm.. ..Hm, ah, så hvis bare \psi tilnærmelsesvist vil følge den rigtige dynamik på en given (\omega, k)-bølge.. ...Ah, jeg behøver jo forresten ikke at bevise det ud fra det diskrete sti-integralet fra udledningen, men jeg kan jo også sikkert bare betragte resultatet, ligesom.. ..Ja, så jeg vil jo helst bare gerne have, at resultatet bliver et sti-integrale over (\omega, k)-bølger, hvor \psi bare følger hver bølge eksakt (i en punktvis konvergerende grænse).. ..Og vil jeg så få det..? 

%(05.03.22) I have several things I need to write about, but I read the inequality that $\|X^M\| \leq \|X\|^M$ (in the beginning of section 16.4 in Hall), and it inspired me to try to finish the proof of the generalized (three-part) Trotter expansion I was in the middle of some days back (just to at least try to get that out the way). The point I have in mind is to use this to get.\,. .\,.\,Hm, let's perhaps use a product with the inverse rather than a difference.\,.
%%% (Kopieret: (til at kigge på))
%%\begin{align}
%%\begin{aligned}
%%	e^{-i (\hat A + \hat B + \hat C) t } \ket{\psi} \to
%%		(e^{-i \hat A t / M } e^{-i (\hat B + \hat C) t / M})^M \ket{\psi}
%%\end{aligned}
%%\end{align} 
%%costs us an error of $\hat \varepsilon_1(M)\ket{\psi}$. And going from 
%%\begin{align}
%%\begin{aligned}
%%	e^{-i (\hat B + \hat C) t } \ket{\psi} \to
%%		(e^{-i \hat B t / M } e^{-i \hat C t / M})^M \ket{\psi}
%%\end{aligned}
%%\end{align} 
%%costs us an error of $\hat \varepsilon_2(M)\ket{\psi}$\ldots\ .\,.\,Oh, and going from
%%\begin{align}
%%\begin{aligned}
%%	(e^{-i (\hat B + \hat C) t })^{1/M} \ket{\psi} \to
%%		e^{-i \hat B t / M } e^{-i \hat C t / M} \ket{\psi}
%%\end{aligned}
%%\end{align} 
%%will then give us an error of $\hat \varepsilon_2(M)^{1/M} \ket{\psi}$.\,.\,!\,.\,. .\,.\,And you could also have defined it the other way around, which would probably make this easier to see.\,. .\,.\,Okay so going from
%%\begin{align}
%%\begin{aligned}
%%	(e^{-i \hat A t / M } e^{-i (\hat B + \hat C) t / M})^M \ket{\psi} \to
%%		(e^{-i \hat A t / M }  e^{-i \hat B t / M } e^{-i \hat C t / M})^M \ket{\psi}
%%\end{aligned}
%%\end{align} 
%%% (slut)
%%\begin{align}
%%\begin{aligned}
%%	\Big\|
%%		e^{-i (\hat B + \hat C) t })^{1/M} 
%%		(e^{-i \hat B t / M } e^{-i \hat C t / M})^{-1}
%%	\Big\|^M 
%%	\geq 
%%	\Big\|
%%		(e^{-i (\hat B + \hat C) t })^{1/M} 
%%		(e^{-i \hat B t / M } e^{-i \hat C t / M})^{-1})^M
%%	\Big\| \,.\,.
%%\end{aligned}
%%\end{align} 
%\begin{align}
%\begin{aligned}
%	\Big\|
%		\big(
%			(e^{-i (\hat B + \hat C) t })^{1/M} 
%			(e^{-i \hat B t / M } e^{-i \hat C t / M})^{-1}
%		\big)^M
%	\Big\| 
%	\leq 
%	\Big\|
%		(e^{-i (\hat B + \hat C) t })^{1/M} 
%		(e^{-i \hat B t / M } e^{-i \hat C t / M})^{-1}
%	\Big\|^M 
%\end{aligned}
%\end{align} 
%\ldots Hm, it must also be true for selv-adjoint bounded matrices that $\|X Y\| \leq \|X\|\|Y\|$. (.\,.\,Yes, and I was actually able for once to find this on the internet (namely the wiki page for `operator norm') (but of course it is true).) And this means that $\|X Y\|^m \leq \|X\|^m\|Y\|^m$, $m\geq 1$. And so we have
%\begin{align}
%\begin{aligned}
%	\Big\|
%		\big(
%			(e^{-i (\hat B + \hat C) t })^{1/M} 
%			(e^{-i \hat B t / M } e^{-i \hat C t / M})^{-1}
%		\big)^M
%	\Big\| 
%	\leq 
%	\Big\|
%		(e^{-i (\hat B + \hat C) t })^{1/M} 
%	\Big\|^M 
%	\Big\|
%		(e^{-i \hat B t / M } e^{-i \hat C t / M})^{-1}
%	\Big\|^M \,.\,.
%\end{aligned}
%\end{align}
%Oh, that of course doesn't help us.\,. .\,.\,Hm, but wouldn't we also have $\|(X Y)^m\| \leq \|X^m Y^m\|$.\,.\,? .\,.\,It definitely looks true.\,. .\,.\,Hm, wouldn't it follow, if we can just show $\|X Y X Y\| \leq \|X X Y Y\|$.\,.\,? .\,.\,Let me just assume it to be true for now (it must be.\,.).\,. If so, we'll have
%\begin{align}
%\begin{aligned}
%	\Big\|
%		\big(
%			(e^{-i (\hat B + \hat C) t })^{1/M} 
%			(e^{-i \hat B t / M } e^{-i \hat C t / M})^{-1}
%		\big)^M
%	\Big\| 
%	\leq 
%	\Big\|
%		e^{-i (\hat B + \hat C) t } 
%		(e^{-i \hat B t / M } e^{-i \hat C t / M})^{-M}
%	\Big\|,
%\end{aligned}
%\end{align}
%where we know from Trotter/Lie that the RHS converges to 0. .\,.\,Hm wait, I'm not interested in any of this, since the operator norm is just 1 for all these expressions. Let me just comment all this out for now and move on to something more interesting.. *..I øvrigt er det lidt lige meget, for man kan sikkert ret nemt lave et mere direkte (brute-force) bevis med (de definerende) Taylor-expansioner, når det kommer til matricer.. 


%..Hm, tilbage til L.-invarians og spørgsmålet, om "resultatet bliver et sti-integrale over (\omega, k)-bølger, hvor \psi bare følger hver bølge eksakt (i en punktvis konvergerende grænse)." Men først går jeg mig måske lige en eftermiddagstur..

%(Klokken kvart i fem.) Hm, måske \emph{er} det faktisk delta-funktioner for \psi-rummet i sti-integralet, man skal have fat i (som jeg nemlig tænkte lidt på tidligere i dag), men bare hvor deres funktion så specifikt bliver at skille alle.. Hm, at vise at vi kun behøver et begrænset sæt af (\omega, k)-bølger.. Hm.. ..Hm tja, jeg mangler alligevel noget i den argumentation.. ..Hm, måske hvis jeg kunne få et \exp(-i H_3 \delta t) i hvert mindste lille tidskridt i sti-integralet, men alligevel få nogle delta-funktioner indsat jævnt men med større (tids-)intervaller imellem sig..!..? ..Hov nej, det giver ikke rigtigt mening.. ..Hm, men måske kunne man bare vise, at \exp(-i H_3 \delta t) på et klassisk felt vil konvergere, selvom man lægger flere og flere (\omega, k)-bølger til.. Hm, men vil det overhovedet det.. ..Kommer nok lidt an på deres amplituder.. ..Ah, hvilke dog er begrænsede.. ..Hm.. ..Hov, men hvis først jeg har delta-funktions-diskretiseringen.. Hvad mangler jeg så egentligt mere..?.. ..Ah, problemet er, om så.. Nej, vent.. ..Hm, for så kunne jeg jo måske bare gøre som jeg fik idéen til i går aftes, og som jeg også tænkte over i formiddags, hvor jeg bare sørger for at vise, at delta-funktionerne godt må skifte i tid, og.. hov, det kommer jeg da aldrig til at kunne vise, hvis de skal skifte med så korte intervaller.. Hm, eller ville jeg have fortsat og sagt: "og hvor man så sørger for at de transformerer om til et andet gyldigt grid.." .. ..Nej, det går ikke rigtigt alligevel.. ...Hm, kunne man mon gøre noget med at begrænse amplituden for.. ..Ah ja, begrænse den mere og mere for større.. eller rettere for indgangene i \boldsymbol{q}?(..!) Så at indgangene altså ikke er begrænset med det samme, og at \boldsymbol{q} ligger i Q^D, men hvor invervallerne bliver mindre og mindre for større j (i følgen (1, 2, ..., D))..!.. ..Det er da lige netop, hvad man må kunne!:D.. ..(Og så kan man nemlig sørge for, at det klassiske felt altid (rent faktisk xD) eksisterer!:D) ..Tja, selvom vi dog ikke har endnu, at det konvergerer til noget kontinuert, når \detla t går mod 0, indtil vi måske på en eller anden måde kan vise, at man kan skille alle tilstrækkeligt stor spring (pr. tidsenhed..) fra.. ..Hm, men gad vide, om man her ikke kan bruge kontinuiteten af \exp(-i H t)..? ..Hm jo, det lyder faktisk ikke helt dumt.. ..Hm, men hvordan skulle man så helt præcist lave dette argument; vil det rent faktisk kunne betyde, at man kan begrænse den tidsafledte rumlige og amplitudemæssige propagation..? ..Hm, eller kunne man sætte en begrænsning på \hat P(_B), der sørger for dette?.. ..Tja, eller skulle man hellere prøve at argumentere ud fra (kontinuiteten af) propagationen (hvad man næsten må kunne..)..? ..Hm ja, det må man faktisk ret nemt kunne..!.. ..(Man \emph{må} kunne argumentere for, at man har lov til at skære en tilstrækkelig bred/flad kegle af propagationen, uden at så giver mere end en vis given fejl..) ..Nice, og så får man også sin begrænsning på \omega?..!..? ..Hm ja, man må nok kunne vise, at dette vil begrænse eller i det mindste dæmpe \omega, mon ikke.. ..Ah, men uanset hvad, så får jeg jo herved mit \emph{eksisterende} klassiske felt..:).. ..Hm ja, og kontinuiteten gør det dejligt integrerbart, hvilket sikkert bliver nok til at vise (i princippet i hvert fald; jeg ved ikke om jeg kan gøre det fuldstændigt (..Tja, eller jo, det kunne jeg måske nok godt, hvis bare jeg brugte lang tid nok på det, om ikke andet..)), at \psi-dynamikken så konvergerer for dette felt..:)..  
%(Klokken ti i otte.) Jeg kom også på, nu her, at man kunne lade interaktionsdelen af \hat H_3 / Dirac-Hamiltonian'en komme med sammen med den finkornede felt-del (som mit sti-integrale er (på vej til at være) nu) af sti-integralet, og så kan man nemlig sikkert vise, at Dirac-hamiltonianen for et klassisk felt approksimeres af helt det samme sti-integrale (når man altså ser bort fra felt-dimensionerne i det fulde sti-integrale)..!:D ..Det bliver sikkert ret nyttigt/nice at kunne gøre det sådan.:D^^ ..(Og så splitter man altså bare \psi-funktionerne op i egnevektorer af..) Hov vent, de tre \gamma^i -operatorer har dog ikke fælles egenvektorer, jo..:\..  
%...Hov vent, vi kan da godt sagtens splitte op i bare to, kan vi ikke?.. ..Vi kan da i hvert fald sagtens godt, som jeg lige foreslog (men da tænkte jeg noget lidt andet), få potentialedelen af H_3 med ind i den indre ekspansion alligevel, for det er jo bare også dele den op i to, voilà! Og hvad med den kinetiske del..? ..Den bør jo kommutere med det hele, ikke? Jo.. ..He, og så nemt var det..x)..
%..Ej, inden jeg gik ind og skrev her igen (som jeg altså gjorde her ti i otte), så fik jeg endelig kigget Path Integral-kapitlet helt igennem i Hall *(hvilket jeg i øvrigt gjorde, fordi jeg ville se, om man ikke fra de ligninger i det kapitel kunne konkludere, at den tidsafledte i stiintegralet kan begrænses (hvilket jeg umiddalbart tror (også nu), at de må kunne gøre, hvis ikke man kan finde et simplere argument)), og jeg er altså virkelig spændt på min idé her til at kunne få stiintegralet til at blive så.. ja, simpelt.. Hvad jeg jo i hvert fald håber, jeg kan. Jeg er ikke helt sikker på endnu, hvordan eller om jeg får brug for det, men.. Tjo, jeg \emph{får} vel brug for det, for det vil jo helt sikkert gøre L.-inv.-argumentationen lettere. Og jeg kunne altså læse mig til, at det især er stiernes ikke-kontinuerte opførsel, der er et kæmpe problem for at.. "rigorisere," lad os bare kalde det det, path integral-formalismen. Og så er det jo bare totalt spændende, at jeg nu har en idé, hvor sådanne felt-integraler måske kan gøres meget mere nede på jorden (og målelige..).. (..!..) ..Så ja, det var bare lige det jeg vil sige; at jeg altså er ret spændt på disse tanker.. (Klokken 25 over otte.)

%(06.03.22) (Kl. halv fire.) Ah, nu har jeg endelig styr på L-inv.-argumenterne (mener jeg)..!^^ Jeg var ude at gå en tur omkring middag, hvor jeg fik styr på, hvordan man kan argumentere for Lorentz-invarians af en teori, før man eliminere gaugen, hvis man kan vise at det konvergerer. Hertil skal jeg faktisk ikke bruge det med den tidsafledte. Og ja, i forhold til det jeg skrev i går aftes lige her ovenfor, så kom jeg også frem til senere i går, at pointen i, at mine argumenter kan blive rigide, jo bare ligger i, at jeg (om alt går vel) kan vise, at de approximere en selv-adjungerende Hamiltonian. Det er der, muligheden for noget rigidt kommer fra. Anyway, men jeg kom så nemlig frem til, der tidligere, at man bare skal sørge for, at de individuelle (\omaga, k)-bidrag konvergerer (punktvist --- og til noget Lorentz-invariant, self.), og hvis man så ved at dynamikken konvergerer (nemlig f.eks., hvis den approksimerer enteori med en selvadjungeret Hamilton-operator bdre og bedre), så følger det, at sti-integralerne konvergere (i hvert af de inertial-systemer, man kigger på), når man tager flere og flere (\omega, k)-bølger med, hvorved man altså må kunne stoppe ved en hvis grænse og holde sig indenfor en given \varepsilon. Og fordi bidragene konvergerer punktvis, og at dynamikken konbvergerer i alle inertialsystemer, så må dynamikken også konvergere til det samme.. Hm, og lade mig lige udtrykke dette en anelse mere præcist.. ..Ah, men det handler bare om, at man ser på en kreds af Lorentz-transformationer og tidsudviklinger (hvor Lorentz-transomationerne forresten er ret lette at difinere, og det er også ret let at vise, at de er norm-bevarnede/unitære). Jep, og så får man altså, at denne kreds giver det samme begge veje rundt (nemlig det samme som man startede med, hvis man vælger at gå hele vejen rundt (men man kan også bare gå fra punkt A til punkt B på to forskellige måder)). Bemærk, at idet vi netop viser, at vi kan stoppe ved et vist højt \omega, så kan vi også lade tidsintervallerne i stiintegralet gå mod 0, uagtet at vi kun ender med at integrere til en \omega_{max}, hvorved det så er let at se, at vi kan lade \psi-dynamikken nærme sig den eksakte Dirac-dynamik (for det givne klassiske felt --- hvilket \emph{vil} være et eksakt (eksisterende) klassisk felt, da det jo så kun betår af en endelig sum af (\omega, k)-bølger). Okay. Og nu var jeg så også ude på endnu en god gåtur (hvor vejret virkeligt nåede at blive godt..!), hvor jeg endeligt fik ordentligt styr på næste skridt også. Min idé er nu at argumentere for, at dynamikken af differentialligningen i Hilbert-rummet, inden vi har elimineret gauge'en, i.e. den ligning det svarer til, hvad jeg ovenfor her har kaldt \hat H', vil være kontinuer i nabolaget omkring mine specialle løsninger, i den forstand at løsninger med en lille forskydning i A_{\parallel, \boldsymbol{k}}-momentummerne stadigvæk approksimativt vil følge den samme dynamik på et givent tidsinterval. Dette vil jeg ikke selv gå i dybden med at vise, men bare posulere det, ligesom. Og ja, så følger det altså, at der er faktiske vektorer i det udvidede Hilbert-rum (i.e.\ inden gauge-elimination), der, når de følger differentialligningen for \hat H', vil konvergerer til noget, der kan lægge arbitrært tæt på, hvad \hat H foreskriver (altså den \emph{efter} gauge-eliminationen, hvis denne er selvadjungeret, hvilket jeg jo antager (inden jeg prøver at vise det på sigt)), hvis man kigger på ikke-gauge-dimensionerne, og hvor bølgerne i gauge-dimensionerne altså også kommer til at ende med, stadig at lægge tæt på mine specialle løsninger (fordi dynamikken altså er (/antages at være) kontinuert i nabolaget). Og når vi så har den diskretiserede (og begrænsede) version af \hat H', så vil dennes dynamik tilnærme sig den underlæggende differentialligning for \hat H. Og da vi har vist, at $\hat H'$'s dynamik er Lorentz-invariant, når bare den konvergerer, og fordi den jo \emph{vil} konvergere her, antaget at \hat H er selvadjungeret, så får man, at disse vektorer --- der følger $\hat H$'s dynamik arbitrært godt, når A_{\parallel, \boldsymbol{k}}-momentummerne går mere og mere mod delta-funktioner (for start-vektoren og for alle andre tidsudnit) --- er udvikler sig på Lorentz-invariant vis. Og ja, da de nærmer sig løsningerne af \hat H, så vil \hat H altså dermed være Lorentz-invarant (givet at den er selvadjungeret). Hurra.:) 
%..Jeg er også kommet til at tænke på, at hvis nu jeg kan hævde, at jeg hermed har en strategi for at løse Yang-Mills-teori-matematikproblemet, så kunne dette måske være en vildt god måde hurtigt at få folk, og matematikkere måske især, op på sæderne..:) ..Jeg tror så faktisk, at jeg lidt af den grund lige vil sørge for i det mindste at forklare min løsningsstrategi (bare med ord mest) i et appendiks.  
%...Jeg kan også lige nævne, at jeg for længst har fundet på en bedre måde at forkorte mine bra/ketter på, og at jeg også har fundet på, at hvis jeg bytter om på \hat I_Q og \hat I_P, så kan jeg sikkert for at pænere udtryk i sidste ende, så det vil jeg prøve at gøre. ..Eller så tror jeg lige, jeg vil tage en velfortjent pause^^ (også selvom meget af min seneste gåtur også var meget en pause^^). 
%(07.03.22) Jeg behøver faktisk ikke at vise/argumentere for (hvilket jeg nemlig ikke gjorde helt godt nok før), at den forskrevne L.-transformation er norm-bevarende, for man kan sådan set bare gange en normeringsfaktor på som en del af transformationen, \emph{hvis} nu den skulle vise sig ikke at være det. Det er let at se, at man så må få den omvendte faktor tilbage, når man transformerer anden gang i kredsen (da tidsudviklingen er norm-bevarende, og fordi integralerne bliver identiske i begge ben af kredsen). Og hermed så tror jeg altså, jeg har alle argumenterne, der skal til. Nå ja, og angående konjunktion, så argumenterer jeg bare ud fra overgangsmatricen/-operatoren, nemlig ved at se at alle overgange må få de samme amplituder før og efter konjugering (hvis man nemlig sammenligner med et Fock-rum af antisymmetriske flerpartikelsbølgefunktioner (før konjugeringen)). Og hermed mangler jeg så bare lige, at få styr på de eksakte argumenter, når jeg når til \square^2\phi-argumentet, men det får jeg bare styr på, når jeg når til det.:) (Og bemærk, at inden da så har jeg altså allerede argumenteret for, at løsningerne løser differentialligningen, som min nuværende argumenter og opbygget). I går aftes kom jeg også frem til (og det var i øvrigt i sengen, jeg kom frem til det omkring det normbevarende), at jeg godt bare kan lade \hat P være \hat P, og så bare nøjes med at simplificere og begrænse V og C. Og så kan jeg nemlig udføre Gauss-integrationen eksakt. I øvrigt skal det fulde hilbert rum (inden gauge elimination) være et endeligt antal lattice-punkter, for vi får fra selvadjungeretheden af \hat H, at vi kan tilnærme den arbitrært godt med et endeligt antal harmoniske oscillatorer (plus fermion-Hilbert-rummet), når dette antal altså bare er stort nok, givet en vis maksimal fejl/\varepsilon. ..Godt! Så er det bare at gøre det hele.:)^^
%*...Ah, jeg kan sikkert forresten selv godt argumentere for kontinuiteten af løsninger i nabolaget af mine specialle løsninger, hvis jeg lader C starte med at være begrænset. (Måske.:)) 

(07.03.22) I have some notes (in Danish) out in the comments before this paragraph, explaining how I should proceed from now. Let me make a new subsection for the sake of navigation and continue from there.

\subsubsection{Continuation of the last subsection (and almost a restart) (07.03.22)}

We have
\begin{align}
\begin{aligned}
	\textbf{H} = \textbf{H}_{1} \otimes \textbf{H}_{2}\ \mathrm{*}(\otimes\ \textbf{H}_3)
\end{aligned}
\end{align} 
where $\textbf{H}_{1}$ *($\otimes\ \textbf{H}_{2}$) is $L^2(\mathbb{R}^D)$ *($= L^2(\mathbb{R}^{D_1}) \otimes L^2(\mathbb{R}^{D_2})$). .\,.\,Hm, I want actually need the simplified $\hat Q$ so why bother. And the $\hat P_j$s is now taken to be the normal momentum operators (with $j\in\{1, \ldots, D\}$). I think, by the way, that I will let $\boldsymbol{q}$ be bounded by $A$ instead of $L/2$ for the simplified operators. .\,.\,Hm, but we would like to have.\,. something like
%\begin{align}
%\begin{aligned}
%	\ket{\boldsymbol{p}_1, \boldsymbol{p}_2, e_3} = \frac{1}{\sqrt{N^{D_1 + D_2}}} 
%		\sum_{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3}
%		e^{i \boldsymbol{p}_1 \cdot \boldsymbol{q}_1} 
%		e^{i \boldsymbol{p}_2 \cdot \boldsymbol{q}_2} 
%%		e^{i \boldsymbol{p}_1 \cdot \boldsymbol{q}_1 + i \boldsymbol{p}_2 \cdot \boldsymbol{q}_2} 
%		\ket{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3} ,
%%	\label{ket_p_01}
%\end{aligned}
%\end{align} 
%\begin{align}
%\begin{aligned}
%	\ket{\boldsymbol{q}_1, \boldsymbol{q}_2, e_3} = \frac{1}{\sqrt{N^{D_1 + D_2}}} 
%		\sum_{\boldsymbol{p}_1, \boldsymbol{p}_2, e_3}
%		e^{-i \boldsymbol{q}_1 \cdot \boldsymbol{q}_1} 
%		e^{-i \boldsymbol{q}_2 \cdot \boldsymbol{q}_2} 
%%		e^{i \boldsymbol{p}_1 \cdot \boldsymbol{q}_1 + i \boldsymbol{p}_2 \cdot \boldsymbol{q}_2} 
%		\ket{\boldsymbol{p}_1, \boldsymbol{p}_2, e_3} ,
%\end{aligned}
%\end{align} 
\begin{align}
\begin{aligned}
	\braket{\boldsymbol{q}, \psi | \boldsymbol{p}, \psi} =
		e^{i \boldsymbol{p} \cdot \boldsymbol{q}} \,.\,. 
\end{aligned}
\end{align} 
Hm, why not keep $\hat P$ simplified, and then.\,. Hm, wait.\,. \ldots Hm, the problem is that if I simplify, then I need to show that the error of the Trotter expansion doesn't grow for fixed $M$, when $\hat P_B$ goes to $\hat P$.\,. \ldots Ah wait, maybe I just need the $\hat I_P$ approaches $\hat I$ (point-wisely), so when I have $M$ $\hat I_P$ rather than $M$ $\hat I$, then the error of this replacement will go to 0 as $\hat I_P \to \hat I$ (for fixed $M$).\,:) .\,.\,Nice. .\,.\,Yes, cool. Okay, so all I need to do is actually just to introduce the $\hat I_Q$ and $\hat I_P$ and insert these (and letting them tend to $\hat I$ afterwards) in the Trotter expansion instead of $\hat I$ (and I should also still ``simplify'' $\hat V$ $\hat C$, which is something I can just keep throughout the derivation of the path integral).  

Let me actually just do the path integral derivation first, and then find out exactly what the definitions should be afterwards. (And I'll also figure out whether to divide the Hilbert space in two or three then.) We have (with definitions that I am working out)
\begin{align}
\begin{aligned}
	\bra{\psi'} e^{-i \hat H t} \ket{\psi}
	=&\,
	\lim_{M \to \infty}
		\bra{\psi'} (
			e^{-i  \hat H_{1} \delta t}
			e^{-i  \hat H_{2} \delta t}
		)^M
		\ket{\psi}
	\\=&\,
	\lim_{M \to \infty} \lim_{\,\,\hat I_Q = \hat I_P\, \to\, \hat I\,}
		\bra{\psi'} \hat I_P (
			e^{-i  \hat H_{1} \delta t}
			\hat I_Q
			e^{-i  \hat H_{2} \delta t}
			\hat I_P
		)^M
		\ket{\psi}
\end{aligned}
\end{align} 
If we let the summations and limits be implicit, then this can be written on the form (/ we see that the inner expression can be written as) %..no.. *yes, why not? The expression is still defined without the summation, so why not express it like that instead?. 
\begin{align}
\begin{aligned}
	\braket{\psi' | \psi_{\boldsymbol{p}_{M+1}, e_{M+1}'}} 
%		\bra{\psi_{\boldsymbol{p}_{M+1}, e_{M+1}}}
			T^1_{M}T^2_{M} T^1_{M-1}T^2_{M-1} \cdots T^1_{1}T^2_{1}
		\braket{\psi_{\boldsymbol{p}_{1}, e_{1}} | \psi},
\end{aligned}
\end{align} 
where 
\begin{align}
\begin{aligned}
	T^1_{m} =&\,
		\bra{\psi_{\boldsymbol{p}_{m+1}, e_{m+1}'}}
			e^{-i  \hat H_{1} \delta t}
		\ket{\psi_{\boldsymbol{q}_{m}, e_{m}}} \\
	T^2_{m} =&\,
		\bra{\psi_{\boldsymbol{q}_{m}, e_{m}}}
			e^{-i  \hat H_{2} \delta t}
		\ket{\psi_{\boldsymbol{p}_{m}, e_{m}'}}.
\end{aligned}
\end{align} 
.\,.\,Hm, and will $H_{fermion}$ get us something neat wrt.\ the $\ket{e_m}$s.\,.\,? \ldots yes, since it will commute with the rest, we can.\,. hm, draw the $\exp(-i H_{i, ferm.} \delta t)$ out, but can we then do a reverse Trotter in the end to get $\exp(-i (H_{1, ferm.} + H_{2, ferm.}) t)$ back.\,.\,? .\,.\,Except now, $\hat H_{ferm}$ will be a time-dependent operator at this point.\,. .\,.\,Hm, so I need a time-dependent version of the Trotter product formula in this case.\,. \ldots Hm, the alternative could of course be to go back to a three-part expansion.\,. .\,.\,Hm, or maybe I should just assume without proof that this expansion applies for all bounded versions of $\hat H_{ferm}$.\,. .\,.\,Oh wait, It actually won't be hard to argue, that it is the case. Because if you just argue, that the differential equation can be approximated by ``simplified'' versions of the potential, then when you do the Trotter expansion finely enough, at some point it'll consist of finitely many Trotter expansions on constant potentials. We know that the expansion will then apply for each of these, and therefore, it must apply to the whole as well. Nice. .\,.\,I almost feel like I should do this for a living.\,.\,;) (.\,.\,But only almost.\,.\,;))

Okay, continuing on, we have
\begin{align}
\begin{aligned}
	T^1_{m} =&\,
		\bra{\psi_{\boldsymbol{p}_{m+1}, e_{m+1}'}}
			e^{-i  \hat H_{1} \delta t}
		\ket{\psi_{\boldsymbol{q}_{m}, e_{m}}} 
	\\=&\,
		\bra{\psi_{\boldsymbol{p}_{m+1}, e_{m+1}'}}
			e^{-i  \hat H_{B1} \delta t} e^{-i  \hat H_{F1} \delta t}
		\ket{\psi_{\boldsymbol{q}_{m}, e_{m}}} 
	\\=&\,
		e^{-i  H_{B1}(\boldsymbol{p}_{m+1}, \boldsymbol{q}_{m}) \delta t} 
		\bra{\psi_{\boldsymbol{p}_{m+1}, e_{m+1}'}}
			e^{-i  \hat H_{F1} \delta t}
		\ket{\psi_{\boldsymbol{q}_{m}, e_{m}}} 
	\\=&\,
		e^{-i  H_{B1}(\boldsymbol{p}_{m+1}, \boldsymbol{q}_{m}) \delta t} 
		\braket{\boldsymbol{p}_{m+1} | \boldsymbol{q}_{m}}
		\bra{e_{m+1}'}
			e^{-i  \hat H_{F1}(\boldsymbol{q_m}) \delta t}
		\ket{e_{m}} 
	\\=&\,
		e^{-i  (H_{B1}(\boldsymbol{p}_{m+1}, \boldsymbol{q}_{m}) - \boldsymbol{p}_{m+1} \cdot \boldsymbol{q}_m) \delta t} 
		\bra{e_{m+1}'}
			e^{-i  \hat H_{F1}(\boldsymbol{q_m}) \delta t} 
		\ket{e_{m}}  \,.\,.
	\label{T1_m_calculation_01}
\end{aligned}
\end{align} 
Hm, this require me to show how these steps work in advance, and let me also mention that $\hat H_{F1}$ here does double duty (which is perhaps not too great.\,.).\,. .\,.\,Hm, I could divide $\hat H_{F}$ into.\,. hm, into two parts, $\hat H_F$ and $\hat H_I$, and then the labels will also make more sense.\,. (And then the $e$ vectors could be eigenvectors of $\hat H_F$.\,.) .\,.\,Hm, and I should remember that $\hat H_F$ and $\hat H_I$ commute, even though it might seem a bit counterintuitive at a glance.\,. .\,.\,Oh wait, no. They of course don't commute.\,. (It is with $\hat V$ that $\hat H_F$ (and $\hat H_I$) commutes.\,.)

.\,.\,Hm, going from $\hat H_{F1}$ to $\hat H_{F1}(\boldsymbol{q_m})$ in the relevant step above must only be an approximation when the $\ket{\boldsymbol{q}}$s are simplified.\,. %Hm, let me take a break now (i.e. a walk of course) and think about these things for a bit..

\ldots\ I took a walk, just now, where I realized again that I don't need to simplify.\,. Oh wait, that actually maybe doesn't matter.\,. .\,.\,Okay, I have found another solution where I let don't insert the approximated $\hat I_P$ (only $\hat I_Q$; and do it more similarly to Hall), but no, it is probably much easier to do it like I wanted to before. The point of the other proof is to use that $\hat C$ is bounded to show self-adjointness. $\hat C$ should by the way still be bounded in any case. 

.\,.\,Let me just look up if $\exp(-i (A + B) t) = \exp(-i A t) \exp(-i B t)$ for two commuting operators (or a similar theorem, I can use).\,. \ldots Hm, it actually also follows from the Trotter expansion (as well as proposition 7.16 in Hall).\,. \ldots I can't find the proposition I'm looking for in Hall, but it's nice to know that it's easy to prove from Trotter. 

I'm still going to ``simplify'' the $\ket{\boldsymbol{q}}$s, so the step going to the second last (i.e.\ the fourth) line in eq.\ (\ref{T1_m_calculation_01}) is only approximately true; we cannot pull $\ket{\boldsymbol{q}}$ out of the matrix element exactly.\,. .\,.\,Hm, what to do then? Do I then add an error to the expression (and keep account of the $2M$ errors coming from this), or.\,.\,? .\,.\,Hm, I guess this should be possible, but it seems a bit.\,. much.\,. .\,.\,Ah, why don't I just assume that $H_F$ is ``simplified''/discretized the same way, namely such that it does indeed leave the $\ket{\boldsymbol{q}}$s alone?\,\texttt{:D} Okay, I should do that.\,. .\,.\,Yes, and $\hat V$ and $\hat C$ should of course be discretized/simplified the same way. Okay.\,. 

.\,.\,And now, eq.\ (\ref{T1_m_calculation_01}) will actually be true, right? .\,.\,Hm, except that going from $\hat H_B$ to $H_B(\boldsymbol{p}, \boldsymbol{q})$ is currently an approximation (.\,.\,i.e.\ with the current definitions).\,. .\,.\,And we can't pull $\bra{\boldsymbol{p}}$ through it, not exactly.\,. .\,.\,Hm, is that why I should rather do the other proof, I had in mind coming back from my walk.\,.\,? .\,.\,Hm, but is $\ket{\boldsymbol{q}}$ is still simplified, then it will get messy anyway.\,. .\,.\,Hm, what happens, if you insert $\hat I_P$ around the true $\hat P$.\,.\,? .\,.\,Then you'll get a non-diagonal operator.\,. .\,.\,Hm, should I then just basically do what I thought about for $\hat H_F$ and keep account of the errors (coming from going to the third line of eq.\ (\ref{T1_m_calculation_01})).\,.\,? .\,.\,Hm yeah, I will just get exactly $M$ errors, which.\,. Hm, and I'll get errors from $\braket{\boldsymbol{p}_{m+1} | \boldsymbol{q}_{m}}$ as well, which are perhaps harder to deal with.\,.\,:\textbackslash\,.\,. .\,.\,Hm, but if I do something similar to Hall, then I should just end up with a small integral (of $\boldsymbol{q}$ in the volume of $\delta q^D$), which I can then just pull out and deal with later.\,. right.\,.\,? .\,.\,Right, that's perhaps not such a bad idea.\,. .\,.\,And then as I send $\hat I_Q \to \hat I$,\,.\,. wait.\,. This makes me realize that the $\ket{\boldsymbol{q}}$s doesn't have to follow the discretization of $\hat V$, $\hat C$ and $\hat H_I$.\,. .\,.\,right, that's good to note.\,. Ah, and then all the errors will tend to 0, when I send $\hat I_Q \,(= \hat I_P)\, \to\, \hat I$. .\,.\,Or alternatively, one could do what I had just in mind, if it makes it a bit easier to rigorize completely, but I think this solution (i.e.\ this argument) can be rigorized as well. 

.\,.\,Hm, or maybe the solution closer to the approach in Hall is actually the prettiest one.\,. .\,.\,It also divides the problem up a bit, which is kinda nice.\,. .\,.\,Yeah, maybe I'll actually do that instead. .\,.\,For a more rigor proof, that would also probably be the preferred approach anyway. And thus it will only make it easier for everyone, if I also follow that approach.\,. 
\ldots Or maybe I will actually do a mix of the two, in a way: Maybe I'll still divide the problem up like so, but I might then still argue via the simplified $\ket{\boldsymbol{p}}$s.\,. %(Kl. kvart i seks.)
.\,.\,Yeah, I'll do that. 

%(Kl. fem over syv)
\ldots\ On the other hand, It might be better for me to just approximate $\hat P$ with the simplified version everywhere in the Trotter expansion, and then argue that the error will tend to 0 when $\hat P_B$ (or whatever we will call it) tends to $\hat P$.\,. So let me make sure that I know how that argument goes.\,. .\,.\,Hm, isn't it just that when a vector is send to an almost-parallel vector by an operator, then it must be approximately equal to an eigenvector / virtual eigenvector of that operator.\,. (And therefore for instance the two versions of $\exp(-i \hat P)t$ and so on will also have eigenvectors (virtual or not) that are close to each other.\,.) .\,.\,(And if the also have approximately the same eigenvalue.\,.) .\,.\,Hm, yeah.\,. I should formulate this more precisely and then either assume it to be true, find the theorem/proposition somewhere or show it from other known stuff. And I'll then let my whole derivation rely on this.\,. .\,.\,Hm, but didn't I read something earlier in Hall, that might help show this.\,?\,.\,. .\,.\,Hm, proposition 7.15 in Hall.\,. .\,.\,Right, that's it.\,. .\,.\,Oh no, I need it the other way around.\,. .\,.\,Hm, but maybe it actually follows from this proposition.\,. \ldots Hm, heuristically one can argue that it must be so by taking a vector with to substantial parts in two different spectral subspaces, or rather in the range of these subspaces, and if the intervals are separated substantially, then it is easy to see that the image vector will (substantially) not be parallel to the original vector.\,. (.\,.\,So constructing a vector partly from two different spectral subspace ranges will put a lower limit of the angel obtained from the operation.\,.) (.\,.\,And here we of course use the orthogonality of the two ranges and the invariance of them under the operator.\,.) .\,.\,And since the eigenvectors *(together with their eigenvalues) converge to each other (point-wisely), so must the eigenvectors *(and their eigenvalues) of any functions of the operator (such as $\exp(-i \hat A t)$). 

.\,.\,Okay, so I will actually just do all the (small constant integer times $M$) approximations and then keep track of the (small number times $M$) error, and argue at last, that these errors must tend to 0 or that they must tend to $\hat I$, depending on how I define them, when I let the operators $\hat I_Q$, $\hat I_P$ and $\hat P_B$ (or what to call it) tend to their respective limits.\,. %(Kl. otte.)

(08.03.22) Last evening I realized that the only errors I get (now that everything on the inside of the expansion is discretized) are the errors at the ends for applying $\hat I_Q$/$\hat I_P$ and then from integrating rather than summing the Gaussian functions, and that doing so will only be the difference between two unitary operators.\,! So.\,. Hm, let me actually think about what exact argument I'm gonna use.\,. .\,.\,Hm, that the error coming from each.\,. .\,.\,Hm, I have to take into account that these unitary difference operators are not constant when we approach the limits (for all I know in this moment, at least).\,. .\,.\,Hm no, I might have to quantify the relevant error.\,. .\,.\,Hm, no the argument is actually much more complicated than I anticipated yesterday (evening).\,. .\,.\,Hm, let's see, we have a unitary operator as a function the bounds/discretization.\,. .\,.\,which converges for each transition between two $\ket{\boldsymbol{q}}$s, which do, however, also change when going to the limit.\,. .\,.\,But one can then show, that the transition between any two constant step functions (and other functions) converges.\,. .\,.\,Hm, actually still probably a good idea to then divide the problem in two, by the way.\,. Hm, or.\,.(?) .\,.\,Hm, maybe not.\,. I guess we just need to show that the two unitary operators converges to each other. Because then we can just add the inverse difference operator (unitary) at each point beforehand and only get an error that converges to 0.\,. .\,.\,So first we can find a sufficient bound on $\hat I_{Q/P}$ for a given $\varepsilon$, and then we can find a sufficient high bound on the inverse difference operator given $\varepsilon$ --- or $\varepsilon/2$ rather, and then we can choose $\hat I_{Q/P}$ wrt.\ $\varepsilon/2$ as well --- and make sure to also choose one that is higher than the $\hat I_{Q/P}$ bound. Afterwards we can crank the $\hat I_{Q/P}$ bound up to match the difference operator bound exactly.\,. right.\,.\,? (And if this indeed works, then we get our discretized Trotter with summation replaced for integration (that we want).\,.) .\,.\,Yeah, or rather, you can choose both independently to match the error and then raise the lower to the other.\,. Hm, but let me think if there's an easier argument.\,. \ldots Hm, but why do I need this at all?\,.\,. Can't I just keep the $\boldsymbol{p}$s in the action integral/sum and then get the limit later.\,.\,? .\,.\,Yeah, and then when $\hat P_B \to \hat P$, we will just see that the expression converges to the Lagrange action.\,. .\,.\,Right, that seems legit.\,. And if so, this is much easier, so even if.\,. the intermediary result.\,. Hm no, the intermediary result about $\braket{\boldsymbol{q}' | \exp(-i \hat H_{1B} t) | \boldsymbol{q}}$ will just follow from the end result when the other parts of the Hamiltonian is taken to be trivial. .\,.\,Or maybe not, but it doesn't matter anyway: It is far better for me to just write up the action integral \emph{with} the $\boldsymbol{p}$s, and then when $\hat P_B \to \hat P$, we get the desired result anyway. .\,.\,And one should note, that I can let $\hat P_B \to \hat P$ while keeping $M$ constant, in with case the result will converge to Trotter$(M, \exp(-i\hat H t))$, where $\hat H$ uses the standard (unbound) $\hat P$. 

Cool, and then we will get 
\begin{align}
\begin{aligned}
	T^1_{m} =&\,
		e^{-i  (H_{B1}(\boldsymbol{p}_{m+1}, \boldsymbol{q}_{m}) 
			- \boldsymbol{p}_{m+1} \cdot\, \boldsymbol{q}_m) \delta t} 
		\bra{e_{m+1}'}
			e^{-i  \hat H_{F1}(\boldsymbol{q_m}) \delta t} 
		\ket{e_{m}} 
%	\label{T1_m_01}
\end{aligned}
\end{align}
exactly (not an approximation). And for $T^2_m$, we'll get
\begin{align}
\begin{aligned}
	T^2_{m} =&\,
		\bra{\psi_{\boldsymbol{p}_{m}, e_{m}}}
			e^{-i  \hat H_{2} \delta t}
		\ket{\psi_{\boldsymbol{q}_{m}, e_{m}'}} 
	\\=&\,
%		\bra{\psi_{\boldsymbol{p}_{m+1}, e_{m+1}'}}
%			e^{-i  \hat H_{B1} \delta t} e^{-i  \hat H_{F1} \delta t}
%		\ket{\psi_{\boldsymbol{q}_{m}, e_{m}}} 
%	\\=&\,
%		e^{-i  H_{B1}(\boldsymbol{p}_{m+1}, \boldsymbol{q}_{m}) \delta t} 
%		\bra{\psi_{\boldsymbol{p}_{m+1}, e_{m+1}'}}
%			e^{-i  \hat H_{F1} \delta t}
%		\ket{\psi_{\boldsymbol{q}_{m}, e_{m}}} 
%	\\=&\,
%		e^{-i  H_{B1}(\boldsymbol{p}_{m+1}, \boldsymbol{q}_{m}) \delta t} 
%		\braket{\boldsymbol{p}_{m+1} | \boldsymbol{q}_{m}}
%		\bra{e_{m+1}'}
%			e^{-i  \hat H_{F1}(\boldsymbol{q_m}) \delta t}
%		\ket{e_{m}} 
%	\\=&\,
		e^{-i  (H_{B2}(\boldsymbol{p}_{m}, \boldsymbol{q}_{m}) 
			+ \boldsymbol{p}_{m} \cdot\, \boldsymbol{q}_m) \delta t} 
		\bra{e_{m}}
			e^{-i  \hat H_{F2}(\boldsymbol{q_m}) \delta t} 
		\ket{e_{m}'}.
	\label{T2_m_01}
\end{aligned}
\end{align}
So for our expression,
\begin{align}
\begin{aligned}
	\braket{\psi' | \psi_{\boldsymbol{p}_{M+1}, e_{M+1}'}} 
			T^1_{M}T^2_{M} T^1_{M-1}T^2_{M-1} \cdots T^1_{1}T^2_{1}
		\braket{\psi_{\boldsymbol{p}_{1}, e_{1}} | \psi},
\end{aligned}
\end{align} 
we'll get
\begin{align}
\begin{aligned}
	T^1_{M} \cdots T^2_{1} 
	=&\,
		e^{-i  
			\sum_{m=1}^{M} (
				H_{B1}(\boldsymbol{p}_{m+1}, \boldsymbol{q}_{m}) + 
				H_{B2}(\boldsymbol{p}_{m}, \boldsymbol{q}_{m}) -
				(\boldsymbol{p}_{m+1} - \boldsymbol{p}_{m}) \,\cdot\, \boldsymbol{q}_m 
			) \delta t
		} \,.\,.\ U(\hat H_{F}; \boldsymbol{q}_1, \ldots, \boldsymbol{q}_M)\,.\,.
\end{aligned}
\end{align} 
Hm, something must be wrong since the.\,. No, never mind.\,. .\,.\,Hm, ah, the Gaussian integration does not care about the sign on term that linear in $\boldsymbol{p}$, so we can actually just do the two integrations with $H_{B1}$ and $H_{B2}$ separately. So that should give us the right thing. Let us therefore look at the fermionic part.\,. .\,.\,Hm, we can just do the sum over all $e_m$s here, by which the expression will become
\begin{align}
\begin{aligned}
	%\prod_{m=M}^{1} e^{-i  \hat H_{F2}(\boldsymbol{q_m}) \delta t} 
	e^{-i  \hat H_{F2}(\boldsymbol{q_M}) \delta t} \cdots 
	e^{-i  \hat H_{F2}(\boldsymbol{q_1}) \delta t}.
\end{aligned}
\end{align} 
Cool, and now we are actually where we want to be before the $\hat P_B \to \hat P$ argument.\,:) Now I should just take a moment to choose the right names for everything so far.\,. 

Hm, but I guess I can't integrate over $\boldsymbol{p}_{M+1}$ and $\boldsymbol{p}_1$.\,. .\,.\,Should I then insert $\boldsymbol{q}_{M+1}$ and $\boldsymbol{q}_0$.\,.\,? .\,.\,Hm, and I could then let $\boldsymbol{q}_{M+1}$ go into the exponential with $H_{B1}$ and $\boldsymbol{q}_{0}$ go into the one with $H_{B2}$.\,. .\,.\,Hm, no.\,. .\,.\,Oh right, yes.\,. .\,.\,Hm, this should not be hard to figure out.\,. .\,.\,Oh right, now I think I know.\,. .\,.\,No, not quite yet.\,. .\,.\,Ah, now I know why: I must have the wrong expression. I really could not understand, why it was so hard for me.\,\texttt{xD} .\,.\,Hm, let's see, I should be able to gather the terms like
\begin{align}
\begin{aligned}
%	T^1_{M} \cdots T^2_{1} 
%	=&\,
		e^{-i  
			\sum_{m=0}^{M} (
				H_{B1}(\boldsymbol{p}_{m+1}, \boldsymbol{q}_{m}) + 
%				\boldsymbol{p}_{m+1} \cdot\, (\boldsymbol{q}_{m+1} - \boldsymbol{q}_{m}) +
				H_{B2}(\boldsymbol{p}_{m}, \boldsymbol{q}_{m}) +
				\boldsymbol{p}_{m+1} \cdot\, (\boldsymbol{q}_{m+1} - \boldsymbol{q}_{m})
			) \delta t
		},
%\,.\,.\ U(\hat H_{F}; \boldsymbol{q}_1, \ldots, \boldsymbol{q}_M)\,.\,.
\end{aligned}
\end{align} 
and that's if I do insert $\boldsymbol{q}_{M+1}$ and $\boldsymbol{q}_0$ (ket-bras) at the ends. .\,.\,Right, of course.\,:) .\,.\,And this can then also be written as 
\begin{align}
\begin{aligned}
%	T^1_{M} \cdots T^2_{1} 
%	=&\,
		e^{-i  
			\sum_{m=0}^{M} (
				H_{B}(\boldsymbol{p}_{m+1}, \boldsymbol{q}_{m}) + 
				\boldsymbol{p}_{m+1} \cdot\, (\boldsymbol{q}_{m+1} - \boldsymbol{q}_{m})
			) \delta t
		}.
%\,.\,.\ U(\hat H_{F}; \boldsymbol{q}_1, \ldots, \boldsymbol{q}_M)\,.\,.
\end{aligned}
\end{align} 
.\,.\,Oh wait, it's actually
\begin{align}
\begin{aligned}
%	T^1_{M} \cdots T^2_{1} 
%	=&\,
		e^{-i  
			\sum_{m=1}^{M} (
				H_{B1}(\boldsymbol{p}_{m+1}, \boldsymbol{q}_{m}) + 
%				\boldsymbol{p}_{m+1} \cdot\, (\boldsymbol{q}_{m+1} - \boldsymbol{q}_{m}) +
				H_{B2}(\boldsymbol{p}_{m}, \boldsymbol{q}_{m}) +
				\boldsymbol{p}_{m+1} \cdot\, (\boldsymbol{q}_{m+1} - \boldsymbol{q}_{m}) +
				\boldsymbol{p}_{1} \cdot\, (\boldsymbol{q}_{1} - \boldsymbol{q}_{0})
			) \delta t
		}.
%\,.\,.\ U(\hat H_{F}; \boldsymbol{q}_1, \ldots, \boldsymbol{q}_M)\,.\,.
\end{aligned}
\end{align}
.\,.\,Which is good; we will get the right result when we do both the Gaussian integrations (which will just have to be done separately, then). .\,.\,Okay, now I can look into revising the names.\,. %..Hm, let me take a midday walk and think about this..

%(Kl. ti over to.)
\ldots\ Okay, I think I have a good idea now of how to structure this whole section. But first, I need to think about how to get/write line four in eq.\ (\ref{T1_m_calculation_01}) in a neat way.\,. 
.\,.\,With my new names, we will probably stand at
\begin{align}
\begin{aligned}
%	T^1_{m} =&\,
		\bra{\boldsymbol{p}, e'}
			e^{-i  \hat H_{11} \delta t} e^{-i  \hat H_{12} t}
		\ket{\boldsymbol{q}, e} 
	=&\,
		e^{-i  H_{11}(\boldsymbol{p}, \boldsymbol{q}) t} 
		\bra{\boldsymbol{p}, e'}
			e^{-i  \hat H_{12} t}
		\ket{\boldsymbol{q}, e} 
	\\=&\,
		\ldots \,.\,.
%		e^{-i  H_{B1}(\boldsymbol{p}_{m+1}, \boldsymbol{q}_{m}) \delta t} 
%		\braket{\boldsymbol{p}_{m+1} | \boldsymbol{q}_{m}}
%		\bra{e_{m+1}'}
%			e^{-i  \hat H_{F1}(\boldsymbol{q_m}) \delta t}
%		\ket{e_{m}} 
%	\\=&\,
%		e^{-i  (H_{B1}(\boldsymbol{p}_{m+1}, \boldsymbol{q}_{m}) - \boldsymbol{p}_{m+1} \cdot \boldsymbol{q}_m) \delta t} 
%		\bra{e_{m+1}'}
%			e^{-i  \hat H_{F1}(\boldsymbol{q_m}) \delta t} 
%		\ket{e_{m}}  \,.\,.
\end{aligned}
\end{align} 
Hm, and we will assume that the $\ket{\boldsymbol{q}}$s are invariant under $\hat H_{12}$.\,. .\,.\,which more precisely means that (in this case with $f=\exp(-i \cdots t)$) we have $e^{-i  \hat H_{12} t} \ket{\boldsymbol{q}, e} = \ket{\boldsymbol{q}, e^{-i  \hat H_{12} t} e}$.\,. \ldots Hm, let me just use a notation where I (only) allow brakets.\,. Hm wait, cause $\hat H_{12}$ is still doing double duty, even when I define $\hat H_{12}(\boldsymbol{q})$ (and the previous expression should actually be $e^{-i  \hat H_{12} t} \ket{\boldsymbol{q}, e} = \ket{\boldsymbol{q}, e^{-i  \hat H_{12}(\boldsymbol{q}) t} e}$).\,. .\,.\,Hm, how about $\hat{\bar H}_{12}(\boldsymbol{q})$.\,. .\,.\,Hm, maybe that would actually work.\,. .\,.\,Hm, and for consistency, I could also label all such bra-kets with their (smaller) Hilbert space.\,. .\,.\,Alright.\,. (And I'll put bars on $\bar H_{1i}$ as well, just for good measure.) .\,.\,I'll stick to the $e$s btw, even though we now could use $\psi$ instead as well. 

Okay, good. Now I should be pretty much ready.\,. %..But let me take a small break before I continue.. (Kl. kvart i tre.)

%(Kl. fem.) Nå det blev så en lang pause, men sådan kan det jo gå, når vejret er så godt. Jeg fik da også lige tænkt på nogle tanker, så jeg nu har endnu bedre styr på det.

\ldots\ I'm gonna make a new subsection and restart the derivation (and definitions).



%\subsubsection{A generalized path integral for finite dimensions (a restart of the above)}
\subsubsection{A generalized path integral for a discretized Hamiltonian (a restart of the above)}

%Let a Hilbert space $\textbf{H}$ be given by 
%\begin{align}
%\begin{aligned}
%	\textbf{H} = \textbf{H}_{1} \otimes \textbf{H}_{2},
%\end{aligned}
%\end{align} 
%where $\textbf{H}_1 = L^2(\mathbb{R}^D)$, and where $\textbf{H}_2$ is some %finite-dimensional 
%Hilbert space %spanned by %..Hm, maybe I \emph{will} use \psi.. ..No.. ..Yeah, actually.. Let me do that.. ..Hm, but let me actually just write \{e_j\} or \{\psi_j\} like in Hall and sum over j..
%with an orthonormal basis $\{\psi_k\}$. 
%Let a Hilbert space $\textbf{H}_1$..
Let %also
$\{\ket{\boldsymbol{q}}\}$ be a set of multidimensional step functions in $L^2(\mathbb{R}^D)$, where $\boldsymbol{q}\in\mathbb{R}^D$ denotes the coordinate vector at the center of the multidimensional steps. Let each entry of $\boldsymbol{q}$ be contained in $Q=\{-A  + (n -1/2) \delta q\}_{n=1}^{N}$ with $N \delta q = A$, and let the width of the steps be $\delta q$ in all $D$ dimensions, such that the step functions stand close and cover all of $[-A, A]^D$, so to speak. Let furthermore each $\ket{\boldsymbol{q}}$ be normalized, which means that their height should be $1/\delta q^D$. We will then also define a set $\{\ket{\boldsymbol{p}}\}$ of simple functions in $L^2(\mathbb{R}^D)$, given by
\begin{align}
\begin{aligned}
	\ket{\boldsymbol{p}} = \frac{1}{\sqrt{N^{D}}} 
		\sum_{\boldsymbol{q}\in Q^D}
		e^{i \boldsymbol{p} \cdot \boldsymbol{q}} 
		\ket{\boldsymbol{q}}.
	\label{ket_p_02}
\end{aligned}
\end{align} 
where each entry of $\boldsymbol{p}$ is contained in $P=\{-\Lambda  + (n -1/2) \delta p\}_{n=1}^{N}$ with $N \delta p = \Lambda$ and $\Lambda = N \pi / 2A$. %*(Not sure about this last equation yet..)
*(No, it \emph{was} $\Lambda = N \pi / A$.) *(I can change this paragraph, by just writing $\{\ket{\boldsymbol{q}}\}_{\boldsymbol{q}\in Q^D}$, $Q= \{-A  + (n -1/2) \delta q\}_{n=1}^{N} \subset \mathbb{R}$ immediately.)

It is clear to see see that $\{\ket{\boldsymbol{q}}\}$ is an orthonormal set, and it is also easy to see that $\{\ket{\boldsymbol{q}}\}$ is orthonormal as well, when using that 
%\begin{align}
%\begin{aligned}
%	
%\end{aligned}
%\end{align} 
$\sum_{\boldsymbol{q}\in Q^D} 
\exp(i (\boldsymbol{p}' - \boldsymbol{p}) \cdot \boldsymbol{q}) 
= N\delta_{\boldsymbol{p}' \boldsymbol{p}}$, 
where $\delta_{ij}$ is the Kronecker delta. And this identity can be shown by noting that expressions on the form $\boldsymbol{p} \cdot \boldsymbol{q}$ take values of\ldots %Let me take a break.. (Kl. syv.)

%(09.03.22) (Kl. ti i elleve.)
(09.03.22) Hm, let's see, $\boldsymbol{p} - \boldsymbol{p}'$ takes values from %$-2\Lambda + 1$ to $2\Lambda - 1$ 
$-2\Lambda + \delta p$ to $2\Lambda - \delta p$ 
in steps of $\delta p$. The wave lengths thus have the form $2\pi / m\delta p$.\,. .\,.\,Hm, and it should be so that a wave length of $2\Lambda$ is exactly $\delta q$.\,. .\,.\,And since.\,. Oh wait, is it $\Lambda$ and not $2\Lambda$.\,.\,? .\,.\,Oh no, it must be $2\Lambda$; that way the solutions approaches each other at the $-\Lambda$-$\Lambda$ boundaries. And since we have $\delta q = A / N$, the minimal wave length of $\boldsymbol{p} - \boldsymbol{p}'$ (in any direction) is just above of $\pi/\Lambda$ (apart from the ``infinite'' wave length). So I want $\delta q = \pi/\Lambda$, meaning $\Lambda = \pi/\delta q = N\pi / A$. Let me change that back above then.\,.  And with this, the wave lengths of $\exp(-i(\boldsymbol{p} - \boldsymbol{p}') \cdot \boldsymbol{q})$ run from.\,. .\,.\,just above $\pi/\Lambda=\delta q$ and to --- apart from the infinite case --- $2\pi / \delta p = 2N\pi/\Lambda = 2N \delta q = 2A$.\,. Good, but then I should also look at $2A / (2\pi/m\delta p)$ and make sure that.\,. Ah, but we have $2A / (2\pi/m\delta p) = 2A / (2A / m) = m$, so the (non-infinite) wave lengths does all indeed divide $2A$. And from there it is easy to see that
$\sum_{\boldsymbol{q}\in Q^D} 
\exp(i (\boldsymbol{p}' - \boldsymbol{p}) \cdot \boldsymbol{q})$ 
vanishes for all but when $\boldsymbol{p}' - \boldsymbol{p}$ is zero on all entries, and thus that  
$\sum_{\boldsymbol{q}\in Q^D} 
\exp(i (\boldsymbol{p}' - \boldsymbol{p}) \cdot \boldsymbol{q}) 
= N\delta_{\boldsymbol{p}' \boldsymbol{p}}$.


Moving on.

*From now on, I will suppress or shorten labels of $\boldsymbol{q}\in Q^D$, $\boldsymbol{p}\in P^D$ in sums and sets and thus make their ranges implicit. *This should be rewritten when I get to it. .\,.\,Hm, perhaps I should just insert it below after the operator definitions.\,. .\,.\,Yeah, let me just do that instead.

*With this identity, it is also easy to show that
\begin{align}
\begin{aligned}
	\ket{\boldsymbol{q}} = \frac{1}{\sqrt{N^{D}}} 
		\sum_{\boldsymbol{p}\in P^D}
		e^{-i \boldsymbol{p} \cdot \boldsymbol{q}} 
		\ket{\boldsymbol{p}}.
	\label{ket_q_02}
\end{aligned}
\end{align}

*In fact, let me just argue for 
$\sum_{\boldsymbol{q}} 
\exp(i (\boldsymbol{p}' - \boldsymbol{p}) \cdot \boldsymbol{q}) 
= N\delta_{\boldsymbol{p}' \boldsymbol{p}}$ 
directly under eq.\ (\ref{ket_p_02}) (by noting that the wave lengths for $\boldsymbol{p}' - \boldsymbol{p}$ are $2A/m$ (when $m\neq 0$), where $m$ runs from $-2N+1$ to $2N-1$. And then I can just list eq.\ (\ref{ket_q_02}) as well as the orthonomality relations directly and refer to an appendix for details.)\\


For the generalized (but discretized) path integral.\,. Hm, I should maybe figure out a good way to refer to this.\,. .\,.\,Ah, but I don't need to limit the section to the discretized version, so let me just leave that out.\,.

For the generalized path integral, we want to look at a Hilbert space $\textbf{H}$ given by
\begin{align}
\begin{aligned}
	\textbf{H} = \textbf{H}_{B} \otimes \textbf{H}_{F},
\end{aligned}
\end{align} 
where $\textbf{H}_B = L^2(\mathbb{R}^D)$, and where $\textbf{H}_F$ is just some separable Hilbert space 
with an orthonormal basis %$\{\ket{\psi}\}_{\psi\in \Psi}$.
$\{\ket{\psi_k}\}%_{k\in I_k}$
$, with indices in some (countable) set $I_k$. The idea is to later on identify $\textbf{H}_{B}$ with a system of $D$ modes of a bosonic field *(where the values of $\mathbb{R}^D$ represent the amplitudes of the field modes) and to identify $\textbf{H}_{F}$, not as a fermionic \emph{field}, but simply as a (separable) Fock space of fermionic particles.\footnote{
	Or to put it more precisely, we want to identify it with a (separable) Fock space of antisymmetric (spinor-valued) wave functions over domains that represent $n$ sets of particle coordinates.
} 
This is where my approach diverges from the common approach of QFT. 

At first, we are going to derive the path integral for certain bounded Hamiltonians %. Specifically, we are going to look at Hamiltionains 
that are also ``discretized'' in the sense that they preserve the subspace spanned by 
%$\{\ket{\boldsymbol{q}} \otimes \ket{\psi}\}_{\boldsymbol{q}\in Q^D, \psi \in \Psi}$ (and also by $\{\ket{\boldsymbol{p}} \otimes \ket{\psi}\}_{\boldsymbol{p}\in P^D, \psi \in \Psi}$). 
$\{\ket{\boldsymbol{q}} \otimes \ket{\psi}\}$ (and also by $\{\ket{\boldsymbol{p}} \otimes \ket{\psi}\}$). We will let $\ket{\boldsymbol{q}, \psi}$ and $\ket{\boldsymbol{p}, \psi}$ denote $\ket{\boldsymbol{q}} \otimes \ket{\psi}$ and $\ket{\boldsymbol{p}} \otimes \ket{\psi}$ respectively. Specifically, we will then look at Hamiltonians on the form
%..Hm, what about using primes when splitting \hat H into two instead..? ..That would actually not be bad.. (I think..) ..Hm, or what about the other way around..? ..No that doesn't help: I feel that it's not very pretty, if I let \hat H_2 include the interaction part as well.. ..Hm, but why don't we just call that \hat H', and then.. Hm, but will it be confusing with the indices of the two Hilbert spaces..? ..Should I just call them H_B and H_F or something..? ..Right, that could work.. ..Okay, let me just do that.:) (So let me change this (from H_1 and H_2) above..) Okay, and then I will name \hat H_{F1} + \hat H_{F2} as \hat H' instead in the following equation (and from there on).
\begin{align}
\begin{aligned}
	\hat H = \sum_{j=1}^{D} 
		\big( \hat P_{\Lambda j}^2 + \hat C_j \hat P_{\Lambda j} \big) + 
		\hat V + \hat H',
\end{aligned}
\end{align} 
%where for all $j\in\{1, \ldots, D\}$, we define
%with the following definitions. We define
%where for all $j\in\{1, \ldots, D\}$, we define
with the following definitions. For all $j\in\{1, \ldots, D\}$, we define
\begin{align}
\begin{aligned}
	\hat P_{\Lambda j} =&\, \sum_{\boldsymbol{p}, k} p_j 
		\ket{\boldsymbol{p}, \psi_{k}} \bra{\boldsymbol{p}, \psi_{k}}, \\
%\end{aligned}
%\end{align} 
% with $p_j$ denoting the $j$th entry of $\boldsymbol{p}$, and
%\begin{align}
%\begin{aligned}
	\hat C_{j} =&\, \sum_{\boldsymbol{q}, k} 
		C_j(\boldsymbol{q}) \ket{\boldsymbol{q}, \psi_{k}} \bra{\boldsymbol{q}, \psi_{k}}, \\
	\hat V =&\, \sum_{\boldsymbol{q}, k} 
		V(\boldsymbol{q}) \ket{\boldsymbol{q}, \psi_{k}} \bra{\boldsymbol{q}, \psi_{k}},
\end{aligned}
\end{align} 
where $p_j$ denotes the $j$th entry of $\boldsymbol{p}$, and where $V$ and all the $C_j$s are all real-valued functions.
The reason for the $\Lambda$ index on $\hat P_{\Lambda j}$ is to avoid confusing it with the true momentum operators of $L^2(\mathbb{R}^D)$, which we will introduce later in this section as $\hat P_j$.
%Here, the $C_j$s and $V$ are all real-valued functions. 

*Note that I have also let the summation ranges be implicit. It is thus understood that all $\boldsymbol{q}$s, $\boldsymbol{p}$s and $k$s take all values in $Q^D$, $P^D$ and $I_k$, respectively. .\,.\,(I can probably omit this, or perhaps at least pull it down as a footnote.\,.)

%Furthermore, we 
We will also assume that each $C_j(\boldsymbol{q})$ is constant with respect to the value of $q_j$, such that.\,.
\begin{align}
\begin{aligned}
	\hat C_{j} \hat P_{\Lambda j} = 
		\sum_{\boldsymbol{q}, \boldsymbol{p}, k, k'}\delta_{k, k'} 
		p_j C_j(\boldsymbol{q})
		\ket{\boldsymbol{q}, \psi_{k'}}
		\braket{\boldsymbol{q}, \psi_{k'} | \boldsymbol{p}, \psi_k} 
		\bra{\boldsymbol{p}, \psi_{k}}.\,.
\end{aligned}
\end{align} 
Ah yes, which.\,. .\,.\,requires $p_j$ to be 0 in the summation for it to not.\,. hm no, that doesn't seem right.\,. .\,.\,Hm, if we continue, we have 
\begin{align}
\begin{aligned}
	\hat C_{j} \hat P_{\Lambda j} = 
		\sum_{\boldsymbol{q}, \boldsymbol{p}, k}
		p_j C_j(\boldsymbol{q}) e^{i \boldsymbol{p} \cdot \boldsymbol{q}}
		\ket{\boldsymbol{q}, \psi_{k}}
		\bra{\boldsymbol{p}, \psi_{k}} \,.\,.
\end{aligned}
\end{align} 
oh right, the presence of $\ket{\boldsymbol{q}, \psi_{k}}$ means that that wasn't true.\,. .\,.\,Ah, but we can probably extract $\ket{\boldsymbol{p}, \psi_k}$ from this, let's see.\,. .\,.\,Hm, not straight away.\,. .\,.\,Hm, how about expanding the bra or the ket.\,.\,? That can give us
\begin{align}
\begin{aligned}
	\hat C_{j} \hat P_{\Lambda j} = 
		\sum_{\boldsymbol{q}, \boldsymbol{q}', \boldsymbol{p}, k}
		p_j C_j(\boldsymbol{q}) e^{i \boldsymbol{p} \cdot (\boldsymbol{q} - \boldsymbol{q}')}
		\ket{\boldsymbol{q}, \psi_{k}}
		\bra{\boldsymbol{q}', \psi_{k}} \,.\,.
\end{aligned}
\end{align} 
Ah, and this picks out $q_i' = q_i$ for all $i\neq j$.\,. (.\,.\,when we sum over all $p_i$, $i\neq j$.) And then we can also sum over $q_j$, which will pick out $p_j = 0 \,\lor\, q_j' = q_j$.\,. Oh, and then the factor of $p_j$ will pick off $p_j = 0$, and we are left with contributions only when $ q_j' = q_j$, which means that now $\boldsymbol{q}' = \boldsymbol{q}$ (as they are equal on all entries). And we are thus left with 
\begin{align}
\begin{aligned}
	\hat C_{j} \hat P_{\Lambda j} = 
		\sum_{\boldsymbol{q}, p_j, k}
		p_j C_j(\boldsymbol{q}) 
		\ket{\boldsymbol{q}, \psi_{k}}
		\bra{\boldsymbol{q}, \psi_{k}}\,.\,.
\end{aligned}
\end{align} 
Hm, that doesn't seem right.\,. %..Hm, let me take I break now, in time to get some sun for the day.. (Kl. tyve over tre.)

%(Kl. kvart i fem.)
\ldots .\,.\,Hm, picking out $q_j' = q_j$ when summing over $q_j$ makes no sense; we should just pick out $p_j = 0$.\,. .\,.\,Ah, and shouldn't we also keep the factor of $\exp(i p_j q_j)$ then? Yes, that must be it.\,. Cool, and now it looks a bit more right.\,. .\,.\,So we should get
\begin{align}
\begin{aligned}
	\hat C_{j} \hat P_{\Lambda j} = 
		\sum_{\boldsymbol{q}, p_j, k}
		p_j C_j(\boldsymbol{q}) e^{i p_j q_j}
		\ket{\boldsymbol{q}, \psi_{k}}
		\bra{\boldsymbol{q}, \psi_{k}}.
\end{aligned}
\end{align} 
.\,.\,And for $\hat P_{\Lambda j} \hat C_{j}$, all the signs in the exponents should just be opposite, so we should therefore get
\begin{align}
\begin{aligned}
	\hat C_{j} \hat P_{\Lambda j} - \hat P_{\Lambda j} \hat C_{j} =&\,
		\sum_{\boldsymbol{q}, p_j, k}
		p_j C_j(\boldsymbol{q}) (e^{i p_j q_j} - e^{-i p_j q_j} )
		\ket{\boldsymbol{q}, \psi_{k}}
		\bra{\boldsymbol{q}, \psi_{k}} 
	\\=&\,
		\sum_{\boldsymbol{q}, p_j, k}
		2i p_j C_j(\boldsymbol{q}) \sin(p_j q_j)
		\ket{\boldsymbol{q}, \psi_{k}}
		\bra{\boldsymbol{q}, \psi_{k}}.
\end{aligned}
\end{align} 
And now, since $C(\boldsymbol{q})$ is constant wrt.\ $q_j$, this will sum to 0, and we can then confirm that $[\hat C_{j}, \hat P_{\Lambda j}] = 0$. Okay, not bad. 

I'll assume that I have now explained that each $C_j(\boldsymbol{q})$ is constant with respect to the value of $q_j$ as well as why this makes $[\hat C_{j}, \hat P_{\Lambda j}] = 0$ (in a more compact way).
.\,.\,Hm, I could by the way.\,. No, I \emph{should} by the way move such (known) arguments down on the appendices!\,:) 

*(I can probably do the sum over $q_j'$ a bit earlier, by the way.\,. .\,.\,And I am probably missing an $N$ coming from that summation as well.\,.)

Moving on.

For $\hat H'$, we will also assume that %..Hm, let me try with H_F' instead of \hat\bar{H}'..
*(I should also state that $\hat H'$ is assumed to be self-adjoint immediately.)
\begin{align}
\begin{aligned}
	\hat H' \ket{\boldsymbol{q}, \psi_{k}} = 
		\ket{\boldsymbol{q}} \otimes \hat H_F'(\boldsymbol{q}) \ket{\psi_{k}},
\end{aligned}
\end{align}
where $\hat H_F'(\boldsymbol{q})$ is a %self-adjoint and bounded 
(self-adjoint) 
operator on $\textbf{H}_2$ for all values of $\boldsymbol{q}$. And lastly, we will assume that $\hat H$ can be split in two parts, %...
such that we can write it as
\begin{align}
\begin{aligned}
	\hat H'  = \hat H_1' + \hat H_2',
\end{aligned}
\end{align}
where for $i\in\{1, 2\}$,
\begin{align}
\begin{aligned}
	\hat H_i' \ket{\boldsymbol{q}, \psi_{k}} = 
		\ket{\boldsymbol{q}} \otimes \hat H_{Fi}'(\boldsymbol{q}) \ket{\psi_{k}},
\end{aligned}
\end{align}
where $\hat H_{F1}'(\boldsymbol{q})$ is constant with respect to the $D_1$ first entries of $\boldsymbol{q}$ and where $\hat H_{F2}'(\boldsymbol{q})$ is constant with respect to the $D_2 = D - D_1$ last entries of $\boldsymbol{q}$. A.whatever will show that this ensures that $\hat H_1'$ commutes with $\hat P_{\Lambda j}$ for all $j\in\{1, 2, \ldots, D_1 \}$ and that $\hat H_2'$ commutes with $\hat P_{\Lambda j}$ for all $j\in\{D_1 +1, D_1 + 2, \ldots, D \}$. 


Note that with these restrictions on $\hat H$, we do indeed ensure that $\hat H$ preserves the subspace of \textbf{H} spanned by $\{\ket{\boldsymbol{q}, \psi_{k}}\}$ and by $\{\ket{\boldsymbol{p}, \psi_{k}}\}$. And additionally, these restrictions also ensure that $\hat H$ can be written as
\begin{align}
\begin{aligned}
	\hat H  = \hat H_1 + \hat H_2,
\end{aligned}
\end{align}
with
%..Hm, I also need I simlar restriction on \hat V.. ..Let me take a break.
\begin{align}
\begin{aligned}
	\hat H_1  = \sum_{j=1}^{D_1} 
		\big( \hat P_{\Lambda j}^2 + \hat C_j \hat P_{\Lambda j} \big) + \,\,\ldots
\end{aligned}
\end{align}

%(Kl. ti i syv.)
\ldots\ I realized that I also need similar restrictions on $\hat V$. So I should probably just begin by defining
\begin{align}
\begin{aligned}
	\hat P_{\Lambda j} =&\, \sum_{\boldsymbol{p}, k} p_j 
		\ket{\boldsymbol{p}, \psi_{k}} \bra{\boldsymbol{p}, \psi_{k}}, \\
	\hat C_{j} =&\, \sum_{\boldsymbol{q}, k} 
		C_j(\boldsymbol{q}) \ket{\boldsymbol{q}, \psi_{k}} \bra{\boldsymbol{q}, \psi_{k}}, \\
	\hat V =&\, \sum_{\boldsymbol{q}, k} 
		V(\boldsymbol{q}) \ket{\boldsymbol{q}, \psi_{k}} \bra{\boldsymbol{q}, \psi_{k}},
	\label{P_C_V_01}
\end{aligned}
\end{align} 
for all $j$, and %define 
assume 
*(I should also state that $\hat H'$ is assumed to be self-adjoint immediately.)
\begin{align}
\begin{aligned}
	\hat H' \ket{\boldsymbol{q}, \psi_{k}} = 
		\ket{\boldsymbol{q}} \otimes \hat H_F'(\boldsymbol{q}) \ket{\psi_{k}},
	\label{H'_01}
\end{aligned}
\end{align}
for all $\boldsymbol{q}$. And then.\,. .\,.\,Hm, and at this point, I can say that this ensured the preservation of the subspace of \textbf{H} spanned by $\{\ket{\boldsymbol{q}, \psi_{k}}\}$ and by $\{\ket{\boldsymbol{p}}\}$.\,. And should I then go on to write up
%\begin{align}
%\begin{aligned}
%	\hat P_{\Lambda j} =&\, \sum_{\boldsymbol{p}, k} p_j 
%		\ket{\boldsymbol{p}, \psi_{k}} \bra{\boldsymbol{p}, \psi_{k}}, \\
%	\hat C_{j} =&\, \sum_{\boldsymbol{q}, k} 
%		C_j(\boldsymbol{q}) \ket{\boldsymbol{q}, \psi_{k}} \bra{\boldsymbol{q}, \psi_{k}}, \\
%	\hat V =&\, \sum_{\boldsymbol{q}, k} 
%		V(\boldsymbol{q}) \ket{\boldsymbol{q}, \psi_{k}} \bra{\boldsymbol{q}, \psi_{k}},
%\end{aligned}
%\end{align} 
%for all $j$, and define 
\begin{align}
\begin{aligned}
	C_j(\boldsymbol{q}) = C_j(\boldsymbol{q})\,.\,.
\end{aligned}
\end{align}
Oh no, I don't need that; the $C_j$s should have the restriction stated above.\,. 
*(Let me also note here (in a new, separate paragraph), why the above restrictions ensures that $\hat H$ is self-adjoint. .\,.\,Hm, and I should by the way make a footnote somewhere about ``Hermitian'' versus.\,. Oh, but I will have to do this in the introduction, so never mind.\,.)
But then I could write
\begin{align}
\begin{aligned}
	V(\boldsymbol{q}) =&\, V_1(\boldsymbol{q}) + V_2(\boldsymbol{q}), \\
	\hat H_F'(\boldsymbol{q}) =&\, \hat H_{F1}'(\boldsymbol{q}) + \hat H_{F2}'(\boldsymbol{q}),
\end{aligned}
\end{align}
where we assume that $V_1(\boldsymbol{q})$ and $\hat H_{F1}'(\boldsymbol{q})$ are both constant with respect to the $D_1$ first entries of $\boldsymbol{q}$, and where $V_1(\boldsymbol{q})$ and $\hat H_{F2}'(\boldsymbol{q})$ are constant with respect to the $D_2 = D - D_1$ last entries of $\boldsymbol{q}$. 

All these restrictions then ensure that $\hat H$ can be split up into two parts where all the terms in their formulas commute. We can thus write $\hat H$ as
\begin{align}
\begin{aligned}
	\hat H  = \hat H_1 + \hat H_2,
\end{aligned}
\end{align}
with
\begin{align}
\begin{aligned}
	\hat H_1  =&\,
		\sum_{j=1}^{D_1} \big( \hat P_{\Lambda j}^2 + \hat C_j \hat P_{\Lambda j} \big) + 
		\hat V_1 +
		\hat H_1', \\
	\hat H_2  =&\,
		\sum_{j=D_1 + 1}^{D} \big( \hat P_{\Lambda j}^2 + \hat C_j \hat P_{\Lambda j} \big) + 
		\hat V_2 +
		\hat H_2', 
	\label{H1_H2_01}
\end{aligned}
\end{align}
where $\hat V_i$ and $\hat H_i'$, $i\in\{1,2\}$, are %of course 
defined similarly to $\hat V$ and $\hat H$ in eq.\ (\ref{P_C_V_01}) and (\ref{H'_01}), only with the same labels added on the functions as well. If we had the true momentum operators $\hat P_j$ (which can be written as a differential operator) instead of the discretized $\hat P_{\Lambda j}$, it would be trivial to see why the restrictions would make terms commute with each other in both $\hat H_1$ and $\hat H_2$. It is also not hard to show it for this discretized $\hat P_{\Lambda j}$. See A.whatever for a derivation of this. This fact will be useful when we derive the path integral for $\hat H$ in the following.


(10.03.22) No, I should actually just assume eq.\ (\ref{H1_H2_01}) right away (and that the inner terms commute), and then I can just explain in the following paragraph, that this can be achieved by.\,. Wait, but do I need the definitions in the following.\,.\,?\,.\,. Hm, let me just wait and see for now, what will make more sense. 

Okay, so I want start the derivation by looking at 
%\begin{align}
%\begin{aligned}
%%	\bra{\boldsymbol{p}, \psi_{k'}} \hat H_1  \ket{\boldsymbol{q}, \psi_k} =&\,\\
%	\braket{\boldsymbol{p}, \psi_{k'} | \hat H_1 | \boldsymbol{q}, \psi_k} =&\,
%		\bra{\boldsymbol{p}, \psi_{k'}}
%			\textstyle\sum_{j=1}^{D_1}\displaystyle
%%			\sum_{j=1}^{D_1} 
%			\big( \hat P_{\Lambda j}^2 + \hat C_j \hat P_{\Lambda j} \big) + 
%			\hat V_1 +
%			\hat H_1'
%		\ket{\boldsymbol{q}, \psi_k}
%	\\=&\,
%		\bra{\boldsymbol{p}, \psi_{k'}}
%			\textstyle\sum_{j=1}^{D_1}\displaystyle
%%			\sum_{j=1}^{D_1} 
%			\big( p_{j}^2 + \hat C_j(q_j) p_{j} \big) + 
%			V_1(\boldsymbol{q}) +
%			\hat H_{1}'(\boldsymbol{q})
%		\ket{\boldsymbol{q}, \psi_k}
%	\\=&\,
%		H_{B1}(\boldsymbol{p}, \boldsymbol{q}) +
%		\bra{\boldsymbol{p}, \psi_{k'}}
%			\hat H_{1}'(\boldsymbol{q})
%		\ket{\boldsymbol{q}, \psi_k}
%	\\=&\,
%		H_{B1}(\boldsymbol{p} | \boldsymbol{q}) +
%		\braket{\boldsymbol{p}, \boldsymbol{q}}
%		\braket{\psi_{k'} | \hat H_{1}' | \psi_k},
%\end{aligned}
%\end{align}
%where we have used linearity to get the third line, and where eq.\ (\ref{H'_01}) (or rather a slightly changed version of it.\,.) is used to get the fourth line, as well as the fact that $(\ket{a'} \otimes \ket{b'})^\dagger (\ket{a} \otimes \ket{b}) = \braket{a' | a} \braket{b' | b}$ for any such vectors.
\begin{align}
\begin{aligned}
%	\bra{\boldsymbol{p}, \psi_{k'}} \hat H_1  \ket{\boldsymbol{q}, \psi_k} =&\,\\
	\braket{\boldsymbol{p}, \psi_{k'} | \hat H_1 | \boldsymbol{q}, \psi_k} =&\,
		\bra{\boldsymbol{p}, \psi_{k'}}
			\textstyle\sum_{j=1}^{D_1}\displaystyle
%			\sum_{j=1}^{D_1} 
			\big( \hat P_{\Lambda j}^2 + \hat C_j \hat P_{\Lambda j} \big) + 
			\hat V_1 +
			\hat H_1'
		\ket{\boldsymbol{q}, \psi_k}
	\\=&\,
		\bra{\boldsymbol{p}, \psi_{k'}}
			\textstyle\sum_{j=1}^{D_1}\displaystyle
%			\sum_{j=1}^{D_1} 
			\big( p_{j}^2 + \hat C_j(q_j) p_{j} \big) + 
			V_1(\boldsymbol{q}) +
			\hat H_{1}'(\boldsymbol{q})
		\ket{\boldsymbol{q}, \psi_k}
	\\=&\,
		\braket{\boldsymbol{p}, \psi_{k'} | \boldsymbol{q}, \psi_k} 
		H_{B1}(\boldsymbol{p}, \boldsymbol{q}) + 
		\bra{\boldsymbol{p}, \psi_{k'}}
			\hat H_{1}'
		\ket{\boldsymbol{q}, \psi_k},
	\label{H1_braket_calc}
\end{aligned}
\end{align}
where, to get the second line, we have used the fact that %all the terms commute and that 
$\hat C_j$ and $\hat P_{\Lambda j}$ commutes %as well 
for all $j$ to let each $\hat P_{\Lambda j}$ ``hit'' the bra to the left and let all the other operators ``hit'' the ket to the right. The fact that we can let operators work on bras this way is ensured since they are all self-adjoint. 
To get the last line, we have used linearity, and also defined $H_{B1}$ to be the classical counterpart of the purely bosonic part of $\hat H_1$, namely such that $H_{B1}(\boldsymbol{p}, \boldsymbol{q})= 
			\sum_{j=1}^{D_1} 
			\big( p_{j}^2 + \hat C_j(q_j) p_{j} \big) + 
			V_1(\boldsymbol{q})
$. 
%\begin{align}
%\begin{aligned}
%	H_{B1}(\boldsymbol{p}, \boldsymbol{q}) =&\,
%		\sum_{j=1}^{D_1} \big( p_{\Lambda j}^2 + \hat C_j \hat P_{\Lambda j} \big) + 
%		\hat V_1 +
%		\hat H_1',
%\end{aligned}
%\end{align}

We can then use eq.\ (\ref{H'_01}) (or rather a slightly changed version of it.\,.) to get
\begin{align}
\begin{aligned}
%	\braket{\boldsymbol{p}, \psi_{k'} | \hat H_1 | \boldsymbol{q}, \psi_k} =&\,
%		H_{B1}(\boldsymbol{p} | \boldsymbol{q}) +
%		\braket{\boldsymbol{p} | \boldsymbol{q}}
%		\braket{\psi_{k'} | \hat H_{1}' | \psi_k},
	\braket{\boldsymbol{p}, \psi_{k'} | \hat H_1 | \boldsymbol{q}, \psi_k} =&\,
		\braket{\boldsymbol{p} | \boldsymbol{q}}(
			\delta_{k k'} H_{B1}(\boldsymbol{p} | \boldsymbol{q}) +
			\braket{\psi_{k'} | \hat H_{F1}'(\boldsymbol{q}) | \psi_k}
		),
%	\braket{\boldsymbol{p}, \psi_{k'} | \hat H_1 | \boldsymbol{q}, \psi_k} =&\,
%			\braket{\boldsymbol{p} | \boldsymbol{q}} \delta_{k k'} 
%				H_{B1}(\boldsymbol{p} | \boldsymbol{q}) +
%			\braket{\boldsymbol{p} | \boldsymbol{q}}
%				\braket{\psi_{k'} | \hat H_{F1}'(\boldsymbol{q}) | \psi_k}
%	\\=&\,
%		e^{-i \boldsymbol{p} \cdot \boldsymbol{q}}(
%			\delta_{k k'} H_{B1}(\boldsymbol{p} | \boldsymbol{q}) +
%			\braket{\psi_{k'} | \hat H_{F1}'(\boldsymbol{q}) | \psi_k}
%		),
\end{aligned}
\end{align}
where we have also used the fact that $(\ket{a'} \otimes \ket{b'})^\dagger (\ket{a} \otimes \ket{b}) = \braket{a' | a} \braket{b' | b}$ for any such vectors.

Hm, I don't know whether this last equation is beneficial yet, but let's see.\,. 

\ldots\ No, we don't need need it yet.\,. Instead I can continue from eq.\ (\ref{H1_braket_calc}) and say:

This calculation is illustrating, but what we really need in order to derive the path integral is to evaluate $\braket{\boldsymbol{p}, \psi_{k'} | \exp(-i \hat H_1 t) | \boldsymbol{q}, \psi_k}$. Luckily, since all the operators of $\hat H_1$ are self-adjoint and commutating, we can write $\exp(-i \hat H_1 t)$ as 
%..Oh right, I need a factor 1/2 everywhere, and in fact, I should actually make that 1/2m_j instead..
$\exp(-i (\sum_{j=1}^{D_1} \hat P_{\Lambda j}^2 ) t)\exp(-i (\sum_{j=1}^{D_1}\hat C_j \hat P_{\Lambda j} ) t) \exp(-i \hat V_1 t) \exp(-i \hat H_1' t)$, where all these exponentials commutes. *(I should probably rather just write that as a sum in one exponential, but I'll see when that time comes.\,.) And therefore, we can use almost exactly the same procedure as for eq.\ (\ref{H1_braket_calc}) to get
\begin{align}
\begin{aligned}
	\braket{\boldsymbol{p}, \psi_{k'} | e^{-i \hat H_1 t} | \boldsymbol{q}, \psi_k} =&\,
%		\braket{\boldsymbol{p}, \psi_{k'} | \boldsymbol{q}, \psi_k} 
		\bra{\boldsymbol{p}, \psi_{k'} } 
		e^{-i H_{B1}(\boldsymbol{p}, \boldsymbol{q}) t} 
%		\bra{\boldsymbol{p}, \psi_{k'}}
			e^{-i \hat H_{1}' t}
		\ket{\boldsymbol{q}, \psi_k}.
\end{aligned}
\end{align}
.\,.\,Hm, and how exactly do we use eq.\ (\ref{H'_01}) then from here.\,.\,? %(Kl. tolv.)

\ldots\ Ah, since $\hat H_1'$ perserves the subspace spanned by $\{\ket{\boldsymbol{q}, \psi_k}\}_{\boldsymbol{q}\in Q^D}$, we know (see Hall, somewhere) that so does $\exp{-i H_1' t}$, which means that.\,. 
%\begin{align}
%\begin{aligned}
%	e^{-i \hat H_{1}' t} \ket{\boldsymbol{q}, \psi_k} =
%		\ket{\boldsymbol{q}} \otimes e^{-i \hat H_{1}' t} \ket{ \psi_k}.
%\end{aligned}
%\end{align}
Hm, and I should also use a proposition in order to get to $\exp(-i H_{F1}'(\boldsymbol{q}) t)$.\,. 

%(Kl. kvart i fire)
\ldots\ Hm, I don't really have the energy to figure that out exactly today (for some reason I don't know). And even when i find it out, I might just include the explanation/argument in an appendix. Let me instead try to move on. .\,.\,Oh, but let me first mention, that I \emph{should} just look at $\exp(-i \hat H_1 t)$ right away, instead of eq.\ (\ref{H1_braket_calc}), since this is where we need the commutation properties (besides between $\hat C$ and $\hat P_\Lambda$) of $\hat H_1$. So let me just do that directly.

Moving on.

So we (will) get 
\begin{align}
\begin{aligned}
	\braket{\boldsymbol{p}, \psi_{k'} | e^{-i \hat H_1 t} | \boldsymbol{q}, \psi_k} =&\,
%		\braket{\boldsymbol{p}, \psi_{k'} | \boldsymbol{q}, \psi_k} 
%		\bra{\boldsymbol{p}, \psi_{k'} } 
		e^{-i \boldsymbol{p} \cdot \boldsymbol{q} - i H_{B1}(\boldsymbol{p}, \boldsymbol{q}) t} 
		\bra{\psi_{k'}}
			e^{-i \hat H_{F1}'(\boldsymbol{q}) t}
		\ket{\psi_k}.
\end{aligned}
\end{align}
We will also need to evaluate $\braket{\boldsymbol{q}, \psi_{k} | e^{-i \hat H_2 t} | \boldsymbol{p}, \psi_{k'}}$. It is easy to see that a similar calculation will give us
\begin{align}
\begin{aligned}
	\braket{\boldsymbol{q}, \psi_{k} | e^{-i \hat H_2 t} | \boldsymbol{p}, \psi_{k'}} =&\,
		e^{ i \boldsymbol{p} \cdot \boldsymbol{q} - i H_{B2}(\boldsymbol{p}, \boldsymbol{q}) t} 
		\bra{\psi_{k}}
			e^{-i \hat H_{F2}'(\boldsymbol{q}) t}
		\ket{\psi_{k'}}.
\end{aligned}
\end{align}


We can now finally derive the path integral. First we note that if we define $\hat I_Q$ and $\hat I_P$ by
\begin{align}
\begin{aligned}
	\hat I_Q = \sum_{\boldsymbol{q}, k} \ket{\boldsymbol{q}, \psi_{k}}\bra{\boldsymbol{q}, \psi_{k}},
	\\
	\hat I_P = \sum_{\boldsymbol{p}, k} \ket{\boldsymbol{p}, \psi_{k}}\bra{\boldsymbol{p}, \psi_{k}},
\end{aligned}
\end{align}
then since the orthogonal sets $\{\ket{\boldsymbol{q}, \psi_k}\}$ and $\{\ket{\boldsymbol{p}, \psi_k}\}$ span the same subspace, both $\hat I_Q$ and $\hat I_P$ are actually the same projection operator (so $\hat I_Q = \hat I_P$) onto this subspace (which can also easily be seen by direct calculation). And since $\hat H$ preserves this subspace, we.\,. Hm, but unless $\hat H'$ is only supported by this subspace, I can't write $\hat H = \hat H \hat I_Q = \hat I_Q \hat H$ like a had before.\,. .\,.\,So why not just assume that to make it easier (it doesn't cost anything as well.\,.) (Inserted comment: I know, by the way, that I need factors of $1/2$ (or $1/2m_j$) on the $\hat P_\Lambda$s above (in the moment of writing), but let me deal with that at a later time.\,.) .\,.\,Hm yeah, it is probably easiest and best to just assume, that $\hat H'$ is only supported on this subspace as well. And then we have that $\hat H$ is supported only on this subspace. And then we get:
\begin{align}
\begin{aligned}
	\hat H = \hat H \hat I_Q = \hat I_Q \hat H = \hat I_P \hat H = \hat H \hat I_P,
\end{aligned}
\end{align}
and the same applies for $\hat H_1$ and $\hat H_2$ as well. .\,. .\,.\,Hm, Let me just start by defining $\hat I_Q$ and writing  $\hat H = \hat H \hat I_Q = \hat I_Q \hat H$.\,. Hm, or maybe this way was fine.\,. Anyway, I'd rather move on for now.\,. 

.\,.\,Oh, and the same then applies for $\exp(-i \hat H t)$ and so on.\,. .\,.\,Whatever, and then I should write up.\,.

We then look at the time evolution, which is given by
\begin{align}
\begin{aligned}
	e^{-i \hat H t} =&\, e^{-i (\hat H_1 + \hat H_2) t}.
\end{aligned}
\end{align}
We use the Trotter product formula (see Hall) to write this as 
\begin{align}
\begin{aligned}
	e^{-i \hat H t} =&\, \lim_{M\to\infty} (e^{-i \hat H_1 t} e^{-i \hat H_2 t})^M.
\end{aligned}
\end{align}
Note that this formula applies since all these operators are self-adjoint.\,. In fact, they are all (now (again.\,.)) bounded and self-adjoint, which means that the domains of these operators.\,. Oh wait, they are unchanged anyway.\,. 

(\ldots\ Inserted comment: Hm, maybe I should make a less careful derivation for the main article and then refer to an appendix for this more careful derivation.\,. An interesting idea to keep in mind, anyway.\,. \ldots Hm, let me just make this careful one first (where I can still refer to (other) appendices for details), and \emph{then} I can see if I should try to move partly down as an appendix instead.\,. .\,.\,Hm, it is also nice, to not spend too much energy on it, as I don't really consider it part of the \emph{discovery} all that much.\,.) %(Kl. fem over fem.)

.\,.\,Hm, I just got an idea to maybe show the three-term Lie-Trotter-Suzuki formula.\,. Let me see.\,. 
.\,.\,Hm, basically, we should just choose either a large enough $M$ or $N$ first then choose a large enough value for the other and lastly, we should then raise the first one up to the second one.\,. .\,.\,Oh, and we can even ``increase'' the outer power, say that that's $M$, by making a third Trotter exp.\,. Hm, let me go up and look at my old equations for a moment.\,. %(Kl. kvart over fem.)
\ldots Hm no, embarrassing.\,. \ldots Hm, or maybe.\,. .\,.\,Hm, now I have gotten the idea to basically rewrite it as
\begin{align}
\begin{aligned}
	\ldots \approx&\, (e^{-i (\approx  \hat A + \hat B) t / M} e^{-i \hat C t / M} )^M
	\\=&\, 
	\,.\,.
\end{aligned}
\end{align}
Hm.\,. .\,.\,Hm yeah, and using.\,. Ah wait, first I then use
\begin{align}
\begin{aligned}
	\ldots \approx&\, (e^{-i (\approx  \hat A + \hat B) t / M} e^{-i \hat C t / M} )^M
	\\\approx&\, 
		\lim_{M\to \infty} \,.\,.
\end{aligned}
\end{align}
Or can I say that.\,. .\,.\,No, I can't.\,. .\,.\,Hm, unless I maybe \emph{actually} use that the operator in the parentheses must converge to $\hat A + \hat B$.\,. %(Kl. kvart i seks.)
.\,.\,Hm, and one can surely argue this from the eigenvectors.\,. .\,.\,Hm, and.\,. Ah, and we must then be able to begin with a big enough $M$, given the aimed for error for $\hat A + \hat B - (\approx \hat A + \hat B)$.\,. .\,.\,(that the above expression is close to the original evolution.\,.) .\,.\,And now one should just then be able to do a new Trotter, where $M$ is then increased to $N$.\,. .\,.\,Okay, let me try to walk through that argument.\,. Let us define Trotter$(N, \hat A, \hat B)$ as the self-adjoint generator for $(e^{-i \hat A t / N} e^{-i \hat B t / N} )^N$.\,. Then $\lim_{N\to \infty} \mathrm{Trotter}(N, \hat A, \hat B) = \hat A + \hat B$.\,. .\,.\,Let us then choose I large enough $M$, that $(e^{-i (\hat A + \hat B) t / M} e^{-i \hat C t / M} )^M$ and $(e^{-i \mathrm{Trotter}(N, \hat A, \hat B) t / M} e^{-i \hat C t / M} )^M$ are both within a given error $\varepsilon_1$ compared to $e^{-i (\hat A + \hat B + \hat C) t}$ when working on a given $\psi$. .\,.\,Hm, and can I argue, that a larger $N$ only allows $M$ to be smaller if anything.\,.\,? .\,.\,Hm.\,. %(Kl. fem over seks.) 
.\,.\,Hm, it should be so, but why.\,.\,? .\,.\,Hm, I guess I basically then need some sort of continuity of the Trotter expansion in terms of how large $M$ needs to be.\,. .\,.\,Hm, and then we very quickly get to a point where this proof is far too complicated to suit my purposes.\,. 
\ldots Hm, but I'm sure it would be possible to carry this proof through (by showing somehow that increasing $N$ will only bring the two expressions closer to each other for a fixed $M$.\,.).\,. .\,.\,Oh wait, but one \emph{can} indeed argue that.\,. .\,.\,For any fixed $M$, letting $N$ tend to infinity should only bring $(e^{-i (\hat A + \hat B) t / M} e^{-i \hat C t / M} )^M$ and $(e^{-i \mathrm{Trotter}(N, \hat A, \hat B) t / M} e^{-i \hat C t / M} )^M$ (arbitrarily) close.\,. .\,.\,Right, but how do we then un-fix $M$ again.\,. Hm, can we instead argue (like I was about to write), that increasing $N$ will \emph{only} bring the expressions closer for a fixed $M$, at least after a certain value (of $N$ when it's increasing)?\,.\,. .\,.\,Hm yes, that might be provable (maybe at least for bounded operators or something).\,. And if so, then we are free to.\,. Hm.\,. \ldots Hm, now I feel stuck, so let me just quit, at least for now.\,. %(Kl. 25 i syv.) 

%(Kl. fem i otte.)
\ldots\ Hm, I think I might have gotten an idea to solve it, but let's see.\,. .\,.\,The idea is to take the route like.\,. .\,.\,Hm.\,. .\,.\,Or let's look at
\begin{align}
\begin{aligned}
	e^{-i (\hat A + \hat B + \hat C) t} \approx&\,
		e^{-i (\mathrm{Trotter}(N, \hat A, \hat B) + \hat C) t} 
	\\\approx&\,
		(e^{-i \mathrm{Trotter}(N, \hat A, \hat B) t / M} e^{-i \hat C t / M} )^M,
\end{aligned}
\end{align}
.\,.\,and then the idea is to note that the first approximation depends solely on $N$ and that the second approximation depends solely on $M$.\,:)\,.\,. %(Kl. fem over otte.)
.\,.\,Hm well, that's not entirely true about the second approximation.\,. .\,.\,Right, no.\,. 
\ldots Hm, but couldn't we just.\,. .\,.\,Hm, it seems like a complicated argument, but I guess one must be albe to then choose a large enough $M$, and then let $N$ increase and show (somehow) that if $N$ was large enough to begin with, then $(e^{-i \mathrm{Trotter}(N, \hat A, \hat B) t / M} e^{-i \hat C t / M} )^M$ will only get closer to $(e^{-i (\hat A + \hat B) t / M} e^{-i \hat C t / M} )^M$, as $N$ increases from there. (Oh, and we should make sure to choose a larger $M$ than that initial $N$.) .\,.\,And let's assume that we have already chosen a large enough $M$ so that $(e^{-i (\hat A + \hat B) t / M} e^{-i \hat C t / M} )^M$ is close to $e^{-i (\hat A + \hat B + \hat C) t}$, within some error. .\,.\,Oh, and then we don't need the first line of the above equation, do we?\,.\,. No, that's it, cause then we are free to let $N$ increase to $M$.\,. Hm, and one must be able to argue, that for a sufficiently large $N_0$, $(e^{-i \mathrm{Trotter}(N, \hat A, \hat B) t / M} e^{-i \hat C t / M} )^M$ will only be closer to $(e^{-i (\hat A + \hat B) t / M} e^{-i \hat C t / M} )^M$ for all $N$ larger than $N_0$, no matter what integer $M$ is. .\,.\,Yeah, so that seems like a good argument, but let me get back and look at it again tomorrow. %(Kl. 25 i ni.)

%(Kl. fem i ti.)
\ldots\ Ah, I just thought about something, that might lead to a simple (trivial!\,.\,.\,;)) proof, let's see.\,. Let $\hat Z$ be the generator of $\hat U(t) = \exp(-i \hat A t) \exp(-i \hat B t)$. Then
\begin{align}
\begin{aligned}
	e^{-i (\hat Z + \hat C) t} \approx&\,
		(e^{-i \hat Z t / M} e^{-i \hat C t / M} )^M,
	\\=&\,
		(U(t/M) e^{-i \hat C t / M} )^M,
	\\=&\,
		(e^{-i \hat A t / M} e^{-i \hat B t / M} e^{-i \hat C t / M} )^M.
\end{aligned}
\end{align}
And what to do with this, let's see.\,. .\,.\,Hm, if anything, doesn't that show that the desired expansion does not work, or.\,.\,? .\,.\,Hm no, we probably don't have a generator for $\exp(-i \hat A t) \exp(-i \hat B t)$ like that necessarily.\,. (.\,.\,i.e.\ that is the same for all $t$.) .\,.\,No, but I still think my other argument would work.\,. 

%(Kl. tolv.)
(11.03.22) I should probably include $t$ as a variable in Trotter(), but otherwise the argument (from just above the last paragraph) seems to work.\,. .\,.\,Oh, or maybe not quite.\,. \ldots Oh wait, last evening, I had the idea to look at all of $e^{-i \mathrm{Trotter}(N, \hat A, \hat B) t / M} e^{-i \hat C t / M}$ (but I didn't write it down for some reason). .\,.\,Yeah, and then the argument should actually work.\,. .\,.\,(Or rather or rather $e^{-i \mathrm{Trotter}(N, \hat A, \hat B, t) / M} e^{-i \hat C t / M}$.\,.) .\,.\,Okay great, but I'm not sure, I will try to use this --- I don't wanna take the risk.\,. 

*[(12.03.22) No, as I realized last evening, I have forgotten about the $1/M$ factor in the exponents, so we don't technically know if.\,. Well, we can't necessarily pick a $N_0$ that works for all $M$. So the argument does not work. (But it doesn't matter: I actually don't think I will have a need for it, even if a had a clear proof or a clear reference.\,. .\,.\,Hm, or maybe I actually would, I'm not completely sure.\,.)]

Okay, back to the subject of this section in a minute, but let me first mention that I have gotten the idea that I should actually just make a heuristic derivation of the path integral in the main article, and then I can just refer to the appendices for a more careful and detailed derivation. .\,.\,And now I by the way think, that I should just keep the assumption about $\hat V = \hat V_1 + \hat V_2$, and similar for $\hat H'$, and then just mention how this is achieved and refer to the appendices again for details about this. .\,.\,:) .\,.\,And I guess that one of the biggest source of ``nonrigor'' will then actually be the fact that in the heuristic derivation, one just assume that the integrals should be evaluated with the limits growing symmetrically. And that's why I \emph{should} indeed make sure to include a more careful derivation (where I can then also add more details, which I can then allow myself to skip in the main body of the article). .\,.\,And spending as little time on the path integral in the main body is good for several reasons (.\,.\,i.e.\ more than one.\,.). 

Moving on: Let me just go a bit quickly through the rest of the derivation.

We will then be able to write
\begin{align}
\begin{aligned}
	e^{-i \hat H t} =&\, \lim_{M\to\infty} (e^{-i \hat H_1 \delta t} e^{-i \hat H_2 \delta t})^M,
\end{aligned}
\end{align}
where $\delta t = t / M$, and see that
\begin{align}
\begin{aligned}
	(e^{-i \hat H_1 \delta t} e^{-i \hat H_2 \delta t})^M =
		(e^{-i \hat H_1 \delta t} \hat I_Q e^{-i \hat H_2 \delta t} \hat I_P)^M
\end{aligned}
\end{align}
.\,.\,Or maybe I should just first write:
\begin{align}
\begin{aligned}
	\bra{\boldsymbol{q'}, \psi_{k'}}
		e^{-i \hat H t} 
	\ket{\boldsymbol{q}, \psi_{k}}
	=&\, 
	\lim_{M\to\infty} 
	\bra{\boldsymbol{q'}, \psi_{k'}}
		(e^{-i \hat H_1 \delta t} e^{-i \hat H_2 \delta t})^M
	\ket{\boldsymbol{q}, \psi_{k}},
\end{aligned}
\end{align}
and see that 
\begin{align}
\begin{aligned}
	\bra{\boldsymbol{q'}, \psi_{k'}}
		(e^{-i \hat H_1 \delta t} e^{-i \hat H_2 \delta t})^M
	\ket{\boldsymbol{q}, \psi_{k}}
	=&\,
	\bra{\boldsymbol{q'}, \psi_{k'}} 
		\hat I_Q
		\hat I_P
		(e^{-i \hat H_1 \delta t} \hat I_Q e^{-i \hat H_2 \delta t} \hat I_P)^M
		\hat I_Q
	\ket{\boldsymbol{q}, \psi_{k}}.
\end{aligned}
\end{align}
.\,.\,Hm, now I don't need the bra and kets, namely when I use the $\hat I_Q$s at the end instead of renaming $\boldsymbol{q}'$ and $\boldsymbol{q}$. So let me just go (two steps) back and write 
\begin{align}
\begin{aligned}
	(e^{-i \hat H_1 t} e^{-i \hat H_2 t})^M =
		\hat I_Q
		\hat I_P
		(e^{-i \hat H_1 \delta t} \hat I_Q e^{-i \hat H_2 \delta t} \hat I_P)^M
		\hat I_Q
\end{aligned}
\end{align}
instead. We can see that this expression %(on the RHS) 
can be written as *(Hm, I should actually just change back again and just write $\boldsymbol{q}_{M+1}$ and $\boldsymbol{q}_0$ to begin with, instead of $\boldsymbol{q}'$ and $\boldsymbol{q}$.\,.)
%\begin{align}
%\begin{aligned}
%	\sum 
%%	\ket{\boldsymbol{q}_{M+1}, \psi_{k_{M+1}}}
%%	\braket{\boldsymbol{q}_{M+1}, \psi_{k_{M+1}} | \boldsymbol{p}_{M+1}, \psi_{k_{M+1}'}} %Need to rewrite to shorten..
%%	\delta_{\psi_{k_{M+1}} \psi_{k_{M+1}}'} 
%%	e^{i \boldsymbol{p}_{M+1} \cdot \boldsymbol{q}_{M+1}} %Hm, not shorter..
%	\ket{\boldsymbol{q}_{M+1}, \psi_{k_{M+1}}'}
%	e^{i \boldsymbol{p}_{M+1} \cdot \boldsymbol{q}_{M+1}}
%		T^1_{M}T^2_{M} T^1_{M-1}T^2_{M-1} \cdots T^1_{1}T^2_{1}
%	e^{-i \boldsymbol{p}_{0} \cdot \boldsymbol{q}_{0}}
%	\bra{\boldsymbol{q}_{0}, \psi_{k_{0}}'}
%\end{aligned}
%\end{align} 
%
%\begin{align}
%\begin{aligned}
%	\sum 
%	\ket{\boldsymbol{q}_{M+1}, \psi_{k_{M+1}}}
%	\braket{\boldsymbol{q}_{M+1}, \psi_{k_{M+1}} | \boldsymbol{p}_{M+1}, \psi_{k_{M+1}'}}
%	T
%	\braket{\boldsymbol{p}_{1}, \psi_{k_{1}'} | \boldsymbol{q}_{0}, \psi_{k_{0}}}
%	\bra{\boldsymbol{q}_{0}, \psi_{k_{0}}},
%	\label{sum_with_T}
%\end{aligned}
%\end{align} 
\begin{align}
\begin{aligned}
	(e^{-i \hat H_1 t} e^{-i \hat H_2 t})^M =&\, 
		\sum 
		\ket{\boldsymbol{q}_{M+1}, \psi_{k_{M+1}}}
		\braket{\boldsymbol{q}_{M+1}, \psi_{k_{M+1}} | \boldsymbol{p}_{M+1}, \psi_{k_{M+1}'}}
		T
		\braket{\boldsymbol{p}_{1}, \psi_{k_{1}'} | \boldsymbol{q}_{0}, \psi_{k_{0}}}
		\bra{\boldsymbol{q}_{0}, \psi_{k_{0}}}\\
	=&\, 
	\sum 
	\ket{\boldsymbol{q}_{M+1}, \psi_{k_{M+1}'}}
	e^{i \boldsymbol{p}_{M+1} \cdot \boldsymbol{q}_{M+1}}
	T
	e^{-i \boldsymbol{p}_{1} \cdot \boldsymbol{q}_{0}}
	\bra{\boldsymbol{q}_{0}, \psi_{k_{0}'}},
	\label{sum_with_T}
\end{aligned}
\end{align} 
with
\begin{align}
\begin{aligned}
	T = T^1_{M}T^2_{M} T^1_{M-1}T^2_{M-1} \cdots T^1_{1}T^2_{1},
\end{aligned}
\end{align} 
where
\begin{align}
\begin{aligned}
	T^1_m =&\, 
		\bra{\boldsymbol{p}_{m+1}, \psi_{m+1}'}
			e^{-i \hat H_1 \delta t}
		\ket{\boldsymbol{q}_{m}, \psi_{m}}, \\
	T^2_m =&\, 
		\bra{\boldsymbol{q}_{m}, \psi_{m}}
			e^{-i \hat H_2 \delta t}
		\ket{\boldsymbol{p}_{m}, \psi_{m}'}.
\end{aligned}
\end{align} 
Note that the sum here in eq.\ (\ref{sum_with_T}) implicitly is over all $\boldsymbol{q}$s, $\boldsymbol{p}$s and $k$s, including the ones in the expression for $T$ (when writing it out in full).

We can now use eq.\ whatevers to get 
\begin{align}
\begin{aligned}
	T^1_m =&\, 
		e^{-i H_{B1}(\boldsymbol{p}_{m+1}, \boldsymbol{q}_{m}) \delta t 
			- i \boldsymbol{p}_{m+1} \cdot \boldsymbol{q}_{m}} 
		\bra{\psi_{k_{m+1}'}}
			e^{-i \hat H_{F1}'(\boldsymbol{q}_{m}) \delta t}
		\ket{\psi_{k_{m}}}\\
	T^2_m =&\, 
		e^{-i H_{B2}(\boldsymbol{p}_{m}, \boldsymbol{q}_{m}) \delta t 
			+ i \boldsymbol{p}_{m} \cdot \boldsymbol{q}_{m}} 
		\bra{\psi_{k_{m}}}
			e^{-i \hat H_{F2}'(\boldsymbol{q}_{m}) \delta t}
		\ket{\psi_{k_{m}'}}.
\end{aligned}
\end{align} 
%Hm, let me take a break.. (Kl. tyve i to.)

%(Kl. halv fire.)
Now, if we gather all the exponential expressions of $
	e^{i \boldsymbol{p}_{M+1} \cdot \boldsymbol{q}_{M+1}}
	T
	e^{-i \boldsymbol{p}_{1} \cdot \boldsymbol{q}_{0}}
$ on the left and all the matrix elements of $\hat H_F'$ on the right, we get
\begin{align}
\begin{aligned}
	e^{i \boldsymbol{p}_{M+1} \cdot \boldsymbol{q}_{M+1}}
	T
	e^{-i \boldsymbol{p}_{1} \cdot \boldsymbol{q}_{0}}
	=
	e^{i \sum_{m=1}^{M} (
	\boldsymbol{p}_{m} \cdot \dot{\boldsymbol{q}}_{m} 
	- (H_{B1}(\boldsymbol{p}_{m+1}, \boldsymbol{q}_{m}) + H_{B2}(\boldsymbol{p}_{m}, \boldsymbol{q}_{m}) )  
	) \delta t }
	F^1_{M}F^2_{M}\cdots F^1_{1}F^2_{1},
	\label{action_discrete_generalized_01}
\end{aligned}
\end{align}
where $\dot{\boldsymbol{q}}_{m} = (\boldsymbol{q}_{m} - \boldsymbol{q}_{m-1}) / \delta t$ for all $m$, and where $
F^1_{m}F^2_{m} = 		
	\bra{\psi_{k_{m+1}'}}
		e^{-i \hat H_{F1}'(\boldsymbol{q}) \delta t}
	\ket{\psi_{k_{m}}}
	\bra{\psi_{k_{m}}}
		e^{-i \hat H_{F2}'(\boldsymbol{q}) \delta t}
	\ket{\psi_{k_{m}'}}
$.
Using that $\{\ket{\psi_k}\}$ is an orthonormal basis of $\textbf{H}_2$, we can sum over all $k_m$ and $k_m'$ with $m\in\{1, \ldots, M\}$ to give us
\begin{align}
\begin{aligned}
	F^1_{M}F^2_{M}\cdots F^1_{1}F^2_{1} =&\, 
		\bra{\psi_{k_{m+1}'}}
			e^{-i \hat H_{F1}'(\boldsymbol{q}_{M}) \delta t}
			e^{-i \hat H_{F2}'(\boldsymbol{q}_{M}) \delta t}
			\cdots
			e^{-i \hat H_{F1}'(\boldsymbol{q}_{1}) \delta t}
			e^{-i \hat H_{F2}'(\boldsymbol{q}_{1}) \delta t}
		\ket{\psi_{k_{m}'}} 
	\\=&\,
		\bra{\psi_{k_{m+1}'}}
			e^{-i \hat H_{F}'(\boldsymbol{q}_{M}) \delta t}
			\cdots
			e^{-i \hat H_{F}'(\boldsymbol{q}_{1}) \delta t}
		\ket{\psi_{k_{m}'}},
\end{aligned}
\end{align}
where we have used $\hat H_{F}'(\boldsymbol{q}) = \hat H_{F1}'(\boldsymbol{q}) + \hat H_{F2}'(\boldsymbol{q}).$

Hm, will it not be a bit weird, when we only have half of $\boldsymbol{p}_{M+1}^2$ and $\boldsymbol{p}_{1}^2$ at the ends.\,.\,? %(Kl. tyve over fire.)
.\,.\,Hm, I guess we will just get two versions of $L$ (an $L_1$ and an $L_2$), which is what I thought I could avoid by letting $\hat I_Q$ and $\hat I_P$ exchange places, but that turned out not to be the case.\,. .\,.\,Hm, but I actually guess I still prefer this version (where the lattices overlap completely in a sense (in space-time) but where $\dot{\boldsymbol{q}}$ is just approximated in two different ways).\,. %..Let me take another break.. %(Kl. halv fem.)

%(Kl. kvart i seks.)
Hm, the next step to get to $\hat P_{\Lambda j} \to \hat P_j$ must be to actually let $\hat V$, $\hat C$ and $\hat H'$ be constant but to double $A$ and $\Lambda$, which also means halving $\delta q$ and $\delta p$.\,. .\,.\,Hm, and that should give us exactly the same result for $(e^{-i \hat H_1 t} e^{-i \hat H_2 t})^M$ (for a fixed $M$).\,. (Except that now, eq.\ (\ref{action_discrete_generalized_01}) have a sum over more values.\,.) \ldots Hm, and what will we then get for a fixed.\,. Hm, ``a fixed $\bar{\bar{q}}$.\,.'' .\,.\,? .\,.\,Hm, do we then need to look continuous $\bar{\bar{q}}$ fields or what.\,.\,? (.\,.\,Or $q(x)$ fields, rather.\,.) (.\,.\,Well, it would actually be $q(t, \boldsymbol k)$ fields, then, to begin with.\,.) .\,.\,Oh, wait can't we just keep all the old $\hat I_Q$s and then only change the $\hat I_P$s?\,.\,. .\,.\,Yeah, that's it; that's the strategy.\,. .\,.\,So we can just argue, that we can change the $\hat I_P$s to any other version, we $A$ and $\Lambda$ are doubled $n$ times. .\,.\,Hm, and then $\bar{\bar{q}}$ can remain constant. And we'll get a changed $\boldsymbol{p} \cdot \dot{\boldsymbol{q}}$, namely with a different factor in front.\,. .\,.\,Oh no, that factor will be on the whole expression (of the RHS of eq.\ (\ref{action_discrete_generalized_01})).\,. .\,.\,Hm, and will the classical Hamiltonians change.\,.\,? .\,.\,No. Good. Okay, and then that should give us the factor to make the measure of the $p$-path integral constant if we are lucky.\,.(?) .\,.\,Hm, for a given $n$, the height of the step is.\,. .\,.\,Hm, the volume is $n^D$ times smaller so the height squared must be $n^D$ times larger, which means the height itself must be $n^{D/2}$ times larger. So the inner product with the old $\ket{\boldsymbol{q}}$ must then be $1/n^{D/2}$ of what it was.\,. *(which means I have probably written something wrong above (in the beginning of this subsection)) .\,.\,Oh damn, I've forgot factors of $1/N^{1/2}$ in the above.\,. .\,.\,Oh, and we get two for each $T^1_m T^2_m$, so We'll get a factor of $1/N^M$ of these. And when adding the $1/n^{D/2}$ factors to the mix, what will we get then? Well, we'll just get exactly $2M$ of these, so in total, we will have a factor outside of $1/N^M$.\,. Oh no, sorry, the are factors of $1/N^{D/2}$ from each inner product, so in total, we will have $1/N^{D M}n^{D M} = 1/(n N)^{D M}$. Cool, this should be exactly what will make the measure constant.\,. (.\,.\,since $Nn$ is the new number of distinct $\boldsymbol{p}$-values.\,.) %(Kl. tyve i syv.) 
.\,.\,Well, except it's actually $n^2 N$ if we double both $\Lambda$ and $A$, but I should actually only double $A$ to find the integral measure. .\,.\,But what will then happen when we double $A$ / halve $\delta p$.\,.\,? .\,.\,Oh no, I mean the opposite.\,. Hm.\,. If we first double $A$.\,. No, sorry, if we first increase $A$ by a factor of $n$.\,.(?) .\,.\,Then.\,. Hm, then $\delta p$ is reduced correspondingly, but what about the inner product, then.\,.\,? .\,.\,Oh, the height of the new $\ket{\boldsymbol{q}}$ step functions would then be the same, which means that that the inner product is preserved (between that new $\ket{\boldsymbol{p}}$s and the old $\ket{\boldsymbol{q}}$s)! .\,.\,Oh, but this will be a bit strange then.\,. .\,.\,Hm no, I guess a should just stick with my intuition and then make sure to increase $\Lambda$ while $\delta p$ is similarly reduced, and then the factor will indeed go as $1/(n N)^{D M}$, as it should.\,. %(Kl. syv.) 
.\,.\,Hm, or maybe the point is, actually, that $\hat I_Q$ and $\hat I_P$ should both be changed together (such that $\hat P_{\Lambda}$ can be changed).\,. .\,.\,Oh, but will this not actually be quite trivial, since we should already have our $1/N^{D/2}$ factors --- or rather our $1/N^{D M}$ factor --- in front?\,.\,. .\,.\,Hm, but we'd like to have $\bar{\bar{q}}$ be a constant.\,. .\,.\,Hm, I can let $\hat I_Q$ be constant, since the $\hat P_{\Lambda j}$s will never work on its bras or kets.\,. Okay, so that is indeed the strategy.\,. 

%(Kl. kvart over otte.)
Ah, when $\Lambda$ grows, the inner products with the old $\ket{\boldsymbol{q}}$s will be approximately constant, and the constant out in front will converge. But when $A$ grows for the new $\ket{\boldsymbol{p}}$s, the inner products will decrease due to lower heights of the (simple) $\ket{\boldsymbol{p}}$ wave functions. So that is as it should be. .\,.\,Hm, and I guess I can just factor out the error on $\exp(i \boldsymbol{p} \cdot \boldsymbol{q})$ (to the power of $2M$), and then that error should converge to a constant (to the power of $2M$), which depends on $\delta q$, and which goes to 1 when $\delta q$ goes to 0.\,.

%(Kl. ti over elleve.)
Okay, I just realized something interesting. Yesterday, I thought about whether Fourier-transforming the time axis would separate the contributions, but for some reason, I thought there would be all kinds of cross terms coming from $\boldsymbol{C} \cdot \boldsymbol{p}$. But no, I should get the contributions separated out, so that the only cross terms come from contributions with the same.\,. Oh wait, maybe we should first integrate over the $\boldsymbol{p}$s, and then.\,. well then things should absolutely separate out nicely, so we only get cross terms between $(\omega, \boldsymbol{k})$-waves with similar $(\omega, \boldsymbol{k})$-entries, or perhaps also when the entries are similar but with opposite signs.\,. 

By the way, the error from the previous paragraph is not independent on $\boldsymbol{p}$, but for each $\boldsymbol{p}$-dimension, it converges to (I believe) $2\sin(p_j \delta q / 2) / p_j \delta q$. .\,.\,So if I carry this through, which I might, I should maybe try to do the complex analytic integration to see that the Gaussian times this factor converges when integrated to the desired result when $\delta q$ goes to 0.\,. 

.\,.\,Okay, but back to the $(\omega, \boldsymbol{k})$-waves.\,. \ldots Ah, yes, if you could show that, by the assumption of overall convergence, the integrals after some large enough $\omega$ must all converge approximately to 1.\,. .\,.\,Hm, or by some other means.\,. .\,.\,Ooh, maybe by showing that the are independent (at least approximately, but maybe just fully) of the first part of the $\boldsymbol\omega$-vector.\,. (Because if they are all approximately the same, then they will just contribute with an overall factor, which should then be 1.\,.) .\,.\,Hm, I guess what makes then not fully independent on the inner part of $\boldsymbol\omega$, is the fermionic operator on top.\,. .\,.\,But if we choose to only (at this point) include a finite part of the fermionic space, then surely this operator will converge as well for high $\boldsymbol\omega$-entries.\,. (And a question is then: will it converge strongly enough?\,.\,.) %(Kl. fem i tolv.) 
.\,.(I feel like this is the last part I need to figure out precisely; then I should have all the other arguments (at least when you look at just the overall picture).\,. .\,.\,7, 9, 13.\,.) .\,.\,Hm, but how does that actually make sense; how do you calculate the fermionic transitions when you only have a finite amount of (discretized) $k$-solutions?\,.\,. \ldots Hm, but couldn't we just somehow show, that we are allowed to only include fields with vanishing $(\omega, \boldsymbol{k})$-waves after a certain point.\,.\,? 
\ldots Hm, I guess we do need to consider the fermions, whatever we do, since they are the only source of dependencies between higher and the lower $(\omega, \boldsymbol{k})$-waves.\,. %(Kl. 25 over tolv.)

\ldots Hm, can I use something from the wisdom of time-dependent perturbation theory.\,.\,? 

%(Kl. 25 over et.)
\ldots\ Hm, weirdly, I could perhaps use the version of the Trotter expansion (with a nested expansion) where the fermion propagators have larger $\delta t$s between them.\,.\,!\,.\,. .\,.\,Right!\,\textasciicircum\textasciicircum\ .\,.\,Yes, exactly.\textasciicircum\textasciicircum\ 

.\,.\,Then it is only a matter of arguing, that the part that doesn't cancel for the bosonic field propagator between two fermion propagators will converge strongly enough to 0 for increasing $\omega$ that we can indeed omit large $\omega$s at some point.\,. .\,.\,Oh, or rather, it's the free part of the fermionic propagator we want to separate (from the interacting part).\,. 

.\,.\,Hm, I guess we want to show, then, that.\,. well, that the overall (fermionic) propagation then converges when including more and more $\omega$s.\,. .\,.\,Hm, and for each $\omega$, we will get $K$ (if we have $K$ fermionic and $M$ bosonic.\,. no, interaction propagators.\,.) non-canceling interaction propagators with a $t$ proportional to.\,.(?) .\,.\,well, to $1/\omega$.\,. .\,.\,(Well, oscillating between 0 and $1/\omega$.\,.) .\,.\,Hm, so the overall ``error'' will converge to 0, but what do we need exactly, because we do have an infinite amount of those.\,.(?) %(Kl. fem i to.)
.\,.\,Oh wait, want they have alternating signs.\,.\,!\,.\,.\,? .\,.\,Oh, but the amplitudes might be alternating as well.\,. .\,.\,Hm, let me take a break and think about it.\,. %(Kl. fem over to.)

%(Kl. ti over seks.)
\ldots\ Okay, I have a few things to write and a few more thought to think about, but I just want to write that I have finally realized how to choose a discrete approximation that for a given boost will Lorentz-transform into another discretization exactly. All one need to do is to approximate each step function, for both the lattice approximations and fermion wave functions, not to values not exactly at the center of the step, but to values a little off-center (in alternating directions). And with this, one can make one discretized path turn into another discretized path exactly in the boosted inertial system.\,.\,:) This has the potential to be quite useful.\,.\,:) 

\ldots Ah, this is actually pretty awesome; I think this will actually be the easier argument to make.\,. About was I thought about in the previous paragraph about $1/\omega$ and all that, I sort of realized, after some thinking, that I already have the convergence that I tried to argue about, at least in $(t, \boldsymbol{k})$-space(-time).\,. But then the argument seemed to become a bit more complicated when wanting to argue that two (existing, continuous) $\sum (\omega, \boldsymbol{k})$ fields must contribute with the same in the path integrals *(if the are the same, just Lorentz-transformed).\,. .\,.\,The final part of the argument has escaped me so far today (.\,.\,i.e.\ unless I'm forgetting a previous solution of mine).\,. It seems a bit complicated to finalize, so I'm really glad a have this new solution/argumentation strategy.\,:)\,.\,. .\,.\,Which, by the way, more precisely means to approximate a given $\boldsymbol{k}$-wave with step functions with heights set to slightly off-center values (to alternating sides) in the $x$-space (/$\boldsymbol{x}$-space).\,. (.\,.\,One should imagine a wave (just think about it in one dimension) that intersect the steps that approximate it in points off the center, where the distance to the center point is always the same for all steps but where the direction alternates for each step.)


%(Kl. 25 i ti.)
(13.03.22) Ah, I have thought a bit more about things this morning, and now I only need for us to be able to let $\delta q$ go to 0 for a fixed (large) $M$ (i.e.\ fixed time intervals), and then I can construct a full argument. (.\,.\,In which, by the way, I can let $\delta p$ and $\delta q$ tend to 0 together.) .\,. .\,.\,Oh, and we can do this simply by arguing that the inserted $\hat I_Q$ and $\hat I_P$ ($\sim M$ of each) can tend to $\hat I$.\,.\,:) .\,.\,Cool! So now I should have it. 

.\,.\,Okay, let me try to sum up the argument. The idea is to first approximate the fermions by restricting them in space. .\,.\,We also approximate the bosons with a cap on $\boldsymbol{k}$, which is equivalent of choosing a $\delta x$. .\,.\,Then we approximate the boson-fermion interaction by interpreting the $q$-values as amplitudes of simple, approximated $\boldsymbol{k}$-waves, consisting of steps with a width of $\delta x$ and also with that alternating unevenness I talked about yesterday (just above). .\,.\,Now we do a Trotter expansion and choose a large enough $M$ (or small enough $\delta t$, equivalently) (for the given $\varepsilon$ (error)). We don't need to do this unevenly in terms of fermionic and bosonic propagation (I'm pretty sure.\,.); we can just do it like I have shown above in this subsection. .\,.\,Hm, I guess one should also choose $\delta t$ small enough that it.\,. is below $\delta x$.\,. Yeah, and then one should really argue about the step-approximated fields in bot space and time when arguing about how the boson-fermion interaction is approximated. And in relation to this, one should also make sure that it does not matter if these steps are turned and angled so they fit in the Lorentz-transformed lattice.\,. Okay, and from there, we should then choose a small enough $\delta q$ and $\delta p$ (together) for the given $\varepsilon$, where, by the way, the $q$-amplitudes should also approximated in the same (alternating, off-center) way, that the spacial lattice steps are, since we would like the amplitude points for the $A^\mu$ field to transform one to one into points in the Lo.-transformed $A^\mu$ field. Note that we should both think about the approximation to the true propagator (in each inertial system) and the approximation of the Gaussian, not integration, but summation when we choose $\delta q$ and $\delta p$, namely since the summation has to approximate the Lorentz-invariant result. .\,.\,Once this is done, we can now argue about the similarity between two corresponding path in the two inertial systems, and since for any $\psi$, the amplitude measured by.\,. a discretized $\psi^\dagger(x)\psi(x)$ at a space-time point $x$, will be.\,. Oh, I would have said: ``will be the same as in the Lo.-transformed system (when making sure to Lo.-trans.\ the spinor also)'' (i.e.\ not for all $\psi$ at once, but for any given $\psi$ (since $\psi$'s complex amplitude there will be the same (when accounting for spinor transformation))), but who says we need to actually discretize the fermion wave functions.\,. .\,.\,We have bound them to a local area of space (or of space-time, rather), but I don't think we need to give these a $\delta x$ also.\,. .\,.\,Oh well, but one \emph{can} do this --- maybe to make sure that everything is.\,.\, path-ified.\,. --- and if one does so, then one does not need to worry about what the true transform of a certain discretized $\psi^\dagger(x)\psi(x)$ is, since for any given $\psi$, one can just choose a small enough $\delta x$ and then the result will be approximately the same anyway. :) %(Kl. 25 i elleve.)


%(Kl. tyve over et.)
\subsection{To-dos for now going forward (13.03.22)}
Okay, I think I will then just make a heuristic path integral derivation in the main article (where I think I will actually just use $O(\delta t^2)$ arguments), and then link to the more careful, discretized derivation in an appendix. And for the argument for Lorentz invariance, I will actually do something similar, i.e.\ give a (very small) heuristic argument and then link to a more detailed (but maybe not super detailed) argument, that uses the result for the discretized path integral, and which in general looks at descretized paths (except for the fermion $\psi$s, which will be continuous, and thus only be approximated as bound to a local area (in space and time)). Then I will look at the EM Lagrangian, Fourier transform it, and identify the proto-Hamiltonian. Here, I will probably once again link to an appendix for details for the Fourier transform. With the proto-Hamiltonian I will first motivate my special, gauge(-eliminating) wave solutions (just similarly to how I discovered them (which I still remember somewhat)). And then I will probably just show that the are solutions and that they are Lorentz-invariant with the same calculation (if this will indeed be possible), i.e.\ with my ``($\square^2\phi=0$) argument.'' .\,.\,Well after, or perhaps just before, this, I will then give the argument why the Hamiltonian after the gauge elimination must be Lorentz-invariant if it turns out to be self-adjoint. And at last, I can then derive the my Hamiltonian, which I will by the way still introduce in the beginning, before the path integral and so on. And after that, we get to the discussion part, which I still intend should be roughly how I have envisioned it before. *(I should also argue somewhere why we can conjugate the positron solutions.\,.)

So before I get to actually working on the article itself (and not this pre-draft, which is also partly working notes), I should at some point do an argument for the Lorentz invariance of the (discretized) path integral, I should do the heuristic derivation of the path integral, I should do the Fourier transform of the EM Langrangian, I should go through the ($\square^2\phi=0$) argument, and I should.\,. Oh, wait. I also forgot to include an argument for why we can conjugate the positron solutions.\,. Let me just insert that above.\,. .\,.\,Well, I don't know when to include it, but I can just see what makes most sense, when I have gone through it here, which is in fact another one of these to-dos. I should also of course derive the final Hamiltonian from this, and is there anything else.\,.\,? .\,.\,Well, maybe go through the mentioned motivation quickly as well.\,. .\,.\,Ah, and of course I should also go through the argument of why the resulting Hamiltonian will be Lorentz-invariant if it is self-adjoint. Okay. Let me then start with the ($\square^2\phi=0$) argument, that seems like the most interesting of these to-dos.

\ldots Oh, let me actually just think a bit about the last-mentioned to-do first.\,. I'm not sure, if I've mentioned this, but I now think that I can argue for it simply using that a series of bounded, and therefore self-adjoint, Hamiltonians will be able to approximate it arbitrarily well for any given vector (that is located just in the neighborhood of a special (``GEW'' (or whatever)) solution).\,. (.\,.\, Or gauge \emph{symmetry}-eliminating wave solution.\,.) .\,.\,Hm, and would this argument work like I have thought.\,.\,? (.\,.\,It surely must, but precisely how do we make the argument.\,.\,?) .\,.\,Hm, since it's so nice weather, let me actually just take a walk (another one) and think about this --- oh, and if i figure it out quickly, then I can just think about the ``($\square^2\phi=0$) argument.'':) %(Kl. kvart over to.)
%(Kl. kvart i fire.)
\ldots\ I think I will actually just do a heuristic argument, where I will use that a non-zero, but small, effective $eV$ will just be a little momentum boost. There will thus be $M$ of those in a Trotter expansion, so if you take $\psi$s.\,. Hm, I would have said: ``take $\psi$s closer and closer to the GSEW (or whatever) restriction, then these $M$ boosts will be smaller and smaller,'' but I guess you can fix $M$ like that when changing $\psi$ also.\,. .\,.\,Oh, but in a heuristic argument, we can probably just argue, that, okay, then you will just have $nM$ boosts with a strength going as $1/n$ on top of the smaller and smaller strength due to a lower effective $eV$.\,. .\,.\,Hm, I will find this out.\,. %(Kl. ti i fire.)

%(Kl. fem over ti.)
(14.03.22) It is not hard to show that the GSEW solutions work with via the Trotter expansion so I will just do this directly after my motivation. And I feel like I know how my ``($\square^2\phi=0$) argument'' should go, so I will actually not go through either of those things now after all. Instead I will actually just begin working on the first draft (but starting from the path integral section) right away. Before I do that, I should mention that even though the conjugation should happen before the gauge elimination, I might just put it in a section after and then just backtrack in the argument.\,. (and explain why it still works).\,. .\,.\,Hm, perhaps.\,. I will see in time. Another quick thing is that I have to remember to include an argument of why it is fine that $L$ (and thus also $\delta k$) stays finite (/non-infinitesimal), as the argument for Lorentz invariance still works (as long as we can just always choose it large enough --- and then afterwards, one can argue that the dynamics converge for $L$ going to infinity, simply because of the limit on how fast information can travel, which we will have once the Lorentz invariance is shown). .\,.\,Okay so let me instead change section and start working on the first draft.
%
\\
\noindent*[

%(Kl. halv ti.)
(16.03.22) The day before yesterday evening, I found out that I need something for the argument for Lorentz invariance. So a started to think about that. I have come up with a few different ideas in the process, but the big idea was really the one I got yesterday late afternoon--early evening. There I found out that I can narrow the potentials in the direction(s) of time so that the are sent towards lines, basically. That was, by the way, the big problem I discovered, namely that my argument for the path integrals in the two different inertial systems to be exactly the same wasn't quite right since the approximated fields (that the fermions see) was not exactly the same. And there's a problem, the way I see it, of just letting $M$ (and $N$) going to zero since that changes the number of paths as well.\,. But with this line approximation solution, we are not changing the number (or space) of paths while the potential width is tending to 0. Now, the idea is also to then do this within a Trotter expansion such that there is no free-energy propagation happening while we propagate the fermions over each step/line. This is how we can then argue that the step potential that we would normally propagate the fermion over --- and where we have now made sure to separate the free-energy part and the potential part of the fermion propagator (namely as part of a Trotter expansion) --- .\,.\,let me restart this sentence. Since the fermion propagator is now split up, when we potential-propagate the fermion over a potential step (when the boson-fermion interaction is approximated by step potentials / simple potentials first), then in terms of the calculation, it gives the same outcome if we let it propagate over a narrower but higher/stronger potential instead (and let the rest of the potential be of 0 height/strength). So once an $M$ (and $N$ (which I (now) intend to use for the total number of lattice points)) is fixed, we can change the potential steps into lines without changing the result. And these lines can also be rotated so that they approximate (better and better for smaller line width) what we would naturally choose them to be in the other inertial system. In other words, when we have two Trotter expanded paths of two different inertial systems next to eachother, (with fixed $M$s), we can narrow the potential steps and rotate them so they tend to one another. .\,.\,And now comes the last part, cause I should now try to make sure that we can then do the Trotter expansion related to the fermion propagator split-up in reverse and obtain exactly the same path integrals (where the fermion part of the paths are once agian just the full Dirac propagators on top of the fields of the paths).\,. .\,.\,Yeah, but I guess the point is just.\,. Hm, will it really give the exact same result back when we reverse the fermion Trottorization.\,.\,? .\,.\,Ah, sure. Yes, we can reverse the fermion propagator Trotterization since we havn't changed the result by narrowing and rotation the potential steps. But we will just not ``get the error back'' again; the error from splitting up the fermion propagator will not disappear again, of course. But yeah, since we are not actually changing the result.\,. Hm, wait a minute.\,. .\,.\,Hm, maybe it's not quite so easy.\,. .\,.\,Hm no, maybe it is actually hard to get the complete fermion propagator back again.\,. \ldots Hm no, I can actually see a big problem with this approach.\,. .\,.\,Hm, let me think some more, cause I might have some other ideas that could be more appropriate to try, then.\,. %(Kl. halv elleve.)

%(Kl. ti over et.)
\ldots\ Ah, I just found the idea that might carry my previous solution through. The overall idea is not fundamentally problematic like I thought earlier. It might work. Heuristically, one could do an argument, where we argue that as the potential line width becomes smaller, free-energy propagator on top of it becomes less and less significant. Maybe this way, one could argue that it can be removed in the end from the complete propagator (yielding an arbitrarily small error). And once it is removed, we obtain (if all else is done right) the path integral in both systems, where the potential can be rotated and narrowed to become arbitrarily close to the other. But while this argument could make sense intuitively, maybe it is better to argue about the complete (fermion) propagator on top of a full ``step'' (i.e.\ a small volume in space with constant field/lattice amplitude throughout) versus on a volume with a narrow (but all the higher/stronger) line potential, and argue.\,. hm, that the Hamiltonian of each of the two $\delta t$ propagators must be approximately equal to one another.\,. Hm.\,. .\,.\,Hm yeah, I guess that could actually make good sense to do.\,. .\,.\,Essentially, we would then want to use that the $\delta t$ propagators for the fermions *(on the whole $x$-space, that is (and for a little interval, $\delta t$, in time)) are approximated by corresponding propagators but where the steps of the potential are narrowed into lines (and potentially with a rotation as well).\,. .\,.\,Yes, that should be possible (we are already approximating the potentials with steps so why not go one step further and approximate it further with ``lines'' (possibly with rotations) before we start comparing the paths to those of the other inertial system?\,.).\,. .\,.\,Great. (.\,.\,!) Now I need to figure out, if I really can form the whole argument now, and also then how much of it, I should include in the article.\,.  %...Let me take a break, go for a walk (in the lovely weather) and think about it..

%(Kl. fem i tolv.) (Sov rigtigt længe i dag.)
(17.03.22) I forgot to mention yesterday that I \emph{should} let $L$ *(I'm talking about the universe / $x$-space length here (meaning that the $k$-space tends toward continuity)) go to infinity.\,. And another point is that one might be able to make an easier argument about the Lorentz invariance. Instead of arguing via a ``closed circuit'' of propagations and transformations, one could perhaps argue by ``turning on'' the interaction in a local space-time area and show that this dynamic is Lorentz-invariant. And then it just follows that you can make that area arbitrary large, and so the theory without the interaction localization must also be Lorentz-invariant. I think this could be an easier argument to carry through (but the ``closed circuit'' argument should also work (and be ``rigorizable'')).\,. 

.\,.\,Okay, let me now try to go through the argument for how the paths for two different inertial systems can become exactly the same for the two calculations while the two calculations each still approximate the dynamics of their inertial system (to an arbitrary degree of precision). .\,.\,First we should approximate the dynamics for each system with, not just a bounded, but a finite dimensional Hamiltonian, why not?\,. .\,.\,Hm, before a move on, let me actually take a moment to go through the geometry argument.\,. 
%(Kl. 25 i et:)
\ldots Hm, there might actually be a problem with it.\,. No, wait.\,. .\,.\,It's definitely not as simple as I thought, but let's see.\,. \ldots No, it's definitely not as simple, in fact, there are some definite problems with drawing such a space-time grid.\,.\,:\textbackslash\ \,.\,.\,Okay, so what then?\,.\,. .\,.\,Hm well, then I need to think a bit.\,. 

%(Kl. tre.)
\ldots\ I just got a great idea about a half hour ago (and three o' clock now), which might just be the key.\,. If instead of using my discretized %$\ket{\boldsymbol{q}}$s and 
$\ket{\boldsymbol{p}}$s from above, we use $\delta p$ momentum wave packets (i.e.\ wave functions that are also step functions, but just in momentum space), then I'm pretty sure we should get something like $4\exp(i \boldsymbol{p}\cdot \boldsymbol{q})\sin^2(\delta p \delta q / 2)/\delta p \delta q$.\,. hm, let me just try to Wolfram Alpha it quickly.\,. .\,.\,Okay, it doesn't evaluate to what I thought just now; instead it evaluates to a ``sine integral'' (of course, since my result from earlier (when integrating in only one dimension) was $\sim 2\sin(\delta p \delta q / 2)/\delta p\delta q$, and that is the form of the integrand in this ``sine integral'').\,. .\,.\,Hm, and when dividing with $\delta p \delta q$, as I should, gives something with an (alternating) even Taylor series --- starting with 1 of course as the 0th-order term.\,. .\,.\,Oh wait, I'm not calculating the right thing exactly.\,. \ldots No, it's actually not a very nice integral, but the idea might still be good enough.\,. .\,.\,Oh, but for.\,. most $p$ and $q$, the result wil be approximately $4\sin(p \delta q/2)\sin(q \delta p/2)/pq$.\,. .\,.\,And that's before I divide with $\delta p\delta q$ as well.\,. .\,.\,Okay, great.\,. 
\ldots Oh, and I've also forgot a factor of $\exp(i p q)$ in front (of course).\,. 

\ldots\ Ah, no, I'm actually gonna use my original idea instead and just time the $\ket{\boldsymbol{p}}$ functions with a Gaussian.\,. .\,.\,And that should then give me something like $\exp(i \boldsymbol{p} \cdot \boldsymbol{q} - \,.\,.\,)$.\,. Hm, should I make the $\sigma$ *(or $\boldsymbol{\sigma}$) of the Gaussian depend on $\boldsymbol{p}$.\,.\,? .\,.\,Hm, or should I time the functions with something like $\exp(-|q|)$ instead.\,.\,? .\,.\,(or $\exp(-p |q|)$.\,.(?)) .\,.\,Hm, no the absolute value will make the result ugly.\,. .\,.\,Hm, but maybe something like $\exp(-p q^2/2\sigma^2)$ isn't such a bad idea.\,. .\,.\,Or what about just $\exp(-q^2/2\sigma^2)$.\,.\,? .\,.\,And that's how we can ``renormalize'' the path integral, if I'm using that term just somewhat correctly.\,. (.\,.\,or maybe ``regularize'' it.\,.) .\,.\,Hm, and I guess $\sigma$ should actually not just be as large as possible, but should perhaps be \emph{bounded} by the choice of $\delta p$ for it to work.\,. Hm.\,. .\,.\,Hm, oh wait, what am I really achieving with this that I didn't have with just an $A$-cutoff for the $\ket{\boldsymbol{p}}$ wave functions.\,.\,? %(Kl. 25 i fem.)
\ldots Maybe I just need a more general approximation.\,. 

%(Kl. ti i seks.) Jeg tog lige på en lidt slukøret handletur, men på vej hjem nu her kom jeg så på følgende idé.:D..
\ldots\ I just got an idea that I'm quite excited about.\,. The idea is to ``regularlize'' (or whatever) the path integral with an exponential decay, not as $A_\mu A^\mu$ and not just as $\sum_\mu A_\mu^2$, but as $\sum_\nu ((\Lambda_\nu^\mu A_\mu)^2)$, where $\Lambda_\nu^\mu$ can just be an arbitrary Lorentz transformation (for whatever $\boldsymbol{\beta}$ we like).\,\texttt{:D}\,.\,. (So while this change to the resulting $L$ (or /$\mathcal{L}$, rather.\,.) won't be Lorentz-invariant, it is general enough that it essentially becomes Lorentz-invariant.\,\texttt{:D}\,.\,.) (.\,.\,We can namely then just chose $\boldsymbol{\beta}=0$ for one of the two inertial systems and choose a $\boldsymbol{\beta}$ equal to the difference between the two inertial systems for the other.\,.) .\,.\,Okay, I hope this works.\,. What is required for this to be possible.\,.\,? .\,.\,Hm, that we are allowed to time the $\ket{\boldsymbol p}$ functions with some $\exp(-(\bar{\bar M} \boldsymbol{q})^2/2)$.\,. .\,.\,Right, and we must.\,. Hm.\,. .\,.\,Hm, should I at least try to re-orthogonalize them.\,.\,? .\,.\,Hm, maybe yeah.\,. .\,.\,Hm, but why wouldn't I then just try to put an $A$-cutoff on them according to $\sum_\nu (\Lambda_\nu^\mu A_\mu)^2$?\,.\,. .\,.\,Hm, let me just think for a bit.\,. %(Kl. kvart over seks.)

%(Kl. fem i syv.)
\ldots\ Hm, I started thinking about the ``imaginary time'' trick for evaluating path integrals (and read a bit in Hall (sections 20.3--20.5)) and now I just had the idea: what about looking at $\exp(-i \hat H t -\epsilon \hat H t)$?\,.\,.
.\,.\,Hm, I should figure out, what the Gaussian integration will yield then.\,. 
%(Kl. 25 over syv:)
\ldots Uh, that might yield slightly different factors on the kinetic and potential part of $\mathcal{L}$ but maybe we can just cancel this by putting a separate factor on $\hat p^2 / 2$ as well (which should be possible if we have approximated $\hat H$ as a finite-dimensional operator)!\,.\,. In-te-rest-ing.\,.\,!\,.\,. 

%(Kl. tyve i tolv.) Jeg stod op frisk ved otte-tiden i dag, men har så brugt hele formiddagen på at tænke videre over, hvad det præcise argument skal blive.. Lad mig fortsætte i renderet tekst..
(18.03.22) I've spent the morning/noon today thinking about how to complete the argument from yesterday evening (i.e.\ where you rotate the kinetic and potential part of $\hat H$ slightly into imaginary time (with a small phase that later tends to 0), but in opposite directions). I've thought about how to perhaps use Wiener measure, but now I think I've finally landed on a different strategy. But let me just talk a bit about my ideas for using the Wiener measure. First of all, I got the idea last evening to only use part of the $\exp(-\epsilon \dot q^2/2)$ term in the wiener measure (and split it up into $\exp(-\epsilon \dot q^2/4)\exp(-\epsilon \dot q^2/4)$), since theorem 20.2 in Hall needs $f$ to be non-negative (and real). But if we leave a factor of $\exp(-\epsilon \dot q^2/4)$ in the integrand (to become part of $f$), then we can split $f$ up into four non-negative functions, each with a pre-factor of $i^j$, $j\in \{0,1,2,3\}$, for which (because of the kept $\exp(-\epsilon \dot q^2/4)$ factor) the four integrals all converges. And then we can use theorem 20.2 on each. (To what end, I don't quite know, which is why I have (luckily) found another strategy.) Let me also mention that today, I got the idea to maybe also try to include a similar portion of the rest of the Lagrangian (and not just $\exp(-\epsilon \dot q^2/4)$) to make a new measure that is Lorentz-invariant. Again, I don't know if this would be helpful at all, and luckily I have (hopefully) found another strategy (i.e.\ that \emph{might} work). .\,.\,I guess I wanted to mention this especially since this more sorta beautiful mathematical approach (once such is found) might bring some more.\,. nice mathematical insight with it.\,. I don't know.\,. Anyway, my strategy that I've just landed on a little time ago is to simply argue about the error between the contributions in the neighborhood of a certain $C([1,t], \mathbb{R}^N)$ path in the two different inertial systems, namely in the form of the difference between the two contributions. When we integrate, since we now have that $\sim \exp(-\epsilon \dot q^2/2)$ (or $\sim \exp(-\epsilon (\dot q- C)^2/2)$) factor in front, we can then split the integral into two and integrate the error (i.e.\ the difference) apart from the rest (together with the $\exp(-\epsilon \dot q^2/2)$ factor). And now we should just, as I see it, be able to use that this integral goes to 0 in the appropriate limits, even when $M$ is also increasing as part of these limits (since the normalization factor (as a function of $M$) should make sure of this), when we know that the error converges to 0 everywhere in the limits.\,. It of course requires me to argue from the equations to really be able to make a sensible argument, but this is the idea, and I think (and hope!) it will work (7, 9, 13).\,:)\,.\,. 

%(Kl. fem i elleve.) Jeg har sovet længe i dag, selvom jeg gik rigtigt tidligt i seng i går. Jeg tog resten af i går fri og nød det ekstremt dejlige vejr. (Og ja, fejrede at jeg nu nok har styr på alle argumenterne overordnet set.) Fortsætter i den renderede tekst nu. ..Nej, lad mig lige også sige her, at da jeg startede min gåtur i går kom jeg på den idé, at man måske bare kunne bruge Wiener-målet og fremgangsmåden til udledning af Feynman-Kac-formularen, som ses i Hall, bare for error-funktionen, men efter et lille stykke kom jeg frem til, at det ville være overkill; argumentet er nemt at gøre uden; det er nemt at se, at den samlede fejl må gå mod 0 i grænsen, også når $M$ (sammen med $N$ (samt self. også \Lambda og A)) går mod uendelig.
(19.03.22) I indeed don't need to argue from the Wiener measure (even though I liked my little idea to split it up as $\exp(-\epsilon \dot q^2/4)\exp(-\epsilon \dot q^2/4)$ and let one of these factors be in the integrand *(though not at all as much as my idea to rotate slightly into imaginary time (and in opposite directions for $\hat V$ and $\hat p^2 / 2$)\,:)\textasciicircum\textasciicircum\,)); it will be quite easy to show that the error (i.e.\ the difference between pairs of paths (or rather the values of them) in the two inertial systems that are all the closest ones to each other) tend to 0 in the limits. I confirmed this yesterday (on a walk in the extremely lovely weather), and it was also yesterday (evening), by the way, that I found out how simple a task it is to pair the paths of the two different systems; just take the closest neighbor in each case (and if two neighbors have exactly the same distance to a point, just use the angle for the sub-ordering (obviously with opposite signs when starting in one of the two different systems and then finding nearest-neighbor pairings to the points in the other system)). On my walk yesterday, I also thought some more about the arguments for how Lorentz-invariant path calculations give Lorentz-invariant dynamics. An argument that might be easier to explain is to use the fact that we can turn the interaction on only for a specific, local space-time volume without breaking the symmetry. And I would imagine that it is quite easy to show how the solutions of the free theory (before the gauge elimination) transform. Then one can just prepare the incoming free particles (perhaps in a highly entangled way if need be) to get whatever in-state one wants (at the interface where the interaction starts). And at the end.\,. .\,.\,Hm, maybe this argument is not actually easier, cause I guess one still needs to use the fact that the path integrals can be divided into propagators for local space-time areas/volumes (and not necessarily with the angles on the initial and final hyperplane).\,. Oh well, I guess one should just make the other argument (which I think is the easiest one to rigorize anyway), namely the one similar to what I did (or tied to do at least (it's a long time ago now)) in my bachelor's thesis, namely where you show the ability I just mentioned to divide path integrals up into local volumes, show that they are equivalent across inertial systems and regardless of whether they're part of af Lorentz transformation or part of a time-evolution propagation, and also show that doing the same path integral in reverse simply leads to the inverse unitary propagator (and then it is just a matter of seeing that series of local propagations in the two different legs of the closed circuit evaluates to the same overall propagation). 

This noon, I have just wondered a bit about the matter of the Jacobian of the transformation when have our system in $(t, k)$ coordinates.\,. .\,.\,I guess I could try to go to $t\to \omega$, but i think it will actually be better to just go to $k\to x$ instead (especially to prepare for the argument about local space-time propagations that I just mentioned).\,. 
\ldots Oh, can't I just use a similar nearest-neighbor procedure to transition from $k$ to $x$.\,.\,!\,:)\,.\,.\,? %(Kl. fem over tolv.) 
.\,.\,(Namely since $\boldsymbol{q}$ (which, remember, is the amplitudes of the different $k$-waves in the $A^\mu$-field/-lattice) is still discretized also.)\,.\,. 

%... Ah, vejret er næsten \emph{for} godt i dag også.. Nå, lad mig lige få tænkt denne tanke færdig og så gå i gang med at genoptage skriveriet.. (Kl. ti i et.)
\ldots\ Ah yes, we should be able to pair each $\boldsymbol{q}$ with a single (nearest) $\tilde{\boldsymbol{q\,}}\!$, where I use the opposite notation from my bachelor's thesis as $\tilde{\boldsymbol{q\,}}\!$ here denotes a lattice in $x$-space.\,. .\,.\,Hm, and when the fermion wave functions are contained in a local space, then we should be able to transform the Lagrangian.\,. hm, to a $x$-space lattice, right.\,.\,?\,.\,. .\,.\,Hm, I almost can't think with that weather outside.\,. %..Hm, it is one o' clock already, and it might be better to just go outside and think of this little matter instead of sitting in here where it's hard to think (and get nothing done).. ..And I can just try to make it a short walk.. Okay, let me just take my break now, then. 

%(Kl. halv fem.) Åh, det blev så en lang, men til gengæld også rigtig produktiv gåtur.:D 
\ldots\ Ah, I just had a really productive walk. There actually was a problem with my idea for pairing ``nearest neighbors,'' but the solution is pretty simple: just do not care that the pairing might not be one-to-one. As long as each path is just paired with another after a procedure where the distance to path in the other discretized system just becomes smaller and smaller, then the argument will work. But more importantly, I found out what that argument should be, exactly, on my walk.\,:) .\,.\,I might actually need the Wiener theorem (20.2 in Hall) to argue that we only need to consider contributions from (the neighborhoods of) continuous paths, but we'll see.\,. (.\,.\,And I think I might just propose my idea to get the Lorentz-invariant version of the measure, not that I will use it (and not that \emph{I} can show its existence), but others might be able to use it for something.\,. .\,.(Maybe to make a more clean-looking proof of Lorentz invariance.\,.)) Okay, but my idea is now to argue that we can propagate the wave function to any space-like hypersurface (but where all the coordinates are un-transformed). Specifically we can propagate it from one (space-like) hypersurface to another over only a little local volume in space-time (and thus where the two surfaces intersect excepts for the two space-like edges of this local space-time volume). And to propagate the wave functions so, one can do a path integral over only that volume. .\,.\,The idea is then to show that for both inertial systems (that one compares), this amounts to two local path integrals which converge to the same result (when also finally transforming the coordinates on the surface in one of the systems). This require us to have the path integrals formulated in $(t, x)$-space first (instead of $(t, k)$-space).\,. .\,.\,And the idea is then to pair $(t, k)$-space paths and $(t, x)$-space paths somehow, let's see.\,. %(Kl. fem i fem.)
.\,.\,(The above points all ideas from my walk, and now I just need to figure out exactly how the ``pairing procedures'' should be (and what the involved ``error functions'' will be for the different transitions/transformations).\,.) %..Lad mig lige tage en lille pause og summe lidt over det..

%(Kl. seks.)
\ldots\ Okay, I think I've got it now.\,. Instead of trying to make one-to-one pairings, one should just go to a more fine-grained discretization for each transition (going first from $k$- to $x$-space, then to the Lorentz-transformed system (in $x$-space) and finally from $x$- to $k$-space). That way, it is ensured that each path is paired with at least one other path (in the transformed (discrete) system) (and that all paths in the group are close by the original path), and we can make sure, at the same time, that all paths of the transformed are paired.\,. no.\,. are associated with exactly \emph{one} path of the original (discrete (but with a rougher grain)) system (though the number is generally more than one and might vary if we go the other way). So for each transformation(/transition), there will just be an error coming from now integrating over all these other paths (close by) instead of the original path. And these errors will tend to 0 when all the discretization grains (collectively) tend to 0. And since what you get in the end is exactly the propagation as seen in the Lorentz-transformed system (viewed in $k$-space), only with a consistently finer discretization grain (since it gets finer for each of the three transformations), then.\,. .\,.\,Yeah, then this means that doing that calculation will give the same result than doing the original (path-integral) calculation, only with three error functions added to the calculation which all tend to 0 in the limits. And using the ``niceness'' of the integrals when we have the $\exp(-\epsilon \dot q^2/2)$ term in front in the integrand, we can conclude that the calculations will then tend to the same result for both systems in the limits. .\,.\,Let me see, something tells me that I've overlooked.\,. oh right, there is also the matter of arguing about the ability to transform/propagate to these ``states'' on the space-like, but not necessarily with constant time in any inertial system, hypersurfaces in the first place.\,. .\,.\,(But cool that I'm this far now.\,:)).\,. .\,.\,(And this is where I'm thinking I might have to use theorem 20.2, namely to argue somehow that we only need to consider (neighborhoods of) continuous paths in the path integrals.\,.) %(Kl. 25 over seks.)
.\,.\,Hm, couldn't we actually make the same propagating-over-these-small-space-time-volumes argument but with the (perhaps Lorentz-invariant) Wiener measure.\,.\,? So in other words, couldn't \emph{this} be the potential, ``more clean-looking'' proof/argument I talked about.\,.\,? %(Kl. 25 i syv.)
.\,.\,Ah yeah, I guess so.\,. .\,.\,Hm, so what do \emph{I} do, then?\,.\,. .\,.\,Maybe I should read a bit more up on Borel algebras and measure theory, then.\,.(?\,.\,.) .\,.\,Yeah, it seems too good to just pass, so let me definitely try to see what might be possible for me.\,. %(Kl. tyve i syv.)

%(Kl. tyve over syv.)
Ha, I think it's actually pretty easy to define the Lorentz-invariant measure from the Wiener measure.\,\texttt{:D} .\,.\,I'm a bit proud that I didn't actually need to read any more up on the topic (despite my low level of knowledge in the area).\textasciicircum\textasciicircum\ One should be albe to define the new from the old $\mu$ simply by integrating each set in the Borel algebra (if that's the one that is a set of all closed sets one could integrate over) with the integrand of the remaining exponential functions (that we want to absorb in the measure to make it Lorentz-invariant) using the wiener measure for the integration. And that should then for each set in the borel algebra give us a value that should then be the function value of our new $\mu$ for the given set. .\,.\,Way to go!\,\texttt{:D}\, %(Kl. halv otte.)
.\,.\,Oh, I can see that what I'm talking about is called the Borel \emph{set}.\,.

%(Kl. ni.)
(20.03.22) I think I know roughly how one should make the argument without using the Wiener measure, namely by arguing that the $\exp(-\epsilon \dot q^2 / 2)$ factor makes the wave function on top of a rugged hypersurface in a discretized system approach the wave function on the smooth (space-like) hypersurface when the discretization grain tend to 0. .\,.\,But, it would be a shame, almost, not use the Wiener measure and try to see if the argument can be done in a pretty way.\,;)\textasciicircum\textasciicircum\ .\,.\,I'm going to try to go through it now and resume the section below. %(I didn't get a lot of sleep last night (..i.e. this night..) for some weird reason I don't know, so let's see how much I can get done today; I feel quite fresh but a bit.. dizzy.. ..And a bit slow.. ..Oh, now I can actually really feel it.:\ A shame if it means I can't get much work done today..:\ ..I'll just have to try.. (I woke up at half past three or so --- and I went to bed late; at half past one or so --- a bit warm, but I (opened a window and) should definitely have been able to fall asleep again..))

(25.03.22) Okay, I have written some notes in the comments that are.\,. .\,.\,just above the ``Arguments and formulas'' section below. In these, I have worked quite a bit on the problem of showing Lorentz-invariance (in a way that can be rigorized (that is the goal at least)), and I've reached an approach that I think will work. Now, I will start working on that ``Arguments and formulas'' section I just made the header for, in which I will go through all the formulas and arguments that I will use in article (but just in a loose writing style again). 



\phantom{\ }

\noindent]




%\subsection[square phi arg.]{The ``($\square^2\phi=0$) argument'' (13.03.22)}
%Her er min text fra main.tex-noterne (2021(--22)-noterne) igen:
	%"(06.12.21) Okay, i går aftes kom jeg endelig frem til argumentet igen, og kom vist også på en god måde at formulere det på. Hvis man nemlig starter med vilkårlig start-tilstand for V og A_\parallel, så har man i første omgang en fase på denne i henhold til løsningsdomænet. Denne fase svarer til \exp(-i phi(\sum x_{fermions})), hvor denne phi er identisk med den, man skal lægge til nul- ((V=0, A_\parallel=0)-) tilstanden for at komme til den vilkårlige tilstand. Når vi specifikt lægger en phi til nul-tilstanden med \square^2 phi = 0, så vil den transformerede vilkårlige tilstand (som jeg har kaldt (V', A')) blive til en slut-tilstand, som svarer til den transformerede nul-tilstand, bare centreret om et andet punkt, og nu med en fase på, der afhænger af phi(\sum x_{fermions}_{fin}). Min argumentations-idé (hvilket jeg jo nok i sidste ende bare oversætter til matematik, hvis jeg kan) er så, at man ser på en transformeret base af slut-tilstanden, så slut-fasen, der afhænger af phi(\sum x_{fermions}_{fin}) altid bare går ud med denne base-transformation. Nå, hvis vi så går lidt tilbage, er vi altså frie til at lægge en \square^2 phi = 0 -bølge til nul-tilstanden, hvis.. Hm, \emph{skal} jeg mon ikke transformere basen i begge ender for det mest overskuelige argument?.. Tja nej, måske skal jeg egentligt bare argumentere med, at slut-tilstanden bliver den samme bare forskudt og med en fase på \exp(-i (phi(X_{fin}) - phi(X_{init})), men at man så i første omgang også samler \exp(-i phi(X_{init})) op pga., hvordan den samlede start-tilstand ser ud (og altså pga. løsningsdomænet). Så i sidste ende får man en slut-tilstand, der bare er forskudt (i henhold til (V', A') og til \square^2 phi=0 -bølgen (som også afhænger af (V', A'))) og som altså får en fase på sig oveni, lig \exp(-i phi(X_{fin})) (fordi de to andre faser spiste hinanden), hvor phi er i form af \square^2 phi=0 -bølgen. Og når jeg siger "centreret," så behøver det altså slet ikke at være der, hvor slut-tilstanden er størst omkring eller noget. Vi kan med andre ord vælge nul-tilstandens "modpart" frit, og kan altså vælge (V=0, A=0) her også. Det vil sige at dette "center-punkt" vil forskydes med phi-bølgen (og kun denne) i det Lo.-transformerede tilstandsrum også. Dette vil sige at den samlede sluttilstand vil være en sum, eller et integrale rettere, af en masse næsten identiske tilstande bare centrerede om forskellige punkter og med en fase hver især som den eneste forskel, som er lig \exp(-i phi(X_{init})), hvor \partial^\mu phi = A^\mu = "centerpunktet" for det pågældende slut-tilstands-bidrag. Det kan godt være, at jeg bare vil argumentere matematisk, men intuitivt kan man så herfra argumentere med, at vi kan lave et baseskift af sluttilstanden, som går fra løsningsdomænet og til \hat P_V = \hat P_{A_\parallel} = 0 -løsninger, hvorved dette så for alle slut-tilstands-bidrag vil spise vores \exp(-i phi(X_{init})). Så nu har vi altså bare en masse identiske slut-tilstande, bare centrerede om forskellige (V, A_\parallel)-punkter, lagt sammen til den endelige slut-tilstand (efter Lorentz-transformationen). Og så skal man bare lige vise, at determinanten af Jacobianten fra phi_{init} til phi_{fin} er 1 for sådanne \square^2 phi = 0 -bølger, og herved får man så, at slut-tilstands-bidragenes "centerpunkter" vil være fordelt jævnt over hele tilstandsrummet, og herved får man, når man summer/integrerer dem samme, en samlet slut-tilstand, der ikke afhænger af V eller af A_parallel. Til sidst skal vi så lige transformere slut-basen tilbage, og så opnår vi altså en løsning indeholdt i vores løsningsdomæne. Fedt! Rart endelig at have styr på den del af beviset (det tog godt nok lidt længere, end jeg havde regnet med ^^). ^^" 
%


\section{Working towards a first draft}
(14.03.22) I will here start from the path integral section and try to work on writing a draft for this and the following section. I will probably just refer to the appendices before I have actually made them (and then make them at a later point). I might also leave paragraphs and so on to-be-made and then dela with them later.\,. 
%*I will also just have some text sections that are just working notes, essentially, just like how a lot of it was in the last section.\,.


\subsection{A generalized path integral}
\textit{Copied from above (and with some small changes added):}\\
For the generalized path integral, we want to look at a Hilbert space $\textbf{H}$ given by
\begin{align}
\begin{aligned}
	\textbf{H} = \textbf{H}_{B} \otimes \textbf{H}_{F},
\end{aligned}
\end{align} 
where $\textbf{H}_B = L^2(\mathbb{R}^N)$,\footnote{
	$L^2(\mathbb{R}^N)$ denotes the space of square-integrable functions on $\mathbb{R}^N$ (see Hall \cite{}).
	%$N$ is of course assumed to be a positive integer.
} 
and where $\textbf{H}_F$ is just some separable Hilbert space 
with an orthonormal basis %$\{\ket{\psi}\}_{\psi\in \Psi}$.
%$\{\ket{\psi_j}\}%_{k\in I_k}$
%$%, with indices in some (countable) set $I_j$. 
%%, $j\in\{1, 2, \ldots\}$. 
$\{\ket{\psi_j}\}_{j\in \{1, 2, \ldots\}}$. 
The idea is to later on identify $\textbf{H}_{B}$ with a system of $N$ modes of a bosonic field *(where the values of $\mathbb{R}^N$ represent the amplitudes of the field modes) and to identify $\textbf{H}_{F}$, not as a fermionic \emph{field}, but simply as a (separable) Fock space of fermionic particles.\footnote{
	Or to put it more precisely, we want to identify it with a (separable) Fock space of antisymmetric (spinor-valued) wave functions over domains that represent $n$ sets of particle coordinates.
} 
This is where my approach diverges somewhat from the common approach found in QFT literature. 

The kind of Hamiltonian we want to analyze is one given by
\begin{align}
\begin{aligned}
	\hat H = \sum_{n=1}^{N} 
		\big( \frac{1}{2} \hat p_{n}^2 + \hat C_n \hat p_{n} \big) + 
		\hat V + \hat H',
\end{aligned}
\end{align} 
where $\hat p_n$ denotes the $n$th momentum operator on $L^2(\mathbb{R}^N)$, and where for all $n$, $\hat C_n$ commutes with $\hat p_n$. We will also assume $\hat V$ and $\hat C_n$ for all $n$ to be self-adjoint operators on the form
\begin{align}
\begin{aligned}
	\hat V =&\, \sum_{j} \int d\boldsymbol{q}\,  
		V(\boldsymbol{q}) \ket{\boldsymbol{q}, \psi_{j}} \bra{\boldsymbol{q}, \psi_{j}}, \\
	\hat C_{n} =&\, \sum_{j} \int d\boldsymbol{q}\,  
		C_n(\boldsymbol{q}) \ket{\boldsymbol{q}, \psi_{j}} \bra{\boldsymbol{q}, \psi_{j}},
\end{aligned}
\end{align} 
where $V$ and $C_n$ for all $n$ are real-valued functions. And lastly, we assume $\hat H'$ to be a self-adjoint operator on the form
%\begin{align}
%\begin{aligned}
%	\hat H' \ket{\boldsymbol{q}, \psi_{j}} = 
%		\ket{\boldsymbol{q}} \otimes \hat H_F'(\boldsymbol{q}) \ket{\psi_{j}},
%\end{aligned}
%\end{align}
\begin{align}
\begin{aligned}
	\hat H' =&\, \sum_{j} \int d\boldsymbol{q}\,  
		(\ket{\boldsymbol{q}} \otimes \hat H_F'(\boldsymbol{q}) \ket{\psi_{j}}) 
%		\ket{\boldsymbol{q}} \otimes \hat H_F'(\boldsymbol{q}) \ket{\psi_{j}} 
		\bra{\boldsymbol{q}, \psi_{j}}, 
\end{aligned}
\end{align} 
where for all $\boldsymbol{q}$, $\hat H_F'(\boldsymbol{q})$ is a self-adjoint operator on $\textbf{H}_F$. $\hat H'$ is thus going to include both the free energy of the fermions as well as the interaction part of the Hamiltonian. 

Note that $[\hat C_n, \hat p_n] = 0$ is ensured %if the $\partial C_n(\boldsymbol{q}) / \partial q_n = 0$ everywhere, where $q_n$ is taken to denote the $n$th entry of $\boldsymbol{q}$. %No.. ..Oh yes; it works when C_n(\boldsymbol{q}) is seen as a formal functional expression.. ..Hm, but that is not so neat (for mathematicians especially).. 
%if, as a functional expression, $C_n(\boldsymbol{q})$ is constant with respect to $q_n$, where $q_n$ is taken to denote the $n$th entry of $\boldsymbol{q}$. %..No let me just write:
if the $\partial C_n / \partial q_n = 0$ everywhere, where $q_n$ is taken to denote the $n$th entry of the coordinate vector $\boldsymbol{q}$.
Note also that since $[\hat C_n, \hat p_n] = 0$, all the terms in the formula for $\hat H$ are self-adjoint. This is, however, not sufficient to ensure that $\hat H$ is self-adjoint.\footnote{See Hall \cite{}.} But for now, we will simply assume that this is the case. 

I will now give a heuristic derivation of the path integral for this $\hat H$ to show what form we should expect it to have. In A.dis-path, I have given a more careful and detailed derivation for a discretized version of the path integral. I suggest that the interested reader first read the following heuristic derivation and then read A.dis-path. But for a lot of readers, the following derivation might suffice. It follows a similar procedure the path integral derivations found in a lot %quantum mechanics
QM/QFT literature, such as in Srednicki \cite{} and in Lancaster and Blundell \cite{} **Check. Only now, we have the extra $\hat C_n \hat p_{n}$ terms in the bosonic part of the Hamiltonian, and we also have the extra $\hat H'$ term as well. 

First we note that the propagator for a small $\delta t$, given by $\exp(-i \hat H \delta t)$, will have matrix elements in the $q$-basis given by
\begin{align}
\begin{aligned}
	\bra{\boldsymbol{q}_2, \psi_{j_2}} e^{-i \hat H \delta t} \ket{\boldsymbol{q}_1 , \psi_{j_1}} 
	=&\,
		\int d \boldsymbol{p}\, 
		\braket{\boldsymbol{q}_2, \psi_{j_2} | \boldsymbol{p}, \psi_{j_2}} 
		\bra{\boldsymbol{p}, \psi_{j_2}}  e^{-i \hat H \delta t} \ket{\boldsymbol{q}_1, \psi_{j_1}} 
	\\=&\,
		(2\pi)^{-N/2}
		\int d \boldsymbol{p}\, 
		e^{i \boldsymbol{p} \cdot \boldsymbol{q}_2}
		\bra{\boldsymbol{p}, \psi_{j_2}}  e^{-i \hat H \delta t} \ket{\boldsymbol{q}_1, \psi_{j_1}},
\end{aligned}
\end{align} 
where we have inserted the identity operator $\hat I = \sum_j \int d\boldsymbol{p}\,\ket{\boldsymbol{p}, \psi_j}\bra{\boldsymbol{p}, \psi_j}$ and used the fact that $\braket{\boldsymbol{q}, \psi_{j} | \boldsymbol{p}, \psi_{j'}\!}\! = \delta_{j j'}(2\pi)^{-N/2}\exp(i \boldsymbol{p} \cdot \boldsymbol{q})$. Since $\delta t$ is assumed small, let us then note that $\exp(-i \hat H \delta t)$ in this expression can be substituted according to
\begin{align}
\begin{aligned}
	e^{-i \hat H \delta t} =
		e^{-i \sum_n (\hat p_n^2 / 2) \delta t} 
		e^{-i \sum_n \hat C_n \hat p_n \delta t} 
		e^{-i \hat V \delta t} 
		e^{-i \hat H' \delta t} 
		+ O(\delta t^2).
\end{aligned}
\end{align} 
We can now, since $\hat C_n$ and $\hat p_n$ commutes, let all the $\hat p_n$ operators in the substituted expression hit the $\bra{\boldsymbol{p}, \psi_{j_2}}$ bra to the left and all other operators hit $\ket{\boldsymbol{q}_1, \psi_{j_1}}$ on the right, which gives us
\begin{align}
\begin{aligned}
	\bra{\boldsymbol{q}_2, \psi_{j_2}} e^{-i \hat H \delta t} \ket{\boldsymbol{q}_1 , \psi_{j_1}} 
	=&\,
		(2\pi)^{-N/2}
		\int d \boldsymbol{p}\, 
		e^{i \boldsymbol{p} \cdot \boldsymbol{q}_2 - i H_B(\boldsymbol{p}, \boldsymbol{q}_1)}
		\braket{\boldsymbol{p} | \boldsymbol{q}_1}
		\bra{\psi_{j_2}}  e^{-i \hat H'_F(\boldsymbol{q}_1) \delta t} \ket{\psi_{j_1}}
		+ O(\delta t^2)
	\\=&\,
		(2\pi)^{-N}
		\int d \boldsymbol{p}\, 
		e^{i \boldsymbol{p} \cdot \dot{\boldsymbol{q}}_1 - i H_B(\boldsymbol{p}, \boldsymbol{q}_1)}
		\bra{\psi_{j_2}}  e^{-i \hat H'_F(\boldsymbol{q}_1) \delta t} \ket{\psi_{j_1}}
		+ O(\delta t^2),
\end{aligned}
\end{align} 
where we have defined $\dot{\boldsymbol{q}}_m = (\boldsymbol{q}_{m+1} - \boldsymbol{q}_{m}) / \delta t$ and $H_B(\boldsymbol{p}, \boldsymbol{q}) = \sum_n(p_n^2 / 2 + C_n(\boldsymbol{q}) p_n) + V(\boldsymbol{q})$. 

%Now, in this heuristic derivation, let us assume that we can evaluate the integral over $\boldsymbol{p}$ by letting the upper and lower limit grow to infinity at the same rate, such that we can replace $\int d\boldsymbol{p}$ with $\lim_{a\to\infty}\int_{-a}^{a} d\boldsymbol{p}$. 
%
%\textit{This allows us to use bla bla bla *** to get \ldots}
%\begin{align}
%\begin{aligned}
%	\bra{\boldsymbol{q}_2, \psi_{j_2}} e^{-i \hat H \delta t} \ket{\boldsymbol{q}_1 , \psi_{j_1}} 
%	=&\,
%		e^{iN/4} %..??..
%		(2\pi)^{-N/2}
%		e^{i L_B(\dot{\boldsymbol{q}}_1, \boldsymbol{q}_1)}
%		\bra{\psi_{j_2}}  e^{-i \hat H'_F(\boldsymbol{q}_1) \delta t} \ket{\psi_{j_1}}
%		+ O(\delta t^2),
%\end{aligned}
%\end{align} 
%%Hm, I should rather wait to integrate over p, especially since a "Lagranian" makes more sense if it's defined over time as well.. ..So I'll comment this out for now..

\textit{Insert the rest of this derivation to get:}
\begin{align}
\begin{aligned}
	\bra{\boldsymbol{q}'', \psi_{j''}} e^{-i \hat H \delta t} \ket{\boldsymbol{q}' , \psi_{j'}} 
	\propto&\,
		\int_{\boldsymbol{q}'}^{\boldsymbol{q}''} \mathcal{D} \boldsymbol{q}\, 
		e^{i \int_{0}^{t} d t\,  L_B(\dot{\boldsymbol{q}}, \boldsymbol{q})}
		\bra{\psi_{j''}}  e^{-i \hat H'_F(\boldsymbol{q}) t} \ket{\psi_{j'}}
\end{aligned}
\end{align} 
\textit{.\,.\,if I don't just keep it discrete.\,.} %..Pause..




%(20.03.22) I am a bit tired today, so I'm not gonna try to catch up from where I left, and instead I'm just gonna start a little subsection here of paragraphs.\,. Hm, let me actually make it as and actual (sub-)subsection.\,. where I try to go through the argument for Lorentz invariance (and just see how much I can get done today).\,.
%
%\subsubsection{Some working notes on making a clear (eventually (hopefully)) argument for Lorentz invariance}

%... Ah, jeg kan bare mærke, at jeg altså ikkel ige orker at gå i gang med at rode med formler nu.. Jeg kan prøve at samle mig igen senere.. Jeg ved bare ikke helt, hvad jeg så skulle lave i stedet.. ..Hvis bare der var noget produktivt tænkearbejde, jeg kunne give mig til (det ville jeg bedre kunne overskue nu), men som ikke åbner op for noget andet, der kunne komme til at opsluge mig helt (såsom det potentielt kunne at gennemgå mine selvadjungethed-argumenter igen i større detaljer..).. ..(Ja, det kræver sikkert en længere omgang (med selvadjungethed-argumenterne), så det vil jeg hellere vente med..) 
%.. Hm, lad mig lige prøve at gennemgå Lo.-inv.-argumenterne her på tasterne som kommentarnoter, og så kan jeg se om jeg får energi til at rode med formler.. ..Hov, nu fik jeg måske lige lidt second wind.. Lad mig prøve at se på det.. ...Hm, argumentet bliver jo vel bare, at opstille det discrete phase-space path integrale med den Lorentz-invariante (lille) tidsrotation (hvor \hat p^2/2 og \hat V roteres i modsatte retninger, og hvor \hat C \hat p lades være..), og så derfra argumentere for, at grænsen bliver det pæne, Lorentz-invariante (og ikke-diskrete) integrale. Herfra kan jeg så let definere ikke-konstant-tid-"tilstandende" (på det rum-agtige hyperflader) og argumentere for, at en propagering imellem to hyperflader, der kun afviger i et lokalt område (og hvor man altså integrerer over en lille lokal lomme indkapslet imellem to rum-agtige hyperflader), der må resultatet så give det samme uafhængigt af hvilket inertial system, man er i. Og deraf er det nemt at konkludere, at teorien må være Lorentz-invariant.. (Kl. 25 i elleve.) ..Hm, og ja, så får jeg i øvrigt også lov at bruge mit trick med kun at absorbere en del af det \exp(-\epsilon \mathcal{L})-led, der fremkommer af den delvise (og forskelligrettede) tidslige komplekst-plan-rotation.. ..Hm, og hvad bliver det så er den del af argumentet, hvor man transformerer $k\to x$, $\lambda^\mu_\nu$, $x\to k$, som jeg jo har i den udgave, der ikke bruger Wiener-målet (og som jeg i øvrigt altså stadig tror på også kan holde, og altså kan gennemføres som argument/bevis)?.. ..Hm, den del behøver man vel så netop ikke, eller hvad (men skal så til gengæld lige igennem argumentet som for Feynman-kac-formularen i Hall..)?.. ..Ah, lad mig da også overveje den del; der behøver jeg ikke nødvendigvis at rode så meget med formler selv for det arbejde.:).. ..Hm, men angående forrige spørgsmål, så kommer den del nok bare til at ligge i, hvordan integralet over mængden af kontinuerte paths i $k$-space svarer til kontinuerte paths i $x$-space.. ..Ja, men det kan jeg også prøve at overveje nærmere, imens jeg alligevel stirrer på Feynman-Kac-udledningen i Hall, så lad mig bare gå i gang med det nu. (Kl. fem i elleve.)
%(Kl. tyve i tolv.) Okay, jeg skal nok egentligt bare først koncentrere mig udelukkende om at vise det flotte path integrale i ét system --- og måske altså bare i $k$-space først --- og så kan jeg så bagefter starte på Lo.-inv.-argumentet, når jeg har det glatte integrale. Så skal jeg så bare som nævnt lige sikre mig, at man kan komme godt fra $k$-space og over i $x$-space.. Hm, er alle kontinuerte $k$-mode-paths virkeligt også kontinuerte i $x$-space, eller skal vi mon sørge for at gå til $x$-space inden..?.. ..Hm ja, for det gælder nok ikke, at alle kontinuerte $k$-paths er.. Hm.. ..Tjo, i endelige dimensioner gør det jo.. Hm.. ..Hm, men så skal jeg vel netop sørge for at transformere, inden vi lader dimensionerne gå imod uendeligt..(?..) ..Hm, gad vide om jeg mon så alligevel \emph{skal} have fat i min strategy med at lade $x$-diskretisationsfinheden være konstant finere end for $k$-lattice'et (og så gruppere alle $x$-paths under den $k$-paths, der er tættest på dem, og så hver $k$-paths for mindst et vist antal $x$-path under sig).. (Kl. fem i tolv.)
%..Hm, men det kræver så lige del argumentation, bl.a. om den "error-funktion," man så skal bruge.. ..Hm, men vent, kan man ikke også bare tranformere til $x$-space i princippet selv efter, man har vist det i $k$-space, for kan man ikke bare bruge sætning 20.2 (i Hall) til at folde det ud i først $k$-space, og så transformere om til $x$-space der?.. (..Ikke at man så ikke også kan gøre det før, men måske kan det blive rart nok at kunne dele det op, hvem ved?.).. ..Hm, jo det er da lige før, at det faktisk bliver strategien, for så kan man nemlig måske få elimineret alle \boldsymbol{p}'erne i første omgang, og så koncentrere sig om transformationen til $x$-space efterfølgende..:).. (Kl. fem over tolv.) ..Cool. Og hvis det så ikke kan lade sig gøre, og jeg finder ud af, at jeg bliver nødt til at transformere til $x$-space inden da, jamen så må jeg bare gøre det.:).. ..Hm, men der \emph{er} nu ingen grund til, at jeg ikke skal kunne eliminere \boldsymbol{p}'erne først (og altså følge denne plan)..:) ..7, 9, 13.;).. 
%..Dejligt, så har jeg hermed allerede nået \emph{noget} i dag. Og lad så mig også lige prøve at stirre lidt på, hvordan jeg så får gået til $x$-space derfra, inden jeg holder pause.. ..Hm hov, og lad mig lige bemærke (til mig selv), at jeg jo ikke behøver at bryde andre begrænsninger end båndet på p'erne (i.e.\ hvad jeg har kaldt \Lambda).. Så jeg kan altså godt lade dimensionsantallet være.. hm, eller?.. Skulle man måske lade.. nej, lad mig lige tænke lidt mere, før jeg foreslå noget.. ..Ah, never mind, vi kan godt sagtens lade alle dimensionsbegrænsningerne være (på nær selvfølgelig \delta t), når vi skiller os af med p'erne. Og så skal jeg bare lige tænke over: hvad så derfra?.. (Kl. tyve over tolv.) ..Ah, men vi skal så netop også lade \delta q gå mod 0 i samme ombæring (mere eller mindre), sådan at rummet af $k$-space paths får et én-til-én map til rummet af $x$-space paths.:).. (Kl. 25 over tolv.) 
%..Og ja, så kan jeg jo eventuelt finde en matematisk sætning om at transformere (Lesbeque-)integraler, hvis ikke jeg bare tør gøre det direkte selv (..hvad jeg nok gør).. Cool.:) 
%(Kl. 25 over tre.) Nå, det blev faktisk en rigtig produktiv gåtur!:) Jeg fik tænkt en hel del over det problem, jeg kom i tanke om på vej ud af døren, nemlig at det jo er problematisk at sende \Lambda_p til uendelig, når \epsilon holdes konstant. Det tænkte jeg så frem og tilbage over, og kom ikke helt frem til noget brugbart, indtil jeg søgte på erf(x)'s asymptote (og ja, det er jo lidt forvirrende, at jeg har kaldt noget andet "error functions" ovenfor (hvor jeg altså i stedet taler om en differens mellem den ønskede og den approksimerede function)), og fandt frem til (på stackexchange) at den er O(\exp(-x^2)/x). Og jeg fik så tænkt videre og fundet frem til, at man for en given \varepsilon på \exp(-i\hat H t)\psi må kunne lade \Lambda_p gå mod uendeligt, hvis bare man samtidigt lader \epsilon gå som 1/\Lambda_p^2 (og også med en lille nok proportionalitetsfaktor). Og når det sker, så må området man "integrere over, som giver bidrag til path-integralet," når \epsilon går mod 0 vistnok gå som ca. 1/\sqrt{\epsilon}, imens fejl-difference-funktionen nok går som \sim epsilon\exp(-\espilon).. Så ja, jeg er ret sikker på, at man nok skal kunne konkludere, at man bare sådan set kan erstatte det delvise (og måske diskrete) gaussiske integrale med den eksakte version, for, jamen, når \epsilon går imod 0 (og vi således også er frie til samtidigt at lade \Lambda_p gå som 1/\epsilon^2), så vil resultatet alligevel konvergere til det samme. (..!:)) Og bum, så får vi --- skulle vi gerne --- vores flotte path-integrale!:) (Kl. kvart i fire.)
%..Hm, skulle jeg lige nævne nogle andre idéer fra turen, selvom de ikke førte til noget..? ..Jo, lad mig bare nævne, at jeg overvejede om den tidsroterende \hat H_B kunne gøres normal (som i: normal operator) på en eller anden måde, men det så det så ikke ud til.. ..Ja, og så ellers bare et par små idéer, som heller ikke er så interessante. Fint. Jeg bør lige skrive min nyfundne idé her ind i det renderede.. ..Fedt, at det alligevel blev en rimelig produktiv dag i dag (allerede)!^^ 
%
%(Kl. 25 over seks.) Ah, en sti (path) i $x$-space er kontinuer (i hvert fald for endeligt antal dimensioner..), hvis og kun hvis den er kontinuer i $k$-space (og her er bliver vi altså i samme inertialsystem..).. ..Så derfor kan jeg måske nok godt gøre det, jeg planlægger nu, nemlig at bruge Wiener-mål-sætningen for $k$-space først (og opnå et pænt integrale over alle kontinuerte stier) og så gætte på en tilsvarende $x$-space-procedure, som jeg så gerne skal kunne vise giver det samme resultat i grænsen/erne.. ..Ja, så det er altså planen nu..:) ..(Og det gør nemlig ingenting her, at rum forbliver diskretiseret imens tid bliver kontinuer, for som sagt ser vi kun på ét inertial system i denne del af argumentet (hvor vi altså bare vil nå frem til det pæne sti-integrale i x-space).) (Kl. halv syv.) 
%(Kl. ti i syv) Hov, det er lidt mere kompliceret end det, for når \delta x og \delta k skal gå mod 0, så får vi umiddelbart også ikke-differntierbare felter med --- men i princippet kunne man så sikkert her, hvis man havde evnerne, bevise et nyt form for Wiener-mål, hvor der kun integreres over differentierbare funktioner, nemlig ved på en måde at bruge \exp(-\epsilon \nabla \times A^2)-termet osv. og opsuge disse som en del af målet og på en eller anden måde vise (og jeg aner ikke hvordan, for jeg har aldrig set beviset for Wiener-måls-sætningen), at dette så gør at vi kan undlede at tage alle ikke-differentierbare funktioner med. ..Så ja, der er jo lidt at tænke over her..
%.. Nå, nu kom jeg lige til at tænke på, at man måske bare kan bruge Wieners sætning direkte(?).. Det kan man jo måske i x-space, men hvad med k-space, mon..? (Kl. syv.) ..Hm, men hvis vi er heldige, så behøver vi det ikke der, fordi differentialerne måske allerede er veldefinerede der.. ..Hm, men problemet bliver måske \nabla V og \nabla \cdot A, for de indgår jo kun i \hat C \hat p-leddet.. Så skulle man måske prøve tilføje et ekstra led til det hele for at regularisere (eller whatever) det.. ..Hm, jeg bryder mig af en eller anden grund ikke så meget om den tanke, måske fordi jeg har rodet så meget med lignende før i tiden (der i forårshalvåret '16).. ..Nej, det tør jeg ikke give mig i kast med; det virker/føles håbløst at prøve på.. ..Hm, lad mig lige tænke over, om differentialerne \emph{er} veldefinerede i k-rum, for det kunne måske give mig noget.. ..Hm, det må de næsten være.. ..Hm, og dog; nok ikke hvis vi snakker uendelige dimensioner.. ..Men kunne det så bare være nøglen: kunne vi måske bare vise at de to udregninger nærmer sig hianden på en måde for de diskretiserede rum..? ..Hm vent, hvad egentligt med bare at bryde Lo.-invariansen midlertidingt of bare tilføje et \nabla V^2- og et \nabla \cdot A-led?.. ..Hov, men så bliver der godt nok et problem med, at \hat V (\emph{hat} V, og ikke V som i: A^0) gerne skal holdes begrænset.. (Kl. tyve over syv.) 
%
%(Kl. ni.) Ah, jeg har tænkt nogle forskellige tanker, men nu fik jeg lige en tilsyneladende god idé. Jeg skal da bare droppe alt om x-space, og om mit (ellers ret opfindesomme, synes jeg selv.. *(tja ej, det er lidt meget sagt..)) argument, hvor jeg argumenterer via integraler over "lokale lommer imellem hyperfalder," og så egentligt bare i stedet prøve at bruge Wiener-måls-sætningen til at gå fra t\to\omega..! ..Og så må jeg bare finde tilbage til et godt argument til at færdiggøre denne argument-strategi, men det tror jeg også nok --- 7, 9, 13 --- jeg må kunne finde..:)..


%(24.03.22) Okay, jeg har lige haft tre hele tænkedage, hvor der er sket en hel masse. Har også fået tænkt lidt her til formiddag. Jeg har alle dage sluttet af med, om aftenen, at være nået til et punkt, hvor jeg har følt at jeg har haft den, men hvor jeg så næste morgen har fundet frem til nogle fejl eller mangler --- på nær i dag indtil videre.. (Kl. tyve over ti btw.) Lad mig for det første lige nævne, at jeg har tænkt en del mere over den der Feynman-Kac-agtige fremgangsmetode, men nu har jeg kastet den fra mig igen. Der kunne dog ptentielt set være en mulighed i at gå til (\omega, k)-space (for det virker nemlig slet ikke i x-space, heller, da differentialerne ikke giver mening), og så prøve at bevise mine specielle GEW-løsninger allerede med det samme, så man derefter kan få noget hvor \sigma i diverse gaussiske integraler går som 1/k / 1/\omega, og hvor man måske så netop kan bruge noget omkring det "gaussiske mål" ("Gaussian measure"), men selv her vil der så, som jeg forudsiger det, komme nogle problemer med at fremgangsmåden kræver boundedness, at man.. Nå ja, og idéen med alt dette var nemlig, så man kunne få lagt en faktor a la \exp(-\epsilon\int\mathcal{L}) på stiintegralet.. *(Og det er nemlig derfor, det nok så bliver vigtigt at gøre GEW-løsningerne, inden man udleder stiintegralet (og gøre disse løsninger til en del af stiintegralet), for så kan man nemlig få sin k^{-1}- og sin \omega^{-1}-afhængighed for \sigma på alle de resterende frihedsgrader i feltet --- og måske ville det også være smart i det hele taget, for så kan man bruge antagelsen om at denne \hat H er selvadjungeret dirrekte. Ville bare lige præcisere dette, men det er altså slet ikke fordi, jeg tror at denne fremgangsmåde overhovedet vil være smartere end én, der bliver i det diskrete --- men måske kunne der jo komme noget elegant ud af det, hvis det kunne lykkes.) *(...Nå ja, og det \emph{kan} også være, at man ikke bør bruge mit "trick" der omkring modsatrettet rotation (kun for \hat H_B), men at man måske i stedet bare skulle prøve at rotere tiden for hele \hat H, og i samme retning.. Men igen: langt fra sikkert, at noget af det her overhovedet vil kunne bære frugt.. ..Hm, måske vil dette faktisk være det smarteste (hvis man kan argumentere for, at det ikke vil bryde Lorentz-symmetrien (hvilket jeg nemlig ikke har helt styr på)), for så får man måske ikke nær de samme problemer med at sende begrænsningerne på potentialerne i \hat H mod uendeligt (og altså ophæve dem).. Interessant tanke, men altså nok ikke noget, jeg selv vil prøve at gå videre med forløbigt..) Men ja, og der bliver så også nok et problem, når man skal argumentere, og bliver tvunget til også at skifte measure hele tiden i grænsen.. Og derudover så kan jeg heller ikke lige se det endelige argumenter helt præcist, selv hvis man fik alt dette til at lykkes, så det skal man også have styr på. Nå, nok om det. Jeg har gjort en masse tanker i disse dage, men langt fra alle er værd at nævne (eller at gå videre med). ..Jeg kan dog også lige nævne, at jeg har gjort en masse nye gode tanker omkring diskretisationen af de to inertialssystemer og ting i den dur (og i går fik jeg også lige nogle idéer om muligheden for at bruge.. hvad hedder det nu, hedder det "circular boundary conditions?".. *("periodic," selvfølgelig; sjovt at det lige glippede..) whatever, det at man kan antage, at der er en gentagende symmetri i sit univers (og der kan nemlig også sagtens være en tidsforskydelse i denne gentagelse), men jeg har dog ikke helt fundet ud af, hvordan jeg skulle bruge det).. Men ja, nu har jeg så nogle andre idéer til, hvordan man kan opbygge et argument. Lad mig lige skifte linje og begynde at opsummere idéen (kort).
%Planen er at se på (\omega, k)-stiintegraler, og så bruge argumenter fra tidsafhængig pertubationsregning for at argumentere for, at der må findes en vis \omega_{max}, hvorefter alle (formentligt gaussiske) \omega-integraler vil være negligible (givet en vis \varepsilon). Her bruges både at pertubationsregningen nok kommer til at fortælle os, at der kommer en \alpha/\omega afhængighed for en overgang mellem to fri impuls-tilstande med en impulsdifference på k (i.e.\ hvis vi ser på en overgang, der passer med den givne k for (\omega, k)-bølgen). Her er \alpha (eller hvad vi skal kalde den) så altså bølge-aplituden. Samtidigt kan vi så også bruge, at bidraget fra det gaussiske integrale over \alpha også går som 1/\omega, eller noget i den stil, hvorved vi forhåbentligt får en samlet \omega-afhængighed, der aftager skarpere end \omega^{-1}, og hvorved vi så opnår vores \omega_{max}, hvorefter vi kan se bort fra resten. ...Ej, det er også et lækkert vejr i dag.. Nå, der skulle heldigvis snart komme nogle gråvejrsdage, har jeg hørt.;) Men ja, og det nævnte argument kræver så lige, at man ved.. Hm ja, jeg skal nok på en eller anden måde bruge (som jeg nemlig fik tænkt her i morges (Kl. ti over elleve nu, btw)), at det indre \omega(,k)-bølger heller ikke får fermion-løsningerne til at.. ..Hm, nå nej, jeg har allerede begrænset rummet af (diskrete) k-fermionløsninger, så det er nok mere den tidslige afhængighed, jeg skal bekymre mig om (når jeg ser på pertubationsregningen).. ...Hm, og min tanke fra i morges var så (hvilket jeg også bør kunne bruge her..), at bruge at for en givendiskretisering med en vis \omega_{max}.. hm, nu kommer det til at betyde to forskellige ting. Hm, lad mig bare kalde diskretiseringsgrænsing for \Omega her for nu.. Så givet en vis \Omega, så vil dette jo approksemere den faktiske løsning, når man altså integrerer over alle stier. Og.. Hm, men det er da ikke ensbetydende med, at fermion-bølgefunktionerne holder sig indenfor de grænser, når man sig på det specifikke stier, nej.. ...Nej, for det kan også være, at de bare intefererer destruktivt med andre stier i endepunktet.. ...Hm, det kan faktisk være, at jeg ender med at genoverveje nogle andre muligheder så.. Jeg har nemlig også på et tidspunkt syntes, at det lykkedes mig at gøre fermion-propagationen identisk for par af stier i de to inertialsystemer.. selvom det vist ikke passer helt (men måske tæt på).. ..Hm, og ellers er der også en klar mulighed for, at det faktisk ikke bliver nødvendigt med dette \omega_{max}-argument, hvis man nemlig i stedet bare kan udføre diskretisationen, så (\omega, k)'erne passer med, hvad de er (mere naturligt) i det andet intertialsystem..
%(Kl. halv fem.) Nå, det blev endnu en dag med en god lang tænke-gåtur. Jeg kom ret hurtigt på en god ny idé på min tur, om at man går til (t, x)-space først, og så simpelthen omparametriserer med (\omega', k')-bølger, hvor (\omega', k')=\Lambda_\nu^\mu(\omega, k). Så man Fourier-transformerer med bølgerne fra et Lorentz-transformeret system i stedet for fra det naturlige system, hvor (\omega, k) bare løber over værdier af et direkte/ydre produkt imellem jævnt diskretiserede intervaller. Problemet derfra blev så bare at finde ud af, hvordan man viser, at fermion-løsningerne vil blive approksimativt lig hinanden. Og jo, her kunne man altså sikkert godt på en aller anden (måske kompliceret) måde bruge et argument, der bygger på tidsafhængig pertubationsregning, ligesom, men efter noget tid kom jeg i tanke om igen, at jeg jo lidt allerede har løst dette problem (som jeg også antydede ovenfor i formiddags). Det tror jeg i hvert fald muligvis, jeg har. Idéen er at approksimere fermion-boson-interaktionen med en \hat H, hvor fermion-dynaikken i stedet svarer til en udvikling over Lorentz-transfomerede felt-step-funktioner --- hvilket jeg også har tænkt på før --- og nu mener jeg nemlig at jeg har en metode til at få dette til at gå op. Jeg har for det første nemlig også fundet en diskretisation af de to inertial-systemer, hvor punkterne falder sammen --- og hvor man i det ene system så har nogle stier, hvor tiden starter tidligere i den ene ende af x-intervallet, men hvor x-intervallet er konstant, og et andet system, hvor stierne starter og slutter samtidigt over det hele, men hvor x-intervallet rykker sig hele tiden.. Og ja, jeg tror nemlig godt man kan omdanne sti-integralet på begge disse former --- selv uden at bruge periodiske randbetingelser (men ellers kan der måske være en mulighed/fordel i at bruge sådanne). Herved får man så to sti-integraler fra de to systemer, hvor alle punkterne i de to lattices er de samme (bare transformerede), og som sagt opnår man så også den samme (\omega', k')-parametrisering af stierne i begge systemer. Der gælder dog for det første, at den egentlige \exp(i\int\mathcal{L}) i det ene system skal regnes ud fra (\omega, k)-bølgerne i virkeligheden, og ikke de (\omega', k')-bølger, man har fået omskrevet stierne med. Men jeg mener altså her, at det er ret nemt at argumentere for (forhåbentligt; 7, 9, 13), at de to \exp(i\int\mathcal{L})-udregninger for en given (\omega', k') må gå tilstrækkeligt hurtigt mod hinanden, når finheden bliver mere og mere præcis (svarende til at A (eller L, kunne vi også sige) og t går mod uendeligt --- og hvor man så bare også skal sørge for at formindske \delta\omega og \delta k i samme ombæring, for at være sikker på at overholde sit \varepsilon (i.e.\ den overordnede maks-fejl på sluttilstanden)), til at den samlede fejl/difference på \exp(i\int\mathcal{L}) må gå mod 0.. Tilbage er der så det faktum at fermion-løsningerne heller ikke nødvendigvis er helt ens, men her er det så, at min strategi ville være at approksimere \hat H_F, så hver lille propagering over et lattice-step faktisk svarer til propageringen over et Lorentz-transformeret step (i stedet for et mere kubisk (i fire dimensioner) lattice-step). Og så får vi to sti-integraler, der altså bliver mere og mere ens, når lattice-finheden, og lattice størrelsen (så så \delta\omega, \delta k, \delta t og \delta x skal altså alle gå mod 0), går imod sine grænser. Så er det så bare lige at fuldføre argumentet derfra. Og her tror jeg altså, man godt kan klare sig uden peridiske randbetingelser, men ellers kunne dette altså også være en mulighed. Lad mig i øvrigt lige nævne hurtigt her, indskudt, at jeg også på min tur nu her kom på den idé, at man godt i princippet kan antage periodiske randbetingelser i tid også, for hvis man går langt nok frem i tiden, og hvis man har ting diskretiserede, så.. ja, så burde ting jo gentage sig.. Så ja, der er en idé der, men jeg kan ikke fide ud af, hvordan jeg helt skulle bruge den (og det tror jeg jo heller ikke bliver nødvendigt; jeg tror jeg har argumentet uden at antage periodiske randbetingelser). Nå, og den sidte del af argumentet er så at se på alle stier, hvor.. hm, lad mig lige se, to sekunder.. ...Hm ja, jeg \emph{skal} nok bare bruge det jeg nævnte, hvor jeg altså først (på en eller anden måde, men jeg har da en idé..) får vist, at man lave stiintegralerne over de nævnte parallelogrammer i stedet.. 
%...Hov, inden jeg går videre, bør jeg også lige nævne noget andet vigtigt, nemlig at jeg har ændret strategi for, hvornår positron-hæve-sænke-operatorerne skal konjugeres. Nu tror jeg, det er smartest bare simpelthen først at vise Lorentz-invarians for den ikke-konjugerede teori først, og så bare konjugere (stadig bare de "bare" hæve-sænke-operatorer) bagefter. For mit bevis for selvadjungerethed bør jo også virke for den ikke-konjugerede teori, så denne teori bør altså også være veldefineret. Og derfra er det så bare at argumentere for, at man vil få de samme matrixelementer i U(t)-propagatoren efter konjugeringen, som man havde før. Og da selvadjungeringsbeviset også gælder for den konjugerede teori, må man hermed få en Lorentz-invariant teori også. (Jeg husker det som om, det var i går, jeg kom frem til dette, men der er lidt mange idéer at holde styr på på de forgangne tre dage.. (..og ellers var det i forgårs.)) Så ja, det er altså planen i stedet nu (selvom det vistnok bør give helt det samme resultat, som jeg ser det (men det er sikkert nemmere at argumentere for Lorentz-invarians i det ikke-konjugerede system)). (Kl. fem i seks.) ...Hm, jeg tror, jeg tager en pause og summer lidt over det med parallelogrammerne, så jeg lige får helt styr.. eller dvs. får nogenlunde ordentligt styr på argumentet, inden jeg går videre..
%(25.03.22) (Kl. tyve i elleve.) Okay. Argumentet er bare, at når man sti-integrerer over to 4d-volumener, der begge kan parametriseres (eller rettere boson-feltet kan) via både sættet af (\omega, k)- og af sættet af (\omega', k')-bølger, hvor al foton-fermion-interaktion kan approksimeres tilstrækkeligt med disse sæt, og hvor fermion-stierne (og her kan man forestille sig en mængde af partikel-stier i x-rummet) alle er indeholdte i de (t, x)-space-volumener, som de to sæt af bølger parametriserer --- og lad mig vende tilbage til, hvornår og hvorfor man kan antage dette --- jamen så må ses, at de to propageringer (i de to inertialsystemer), må stemme over ens, når man ser på fermion-tilstandende.. nå ja, og det hører så også med, at de to volumener deler den foreste og bagerste kant.. ja, eller faktisk deler de jo alle punkter --- de er de samme volumener bare transformerede. Dette kræver at i mindst én af de to systemer, vil x-intervallet.. eller rettere x_1-intervallet, hvis Lo.-transformationen er et boost i x_1's retning (hvor x = (x_1, x_2, x_3)).. vil x_1-intervallet ikke være konstant. Men dette bør være helt fint, så længe fermionerne bare bliver i den indre del af 4d-volumenet, og altså ikke kommer ud til kanten (hvilket jeg jo vender tilbage til). ..Og den anden store ting er så, at i mindst ét af systemerne vil den foreste og/eller den bagerste kant (i den overvejende tidslige retning) ikke have konstant tid. Men dette er heller ikke så galt, for hvis vi definere den kvantemekaniske Lorentz-transformation på den oplagte måde, så transformerer man bare først i det indre system og antager, at man får det passende resultat på den ("skæve") hyperplan, hvilket man er fri til at gøre, for man kan altid vælge en start-tilstand længere bagud med konstant tid, der vil transformere til den ønskede start tilstand. Og så er det bare at notere sig, at fordi Lo.-transformationen svarer til et delvist stiintegrale, så vil fermion-bølgefunktionen på den "skæve" hyperplan stemme overens med, hvad amplituden er i disse rum-tids-punkter i det ikke-transformerede system (altså det hvori hyperplanen ses som "skæv"). Og på den foreste kant, altså den med størst tid (i.e.\ længst mod fremtiden), der kan man sige det samme, nemlig at de bølgefunktionen der iagttages i punkterne af denne skæve hyperplan, må.. ja, må komme fra, hvad man for fra sti-integralet over det indre volumen (med de "skæve" foreste og bagerste kanter), i.e.\ det som er parametriseret med (både) (\omega, k)- og (\omega', k')-bølgerne. Og når man så ser, at denne indre propagation har det samme resultat, om end man sti-integrerer i det oprindelige inertials system, eller hvis man går over til det andet inertialsystem og laver sti-integralet der. Så de to inertialsystemer må altså være enige om, hvordan fermionerne propagerer mellem de to hyperplaner (som er "skæve" i et af systemerne), og dermed må teorien konkluderes at være Lorentz-invariant. ..Man kan sikkert sige dette kortere.. Nå, og for så at vende tilbage til den rumlige begrænsning af fermion-stierne, så er idéen selvfølgelig at bruge, at for hver sti ift.\ boson-feltet, der vil fermionerne opfører sig "Lorentz-invariant," og vil altså aldrig propagere hurtigere end en lyskegle. Man kan så antage, at fermionerne er.. Hm, jeg var ved at sige: "ret lokale i et indre punkt" (hvor det så var meningen, at de bagerste tilstande så egentligt bare var defineret ud fra en omvendt propagering fra de indre tilstande i midten af volumenerne), men man skal da i stedet selvfølgelig bare sørge for, at t er relativt lille sammenlignet med x-intervallerne. He ja, selvfølgelig. Ok, og så bruger man altså, at fermionerne aldrig vil overstige en vis lyskegle til bare fra start af at fjerne alle fermion-sti-punkter (i x-space) uden for denne kegle. Bemærk, at det ikke er nødvendigt at begrænse fermion-stierne, så der absolut kun er tidslige stier med (og ikke nogle stier, som er lokalt rumlige); bare stierne ikke overskrider lyskeglen, så er det fint. (Og jeg tror nemlig, det er ret meget nemmere at argumentere for sidstnævnte, frem for at skulle begrænse stierne, så der ingen rumlige.. eller "rum-agtige," skulle man nok sige.. (i.e. "space-like") ..så der ikke er nogen rumagtige spring i stierne. Så det er godt, man ikke behøver det.)
%Okay, så nu tror jeg altså, jeg vil kunne opbygge et godt bevis for Lorentz-invariansen, hvis jeg gives tid til det. Nu vil jeg så fortsætte udkast-arbejdet, men har tænkt mig at gå tilbage til at fokusere mere på formularerne og selv argumenterne, og så slet ikke tænke på at skrive noget, der kan genbruges i selve artiklen (så jeg skriver det bare ret noteagtigt). I øvrigt kan jeg lige sige, at jeg nu tænker at udskyde al avanceret argumentation (udover bare den ultrakorte) omkring Lorentz-invariansen til senere i artiklen --- og jeg ender nok bare med lige at forklare min strategi, og så, på samme måde, som jeg har tænkt mig for selvadjungeretheds-argumenterne, bare lade detalje-arbejdet vente til "fremtidigt arbejde." (Kl. 25 i tolv.)
%*Nå ja, der er også lige det med diskretiseringen eller begrænsningen af felt-værdierne i de to stiintegraler (fra de to inertialsystemer, man sammenligner), men her tror jeg, man nemt kan argumentere for, at man har frihed til at vælge sine begrænsninger / sin diskretisering (i et af systemerne), så de passer så de/den transformerede begrænsninger/diskretisering passer med det andet systems. 


\section{Arguments and formulas}
(25.03.22) The point with this section is to now go through all the relevant formulas and arguments for the article (not necessarily completely in the right order) but try to keep the writing style loose and quick. So while the point is to make a big effort to make the arguments \emph{detailed}, I will just not try hard to make them very clear and well-structured from the get-go (and instead work out the structure more as I go along, namely without much erasing and rewriting).

So the idea is still to announce the my Hamiltonian in the introduction and then to do a short section with a heuristic derivation of the generalized (but still nice and Gaussian where it matters (namely by still being quadratic in $\hat p$ (which I might go back to calling $\hat P$.\,.))) path integral. I will mention the more careful derivation in the appendix beforehand and then go through it as quickly as possible (because there are countless of textbooks that shows how it goes --- and also said appendix!\,.). I will give a quick argument for why it is reasonable to assume that a theory conforming to such a Hamiltonian will be Lorentz-invariant, and then mention that i will (or might.\,.) get back to the matter in a later section. .\,.\,Of course, I goes with that argument to explain what said kind of Hamiltonian should fulfill such that we expect it (or rather such that it is reasonable to expect it) to be Lorentz-invariant. 

And in the following section I will then start considering QED and pull forth the Lagrangian from EM. .\,.\,Hm, I intend to begin working from that section and on now, but let me just go through what I intend to write in this section and in the following (with a risk of repeating what I have written before above).\,. So in said section, I expect to then write up the Fourier-transformed version of the Lagrangian and then read off the proto-Hamiltonian (like I did in my bachelor's thesis). I should also pull forth the Dirac Hamiltonian and thereby get my full proto-Hamiltonian. I intend to finish this section off by noting, what would happen if we assumed $V=0, A_\parallel=0$. Lo and behold, we would get my announced Hamiltonian but without the ``gauge term'' (or what we should call it). A will then point out, that we should neither expect this to be Lorentz-invariant, nor should we expect it to have EOM that agree with the classical EOM (on a large scale (i.e.\ ``when zooming out'')). And in the next section after that, I will introduce my special (``gauge-eliminating'' or whatever) (plane-wave) solutions. I will try to motivate them first in a natural way. .\,.\,Maybe I should do this by letting $V$ remain as $V=0$ (everywhere) and then freeing up $A_\parallel$.\,. .\,.\,Oh yeah, and then $\hat P_V$ is also removed, which then leaves us with something that can be solved. Yes, so I will then solve this by using the gauge symmetry of the Dirac Hamiltonian. I will not derive the resulting Coulomb potential just yet but try to include $V$ again first. After $V$ is reintroduced to get the full solution, I might then back the arguments up by a more careful argument if need be. And finally, I should then derive the.\,. No wait, that should be done in the next section. Yeah, I should instead finish this section off by making the argument.\,. Well, maybe it is not such a bad idea to just derive the Coulomb potential first to sort of keep the reader interested.\,. Okay, let me do that. Yeah, in then in the whole following section can be about how these solutions do not break the Lorentz-symmetry, which will then require my $\square^2 \phi$ argument (i.e.\ my ``$\square^2 \phi = 0$ argument''). .\,.\,Ah, and I should then also conjugate the positron solutions before deriving the final Hamiltonian, so yes, it is a very good idea to just derive (and show off) the Coulomb potential more immediately (to keep the reader interested and to distribute the workload more). So the section next after the ``these solutions do not break Lorentz symmetry'' section will then be about the conjugation, and luckily I have found out now (see the notesin the comments above this section in the source file), that it actually makes more sense to conjugate the positrons \emph{after} we have argued the Lorentz invariance of the pre-conjugation theory (which should be a well-behaved theory also, if my self-adjoint arguments hold). So I should not need to backtrack in order to conjugate the positrons when using this structure of the sections. And once this is done, well then should have a section where I use the results to derive the Hamiltonian and show that we get what was announced --- and note that we expect it to be Lorentz invariant, and in general follow the EOM of classical ED on a large scale. .\,.\,And how should a then structure the last couple of points.\,.\,? Besides the two sections where I note what proof strategies I have to show Lorentz-invariance more carefully and to show self-adjointness (for both the proposed Hamiltonian and the un-conjugated one), I should point out that the known quantum effects such as spin-spin, spin-orbit, gyromagnetic ratio and so on (.\,.\,i.e.\ and Lamb shift.\,. Was there anything else.\,.) should also be predicted by this theory (according to textbooks so and so --- and according to a simple argument in the case of the gm.r.).\,. And then there is the discussion where I point out the potentially new predictions (about pair production at least) and where I advertise that the same approach might (and should!) be tried on other gauge theories. Here, I am particularly excited about the strong nuclear force, but also in fact gravitation(!), even though we do not yet know for sure if there is a quantum theory that can work for GR. .\,.\,Hm, let me just figure out how to structure these parts (and any other part that I have perhaps forgotten about now) when I get there. (.\,.\,But I guess the question mostly will be whether I should do the spin-orbit-and-so-on argument early, just after deriving my Hamiltonian, or I should wait till the discussion at the end, which, I guess, should come after the two yet-to-be-proven-in-detail-and-thus-left-to-future-work sections *(for which I am pretty optimistic that I have good proof strategies --- which I will then try to explain in said sections --- but I might leave it at that for the first (preprint) version of the article, since it seems like a it is going to be some rather long and complicated arguments to make).\,.) %...Okay, jeg tror altså lige jeg vil nyde forårsvejret lidt, imens det er her, og så lige tage en lille tur til centeret of få ordnet nogle ting. Og så vil jeg bare love mig selv at gå i gang med at rode med formler senere i eftermiddag og i aften, måske endda fra sti-integrale og proto-Hamiltonian-sektionerne, så jeg lige får styr på formlerne (og ligningerne) der..:) (Kl. kvart i to.) %... Nå, de var lige lidt blæsende og lidt slørskyet, så det blev bare til en gåtur i stedet, men det nåede så godt nok at blive rigtigt dejligt efter lidt tid.:)

*I think I will cut the part where I ``derive the wrong Hamiltonian'' out and leave the argument for the discussion: best to just keep to the task of deriving my $\hat H$ and keep tangents to a minimum. I have also found out that I will save the first talk about why we should hope to find a Lorentz-invariant theory from the proto-Hamiltonian and why the EOM should be as we want them till after I have derived the proto-Hamiltonian (for QED).

%(28.03.22) Som jeg tænkte i går aftes:
*I should derive the Dyson expansion when I conjugate the positrons (or their ladder operators, rather) --- of course by making an ultra-violet cutoff to make it well-behaved. And then people can also see more easily what the Feynman diagrams will be for this theory. (It will of course be the expected answer, but many people might be used to have the diagrams derived from the Lagrangian (.\,. or the Hamiltonian \emph{density}.\,.) so it's nice that I get to include the derivation here. Then people can more easily see, that my theory \emph{is} a different theory than the current one.)

%(29.03.22) Jeg fik ikke sovet så meget i nat, men til gengæld fik jeg så tænkt et par flere tanker til, hvordan jeg vil strukturere det, så det vil jeg lige skrive her. Med min ihærdige brug af appendixer så kan jeg bl.a. nok trække nogle sektioner sammen. Det betyder bl.a. også, at jeg kan slippe for et finde på ligeså mange sektionsoverskrifter, hvilket jeg nemlig ikke føler er min stærke side *(i.e. at finde på navne og titler/overskrifter) (jeg er f.eks. også lidt flov over mit valg om at kalde den gængse faseoperator for \hat E_{SG} i sin tid x)^^). Og apropos det --- forhåbentligt modsat apropos;), men apropos i den forstand, at jeg ikke er kommet på noget godt navn før nu --- så kom jeg også i sengen på et muligt godt navn (endelig, forhåbentligt) til mit kvanteprogrammeringssprog, nemlig HQ, hvor H så primært her står for High-level (for Hybrid giver ikke så meget mening, når man så har Q lige bagefter og ikke noget C). Hm, lad mig lige søge på dette en gang, forresten.. ..Ah, ingen hits på google med nogen karambolage!:).. Og så er tanken også, for at gøre det lidt bedre fonetisk, at starte med at kalde min version HQ0, og så kunne man kalde det HQ1, HQ2, ... derefter (og hvis der så viser sig at være nogle vigtige issues gemt i min version, jamen så bliver det måske bare HQ1, der bliver den første egentlige version, hvad ved jeg?.).. Nå, jeg skal lige smage lidt mere på det og tænke lidt mere over det, men dette kunne da være en mulighed..:) (For jeg er gået lidt væk fra Q*-idéen. Jeg kom i øvrigt også på Hibrid for nyligt.. Hm, lad mig egentligt stadig holde den idé åben, selvom jeg synes det ser en anelse mærkeligt ud.. Tja.. (Og ellers er Hybrid jo måske også en mulighed..) Men ja, det kan jeg jo bare tænke over, når jeg får lejlighed. *(..Hm nej, Hibrid giver nu ikke så meget mening alligevel (tanken var lidt omkring '\emph{Hi}lbert space' og '\emph{Hi}gh-level,' men de to ting ligger jo allerede ret meget i konceptet om et hybrid-programeringssprog).. ..Og Hybrid er for åbenlyst. Nej, HQx virker som mit bedte forslag hidtil..)) *[Hm, nu kom jeg også lige på Hiq.. Det kunne det også være en god (og sådan lidt sjov) mulighed..:) (Kl. 25 over elleve.) (..Og det kunne jo så forkortes med '.hq' som fil-efternavn..) ..Ej, det er da lige før, det er meget bedre en HQ..!:D.. ..Hiq.. ..Ja. Og det er så ikke det mest mundrette i verden, men det er alligevel nok mere mundret ned de fleste andre ting, jeg har fundet på, også endda mere end HQ/HQx. Og så har navnet tilgengæld lidt god meme-værdi (i.e. så det ligesom ligger sig mere i bevidstheden:)), hvilket jo kun er godt for sådan et navn at have..:)] *[(Kl. 25 over seks.) Nå, HiQ er der noget, der hedder, godt nok med stort Q, hvormed det jo muligvis skal udtales Hi-Q.. (hvor mit var Hiq og skulle udtales Hic..) Nå, så jeg ved altså ikke helt, om den vil gå at kalde det Hiq, men nu har jeg ellers også tænkt på et andet muligt navn: Haql, som så skal fortolkes som stående for "(A) High-level Quantum-programing Language." Og det gode ved det navn er også lidt, at det fonetisk (for jeg tænker, det skal udtales lidt som haggle/hackle/hacle..) minder lidt om Haskell, som syntaksen jo er delvist inspireret af i dens nuværende version. ...(Men nu gider jeg heller ikke tænke mere over dette forløbigt.)] *(Tja, Haql, HAQL.. Det ligger heller ikke så godt i munden. Måske HQL var et bedre bud.. Men ja, for nu tror jeg bare jeg må sige, at dette min stærke side.. Jeg hælder nok mest til HQL, hvis Hiq ikke går, og hvis HQL ikke også er taget, men ja, jeg skal nu nok have lidt hjælp til at navngive det.. ..Hm, kan se, der er noget, der hedder HQL (et query language, self.) allerede..)
*I have some new ideas for restructuring. Let me try to go through it a bit from one end to the other. I think I might just skip the motivation; isn't a new QED theory motivation enough?\,. And in the into, I will still make sure to talk about that the theory is derived from the classical Lagrangian and mention the wisdom (or what to call it exactly) about EOM, but then state that since the theory can seems to clearly give Gauss' laws on a large scale, we can make an even better argument for this if only we make sure to prove that the theory is indeed Lorentz-invariant. I think I will then make the path integral and the proto-Hamiltonian sections into one (with my heavy use of appendices). .\,.\,Oh, and then let me actually note that $\hat H_{12}$ is a set of SHOs before I go on o the next section and then also extract the ground-state energies before I go on. In the next section, again with the heavy use of appendices, I can then also include deriving the Hamiltonian for the non-conjugated theory. And then the fourth (third after the introduction) section can be about Lorentz invariance, of course specifically about the Lorentz invariance of the gauge-elimination (partial) solutions. .\,.\,Hm, and let's see what I might want to do then, exactly.\,. \ldots Oh, I thought about then continuing about Lorentz invariance there, but no, I should stick to the rule that I shouldn't do any detours that might bore some physicists before I get to the primary goal (not in the main body of the text at least, but the readers are of course welcome to read the referenced appendices immediately). So I will just argue for the Lorentz invariance of the GE solutions here. I then, by the way, also intend to gloss over many details, such as why we are allowed to use Trotter and so on. Because then I will just save that for a section where I clear up all such details and that also means that I don't even have to talk about symmetric vs.\ self-adjoint (vs.\ hermitian) and so on until then. And when I do the Trotter expansions and so on, I will just refer to that later section, and say that we will show there that the conditions for this is met (and maybe also give a footnote suggesting why to any reader who is already familiar with how such is shown (e.g.\ by saying that it relies on the fact that the potentials are assumed bounded)). Okay, and in the fifth section, I will then do a Dyson expansion and show that we can conjugate the positron ladder operators without breaking the Lorentz symmetry (when also assuming anti-symmetric fermion wave functions first). And this should then give us the conclusion of the $\hat H$ announced in the intro. From there I should then make the section where I clear up some details in order to show how to make the past argument rigorized. I can make this both about the Lorentz invariance and the existence of the theory (which requires self-adjointness of $\hat H$ --- as well as the non-conjugated $\hat H$ when I have derived it this way, instead of conjugating before I eliminate the gauge symmetry on so on (and I can mention that it can be (I'm pretty sure) done this other way also)). Here I will then state that the only two (seemingly) non-trivial things yet to prove is the Lorentz symmetry of the proto-Hamiltonian and the self-adjointness of $\hat H$ (as well as of the un-conjugated one in our case (but my proof strategy should work for both, luckily)). And the next two sections will then be argument on how I think these two things (these propositions, that is) can be proved. And then we get to the discussion section, where I now also intend to point out that the Yukawa wisdom does have a problem in explaining where there is not more decoherence.\,. Oh wait, maybe not.\,. The point was that with my Dyson expansion, it is probably not hard to argue, that even though they appear as what is called \emph{virtual} photons when rewriting the expansions using Green functions, in the non-rewritten version, the photons still appear as normal (even if perhaps short-lived) particles that can then be a source of decoherence. But I guees you cannot really argue exactly that there \emph{should} be decoherence --- or just more disturbances when compared to the clean Coulomb potential --- so I think I will rather just let that point (and that whole discussion) be. .\,.\,But I will probably mention the fact that my theory, even though in some ways it goes against the common wisdom of QFT, actually ends up supporting one of the main features of conventional QFT, namely that scattering amplitudes a calculated wrt.\ the bare (incoming and outgoing) states (and I can mention why that potentially gives a systematic error to such calculations). But since the Coulomb interaction no longer seems to be carried by the photons (hm, and here one \emph{could} perhaps mention that ``virtual photons'' are only virtual due to a rewriting of the calculation.\,.), it is much more reasonable to think that the bare (momentum) states can be close to the actual momentum eigenstates. .\,.\,Hm, and since I now intend to show the Dyson expansion earlier, maybe it will be easy to refer to this to get the point across.\,. Oh well, I will just wait and see.\,.\,:) .\,.\,Oh, and I can of course conclude, after this discussion, with the section about future work and possible predictions. I quick note to myself here is that I think I \emph{will} mention the idea about the double slit experiment to measure (de-)coherence, and I also think I might mention the Wood-something-potential used for nucleus, and say somthing like: Imagine if this usage can be further justified or, better yet, if we can find some valuable corrections to it. .\,.\,:)

%(Kl. halv syv (stadig d. 29.).) 
*Oh, I think I actually need to make a section about going to the continuum limit before I get to showing Lorentz invarance of the GE solutions (and right after the GE-solution section).\,. I might then drop what I said about glossing over details such as noting why we can Trotter expand.\,. .\,.\,I am not sure I have the brain to continue much more today (only slept for four hours at most last night), %So I'm pretty proud with my level of productivity today --- though I \emph{have} been feeling pretty fresh as well, to be fair..
but when I get to it, I should then try to argue how to discretize a continuous theory (by approximation, correctly) and show that we get the discrete Hamiltonian in question from a certain continuous theory when approximating --- \emph{if} the continuous Hamiltonian is self-adjoint, of course (and I should argue from that assumption). .\,.\,Hm, yeah and then I have to see what kind of argument come after that when I get the brain for it again.\,. (Not that I'm not actually pretty fresh now, but \emph{that} is just to tall an order for me now.\,.)

%(31.03.22)
*I think I might be able to just make one section where I quickly explain all the overall stuff about going to the continuum limit and how Lorentz-invariance is proved, including the Lorentz invariance of the GE solutions. The idea is that I can just explain the general (not-specifically-GE-related) stuff about proving Lorentz invariance as briefly as possible and then refer to an appendix with more elaborations for the ones who are interested in a rigorous proof.\,. (And this section should then be after the GE-introduction section and before the conjugation section, which will then be the sort of final section before the self-adjointness section and the discussion and so on.\,.) 



\ldots\ I am not going to care about making temporal notes going forward with this work (it is more standard work anyway; I should (hopefully! --- 7, 9, 13 (i.e.\ ``knock on wood'')) be over the creative part of the process). So I will probably keep my dot-dot(-dot) notation and star (*) notation to a minimal. %And I will also not really make the timestamps that I have started doing recently. Instead I will just make backups regularly, so that I and anyone interested can read how the proces went afterwards, if I/they want to for some reason.. 

Okay, let me actually start with the proto-Hamiltonian section and then finish up about the (preceding) path integral section afterwards.



\subsection[proto-Hamiltonian]{Guessing the proto-Hamiltonian}
We know that the Lagrangian for electromagnetism is given by
\begin{align}
\begin{aligned}
%	\mathcal{L}=\mathcal{L}_{EM}+\mathcal{L}_{gauge} =
	\mathcal{L}_{EM} = 
		\frac{1}{2}\big(-\nabla V - \frac{\partial}{\partial t} \boldsymbol A	\big)^2 - 
		\frac{1}{2}\big(\nabla \times \boldsymbol A\big)^2.
%	+ \frac{\xi}{2} (\frac{\partial}{\partial t} V+\nabla \cdot \boldsymbol A)^2
\end{aligned} 
\end{align}
This does not quite match what we are looking for, but a known trick is to add a gauge term that does not change equations of motion (EOM) and thus use 
\begin{align}
\begin{aligned}
%	\mathcal{L}=\mathcal{L}_{EM}+\mathcal{L}_{gauge} =
	\mathcal{L} = 
		\frac{1}{2}\big(-\nabla V - \frac{\partial}{\partial t} \boldsymbol A	\big)^2 - 
		\frac{1}{2}\big(\nabla \times \boldsymbol A\big)^2 +
		\frac{\xi}{2} (\frac{\partial}{\partial t} V+\nabla \cdot \boldsymbol A)^2,
\end{aligned} 
\end{align}
where $\xi$ can be any positive constant we like.

This looks promising, but before we try to read of what $\hat H_B$ should then be, let us make a Fourier transform the field to get the Lagrangian in terms of plane-wave modes. 

In A.whatever, I show the details of doing this. At least this is what I should write in the article. I might want to actually take some time now to make sure I get the constants right. I am specifically thinking about the mode mass $m$ here.\,. .\,.\,Hm, oh well, it is only a question of a constant, that I will most likely just set to 1 anyway.\,. .\,.\,Ah wait, the mode mass \emph{should} just be 1, right (regardless of $\Lambda_k$ and $\delta k$).\,.\,? .\,.\,Hm no, it should be proportional to $A^3$ ($A$ here being half of the length of the $x$-space intervals), which means that it should be inversely proportional to $\delta k^3$, which makes good sense. 

Good, so from A.whatever, we get that a discretized and Fourier transformed Lagrangian, making the transform in terms of sine and cosine waves, is given by 
\begin{align}
\begin{aligned}
	L \propto \frac{1}{2}\sum_{\boldsymbol k, \sigma}
	\big(\big(-(-\sigma  V_{\boldsymbol k -\sigma}\boldsymbol k)-\frac{\partial}{\partial t} {\boldsymbol A}_{\boldsymbol k \sigma} \big)^2-\big(\boldsymbol k \times (-\sigma {\boldsymbol A}_{\boldsymbol k -\sigma}) \big)^2
	+ \xi \big(\frac{\partial}{\partial t}  V_{\boldsymbol k \sigma} +\boldsymbol k \cdot (-\sigma{\boldsymbol A}_{\boldsymbol k -\sigma})\big)^2\big).
\end{aligned} 
\end{align}

Bla bla bla, and then we can read off our proto-Hamiltonian as
\begin{align}
\begin{aligned}
	\hat H = \sum_{\boldsymbol k, \sigma}\bigg(
		\sum_{i=1}^2 \Big( 
			\frac{1}{2m} \hat P^2_{{A}_{\perp_i \boldsymbol k \sigma}} +
			\frac{1}{2} m k^2 \hat{A}_{\perp_i \boldsymbol k \sigma}^2
		\Big) +
%		\frac{1}{2} k^2 {A}_{\perp_1 \boldsymbol k s}^2 + 
%		\frac{1}{2} k^2 {A}_{\perp_2 \boldsymbol k s}^2 +
	\frac{1}{2\xi} \hat P^2_{V_{\boldsymbol k \sigma}} +
	\frac{1}{2m} \hat P^2_{A_{\parallel \boldsymbol k \sigma}} +
	k \sigma \hat{A}_{\| \boldsymbol k -\sigma} \hat P_{ V_{\boldsymbol k \sigma}} + 
	k \sigma  \hat{V}_{\boldsymbol k -\sigma} \hat P_{A_{\| \boldsymbol k \sigma}} \bigg).
\end{aligned} 
\end{align}
And here, $m$ will be equal to $(1/(8 A^3) =)\,\, \delta k.\,.$ Hm, whatever, I can find out when it matters.\,. It is proportional to $\delta k^3$, anyway.\,. *(And it is equal to the volume, which I might call $\Omega$.\,.)

We are also free to add a constant term (maybe call it $E_0$) to $\hat H$ (which we can use to cancel out the ground state energies of the photons). 

Hm, we can change variables to make it look more clean (and perhaps I should do this earlier.\,. *(No, I should sure to write the more instructive version --- and maybe I should just postpone simplifying it, even.\,.)). *(Ah, maybe I should just get rid of the $\perp$ and $\parallel$ subscripts and just use $i\in\{1, 2, 3\}$ indices instead.\,. .\,.Yes.\,.) We can then write
%\begin{align}
%\begin{aligned}
%	\hat H = \sum_{\boldsymbol k, \sigma}\bigg(
%		\sum_{i=1}^2 \Big( 
%			\frac{1}{2m} \hat P^2_{i \boldsymbol k \sigma} +
%			\frac{1}{2} m k^2 \hat{X}_{i \boldsymbol k \sigma}^2
%		\Big) +
%%		\frac{1}{2} k^2 {A}_{\perp_1 \boldsymbol k s}^2 + 
%%		\frac{1}{2} k^2 {A}_{\perp_2 \boldsymbol k s}^2 +
%	\frac{1}{2\xi} \hat P^2_{0 k \sigma} +
%	\frac{1}{2m} \hat P^2_{3 \boldsymbol k \sigma} +
%	k \sigma \hat{X}_{3 \boldsymbol k -\sigma} \hat P_{0 \boldsymbol k \sigma} + 
%	k \sigma  \hat{X}_{0 \boldsymbol k -\sigma} \hat P_{3 \boldsymbol k \sigma} \bigg).
%\end{aligned} 
%\end{align}
\begin{align}
\begin{aligned}
	\hat H = \sum_{\boldsymbol k, \sigma}\bigg(
		\sum_{i=1}^2 \Big( 
			\frac{1}{2m} \hat P^2_{i \boldsymbol k \sigma} +
			\frac{1}{2} m k^2 \hat{A}_{i \boldsymbol k \sigma}^2
		\Big) +
	\frac{1}{2\xi} \hat P^2_{0 k \sigma} +
	\frac{1}{2m} \hat P^2_{3 \boldsymbol k \sigma} +
	k \sigma \hat{A}_{3 \boldsymbol k -\sigma} \hat P_{0 \boldsymbol k \sigma} + 
	k \sigma  \hat{A}_{0 \boldsymbol k -\sigma} \hat P_{3 \boldsymbol k \sigma} \bigg).
\end{aligned} 
\end{align}

.\,.\,Hm, I guess this is the desired result, and then I should just finish off by deriving the wrong Hamiltonian by setting $V=0, A_\parallel=0$, right.\,.\,? 

.\,.\,This reveals that the first part is just a set of simple harmonic oscillators.\,. We therefore expect these $A_\perp$ modes to end up as the photons in our theory. %The latter part is not so nice, in fact it looks almost like a free Hamiltonian.\,. .\,.\,Hm, and when the Dirac Hamiltonian comes on board it will give an equation that is hard to solve for the whole space.\,. I am a bit tired now, as one can hear, so I will take a break. The point that I actually wanted to write was really just that I need to remember the Dirac Hamiltonian as well. But I will take a break now and then get back to that when I resume the work. 

We also need to choose an appropriate $\hat H'$ and here, the Dirac Hamiltonian is of course the natural choice. On a classical field, it is given by


Copied from old notes:

In the \textit{Weyl representation} (also known as the \textit{chiral representation}) they are given by
\begin{align}
\begin{aligned}
\gamma^0 &=
\begin{pmatrix}
\: 0 & 0 & 1 & 0 \:\\
\: 0 & 0 & 0 & 1 \: \\
\: 1 & 0 & 0 & 0 \: \\
\: 0 & 1 & 0 & 0 \:
\end{pmatrix}
, \quad
&\gamma^1 =
\begin{pmatrix} 
0 & 0 & 0 & 1 \: \\
0 & 0 & 1 & 0 \: \\
0 & -1 & 0 & 0 \: \\
-1 & 0 & 0 & 0 \:
\end{pmatrix},
\\
\gamma^2 &=
\begin{pmatrix}
0 & 0 & 0 & -i \: \\
0 & 0 & i & 0 \: \\
0 & i & 0 & 0 \: \\
-i & 0 & 0 & 0 \:
\end{pmatrix}
, \quad
&\gamma^3 =
\begin{pmatrix}
0 & 0 & 1 & 0 \\
0 & 0 & 0 & -1 \\
-1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 
\end{pmatrix}.
\end{aligned}
\end{align}
The Dirac Hamiltonian can be derived from eq.\ () by identifying $i \partial_t \psi= H \psi$ and $-i \nabla \psi = \hat{\boldsymbol p}$, giving us
\begin{align}
\begin{aligned}
0 &= (i \gamma^0 \partial_t +i \gamma^i \partial_i - m) \psi(x) \Leftrightarrow
\\
0 =& \: (\gamma^0 \gamma^0 H - \gamma^0 \boldsymbol \gamma \cdot \hat{\boldsymbol p} - \gamma^0 m) \psi(x)
\Leftrightarrow \\
H = \gamma^0 \boldsymbol \gamma \cdot \hat{\boldsymbol p} + \gamma^0 m &=
\begin{pmatrix}
-\hat p_z & -\hat p_x + i\hat p_y & m & 0 \\
-\hat p_x - i\hat p_y & \hat p_z & 0 & m \\
m & 0 & \hat p_z & \hat p_x - i\hat p_y \\
0 & m & \hat p_x + i\hat p_y & -\hat p_z 
\end{pmatrix}.
\label{dirac_H}
\end{aligned}
\end{align}
Under a Lorentz transformation, $\psi$ transforms as
\begin{align}
\begin{aligned}
\psi(x) \to \psi'(x') = S[\Lambda] \psi(\Lambda^{-1} x'), \quad S[\Lambda] =
\begin{pmatrix}
e^{-\frac{1}{2} \boldsymbol \sigma \cdot \boldsymbol \rho} & 0 \\
0 & e^{\frac{1}{2} \boldsymbol \sigma \cdot \boldsymbol \rho}
\end{pmatrix},
\end{aligned}
\end{align}
where $\boldsymbol \rho$ is the rapidity vector, which points in the boost direction and has norm equal to the rapidity, $\rho$, of the boost, defined by $\cosh(\rho) = \gamma = 1/\sqrt{1-\beta^2}$. The components of $\boldsymbol \sigma = (\sigma_x, \sigma_y, \sigma_z)$ are the Pauli matrices:
\begin{align}
\begin{aligned}
\sigma_x =
\begin{pmatrix}
0 & 1 \\
1 & 0
\end{pmatrix}, \quad
\sigma_y =
\begin{pmatrix}
0 & -i \, \\
i & 0 \,
\end{pmatrix}, \quad
\sigma_z =
\begin{pmatrix}
1 & 0 \\
0 & -1
\end{pmatrix}.
\end{aligned}
\end{align}

\begin{align}
H_{Dirac} =\sum_{N=0}^{\infty} \sum_{i=1}^{N} \gamma^0 \boldsymbol \gamma \cdot (\hat{\boldsymbol p\,}_i\! - e \!\hat{\,\boldsymbol A\,\,\,}\!\!\!)(\boldsymbol x_i) + \gamma^0 m + e V(\boldsymbol x_i)
\end{align}

Continuing:

For one particle and on a classical electromagnetic field, $(V(\boldsymbol{x}), \boldsymbol A(\boldsymbol{x}))$, it is given by
\begin{align}
\hat H_{D} \psi(\boldsymbol{x}) = 
	\big(
		\gamma^0 \boldsymbol \gamma \cdot (\hat{\boldsymbol p\,}\! - q \boldsymbol A(\boldsymbol{x})) +
		\gamma^0 m + q V(\boldsymbol{x})
	\big)\psi(\boldsymbol{x}),
\end{align}
where $e$ is the electron charge (if we look at electrons and positrons and not other leptons). *(No, I should just use $q$ rather than $e$, also since we technically do not know, if the bare charge $q$ should be equal to $e$ or if the effective charge that we measure is perturbed somehow (even though I'm almost sure it shouldn't be). And on top of this, if I want to use $\boldsymbol{e}$s rather than $\boldsymbol{u}$s now, then it looks better with $q$.) *Where $q$ here is the coupling constant, which we expect should be just the electron charge when the theory is for electrons/positrons. Note that neither $\boldsymbol{p}$ nor $q$ here has no longer anything to do with the field --- and let me just make a note to myself as well, that I should indeed make sure to use capital $\hat P$ for the lattice momenta. .\,.\,Hm, does it actually look better with $q$, though (i.e.\ in the equation below).\,.\,? .\,.\,Sure, it's fine.\,.

For multiple particles, $\boldsymbol{x}$ should just have more dimension and each $\gamma^\mu$ should just be replaced with $\gamma^\mu \oplus \gamma^\mu \oplus \ldots$ instead, or at least I think so (but I should check this to be sure).\,. 

Ah, and I should just refer to an appendix where I try to give some details on the Dirac Hamiltonian.

Okay, and since this should be our $\hat H_F(\boldsymbol{q})$ (where $\boldsymbol{q}$ is a many-dimensional coordinate vector describing the $A^\mu$ (or $(V, \boldsymbol{A})$) lattice), we see that $\hat H'$ should just be the above Dirac Hamiltonian but now on a larger Hilbert space of all the possible field/lattice configurations, and where we should thus replace $V(\boldsymbol{x})$ with $\hat V(\boldsymbol{x})$ and $\boldsymbol A(\boldsymbol{x})$ with $\hat{\boldsymbol A\hspace{.3em}}\hspace{-.3em}(\boldsymbol{x})$. Or at least, this is what we should do in $x$-space. Now that the bosonic Hilbert space is a space of $(\boldsymbol{k},\sigma)$ modes (for all the four field entries), .\,.\,for a single-particle fermion Hilbert space, we should have *(I am now adobting the notation mentioned (now) above, where I get rid of the $\perp$-$\parallel$ notation.)
\begin{align}
\hat H' \ket{A_\mu, \psi} = 
%(\phi \otimes \psi)(A_\mu, \boldsymbol{x}) =  %(\{A_{i\boldsymbol{k}\sigma}\}, \boldsymbol{x}) =  %(A_\mu, \boldsymbol{x}) = 
	\sum_{\boldsymbol{k}, \sigma}\Big(
		\sum_{i=1}^{3} \gamma^0 \boldsymbol \gamma \cdot (
			\hat{\boldsymbol p\,}\! - 
				q \boldsymbol{e}_{i\boldsymbol{k}} 
				A_{i\boldsymbol{k}\sigma}
				\hat f_{\boldsymbol{k}\sigma}
		) +
		\gamma^0 m + q A_{0\boldsymbol{k}\sigma}
		\hat f_{\boldsymbol{k}\sigma}
	\Big) %(\phi \otimes \psi)(A_\mu, \boldsymbol{x}),
%	\psi(\boldsymbol{x}),
	\ket{A_\mu, \psi},
\end{align}
where $A_\mu = (A_{i\boldsymbol{k}\sigma})$ denotes an ($8N$-dimensional) coordinate vector of all the $A_{i\boldsymbol{k}\sigma}$-coordinates, and where 
%$f_{\boldsymbol{k}\sigma}$ are just the three-dimensional sine and cosine functions.
$\hat f_{\boldsymbol{k}\sigma}\ket{A_\mu, \psi} = \ket{A_\mu, f_{\boldsymbol{k}\sigma} \psi}$, using $(f_{\boldsymbol{k}\sigma}\psi)(\boldsymbol{x}) = f_{\boldsymbol{k}\sigma}(\boldsymbol{x})\psi(\boldsymbol{x})$, with the $f_{\boldsymbol{k}\sigma}$s being our 
three-dimensional sine and cosine functions.

So this is the $\hat H'$ for our proto-Hamiltonian. .\,.\,I guess I should also try to write up the whole proto-Hamiltonian.\,. .\,.\,Hm, I can do that when I need to. I should, however, remember to put the $B$ on $\hat H$ above, such that I write 
\begin{align}
\begin{aligned}
	\hat H_B = \sum_{\boldsymbol k, \sigma}\bigg(
		\sum_{i=1}^2 \Big( 
			\frac{1}{2m} \hat P^2_{i \boldsymbol k \sigma} +
			\frac{1}{2} m k^2 \hat{A}_{i \boldsymbol k \sigma}^2
		\Big) +
	\frac{1}{2\xi} \hat P^2_{0 k \sigma} +
	\frac{1}{2m} \hat P^2_{3 \boldsymbol k \sigma} +
	\sigma k \hat{A}_{3 \boldsymbol k -\sigma} \hat P_{0 \boldsymbol k \sigma} + 
	\sigma k \hat{A}_{0 \boldsymbol k -\sigma} \hat P_{3 \boldsymbol k \sigma} \bigg)
\end{aligned} 
\end{align}
instead for the purely bosonic part of the proto-Hamiltonian.

As I have now mentioned above, I should then finish this section of by speaking about the fact that it is reasonable to expect this to have the right EOM --- and some right quantum mechanical properties also --- and also to expect it to be Lorentz-invariant. Hm, let me try to sum up these points.\,.

If we look at the first part of $\hat H_B$ then we can recognize this a simple harmonic oscillators. And these oscillators are the part of the Hamiltonian that works on the transverse wave modes of the magnetic vector potential $\boldsymbol{A}$. We thus expect these harmonic oscillators to be the photon modes. The properties of the Dirac Hamiltonian is much studied and known give the right predictions for electrons moving in a classical electromagnetic field. The only trouble here is that we at some point need to reinterpret two of the negative energy solutions as positive-energy positrons but this is a well-known matter to deal with, and we will get to it later on. The only unusual part is the latter part of $\hat H_B$ which works on the $A_0$- and the $A_3$-coordinates, which we recall respectively represents the modes of the electric potential $V$ and the longitudinal modes of the magnetic vector potential $\boldsymbol{A}$ --- which are the ones that decide the divergence of $\boldsymbol{A}$ (i.e.\ $\nabla \cdot \boldsymbol{A}$). We note that this part of the Hamiltonian is pretty much free; if not for the presence of $\hat H'$, one should be able to find solutions to this Hamiltonian that are plane wave solutions for.\,. No, that might not be true.\,. I should probably check this but it doesn't really matter much: ``they are sort of free'' is the only point that is worth to make.\,. Anyway, we might note that these two degrees of freedom of the $A_\mu$ field famously have a gauge symmetry to them, meaning that several different field configuration here actually might produce the same ``physical field,'' i.e.\ the same $\boldsymbol{E}$ and $\boldsymbol{B}$ field that we can actually measure. Our hope is therefore to find a way to eliminate this gauge symmetry such that we get rid of these two degrees of freedom. .\,.\,Hm, it gets a bit long-haired, but I could in principle (but probably won't) talk about how it is interesting that we actually need to reduce the two degrees of freedom to \emph{zero} and not just one, which is what they are reduced to (more or less) with gauge eliminations in classical theories. But we even just one degree of freedom would mean an spinor to the photons, if not just a new 1-spinor boson on top, which would be observable in our physical systems. So the quantum mechanical gauge elimination actually has to do \emph{more} than it's classical counterparts. Anyway, but I need to formulate that we hope to find a way to eliminate the gauge symmetry that also brings the number of spinor entries all the way down to just the two which represent the two transverse parts of $\boldsymbol{A}$ (so that our bosons, i.e.\ photons, only get two spinor entries). 

.\,.\,Hm, should I actually postpone the discussion of EOM and Lorentz-invariance a bit.\,. Hm, no I can't seeing as we need to discuss Lorentz-invariance throughout.\,. 

Okay, so I should probably write something like: If we succeed in this (and if we succeed in reinterpreting the negative-energy Dirac-spinor solutions), then we get a theory that will have all the right quantum mechanical properties on a fundamental level. The fermions will have the right behavior when moving in classical (meaning strong enough that the quantum fluctuations can be neglected) fields. It is also very promising, that the Lagrangian (by the usual argument that the most probable paths should be around the classical EOM when we look at the path integral) points to EOM for the fields that matches the classical theory. But there is and even more striking way to argue, that the theory should reproduce the classical theory on a large scale. % Moreover, as I have revealed in the introduction, there will turn out to be a Coulomb potential directly in the Hamiltonian which means that on a large scale, Gauss' law (the electric one.\,.) should apply. And 
This is since, as I have revealed in the introduction, there will turn out to be a Coulomb potential directly in the Hamiltonian which means that on a large scale, Gauss' law (the electric one.\,. *(well, both of them, actually)) should apply. And since Maxwell's equations are the only known Lorentz-invariant extension of Gauss' law, if we can just make sure that the obtained theory is Lorentz-invariant, then it must predict a behavior that matches Maxwell's equation on a large scale. We would of course require the theory to be Lorentz-invariant anyway, but it is nice to know that once this is achieved, we have very good arguments that the theory have the right predictions on a large scale (even without solving it). 

And luckily, one can indeed show that the theory is Lorentz-invariant. 

%(27.03.22) (Kl. halv fire.) I går aftes kom jeg frem til følgende omkring at omtrukturere det, så jeg i stedet bare meget forklarer det gode ved at få vist Lo.-invarians meget i introduktionen.
I have found out that I should actually just explain a lot of this in the introduction (right under when I announce the Hamiltonian of the theory). So in this section, I should probably just mention, that the motivation for deriving this proto-Hamiltonian is that the general wisdom will say that it should then follow the classical electromagnetic dynamics (or EOM). It also makes it plausible that we will obtain a Lorentz-invariant theory. And as mentioned in the intro (to be written), this will be very important to show. Not only is it an expected requirement on its own, but if we then end up with a theory that predicts Gauss' laws on a large scale, then we expect to get the rest of Maxwell's equations on a large scale as well. 

And if we look at the path integral, we see that it is reasonable to think that the resulting theory will be Lorentz-invariant, at least if we do not break this invariance when eliminating the gauge symmetry or when reinterpreting the negative-energy fermion solutions. For we see that every path is\ldots\ Hm, I do not feel like expalining this right now, so let me just get back to it and continue with the gauge-elimiation section. 

But let me first also note, that I have also found out, that I should probably then just keep the arguments for Lorentz invariance on a sort of heuristic level, such that the derivation is more to do with motivating the result rather than sort of ``proving'' it as we go along. And then I will just do a section where I use some of the results of this derivation as well as some additional argument to argue that it is indeed Lorentz-invarant. This is not to say, then, that Lorentz invariance shouldn't be a clear focus of the derivation --- it should --- but I can just allow my self to use more mild language in the derivation itself and just make arguments for the likelihood, so to speak, of the Lorentz invariance. 

\subsection{Eliminating the gauge symmetry}
In classical physics, a gauge elimination typically implies imposing restrictions on the fields and thereby cutting all other field configurations away. It is then natural to try to do this for path integral in the case of quantum mechanics, but if we look at the path integral of eq.\ whatever, we see that this might get in way of the Gaussian integration need to obtain a Hamiltonian back. If for instance we imposed $\partial_\mu A^\mu = 0$ as an restriction (rather than simply adding $(\partial_\mu A^\mu)^2$ to the Lagrangian, we get the Hamiltonian so easy. \ldots

Another problem is that cutting away fields might break the Lorentz invariance\ldots 

Hm, I can think of what to mention here. I could maybe also mention that $V=0$, $A_\parallel=0$ does more than eliminate the gauge symmetry: It also means the $\nabla \cdot \boldsymbol{E} = 0$ everywhere. But in reality, I probably just want to say as little as possible here and only just get the point across: Let us try something else than to go back and try to cut off paths. 

Let me just assume that I have gotten that point across.\,.

*Ah, I can probably just say it in a sentence or to, like: ``\ldots therefore it is natural to try to go back and cut away fields. But by making such cuts, you risk breaking the Lorentz symmetry, and it is also likely to ruin the possibility to do the Gaussian integration that gives you the Hamiltonian.\,.''

The idea that has led me to the Hamiltonian of eq.\ so-and-so is then to instead try to solve the proto-Hamiltionian as is and then just expect un-normalizable solutions in the dimension of $A_0$ and $A_3$ (i.e.\ where the ``probability distribution'' extends through all the coordinate space). 

.\,.\,Hm, should I change the name from $A_\mu$ since it might confuse otherwise when the three last subscript are no longer the three spacial coordinates.\,.\,? .\,.\,$Q$ could of course be one possibility.\,. Hm, and I shouldn't just use maybe something like $\perp$, $\vdash$, $\parallel$.\,.\,? .\,.\,Hm, no.\,. .\,.\,Hm, no let me just keep it as $A_{\mu \boldsymbol{k}}$.\,. 

Okay. The idea for solving this problem comes from the fact that the Dirac equation is known to also exhibit the same gauge symmetry, at least up to an overall complex factor that does change the physical probability distribution. We thus know that if $\psi(x)$, $x=(x_0, x_1, x_2, x_3)$, $x_0 = t$, solves the Dirac equation for a classical field $A_\mu$, then $\exp(i\varphi(x))\psi(x)$ (or whatever it is precisely) will be a solution when $\partial_\mu \varphi(x)$ is added to $A_\mu$. Furthermore, we can see that adding any $\varphi(x)$ that is constant in time will add no curl to $\boldsymbol{A}=(A_1, A_2, A_3)$, and will add nothing to $V = A_0$.\,. Oh, now it does become a bit confusing, that we keep ${1,2,3}$ as indices for the $A_{i\boldsymbol{k}}$s.\,. .\,.\,Hm, should I just put a tilde over $A_{i\boldsymbol{k}}$ ($\tilde A_{i\boldsymbol{k}}$)..\,.\,? .\,.\,Hm, and then maybe just remove the tilde for the $\hat{A}_{i \boldsymbol k \sigma}$s.\,.\,? (.\,.\,Or else it will be $\hat{\tilde A}_{i \boldsymbol k \sigma}$.\,. Oh no, not that!\,.\,\texttt{xD}) .\,.\,Yeah, maybe that's the best idea (as it seems reasonable to remove the tilde (and make them sort of implicit) when the hats come on).

Okay. And to continue the motivation, we thus note that adding a $\varphi(x)$ (or $\varphi(\boldsymbol{x})$) that is constant in time will only add to the divergence of $\boldsymbol{A}$ and will thus only add to $\tilde A_{3\boldsymbol{k}\sigma}$ for each $\boldsymbol{k}, \sigma$. Specifically, when we make a Fourier transform of $\varphi(\boldsymbol{x})$ to get, let us call them $\tilde\varphi_{\boldsymbol{k}\sigma}$s, we that $-\sigma k\tilde\varphi_{\boldsymbol{k}-\sigma}$ is added to each $\tilde A_{3\boldsymbol{k}\sigma}$ (or maybe with the opposite sign.\,.).\,.

So if we start by looking at the proto-Hamiltonian without that parts involving $\tilde A_0$ (or $V$ if one will), and thus setting the $\hat A_{0 \boldsymbol{k}\sigma}$s and $\hat P_{0 \boldsymbol{k}\sigma}$s to 0, there might be simple solution to the $\tilde A_{0 \boldsymbol{k}\sigma}$-dependencies.\,. 

\ldots\ That means we only keep the first, photonic part and then also the $\hat P^2_{3 \boldsymbol k \sigma} / (2m)$ term. 

.\,.\,We can also Fourier-transform $\psi(x)$, which is assumed to be a solution.\,. Hm, should I include the photons as well.\,.\,? 

Let me copy this from above:
\begin{align}
	\hat H' \ket{\tilde A_\mu, \psi} = 
		\sum_{\boldsymbol{k}, \sigma}\Big(
			\sum_{i=1}^{3} \gamma^0 \boldsymbol \gamma \cdot (
				\hat{\boldsymbol p\,}\! - 
					q \boldsymbol{e}_{i\boldsymbol{k}} 
					\tilde A_{i\boldsymbol{k}\sigma}
					\hat f_{\boldsymbol{k}\sigma}
			) +
			\gamma^0 m + q \tilde A_{0\boldsymbol{k}\sigma}
			\hat f_{\boldsymbol{k}\sigma}
		\Big) 
		\ket{\tilde A_\mu, \psi},
	\label{H'(A-tilde)_01}
\end{align}
We should then argue from this, unless we want to do a heuristic argument involving $\exp(i\varphi(x))$ first/instead.\,. 

(.\,.\,Hm, and there is always the solution with the Trotter expansion if necessary.\,.) 

.\,.\,Hm, I guess I do need to motivate the solution some more first (arguing about $\exp(i\varphi(x))$.\,.).\,. 

\ldots Hm, maybe I should point out that since we are adding $-\sigma k\tilde\varphi_{\boldsymbol{k}-\sigma}$ to each $\tilde A_{3\boldsymbol{k}\sigma}$, when $\tilde A_{3\boldsymbol{k}\sigma}$ grows with $\alpha$, we should like it if $\tilde\varphi_{\boldsymbol{k}-\sigma}$ then grows with $-\sigma \alpha / k$. Hm, so if we look at a specific $\tilde A_\mu = (\tilde A_{\mu\boldsymbol{k}\sigma})$ (.\,. or $\tilde A_\mu = \langle\tilde A_{\mu\boldsymbol{k}\sigma}\rangle$.\,.) at a given time, then we expect $\psi(t, \boldsymbol{x})$ to be equal to $\exp\big[i\sum \,.\,.\,\big] \psi(x)$.\,. no, I don't want to write that.\,. How about $\psi_{\boldsymbol{k}\sigma}(t, \boldsymbol{x}) = \psi_0()$.\,. hm, wait.\,. %Let me just think about all this a bit before continuing.. ..(I unfortunately don't feel so sharp at this hour (kl. 25 i otte) (allerede)..) 

%((28.03.22))
Hm, maybe it does make sense to write up the $\exp\big[i\sum \,.\,.\,\big] \psi(x)$ expression.\,. Let's see, 
\begin{align}
	\psi(\boldsymbol{x})=\exp\Big[
		i\sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma} 
		f_{\boldsymbol{k}\sigma}(\boldsymbol{x}) / k
	\Big] \psi_0(\boldsymbol{x})\,.\,.
\end{align}
Oh, and I need the $q$, so
\begin{align}
	\psi(\boldsymbol{x})=\exp\Big[
		i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma} 
		f_{\boldsymbol{k}\sigma}(\boldsymbol{x}) / k
	\Big] \psi_0(\boldsymbol{x}).
\end{align}

Hm, and maybe we can then just plug that into eq.\ (\ref{H'(A-tilde)_01}).\,. .\,.Hm, or you could actually also just argue it (even though it might be nice to check it this way), but since $\tilde A_\mu$ describes a real classical field, and since.\,. Oh, I should also remove $\hat P_3^2/(2m)$ then for the time being, such that the Hamiltonian leaves field eigenstates invariant.\,. Okay, so for now, we are actually solving just the Dirac Hamiltonian.\,. hm, since it is then separable and we thus do not need to consider the space of photons, but then one could say, why do this, since we already know the gauge symmetry property.\,. Hm, maybe I should just make sure, but then say that ``it can be checked that plugging whatever into whatever solves it.\,.'' .\,.\,Hm, by using that $\boldsymbol{k}/k=\boldsymbol{e}_{3\boldsymbol{k}}$.\,. 
.\,.\,Hm, and I guess we should actually use
\begin{align}
	\psi(t, \boldsymbol{x})=\exp\Big[
		i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma}(t) 
		f_{\boldsymbol{k}\sigma}(\boldsymbol{x}) / k
	\Big] \psi_0(t, \boldsymbol{x}).
\end{align}

.\,.\,Oh wait, the Hamiltonian is \emph{not} separable, so I guess I do need to include the photonic space, unless I want to Trotter it of course\ldots\ 

Oh wait, and we can luckily assume that $\tilde A_{3\boldsymbol{k}-\sigma}(t)$ is constant (for all indices), so never mind this last equation.\,. 

Ah, yes since
\begin{align}
\begin{aligned}
\hat{\boldsymbol p\,}\! 
	\exp\Big[
		i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma} 
		f_{\boldsymbol{k}\sigma}(\boldsymbol{x}) / k
	\Big] =
	q\frac{\boldsymbol{k}}{k}\sigma (-\sigma)
%	\exp\Big[
%			i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma} 
%			f_{\boldsymbol{k}\sigma}(\boldsymbol{x}) / k
%		\Big]
	\exp\Big[
			\,.\,.\,
		\Big]
\end{aligned}
\end{align}
Oh wait, I should write the sum symbol differently in eq.\ (\ref{H'(A-tilde)_01}), since we don't wanna sum over $\hat{\boldsymbol p\,}\!$ as well.\,.
\begin{align}
	\hat H' \ket{\tilde A_\mu, \psi} = 
		\sum_{\boldsymbol{k}, \sigma}\Big(
			\gamma^0 \boldsymbol \gamma \cdot (
				\hat{\boldsymbol p\,}\! - 
					\sum_{i=1}^{3} 
					q \boldsymbol{e}_{i\boldsymbol{k}} 
					\tilde A_{i\boldsymbol{k}\sigma}
					\hat f_{\boldsymbol{k}\sigma}
			) +
			\gamma^0 m + q \tilde A_{0\boldsymbol{k}\sigma}
			\hat f_{\boldsymbol{k}\sigma}
		\Big) 
		\ket{\tilde A_\mu, \psi},
\end{align}
And then to continue the calculation from before:
\begin{align}
\begin{aligned}
	\hat{\boldsymbol p\,}\! 
	\exp\Big(
		i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma} 
		f_{\boldsymbol{k}\sigma}(\boldsymbol{x}) / k
	\Big) =&\,
	\sum_{\boldsymbol{k}, \sigma} \Big(
		q\frac{\boldsymbol{k}}{k}\sigma (-\sigma)
		\tilde A_{3\boldsymbol{k} -\sigma} 
		f_{\boldsymbol{k} -\sigma}(\boldsymbol{x})
	\Big)
	\exp\Big(
			i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma} 
			f_{\boldsymbol{k}\sigma}(\boldsymbol{x}) / k
		\Big)
	\\=&\,
	-\sum_{\boldsymbol{k}, \sigma} \Big(
		q \boldsymbol{e}_{3\boldsymbol{k}}
		\tilde A_{3\boldsymbol{k} \sigma} 
		f_{\boldsymbol{k} \sigma}(\boldsymbol{x})
	\Big)
	\exp\Big(
			i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma} 
			f_{\boldsymbol{k}\sigma}(\boldsymbol{x}) / k
		\Big),
\end{aligned}
\end{align}
where we have changed the summation index, $\sigma$ to its reverse to get the last line. 
.\,.\,Hm, so I probably have a sing wrong somewhere.\,. oh wait, and this calculation is also not right: shouldn't I get another factor of $f_{\boldsymbol{k}\sigma}(\boldsymbol{x})$ in the first line.\,.\,? 

\ldots Oh wait, I should also move the other sum symbol inside, right.\,.\,? .\,.\,Sure.\,.
\begin{align}
	\hat H' \ket{\tilde A_\mu, \psi} = 
		\Big(
	%		\sum_{\boldsymbol{k}, \sigma}\Big(
				\gamma^0 \boldsymbol \gamma \cdot \big(
					\hat{\boldsymbol p\,}\! - 
						\sum_{i=1}^{3} \sum_{\boldsymbol{k}, \sigma}
						q\boldsymbol{e}_{i\boldsymbol{k}} 
						\tilde A_{i\boldsymbol{k}\sigma}
						\hat f_{\boldsymbol{k}\sigma}
				\big) +
				\gamma^0 m + 
				\sum_{\boldsymbol{k}, \sigma}
				q\tilde A_{0\boldsymbol{k}\sigma}
				\hat f_{\boldsymbol{k}\sigma}
	%		\Big) 
		\Big)
		\ket{\tilde A_\mu, \psi}.
	\label{H'(A-tilde)_02}
\end{align}

.\,.\,Oh right, no, there should not be an extra factor of $f_{\boldsymbol{k}\sigma}(\boldsymbol{x})$ in the first line.\,:) It is right, except for the wrong sign (which probably comes from the fact that it should be $\exp(-i\varphi(x))$, when we have the whatever-representation where there's a minus sign in front of $q\boldsymbol{A}$ in the Dirac Hamiltonian.\,.). (.\,.\,Or else might come from whether $\boldsymbol{A}\to \boldsymbol{A} + \nabla \varphi$ or $\boldsymbol{A}\to \boldsymbol{A} - \nabla \varphi$.\,.)

%*(06.04.22) (Kl. tyve i fire.)
*(No Abers says $\exp(-i\varphi(x))$, and I pretty sure that his ``minus sign in front of $q\boldsymbol{A}$'' only comes from the fact that he used $-e$ rather than $q$. .\,.\,Oh wait, no: I should then have a plus sign.\,. No, wait.\,. \ldots Hm, Abers does have $\exp(iq\varphi(x))$.\,.)

Okay, and then back to the question of whether I should use Trotter for the problem.\,. .\,.\,Hm, it seems quite reasonable to do.\,. .\,.\,Also since we will at some point need the solution to be an approximated solution instead, and then we might very well more or less need the Trotter argument.\,. .\,.\,Okay, Trotter it is.\,. 

Since the proto-Hamiltonian is bounded in its discretized form, and since it is clearly symmetric\footnote{What many physicists might call \emph{hermitian}; by symmetric we mean so and so\ldots}, we can do a Trotter expansion (of course, since that is where we came from.\,.), but this time, let us not insert any $\int\ket{\boldsymbol{q}}\bra{\boldsymbol{q}}$s or $\int\ket{\boldsymbol{p}}\bra{\boldsymbol{p}}$s. .\,.\,Oh, I guess we should insert the $\int\ket{\boldsymbol{q}}\bra{\boldsymbol{q}}$s, actually.\,. 

\ldots Hm, we could do a double Trotter expansion to first extract the photonic part and then to separate $\hat H'$ and $\hat H_{B,03}$.\,. .\,.\,Right, so we could write
\begin{align}
\begin{aligned}
	e^{-i \hat H t} =&\, 
		\lim_{M_1 \to \infty} \lim_{M_2 \to \infty}
		\big(e^{-i \hat H_{12} t/M_1} 
			\big(e^{-i \hat H_{03} t/(M_1 M_2)} e^{-i \hat H' t/(M_1 M_2)}\big)^{M_2}
		\big)^{M_1}
	\\=&\, 
		\lim_{M_1 \to \infty} \lim_{M_2 \to \infty}
		\big(e^{-i \hat H_{12} \delta t_1} 
			\big(e^{-i \hat H_{03} \delta t_2)} e^{-i \hat H' \delta t_2)}\big)^{M_2}
		\big)^{M_1}
	\\=&\, 
		\lim_{M_1 \to \infty} \lim_{M_2 \to \infty}
		\big(e^{-i \hat H_{12} \delta t_1} 
			\big(e^{-i \hat H_{03} \delta t_2)} e^{-i \hat H' \delta t_2)} \hat I_{A_\mu} \big)^{M_2}
		\big)^{M_1}\,.\,.
\end{aligned}
\end{align}
%..Let me take a walk or bike ride and think about this some more..

%((Kl. tyve i fire))
\ldots\ Ah, I should use this argument, and I do not need to insert $\hat I_{A_\mu}$. The idea is then to argue that $\exp(-i \hat H_{12} \delta t_1)$ and $\exp(-i \hat H' \delta t_2)$ both leave the space of the $\tilde A_3$-wave solutions invariant. And then we might not even need to mention the thing about leaving the $\tilde A_0$ parts out in the beginning. We then note that.\,. .\,.\,Hm, maybe I \emph{should} let $V, \hat P_V = 0$ to begin with.\,. .\,.\,No, it might be better to just argue from $\exp(-i \hat H_{03} \delta t_2)$.\,. .\,.\,Oh wait, we might need another nested Trotter expansion.\,. 
.\,.\,Let's see, we have
\begin{align}
\begin{aligned}
	\hat H_{03} = 
		\sum_{\boldsymbol k, \sigma}\Big(
			\frac{1}{2\xi} \hat P^2_{0 k \sigma} +
			\frac{1}{2m} \hat P^2_{3 \boldsymbol k \sigma} +
			\sigma k \hat{A}_{3 \boldsymbol k -\sigma} \hat P_{0 \boldsymbol k \sigma} + 
			\sigma k \hat{A}_{0 \boldsymbol k -\sigma} \hat P_{3 \boldsymbol k \sigma} 
		\Big)
\end{aligned}
\end{align}
.\,.\,Yeah, so we should just divide this further into $\hat H_{ P_0}$ and $\hat H_{ P_3}$, namely with another (nested) Trotter expansion. And now we can quickly note that.\,. Well, let's see.\,. We have 
\begin{align}
\begin{aligned}
	\hat P_{3 \boldsymbol k \sigma} \psi(x)\,.\,.
\end{aligned}
\end{align}
.\,.\,Oh right, that's easy. We get
\begin{align}
\begin{aligned}
	\hat P_{3 \boldsymbol k \sigma} \psi(\boldsymbol{x}) = 
		\sigma\frac{q}{k}
		f_{\boldsymbol{k}\sigma}(\boldsymbol{x}) \psi(\boldsymbol{x})
\end{aligned}
\end{align}
.\,.\,Hm right, and then we get 
\begin{align}
\begin{aligned}
	\sum_{\boldsymbol k, \sigma} 
		\sigma k \hat{A}_{0 \boldsymbol k -\sigma} 
		\hat P_{3 \boldsymbol k \sigma} 
		\psi(\tilde A_\mu, \boldsymbol{x}) 
	= 
	\sum_{\boldsymbol k, \sigma}
		\tilde A_{0 \boldsymbol k -\sigma} 
		q f_{\boldsymbol{k}\sigma}(\boldsymbol{x}) 
		\psi(\tilde A_\mu, \boldsymbol{x})
	= 
	\,.\,.
\end{aligned}
\end{align}
No wait, I forgot the minus in $\tilde A_{3\boldsymbol{k}-\sigma}$ in  $\exp\big(
	i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma} 
	f_{\boldsymbol{k}\sigma}(\boldsymbol{x}) / k
\big)$, so instead we get
\begin{align}
\begin{aligned}
	\hat P_{3 \boldsymbol k \sigma} \psi(\tilde A_\mu, \boldsymbol{x}) = 
		-\sigma\frac{q}{k}
		f_{\boldsymbol{k}-\sigma}(\boldsymbol{x}) \psi(\tilde A_\mu, \boldsymbol{x}).
\end{aligned}
\end{align}
And then
\begin{align}
\begin{aligned}
	\sum_{\boldsymbol k, \sigma} 
		\sigma k \hat{A}_{0 \boldsymbol k -\sigma} 
		\hat P_{3 \boldsymbol k \sigma} 
		\psi(\tilde A_\mu, \boldsymbol{x}) 
	= 
	-q\sum_{\boldsymbol k, \sigma}
		\tilde A_{0 \boldsymbol k -\sigma} 
		f_{\boldsymbol{k} -\sigma}(\boldsymbol{x}) 
		\psi(\tilde A_\mu, \boldsymbol{x})
	= 
	-q A_0(\boldsymbol{x}) \psi(\tilde A_\mu, \boldsymbol{x})
	\label{=qV_01}
\end{aligned}
\end{align}
.\,.\,Hm, so we should actually probably group the $A_0$ part of $\hat H'$ together with $\hat H_{03}$, and maybe specifically with $\hat H_{P_0}$.\,.\,? %(Kl. 25 i fem.)

.\,.\,Yeah, so let me group them as $\hat H_{A_0}$ (where we also include the term with $A_0$ from $\hat H'$), $\hat H_{P_0}$ and then $\hat H_{P_3^2} = \sum_{\boldsymbol{k}\sigma} \hat P_{3\boldsymbol{k}\sigma}^2/(2m)$ on its own. .\,.\,Hm, but maybe I should first motivate this by calculating eq.\ (\ref{=qV_01}) first. Yes.\,. .\,.\,Hm, ah and then we should also have the necessary motivation to choose $\hat P_0 \psi = 0$.\,:) Nice.\,. .\,.\,``Because then we get
\begin{align}
\begin{aligned}
	\hat H_{03} \psi = -q V(\boldsymbol{x}) + something\ that\ leaves\ A_\mu\ invariant,
\end{aligned}
\end{align}
and the first term here will then just counter the $A_0$ energy coming from $\hat H'$.'' 
And then we see that the $\hat H_{P_3^2}$ energy will then be.\,. regne regne regne.\,. the Coulomb energy! .\,.\,Yes okay, and then I can finish the Trotter argument from there, I guess.\,. %(Kl. fem i fem.)

.\,.\,Ah no, I don't need to start the Trotter argument before I do this. I can just guess at $\tilde A_{3\boldsymbol{k}}$-dependency (and maybe link to an appendix where I check that solution (when looking only $\hat H'$ and with a constant $A_\mu$-field)), and then look at the $A_0\hat P_3$ term that then gives us the result of eq.\ (\ref{=qV_01}). This is then motivation to try with $\hat P_0 \psi = 0$. And to have all the terms accounted for, I should then immediately look at $\hat H_{P_3^2}\psi$ and note that it only adds a constant energy (when having only one particle) if the solution indeed works. And then I can do the multiple Trotter expansions and show that each of the partial propagators all leave the solution restrictions invariant. (And I then have all the motivation needed to just make the beneficial groupings (without further motivation).\,.) %(Kl. fem over fem.)

.\,.\,Ah, and I can just make use of the fact that if some $\hat O$ leaves some subspace invariant, then $\exp(-i\hat O t)$ will do the same for all $t$.\,:) .\,.\,Hm well, maybe I don't need a whole lot of Trotter, then, but I will just see about that in time.\,.

.\,.\,Hm, our $\hat P$s should by the way \emph{not} be bounded here, which should be totally fine if just everything else is.\,. 

%((Kl. tyve i syv.))
\ldots\ Hm, and when we want to go to higher fermion numbers, I guess $\hat{\boldsymbol p\,}\!$ should just be replaced by a (tensor) sum of each, and then I guess $\hat f_{\boldsymbol{k} \sigma}\psi(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em})$ should become 
%$f_{\boldsymbol{k} \sigma}({\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}}_1) 
%f_{\boldsymbol{k} \sigma}({\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}}_2) \cdots
%f_{\boldsymbol{k} \sigma}({\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}}_n)
%\psi(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em})$.\,. 
$f_{\boldsymbol{k} \sigma}({{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}}_1) 
f_{\boldsymbol{k} \sigma}({{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}}_2) \cdots
f_{\boldsymbol{k} \sigma}({{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}}_n)
\psi(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em})$.\,. 
.\,.\,Hm, or shouldn't this also be a sum, rather.\,.\,? .\,.\,Yes, it should of course be a sum. And then what should the factor of $\exp\big(
	i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma} 
	f_{\boldsymbol{k}\sigma}(\boldsymbol{x}) / k
\big)$ turn into.\,.\,? Hm, I guess that's where we should have the 
$f_{\boldsymbol{k} \sigma}({\boldsymbol{x}}_1) 
f_{\boldsymbol{k} \sigma}({\boldsymbol{x}}_2) \cdots
f_{\boldsymbol{k} \sigma}({\boldsymbol{x}}_n)$ product, then.\,. .\,.\,Wait no, shouldn't that also be a sum.\,.\,? .\,.\,Yes, also a sum. So it should be $\exp\big(
	i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma} 
	\sum_{j=1}^n f_{\boldsymbol{k}\sigma}(\boldsymbol{x}_j) / k
\big)$, then.\,. 

Because then we get
\begin{align}
\begin{aligned}
	&\,({\hat{\boldsymbol p\,}\!}_1 + {\hat{\boldsymbol p\,}\!}_2 + \ldots + {\hat{\boldsymbol p\,}\!}_n)
	\exp\Big(
		i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma} 
		\sum_{j=1}^n f_{\boldsymbol{k}\sigma}(\boldsymbol{x}_j) / k
	\Big) \\
	&= \sum_{\boldsymbol{k}, \sigma} \Big(
		q\frac{\boldsymbol{k}}{k}\sigma (-\sigma)
		\tilde A_{3\boldsymbol{k} -\sigma} 
		\sum_{j=1}^n f_{\boldsymbol{k} -\sigma}(\boldsymbol{x}_j)
	\Big)
	\exp\Big(
			i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma} 
			\sum_{j=1}^n f_{\boldsymbol{k}\sigma}(\boldsymbol{x}_j) / k
		\Big)
	\\
	&=-\sum_{\boldsymbol{k}, \sigma} \Big(
		q \boldsymbol{e}_{3\boldsymbol{k}}
		\tilde A_{3\boldsymbol{k} \sigma} 
		\sum_{j=1}^n f_{\boldsymbol{k} \sigma}(\boldsymbol{x}_j)
	\Big)
	\exp\Big(
			i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma} 
			\sum_{j=1}^n f_{\boldsymbol{k}\sigma}(\boldsymbol{x}_j) / k
		\Big).
\end{aligned}
\end{align}
And we could write this more neatly, if we also define 
$\bar f_{\boldsymbol{k} \sigma}(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}) = 
\sum_{j=1}^n f_{\boldsymbol{k} \sigma}(\boldsymbol{x}_j)$:
\begin{align}
\begin{aligned}
	&\, \sum_{j=1}^n ({\hat{\boldsymbol p\,}\!}_j)
	\exp\Big(
		i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma} 
		\bar f_{\boldsymbol{k} \sigma}(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}) / k
	\Big) \\
	&= \sum_{\boldsymbol{k}, \sigma} \Big(
		q\frac{\boldsymbol{k}}{k}\sigma (-\sigma)
		\tilde A_{3\boldsymbol{k} -\sigma} 
		\bar f_{\boldsymbol{k} \sigma}(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em})
	\Big)
	\exp\Big(
			i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma} 
			\bar f_{\boldsymbol{k} \sigma}(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}) / k
		\Big)
	\\
	&=-\sum_{\boldsymbol{k}, \sigma} \Big(
		q \boldsymbol{e}_{3\boldsymbol{k}}
		\tilde A_{3\boldsymbol{k} \sigma} 
		\bar f_{\boldsymbol{k} \sigma}(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em})
	\Big)
	\exp\Big(
			i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma} 
			\bar f_{\boldsymbol{k} \sigma}(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}) / k
		\Big).
\end{aligned}
\end{align}
(I could also consider using the big $\oplus$ notation instead of the first sum symbol, or I could of course find a new name for $\sum_{j=1}^n ({\hat{\boldsymbol p\,}\!}_j)$ (which would, however, not work so well if I use the bar notation.\,.).)

And we can also note that for several fermions, we have
\begin{align}
\begin{aligned}
	\hat P_{3 \boldsymbol k \sigma} 
	\psi(\tilde A_\mu, \bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}) = 
		-\sigma\frac{q}{k}
		\bar f_{\boldsymbol{k} -\sigma}(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}) 
		\psi(\tilde A_\mu, \bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}),
\end{aligned}
\end{align}
which gives us
\begin{align}
\begin{aligned}
	\sum_{\boldsymbol k, \sigma} 
		\sigma k \hat{A}_{0 \boldsymbol k -\sigma} 
		\hat P_{3 \boldsymbol k \sigma} 
		\psi(\tilde A_\mu, \bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}) 
	= 
	-q\sum_{\boldsymbol k, \sigma}
		\tilde A_{0 \boldsymbol k -\sigma} 
		\bar f_{\boldsymbol{k} -\sigma}(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}) 
		\psi(\tilde A_\mu, \bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em})
	= 
	-q \sum_{j=1}^n A_0(\boldsymbol{x}_j) 
	\psi(\tilde A_\mu, \bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}).
	\label{=qV_02}
\end{aligned}
\end{align}
%(Kl. halv otte.)

.\,.Hm, and the preceding derivation can also just by stating that when we change $\hat{\boldsymbol p\,}\!$ to $\sum_{j=1}^n ({\hat{\boldsymbol p\,}\!}_j)$ and $f_{\boldsymbol{k}\sigma}(\boldsymbol{x})$ to $\bar f_{\boldsymbol{k} \sigma}(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em})$ everywhere in the above (corresponding) single-particle derivations, then every step of the derivation will be exactly the same, except only for the last RHS of eq.\ (\ref{=qV_01}) (i.e.\ the single-particle version of eq.\ (\ref{=qV_02})), which will be identified with 
$-q \sum_{j=1}^n A_0(\boldsymbol{x}_j) 
\psi(\tilde A_\mu, \bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em})$ rather than 
$-q A_0(\boldsymbol{x}) \psi(\tilde A_\mu, \boldsymbol{x})$. Neat.\,:) %(Kl. tyve i otte.)

%..I should actually also consider the gammas more (and their tensor sum..) when I get back, but now I will take an evening break..

%((29.03.22))
Okay, let me just take a good look at what becomes of the $\gamma$s for multiple particles, and see if my above calculations are right.\,. .\,.\,Hm.\,. Yes, the calculation will be that simple, but I guess I should also argue for why the Hamiltonian I have in mind is the correct, Lorentz-invariant Dirac Hamiltonian for multiple particles.\,. .\,.\,Hm, it will probably be easy to see why (for a constant (classical-like) field) the direct sum (or what it should be called) will be Lorentz-invariant as well. But I'm a bit to tired now so let me just postpone that revelation. 

Let me instead look at the $\hat H_{P_3^2}$ energy.\,. .\,.\,Oh, by the way, I want to actually start using $\hat \Pi$ (again, sort of (.\,.\,as I recall, I for some reason also used $\hat P$ for $k$-space field momenta in my old notation, and only used $\hat \Pi$ for the $x$-space.\,.)) instead of $\hat P$ for the field/lattice momenta. 

Hm, we should have
\begin{align}
\begin{aligned}
	\hat \Pi_{3 \boldsymbol k \sigma}^2
	\psi(\tilde A_\mu, \bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}) = 
		\frac{q^2}{k^2}
		(\bar f_{\boldsymbol{k} -\sigma}(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}))^2
		\psi(\tilde A_\mu, \bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}).
\end{aligned}
\end{align}
Right, and then since 
$\bar f_{\boldsymbol{k} \sigma}(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}) = 
\sum_{j=1}^n f_{\boldsymbol{k} \sigma}(\boldsymbol{x}_j)$, 
we get the diagonal terms, which can be seen to each independent of $\boldsymbol{x}_j$ (since.\,.).\,. Hm, let me just check that.\,. .\,.\,Or rather, since we sum over $\boldsymbol{k},\sigma$, we get, what do we get.\,.\,? .\,.\,Ah, one can just use the idiot formula here (good thing it didn't take me very long to realize this\,;)). Yeah, so this will give a constant energy equal to $\sum_{\boldsymbol{k}} q^2/(2 m k^2)$. (And good thing, I have already at this point (at that time) argued that we can always throw away constant energies that only depend on the discretization parameters.) And then we will also get all the cross terms, which can be dived into pairs of 
$2
\big(\sin(\boldsymbol{k}\cdot\boldsymbol{x}_i) + 
\cos(\boldsymbol{k}\cdot \boldsymbol{x}_i)\big)
\big(\sin(\boldsymbol{k}\cdot\boldsymbol{x}_j) + 
\cos(\boldsymbol{k}\cdot \boldsymbol{x}_j)\big)$.\,. 
Hm, we should remember here that $\boldsymbol{k}\in \mathbb{R}_+\otimes\mathbb{R}^2$ for the summation.\,. .\,.\,Hm, should I maybe use the addition formula (which \emph{is} a good thing to have memorized!\textasciicircum\textasciicircum) here to reduce some of these terms.\,.\,? .\,.\,Hm, and I can then use the $\sin(v\pm u)$ (so not \emph{perfectly} memorized, but still.\,.\,;)) one for the cross terms here.\,. .\,.\,Oh, right this is exactly what one should do to then get the picture where the term only depends on the relative distance. And it should also be $\sin(v - u)$, by the way, which can be seen by replacing $v$ with $\pi/2 - v$ in (the easy-to-remember) $\cos(v - u) = \cos(v)\cos(u) + \sin(v)\sin(u)$.\,. No wait, rather in $\cos(v + u) = \cos(v)\cos(u) - \sin(v)\sin(u)$.\,. And do it with $u$ (i.e.\ $u\to \pi/2 - u$) instead.\,. (which then gives us $\sin(v - u) = \cos(v)\sin(u) -\,^*(no, +)\, \sin(v)\cos(u)$. *(Oh wait, no.\,. Ah, we \emph{should} do it with $v$ instead.\,. Cool, and then we'll get the expected answer.)) Okay. So we'll this way we can rewrite the cross terms as $2\cos(\boldsymbol{k}\,.\,.\,)$.\,.\, hm, let me just check that I don't also get a combination for each pairs of $\boldsymbol{k}$ as well.\,. .\,.\,Ah no, I don't. Fine. So we'll get 
$2\cos(\boldsymbol{k}\cdot (\boldsymbol{x}_i - \boldsymbol{x}_j)) + 
2\sin(\boldsymbol{k}\cdot (\boldsymbol{x}_i - \boldsymbol{x}_j))$.\,. .\,.\,Ah, and even though $k_1$ only runs over $\mathbb{R}_+$, $k_2$ and $k_3$ still.\,. no wait, that doesn't work.\,. .\,.\,Let us define $\boldsymbol{r}_{ij} = \boldsymbol{x}_i - \boldsymbol{x}_j$, by the way.\,. .\,.\,Hm, we could use the addition formula, saying $\sin(v + u) = \sin(v)\cos(u) - \cos(v)\sin(u)$, and then when summing over $k_2$ and $k_3$, only $\sum_{k_1} 2\sin(k_1 r_{ij1})$ will remain of $\sum_{\boldsymbol{k}}2\sin(\boldsymbol{k}\cdot \boldsymbol{r}_{ij})$.\,. .\,.\,Hm, but then I need to have that this sums to 0 as well, which would make this reduction redundant. .\,.\,Oh, wait! Just like I don't get any combinations of different $\boldsymbol{k}$s, then I should only have one $\sigma$ at a time, i.e.\ only one $\sigma$ in $(\bar f_{\boldsymbol{k} -\sigma}(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}))^2$. Good. .\,.\,Ah, and this will then simply remove $\sum_{\boldsymbol{k}}2\sin(\boldsymbol{k}\cdot \boldsymbol{r}_{ij})$ from the beginning and we will only have the desired $\sum_{\boldsymbol{k}}2\cos(\boldsymbol{k}\cdot \boldsymbol{r}_{ij})$ term.\,:) .\,.\,And with a symmetry argument, we can absorb the 2 and change the summation range to all of $\mathbb{R}^3$.\,.\,:) %(Kl. kvart over et.) 
.\,.\,And when the summation can be approximated with an integration, and when this is then integrated with $q^2/k^2$ it should give us the Coulomb energy for two charged particles with charge equal to $q$ (and a distance of $\boldsymbol{r}_{ij}$ between them).\,:) (.\,.\,We also need to have factor of $1/(2m)$ as well, where, again, $m$ is just the inverse volume the field is defined on.\,.)

And to finish off in this section, I should just then express what is left of $\hat H'$ in terms of the photonic ladder operators (since the $\tilde A_1$ and $\tilde A_2$ are the only parts left). .\,.\,I guess I should also use the free solutions to the Dirac equation as well to make is nicer (and in the way that i have previously shown).\,. \ldots Well, I guess we don't \emph{need} to do this at all, so I should actually just let that be for now.\,. .\,.\,Oh, never mind; we'll need it when we have to conjugate.\,. %..Hm, let me take a break..

\ldots\ Ah, but to write the reduced $\hat H'$ in terms of (only) ladder operators, we indeed just need to calculate the matrix element, so it should be easy (almost trivial for one particle, but let's see with multiple.\,.).\,.  Copied from above:
\begin{align}
	\hat H' \ket{\tilde A_\mu, \psi} = 
		\Big(
			\gamma^0 \boldsymbol \gamma \cdot \big(
				\hat{\boldsymbol p\,}\! - 
					\sum_{i=1}^{3} \sum_{\boldsymbol{k}, \sigma}
					q\boldsymbol{e}_{i\boldsymbol{k}} 
					\tilde A_{i\boldsymbol{k}\sigma}
					\hat f_{\boldsymbol{k}\sigma}
			\big) +
			\gamma^0 m + 
			\sum_{\boldsymbol{k}, \sigma}
			q\tilde A_{0\boldsymbol{k}\sigma}
			\hat f_{\boldsymbol{k}\sigma}
		\Big)
		\ket{\tilde A_\mu, \psi}.
\end{align}
(And then $\tilde A_0$ and $\tilde A_3$ are now removed.\,.) The matrix elements, which define the photon-lepton interaction in the momentum basis, are then given by
\begin{align}
	\bra{\tilde A_\mu, \bar\psi} 
		\sum_{i=1}^{2} \sum_{\boldsymbol{k}, \sigma}
		q(\gamma^0\boldsymbol\gamma \cdot \boldsymbol{e}_{i\boldsymbol{k}})
		\tilde A_{i\boldsymbol{k}\sigma}
		\hat f_{\boldsymbol{k}\sigma}
	\ket{\tilde A_\mu, \bar\psi}.
\end{align}
.\,.\,Hm, and we can also write
\begin{align}
	\bra{\tilde A_\mu, \bar\psi_{\bar{\boldsymbol{k}}'}} 
		\sum_{s=1}^{2} \sum_{\boldsymbol{k}, \sigma}
		q(\gamma^0\boldsymbol\gamma \cdot \boldsymbol{e}_{s\boldsymbol{k}})
		\tilde A_{s\boldsymbol{k}\sigma}
		\hat f_{\boldsymbol{k}\sigma}
	\ket{\tilde A_\mu, \bar\psi_{\bar{\boldsymbol{k}}}}.
\end{align}
.\,.\,Hm, and we should then change $\hat f_{\boldsymbol{k}\sigma}$ into complex exponential functions by changing $\boldsymbol{k}, \sigma$ to just $\boldsymbol{k}$, but with $\boldsymbol{k}\in \mathbb{R}^3$.\,. (And let me also change $i$ to $s$ in the above equation.\,.) .\,.\,Hm, $\hat f_{\boldsymbol{k}\sigma}$ adds
$\bar f_{\boldsymbol{k} \sigma}(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}) = 
\sum_{j=1}^n f_{\boldsymbol{k} \sigma}(\boldsymbol{x}_j)$, which can be rewritten as.\,.\,? .\,.\,Ah, but we should also rewrite the $\hat a_{s\boldsymbol{k}\sigma}$ ladder operators to the $\hat a_{s\boldsymbol{k}}$ ladder operators.\,. Okay, so for each $\boldsymbol{k}\in \mathbb{R}_+\otimes \mathbb{R}^2$ and each $s$, we get a contribution of
\begin{align}
	\bra{\tilde A_\mu, \bar\psi_{\bar{\boldsymbol{k}}'}} 
		q(\gamma^0\boldsymbol\gamma \cdot \boldsymbol{e}_{s\boldsymbol{k}})
		\frac{1}{\sqrt{2mk}} 
		\sum_{\sigma}
		(\hat a_{s\boldsymbol{k}\sigma}^\dagger + \hat a_{s\boldsymbol{k}\sigma})
		\hat f_{\boldsymbol{k}\sigma}
	\ket{\tilde A_\mu, \bar\psi_{\bar{\boldsymbol{k}}}}.
\end{align}
.\,.\,Hm, I should of course actually just keep the bra and ket out of it in the beginning, but how do I then go smoothly from here (without the ket and bra).\,.\,? .\,.\,I can by the way see from my old article that I want
\begin{align}
\begin{aligned}
	\hat a_{s\boldsymbol{k}+1} =&\, 
		\frac{1}{\sqrt{2}} (\hat a_{s\boldsymbol{k}} + a_{s-\boldsymbol{k}})
	\\
	\hat a_{s\boldsymbol{k}-1} =&\, 
		\frac{i}{\sqrt{2}} (\hat a_{s\boldsymbol{k}} - a_{s-\boldsymbol{k}}).
\end{aligned}
\end{align}
Hm, and so we should want
\begin{align}
\begin{aligned}
	\sum_{\sigma} (\hat a_{s\boldsymbol{k}\sigma}^\dagger + \hat a_{s\boldsymbol{k}\sigma}) =&\,
		\frac{1 - i}{\sqrt{2}}\hat a_{s\boldsymbol{k}}^\dagger +
		\frac{1 + i}{\sqrt{2}}\hat a_{s-\boldsymbol{k}}^\dagger +
		\frac{1 + i}{\sqrt{2}}\hat a_{s\boldsymbol{k}} +
		\frac{1 - i}{\sqrt{2}}\hat a_{s-\boldsymbol{k}}
	\\=&\,
		e^{-\pi/4}\,.\,.
\end{aligned}
\end{align}
Hm.\,. .\,.\,Oh right, we need to include the $f_{\pm\boldsymbol{k}}$s as well.\,. .\,.\,Hm, and I should probably use that for a specific.\,. Hm, should we introduce antisymmetry already, by the way.\,.\,? Well, if it makes it simpler somehow, then yes.\,. .\,.\,Hm, maybe it actually \emph{will} make it simpler, but let's see.\,. \ldots Hm no, maybe it actually does not make it simpler, since without it, we can just look at each contribution to the sum of $\bar f_{\boldsymbol{k} \sigma}(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em})$ separately.\,. And then there will only be one $\boldsymbol{k}\in \mathbb{R}_+\otimes \mathbb{R}^2$ that contributes to any matrix element between $\bar\psi_{\bar{\boldsymbol{k}}'}$ and $\bar\psi_{\bar{\boldsymbol{k}}}$. This allows us to look at just
\begin{align}
	q(\gamma^0\boldsymbol\gamma \cdot \boldsymbol{e}_{s\boldsymbol{k}})
	\frac{1}{\sqrt{2mk}} 
	\sum_{\sigma}
	(\hat a_{s\boldsymbol{k}\sigma}^\dagger + \hat a_{s\boldsymbol{k}\sigma})
	f_{\boldsymbol{k}\sigma}(\boldsymbol{x}_j),
\end{align}
where $j$ is the (only) index where $\bar{\boldsymbol{k}}'$ and $\bar{\boldsymbol{k}}$ differ, which the do with either $+\boldsymbol{k}$ or $-\boldsymbol{k}$ (i.e.\ the $\boldsymbol{k}$ that appears in this expression). Let is then rewrite
\begin{align}
\begin{aligned}
	\sum_{\sigma}
	(\hat a_{s\boldsymbol{k}\sigma}^\dagger + \hat a_{s\boldsymbol{k}\sigma})
	f_{\boldsymbol{k}\sigma}(\boldsymbol{x}_j)
	=&\,\,
	(\hat a_{s\boldsymbol{k}+1}^\dagger + \hat a_{s\boldsymbol{k}+1})
		\cos(\boldsymbol{k}\cdot\boldsymbol{x}_j) +
	(\hat a_{s\boldsymbol{k}-1}^\dagger + \hat a_{s\boldsymbol{k}-1}) 
		\sin(\boldsymbol{k}\cdot\boldsymbol{x}_j)
	\\=&\,\,
	\frac{1}{2}
	(\hat a_{s\boldsymbol{k}+1}^\dagger + \hat a_{s\boldsymbol{k}+1} - 
	i\hat a_{s\boldsymbol{k}-1}^\dagger - i\hat a_{s\boldsymbol{k}-1})
		e^{i\boldsymbol{k}\cdot\boldsymbol{x}_j} \,+
	\\\phantom{=}&\,\,
	\frac{1}{2}
	(\hat a_{s\boldsymbol{k}+1}^\dagger + \hat a_{s\boldsymbol{k}+1} + 
	i\hat a_{s\boldsymbol{k}-1}^\dagger + i\hat a_{s\boldsymbol{k}-1})
		e^{-i\boldsymbol{k}\cdot\boldsymbol{x}_j}
	\\=&\,\,
	\frac{1}{\sqrt{2}}
	(\hat a_{s\boldsymbol{k}} + \hat a_{s-\boldsymbol{k}}^\dagger)
		e^{i\boldsymbol{k}\cdot\boldsymbol{x}_j} +
	\frac{1}{\sqrt{2}}
	(\hat a_{s-\boldsymbol{k}} + \hat a_{s\boldsymbol{k}}^\dagger)
		e^{-i\boldsymbol{k}\cdot\boldsymbol{x}_j},
\end{aligned}
\end{align}
where we have introduced
\begin{align}
\begin{aligned}
	\hat a_{s\boldsymbol{k}} =&\, 
		\frac{1}{\sqrt{2}} (\hat a_{s\boldsymbol{k}+1} - i a_{s\boldsymbol{k}-1})
	\\
	\hat a_{s-\boldsymbol{k}} =&\, 
		\frac{1}{\sqrt{2}} (\hat a_{s\boldsymbol{k}+1} + i a_{s\boldsymbol{k}-1}),
\end{aligned}
\end{align}
which can by the way inverted (according for instance to my old article) to give
\begin{align}
\begin{aligned}
	\hat a_{s\boldsymbol{k}+1} =&\, 
		\frac{1}{\sqrt{2}} (\hat a_{s\boldsymbol{k}} + a_{s-\boldsymbol{k}})
	\\
	\hat a_{s\boldsymbol{k}-1} =&\, 
		\frac{i}{\sqrt{2}} (\hat a_{s\boldsymbol{k}} - a_{s-\boldsymbol{k}}).
\end{aligned}
\end{align}
And it should be noted that the way to tell these different variants apart is whether the have two or three subscripts. %(Kl. fire.)

And from here, we can quite easily obtain the desired Hamiltonian in terms of ladder operators.\,:) 






\subsection{The continuum limit, part 1}

%(Kl. kvart i et.) (Sov længe, til omkring elleve, og så har jeg gået lidt og tænkt over problemet her.)
(30.03.22) I almost think I know what to do, but it depends a bit on whether it makes sense to do an argument with the discretized path integral or if it makes.\,. well, more sense to do a, maybe heuristic, argument in the continuous case.\,. .\,.\,But it makes good sense to want to discuss the continuum limit once the (un-conjugated) Hamiltonian is derived since we can then conjecture its self-adjointness and use that to go to the continuum limit, which is by the way a simple enough matter to do. .\,.\,So how do I found out what to do with the $\square^2\varphi=0$ argument, I guess I should think for a bit more first.\,. .\,.\,Hm, and the overall argument for Lorentz invariance is first of all to use the proposition that the discretized proto-Hamiltonian becomes ``more and more Lorentz-invariant'' when the parameters tend towards their limits. And then the argument is, that a certain series of bounded proto-Hamiltonians will approximate the dynamics of $\hat H$ ``more a more.'' This shows Lorentz invariance, except for the fact that if the restrictions (of the GE solutions) are not Lorentz-invariant themselves, then it is not really a true Lorentz invariance, since the actual physics will then not be Lorentz-invariant, necessarily.\,. .\,.\,And then the argument that they \emph{are} Lorentz-invariant should be.\,.\,? .\,.\,Hm, the path integral will, in the scope of this article, only be defined as a limit of the discretized case, and thus the Lorentz transform will be the same.\,. .\,.\,Hm yeah, so the only real thing we can do, if we want the argument to be ``rigorizable,'' is to make the argument for the discrete case and then look at what happens in the limits.\,. .\,.\,But I can perhaps still skip the nitty-gritty parts of that treatment.\,. .\,.\,Hm, I should go ahead and look more into the argument now.\,. (I will name this section `part 1,' then, and then get back to it afterwards.\,.)


\subsection[square2varphi]{Working notes for the $\square^2\varphi=0$ argument}
.\,.\,Hm well, I \emph{should} actually probably just do a heuristic argument first, and then discuss how to make a rigorous proof afterwards.\,. \ldots Hm, it will by the way not be a difficult point of the rigorous proof to show that the Lorentz transform will have a well-defined limit, since it follows from.\,. .\,.\,Hm, doesn't it follow from the fact that $\lim(\hat U_v\exp(-i \hat H t') \hat U_v^{-1}) = \exp(-i \hat H t)$ for some discretized (unitary) boost operator $\hat U_v$.\,.\,? .\,.\,Hm yeah, this must imply that $\hat U_v$ converges in the limit(s).\,. .\,.\,Hm, I guess except if $U_v$ rotates some 0-energy states in a non-convergent way, but we should be able find ways to discount such states. So yeah, I think this will be a rather trivial matter for the rigorized proof.\,. .\,.\,Hm, or $U_v$ could also rotate degenerate states.\,.\,? Ah, but since the relation holds for all boosts $v$, then we can surely get rid of the degenerate states.\,. Oh well, it will surely not be any hard problem no matter what to show that the limit exists --- I even think there will be a proof using a more direct calculation to show this, which might also not be too hard to do. So moving on.\,. .\,.\,Oh, and what will it even matter if $U_v$ changes around some degenerate energy states.\,.\,? .\,.\,Hm, they absolutely won't, but.\,.\,? .\,.\,Let me just get back to that.\,.

.\,.\,Okay, so the heuristic argument is.\,.  .\,.\,Let us look at the paths with all $\tilde A_{3\boldsymbol{k}\sigma}$s and all $\tilde A_{0\boldsymbol{k}\sigma}$s equal to 0 at all time steps (so the remaining degrees of freedom are the photonic and the leptonic paths), and compare this set of paths to another one, with.\,. oh no, wait, we shouldn't require them to be 0 at all time steps: they should just be 0 at the initial point. And we want to then compare this with another set of paths with some arbitrary initial $\tilde A_{3\boldsymbol{k}\sigma}$s and $\tilde A_{0\boldsymbol{k}\sigma}$s.\,. 

.\,.\,So we will look at what happens, if we add a $\varphi$ with $\square^2\varphi = 0$ to the first set of paths such that they now also all starts out with the sets of $\tilde A_{3\boldsymbol{k}\sigma}$s of the second set.\,. Hm, I wonder if we should actually just let $\tilde A_{0}$ be free from the beginning, but let us see.\,. .\,.\,``Adding a $\varphi$'' to the paths means to add $\nabla \varphi$ to $\boldsymbol{A}$.\,. .\,.\,And it thus means to add $k\tilde\varphi_{\boldsymbol{k}\sigma}$ to $\tilde A_{3\boldsymbol{k}\sigma}$ for all $\boldsymbol{k},\sigma$. .\,.\,So far, so good, and then what does $\square^2\varphi = 0$ mean precisely?\,. .\,. .\,.\,Hm, it defines what we should add to all other paths at all points. Hm, but I should be going to $x$-space now, by the way.\,. (And this might be where the argument starts to become a little hard to do, if we are unlucky, meaning that it might be hard to carry out without the use of figures if we want it to be completely clear to everyone.\,.) .\,.\,Hm, or maybe we'll be fine.\,. .\,.We by the way need to transform to $x$-space to explain the Lorentz transform in and of itself, also.\,. 

.\,.\,Okay, so I need to first clarify what the Lorentz transform is, and here I need to discuss going to (discretized) $x$-space.\,. \ldots Hm no, it's not hard to explain or to imaging. We know very well how to go Fourier transform (discretely) to $x$-space, and then when considering the transform, we only need to describe taking a hyperplane and then do the path integration partly until we get to the edge of that (perhaps in both directions of time if the hyperplane intersects our initial one). And the prescription for our discretized $\hat U_v$, so to speak, is then also explained easily enough: we find a fitting way to resolve the (somewhat rugged) edges to $k$-waves of the field in the transformed inertial system and then just put the $\bar\psi(t, \bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em})$ with its values on the hyperplane on top for each ``field value'' of the the hyperplane, meaning each configuration of the the field ``step functions'' on said (rugged) edge.\,. Yeah, I can explain this a bit more clearly.\,. (.\,.\,I can probably explain it quite clearly, in fact.\,.)

And when getting on to what it then means to have $\square^2\varphi = 0$ in this discretized case.\,. Well that just means exactly that at all points in the discrete (t, x) lattice, we add.\,. well, actually, we add $k\tilde\varphi_{\boldsymbol{k}\sigma}(t)$ to $\tilde A_{3\boldsymbol{k}\sigma}$ for all $\boldsymbol{k},\sigma$ at each (discrete) $t$, which then gives us new values for each $(t, x)$ points in the $(t,x)$-space lattice. .\,.\,Hm, I guess then we note, first of all, that adding this $\varphi$, $\square^2\varphi = 0$, will not add to the Lagrangian for the normal, time-propagation path integrals.\,. .\,.\,Hm, I guess this reveals another question, how exactly do we define the path integrals in $x$-space; can we really just transition to taking the (discretized) derivatives instead, or what should we do.\,.\,? 

.\,.\,For if we want to make sense of the Lorentz transform we need to have the path integral defined completely in the $x$-space, right.\,.\,? .\,.\,Hm, but we can't even take the derivatives on the.\,. (rugged) edge, unless maybe we just approximate them with the differences to only one side, I guess (and make sure to only Lorentz transform the appropriate way), but that all seems a bit.\,. nasty.\,. 

.\,.\,Hm, there's a chance (a risk *(.\,.\,if you can say that in English.\,.)) that this might be a somewhat hard problem.\,. 

.\,.\,Hm, unless those derivatives to one side solve it (somehow).\,. %(Kl. 25 i fire.)

\ldots Hm, I wonder why I havn't thought more about this matter; have I already found an answer that just slips my mind now, or have I just somehow been able to glance over.\,. oh wait, I bet the answer lies in going to $(\omega, k)$-space, also.\,. Let's see.\,. %(Kl. kvart i fire.)

%(Kl. fem.)
\ldots\ Yeah, of course we should just define the (discretized) Lorentz transform from the $(\omega, \boldsymbol k)$-space path integral.\,. 

.\,.\,Alright, so with that in mind, we then need (going back to the $\square^2\varphi=0$ argument) to consider two sets of $(\omega, \boldsymbol{k})$-paths *(or maybe we should say $(\bar \omega, \bar{\boldsymbol{k}})$-paths) with two different initial values for the $\tilde A_{3\boldsymbol{k}\sigma}$s (and maybe the $\tilde A_{0\boldsymbol{k}\sigma}$s), and where for the first set, all the $\tilde A_{3\boldsymbol{k}\sigma}$s are equal to 0 initially. .\,.\,And adding $\varphi$, $\square^2\varphi=0$, then means to add to all the $(\omega=k, \boldsymbol{k})$ components of the $(\bar \omega, \bar{\boldsymbol{k}})$-paths.\,. .\,.\,Hm, this should be added to the $\tilde A_3$ field (right?\,.\,.), and then shouldn't we also add to the $\tilde A_0$ field?\,.\,. .\,.\,Hm yes, and we more precisely add $\cos(k t - \boldsymbol{k}\cdot\boldsymbol{x})$-/$\sin(k t - \boldsymbol{k}\cdot\boldsymbol{x})$-waves that sum to $\varphi$, which means that we add values of $k \cos(k t - \boldsymbol{k}\cdot\boldsymbol{x})$ and.\,. well, I guess we don't actually need any sine waves.\,. unless we want to also match a certain arbitrary $\tilde A_0$, I guess.\,. But yeah, we thus add $k \cos(k t - \boldsymbol{k}\cdot\boldsymbol{x})$ to the $\tilde A_{3\boldsymbol{k}\sigma}$s, and perhaps we also add some sine waves as well, if we want to also match the initial $\tilde A_0$ field of the arbitrary-initial-value set of paths.\,. .\,.\,Oh wait, it doesn't make sense to add $k \cos(k t - \boldsymbol{k}\cdot\boldsymbol{x})$ to $\tilde A_{3\boldsymbol{k}\sigma}$, so let's see.\,. .\,.\,Hm, I guess we should actually then use the addition formula on that cosine, which will then tell us what to add to $\tilde A_{3\boldsymbol{k}+1}$ and $\tilde A_{3\boldsymbol{k}-1}$ for each $t$.\,. %(Kl. 25 over fem.) 
(.\,.\,Namely $k\cos(kt)$ and $k\sin(kt)$, respectively, except for the fact that I also need to remember to differentiate this correctly, which I haven't.\,.) But anyway, what's next?\,.\,.

.\,.\,Hm, I should of course add choose a specific initial set of $\tilde A_{0\boldsymbol{k}\sigma}$s as well and then add the sine waves to match it.\,. 

.\,.\,Okay, and the point is then that this does not change the action of the Lorentz-transform path integral, which means that the new sets of paths (with $\varphi$ added) will then give the exact same transformation, only the appropriate final values are added to the $A_0$- and $A_3$-field coordinates of the transformed state.\,. .\,.\,And I guess the next step is then to use the fact that the Jacobian of adding said $\varphi$ (we we see it as a transformation) is 1 and therefore realize that adding said $\varphi$ just gives us exactly the paths we need to integrate over for our arbitrary-initial-value state. So the contributions to the transformed state coming from the set of states with the arbitrary $\tilde A_3$- and $\tilde A_0$-values to the Lorentz transformed (final) state is exactly the same as for the $\tilde A_0, \tilde A_3=0$ state, only with all $\tilde A_0$- and $\tilde A_3$-coordinates translated (i.e.\ with a constant field added).\,. 

(Hm, I think this is going decently well, so I actually think I will just repeat (a neater version of) this written argument in the article (and thus not try to do a lot of calculations for it, unless I realize some way that this can be done in a simple an clear way (i.e.\ that can help the argument without making it a whole lot longer)).)

.\,.\,Okay, and then the final part of the argument should then just be to see what this result implies for our GE solutions.\,. .\,.\,(Hm, I wonder if something like `separate gauge solution' or something like `gauge-eliminating [partial, separate] solution' would be good terms to call them, or.\,.)

%..Hm, lad mig lige tænke lidt over den sidste del af argumentet.. (Kl. fem over seks.)
%(Kl. 25 over seks.) Ja, løsningen herfra må jo bare være så at udregne, hvad disse cosinus- og sinus-bølger transformerer til (og her er det rart at det bare transforerer som \Lambda(\omega, k)), og ja, så argumentere ud fra dette.. ..Hm.. ..Nå, jeg har vist ramt lidt en mur, så jeg må hellere bare lige holde en ordenlig pause..

%(Kl. fem over otte.) Ha, jeg kom først i tanke om her lidt i otte, på vej hjem fra gåtur, at det jo er klart at regnestykket så så underligt/mistænkeligt ud: Jeg har jo helt glemt, at det hele handler om fermion-positionerne..!x) 
\ldots\ Ha, I only just realized now that I have completely forgot about the fermions and that the phase depends on their positions.\,x) .\,.\,Okay, I think it should make more sense now.\,. .\,.\,Yeah, it will work out now. .\,.\,Never mind the stuff earlier about not arguing from formulas, cause that is what I will do (once I have explained that we can look at the path integrals in $(\omega, k)$-space.\,.).\,. 

%...Hm, jeg tror faktisk lige, jeg bare vil vente til i morgen med at få disse formler rigtigt.. Måske vil jeg så bare nøjes med at læse lidt op på mit selvadjungerethedsargument i aften for lige at se lidt på, om det stadig giver god mening.. hvis jeg har energien til det.. *Det havde jeg ikke helt..

(31.03.22) Hm, so what we get as the final, transformed state will be an integral over starting points of the $\tilde A_{03}$ field of the contribution (to the transformed state) coming from $(\tilde A_0, \tilde A_3)=(0,0)$, call it $\chi$ (since I could use $\chi$s for full photon-fermion states if there is the need, which there might be here.\,.).\,. or $\chi_0$, rather.\,. .\,.\,Hm, and we might then use $\chi_\varphi$ to represent the state coming from the $(\tilde A_0, \tilde A_3)$ starting point that matches $(\partial_0 \varphi, \partial_3 \varphi)$.\,. (.\,.\,Maybe I should use $\alpha$ instead of $\varphi$, by the way, but I'll see about that.\,.) .\,.\,And I'll then argue that $\chi_\varphi = \exp\big(i\sum_j\varphi(t, \boldsymbol{x}_j) - \,.\,.\, \big)$.\,. Hm.\,. .\,.\,Hm, I guess the idea is that for all $\ket{\phi, \psi}$-states (i.e.\ the direct products (i.e.\ non-entangled states)) that make up $\chi_\varphi$ (meaning that $\chi_\varphi = \sum_i \ket{\phi_i, \psi_i}$), then.\,. Hm no, let's say that $\chi_0 = \sum_i \ket{\phi_i, \psi_i}$, and then it we get $\chi_\varphi = \sum_i \ket{\phi_i, \psi_i'}$, 
$\psi'_i(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}) = \exp(i\sum_j(\varphi(\boldsymbol{x}_j) - \varphi(\boldsymbol{x}'_j)))\psi_i(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em})$, or something to that extent.\,. .\,.\,Right, that's a good way to formulate it (when we fix it a bit).\,. 

.\,.\,And then we need to integrate over all $\varphi$, essentially.\,. .\,.\,Yeah, so I should probably show directly how the integral over the $A_{03}$-starting points becomes an expression that can then use this relation.\,. .\,.\,And what will thus be the points to finish up this argument.\,.\,? .\,.\,Hm, first of all that the phase factor coming from the initial state solution when integrating over $\tilde A_{03}$ will cancel one of these $\exp(i\sum_j\varphi(\boldsymbol{x}_j))$s.\,. .\,.\,And then we should have something like 
$\exp(i\varphi(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}))\psi_i(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em})$ left.\,. .\,.\,Hm, we should probably simplify, when we get to the actual calculation, and only look at one $(\boldsymbol{k},\sigma)$ for $\tilde A_0$ and $\tilde A_3$.\,. \ldots Hm, but the nice thing about using $\varphi$ directly in the argument is that we know how it transforms, and it transforms in a very simply way (i.e.\ as a scalar, so a trivial way, really).\,. .\,.\,But I could then just use $\varphi$ as an intermediary step to get the transformed $\tilde A_{03}$.\,. .\,.\,Yeah, we \emph{could} do that (since we do know that adding $\partial_\mu\varphi$ to $A_\mu$ simply means that $\Lambda_\mu^\nu\partial_\nu\varphi$ is then added to $\Lambda_\mu^\nu A_\nu$ in the transformed system).\,.

.\,.\,Okay, and that will then tell us that each.\,. $\chi_{\varphi_{\boldsymbol{k}\sigma}}$.\,. Hm.\,. Let me just think for a little bit.\,. .\,.\,Ah, now I just realized how I might use that strategy of trying to transform the final state first, argue that the spread results in a constant function and then transform back.\,. The idea is to use that $\varphi(x')$ adds to the $\tilde A_{3\boldsymbol{k}\sigma}$-coordinates and thereby gives an exponential factor depending on the amount that was \emph{added}.\,.\,:)\,.\,. %(Kl. 25 over elleve.) 
.\,.\,Hm, let me think about how this argument would then work.\,. .\,.\,Hm, it works if I show that transforming the final state will (until we transform back again) absorb the $\exp(i\varphi(\bar{\boldsymbol{x}\hspace{.05em}}\hspace{-.05em}))$ factor.\,. .\,.\,Hm, and we should argue this by noting how said transform can be seen to effectively change each path value.\,. %(Kl. halv tolv.)
\ldots Hm, so we should then argue that the exponential is absorbed and that the resulting state turns into the transformed $\chi_0$ I guess.\,. 

\ldots Hm, maybe I'm making it into something more complicated than it is.\,. The transformation should be seen, I think, to simply absorb the exponential and give $\chi_0$ exactly (right.\,.\,?).\,. Hm no, maybe I was on the right track before, at least about noting the $\varphi$ \emph{add} to the coordinates.\,. .\,.\,Oh, I might actually have been on exactly the right track; also noticing that it should match the transformed $\chi_0$.\,. .\,.\,Right, that should be my strategy.\,. 

.\,.\,Hm, let us look at an initial state written as $\ket{\tilde A_{03}, \tilde A_{12}, \psi}$ and look at the path into a final (Lorentz-transformed) state $\ket{\tilde A_{03}', \tilde A_{12}', \psi'}$. .\,.\,We can then find a $\varphi$, $\square^2\varphi=0$, such that $\tilde A_{03} = (\partial_0 \varphi, \partial_3 \varphi)$.\,. no, that's not right.\,. .\,.\,But I know what I mean.\,. .\,.\,Hm, let me think for a bit, before I write a whole bunch of stuff.\,. 

.\,.\,Ah, I should just go back and note that when we transform the final state (temporarily), then this is the same as changing each $\chi_\varphi$ with a factor of $\exp(i\,\ldots)$, where the $\ldots$ here stand for an expression that depends on the $\tilde A_3$ coordinates. And then the idea is to note how.\,. .\,.\,Ah, it helps to then divide $\chi_\varphi$ further into eigenstates *(.\,.\,or single-coordinate states, we might call them.\,.) of the $\tilde A_{03}$ field first.\,. .\,.\,And the transformation can then be seen as equivalent of giving each of these contributions an added phase corresponding to their $\tilde A_{3}$-values, which are then useful to write as $\tilde A_{3,0} + \tilde A_{3,\varphi}$ (excuse the confusing notation for now.\,.), where we have also noted that.\,. Hm.\,. %(Kl. 25 over tolv.)
.\,.\,Hm, I get my point here, and I'm sure it will work nicely, but how exactly do I make it nice.\,.\,? %..Hm, maybe I should just go for a walk, while there's some snow left, and think about this.. ..Hm, in a moment, but let me just think for a bit more here, and also finish my coffee first.. ..Hm, I bet there's not a whole lot more to it than this, if I can just make a clear argument that \tilde A_{3,0} here matches that of the corresponding constribution to \chi_0.. ..Okay, let me walk on it..:)

%(Kl. fem i tre.)
\ldots\ Okay, the solution will just be to express the relation of $\chi_\varphi$ to $\chi_0$ mathematically, and then we can indeed see that the exponential factor will be consumed when we transform. 

It is by the way amazing how close I feel to be able to write the article. I almost feel like actually just start doing that more or less immediately and then just return here whenever there is some detail that should be cleared up. I even kinda feel like stopping this section already, since I will easily be able to pick this up, when I get to it. (I could then just return to this document and work out a neat version of the argument when I get to this section (about the continuum limit \emph{and} Lorentz invariance) when writing the article.) But I should probably make sure to go through the last path integral equations first, and more importantly, I should definitely also take a look again on my self-adjointness argument and check that it still makes sense --- and maybe see if I want to try to verify it further.\,. .\,.\,I could also do some calculations on the Dyson expansion, but again: I can always just return here from time to time to do some more working notes before working out the actual section (or section parts).\,:) .\,.\,Hm, maybe I will even just only do the self-adjointness checking first and just return here already when I get to the path integral section to do some more working notes in this document.\,:)\,.\,. .\,.\,Because I think it will be rewarding to start getting an increased sense of approaching the goal that I think will come when starting to get things done on the actual article.\,.\,:) .\,.\,Hm, I guess I \emph{should} make sure to check that I have the right $m$, and that the $(\omega, \boldsymbol{k})$-path integral looks right in terms of the proposition that the errors between to similar paths as seen in two different inertial systems will vanish at a sufficient rate in the limits.\,. But I could of course just make sure to return to this agian soon, namely when I write the path integral section.\,. .\,.\,I will then, by the way, make a new chapter below where I will then do working notes \emph{while} I'm working on writing the article (which I will start a new document for (.\,.\,named \texttt{draft0.tex}, I think.\,.)). 

.\,.\,Okay, so let me just dedicate the rest of this day to going through the self-adjointness argument again, and maybe also.\,. oh wait, I forgot something else. I should also make sure I know how the argument for the Lorentz invariance of the GE solutions is completed. Yeah, let me look at that before anything else.\,. %(Kl. halv fire.)

%(Kl. 25 over fem.)
\ldots\ Okay, I don't think it will be hard for me to explain why the GE solutions must be Lorentz-invariant.\,. .\,.\,No, it will be fine.\,. 

.\,.\,Hm, and I'm sure my argument for the errors of the $(\omega, \boldsymbol{k})$-paths will work, cause one \emph{should} be able to argue that we can let $\delta t$ and $\delta k$ (and other relevant limits) approach 0 (or infinity for others) together, so to speak.\,. So yeah, let me just look at the self-adjointness for the rest of today and then start fresh on writing the first sections of the zeroth draft (while I will try not to use too much time on specific formulations, since I still might need to change things up if I discover that something does not work) tomorrow.\,:) %(Kl. 25 i seks.)

%((01.04.22))
.\,.\,Okay, I didn't really get much done about checking the self-adjointness argument, so I'll just wait to I get to that section, which is just right after the Dyson-and-conjugation section.\,. So I will start a new chapter now in which I will calculate the things I have left, but do it as I am writing the zeroth draft. 

.\,.\,Oh wait, before i start the draft, I just got this idea: Is their any change that the proto-Hamiltonian is self-adjoint? %(Kl. 25 over elleve.)
Not that we need it to be, but if there is an easy answer, it would be nice to realize that, just in case.\,. \ldots Hm no, there are some things about it, that are not nice: I think there will be infinite energies that are hard to cure, so to speak, when going to the continuum limit. So never mind that. 



\chapter{Working notes while I am writing the first/zeroth draft}

\section{Notes while writing `Deriving the initial Hamiltonian'}
%(01.04.22) (Kl. kvart over fem.)
Hm, I wonder how it would look if we index with $\sigma = 1$ instead of $\sigma = +1$ for the cosine parts.\,.
\begin{align}
\begin{aligned}
	\sum_{\sigma}
	(\hat a_{s\boldsymbol{k}\sigma}^\dagger + \hat a_{s\boldsymbol{k}\sigma})
	f_{\boldsymbol{k}\sigma}(\boldsymbol{x}_j)
	=&\,\,
	(\hat a_{s\boldsymbol{k}1}^\dagger + \hat a_{s\boldsymbol{k}1})
		\cos(\boldsymbol{k}\cdot\boldsymbol{x}_j) +
	(\hat a_{s\boldsymbol{k}-1}^\dagger + \hat a_{s\boldsymbol{k}-1}) 
		\sin(\boldsymbol{k}\cdot\boldsymbol{x}_j)
	\\=&\,\,
	\frac{1}{2}
	(\hat a_{s\boldsymbol{k}1}^\dagger + \hat a_{s\boldsymbol{k}1} - 
	i\hat a_{s\boldsymbol{k}-1}^\dagger - i\hat a_{s\boldsymbol{k}-1})
		e^{i\boldsymbol{k}\cdot\boldsymbol{x}_j} \,+
	\\\phantom{=}&\,\,
	\frac{1}{2}
	(\hat a_{s\boldsymbol{k}1}^\dagger + \hat a_{s\boldsymbol{k}1} + 
	i\hat a_{s\boldsymbol{k}-1}^\dagger + i\hat a_{s\boldsymbol{k}-1})
		e^{-i\boldsymbol{k}\cdot\boldsymbol{x}_j}
	\\=&\,\,
	\frac{1}{\sqrt{2}}
	(\hat a_{s\boldsymbol{k}} + \hat a_{s-\boldsymbol{k}}^\dagger)
		e^{i\boldsymbol{k}\cdot\boldsymbol{x}_j} +
	\frac{1}{\sqrt{2}}
	(\hat a_{s-\boldsymbol{k}} + \hat a_{s\boldsymbol{k}}^\dagger)
		e^{-i\boldsymbol{k}\cdot\boldsymbol{x}_j},
\end{aligned}
\end{align}
\begin{align}
\begin{aligned}
	\hat a_{s\boldsymbol{k}} =&\, 
		\frac{1}{\sqrt{2}} (\hat a_{s\boldsymbol{k}1} - i a_{s\boldsymbol{k}-1})
	\\
	\hat a_{s-\boldsymbol{k}} =&\, 
		\frac{1}{\sqrt{2}} (\hat a_{s\boldsymbol{k}1} + i a_{s\boldsymbol{k}-1}),
\end{aligned}
\end{align}
\begin{align}
\begin{aligned}
	\hat a_{s\boldsymbol{k}1} =&\, 
		\frac{1}{\sqrt{2}} (\hat a_{s\boldsymbol{k}} + a_{s-\boldsymbol{k}})
	\\
	\hat a_{s\boldsymbol{k}-1} =&\, 
		\frac{i}{\sqrt{2}} (\hat a_{s\boldsymbol{k}} - a_{s-\boldsymbol{k}}).
\end{aligned}
\end{align}
Hm, maybe I actually prefer $+1$, then.\,. 


\ \\\\\\\\
\indent(02.04.22) Hm, I should have had
\begin{align}
\begin{aligned}
	\bra{\boldsymbol{q}_2, \psi_{j_2}} e^{-i \hat H \delta t} \ket{\boldsymbol{q}_1 , \psi_{j_1}} 
	=&\,
		(2\pi)^{-N/2}
		\int d \boldsymbol{p}\, 
		e^{i \boldsymbol{p} \cdot \boldsymbol{q}_2 \delta t - 
			i H_B(\boldsymbol{p}, \boldsymbol{q}_1) \delta t}
		\braket{\boldsymbol{p} | \boldsymbol{q}_1}
		\bra{\psi_{j_2}}  e^{-i \hat H'_F(\boldsymbol{q}_1) \delta t} \ket{\psi_{j_1}}
		+ O(\delta t^2)
	\\=&\,
		(2\pi)^{-N}
		\int d \boldsymbol{p}\, 
		e^{i \boldsymbol{p} \cdot \dot{\boldsymbol{q}}_1 \delta t - 
			i H_B(\boldsymbol{p}, \boldsymbol{q}_1) \delta t}
		\bra{\psi_{j_2}}  e^{-i \hat H'_F(\boldsymbol{q}_1) \delta t} \ket{\psi_{j_1}}
		+ O(\delta t^2)
\end{aligned}
\end{align} 
instead of 
\begin{align}
\begin{aligned}
	\bra{\boldsymbol{q}_2, \psi_{j_2}} e^{-i \hat H \delta t} \ket{\boldsymbol{q}_1 , \psi_{j_1}} 
	=&\,
		(2\pi)^{-N/2}
		\int d \boldsymbol{p}\, 
		e^{i \boldsymbol{p} \cdot \boldsymbol{q}_2 - i H_B(\boldsymbol{p}, \boldsymbol{q}_1)}
		\braket{\boldsymbol{p} | \boldsymbol{q}_1}
		\bra{\psi_{j_2}}  e^{-i \hat H'_F(\boldsymbol{q}_1) \delta t} \ket{\psi_{j_1}}
		+ O(\delta t^2)
	\\=&\,
		(2\pi)^{-N}
		\int d \boldsymbol{p}\, 
		e^{i \boldsymbol{p} \cdot \dot{\boldsymbol{q}}_1 - i H_B(\boldsymbol{p}, \boldsymbol{q}_1)}
		\bra{\psi_{j_2}}  e^{-i \hat H'_F(\boldsymbol{q}_1) \delta t} \ket{\psi_{j_1}}
		+ O(\delta t^2)
\end{aligned}
\end{align} 
above.\,.

With $\tilde m$ included, this will give me the right result.\,. 
.\,.\,Though I should put $\exp(-i \hat H \delta t)$ in the matrix element on the left in
\begin{align}
\begin{aligned}
	\bra{\boldsymbol{q}_2, \psi_{j_2}} e^{-i \hat H \delta t} \ket{\boldsymbol{q}_1 , \psi_{j_1}} 
	=&\,
		\int d \boldsymbol{p}\, 
		\braket{\boldsymbol{q}_2, \psi_{j_2} | \boldsymbol{p}, \psi_{j_2}} 
		\bra{\boldsymbol{p}, \psi_{j_2}}  e^{-i \hat H \delta t} \ket{\boldsymbol{q}_1, \psi_{j_1}} 
	\\=&\,
		(2\pi)^{-N/2}
		\int d \boldsymbol{p}\, 
		e^{i \boldsymbol{p} \cdot \boldsymbol{q}_2}
		\bra{\boldsymbol{p}, \psi_{j_2}}  e^{-i \hat H \delta t} \ket{\boldsymbol{q}_1, \psi_{j_1}}
\end{aligned}
\end{align} 
instead, since that should give me 
$\dot{\boldsymbol{q}}_m = (\boldsymbol{q}_{m} - \boldsymbol{q}_{m-1}) / \delta t$
instead of
$\dot{\boldsymbol{q}}_m = (\boldsymbol{q}_{m+1} - \boldsymbol{q}_{m}) / \delta t$ (which is more common to see.\,.).

%(Kl. halv et.)
Hm, I actually think I will start to name $\hat C$ as $\hat J$ instead.\,. 
.\,.\,Hm, even though that is a bit confusing if one then associates $J$ with a charge/particle current.\,. .\,.\,Hm.\,. .\,.\,$\mathcal{J}$.\,. .\,.\,$\hat{\mathcal{J}}$.\,. .\,.\,No.\,. .\,.\,Ah wait, one could see $C$ as standing for current.\,. Hm.\,. .\,.\,Hm, maybe I am actually just going back to $C$; it is only confusable with `constant,' which is not as bad as confusing it with a particle current --- and also it is kind of nice to finally have it sort of standing for somethng.\,. Hm, or do I just want to use $F$ perhaps instead.\,.\,? .\,.\,No, that clashes with $H_F$, so no way.\,. Okay, whatever, let me just use $C$ like I am used to.\,. .\,.\,Yeah, because I don't know of any classical physical system where $J$ is in play that way anyway, and using $J$ because of its relation to current would actually then be bad. There is the fact that $J$ seems to appear a lot for the Gausssian integration, but.\,. .\,.\,No, let me just keep to my good old $C$ (and it only appears in a few lines in the main body of the article anyway). 


%(Kl. tyve i tre.)
\ldots\ Hm, how on earth have I not realized before that the Cartesian product is written as $A \times B$ and not $A \otimes B$.\,.\,?\,? \ldots Ha!


%(Kl. tyve over seks.)
\ldots\ Hm, I feel like I have still a few things to consider in order to choose the right heuristic derivation of the path integral and so on. And now I just got a new idea: How about making bounds $\boldsymbol{q}$ but not discetize it, and then keep $\boldsymbol{p}$ unbounded, but discretize it!\,.\,. In other words this will be like assuming periodic boundary conditions for $\boldsymbol{q}$. I think this might be very nice, if I wanna make sure I can do the GE section without going to the continuum limit.\,. .\,.\,And for the careful derivation, we can just discetize $\boldsymbol{q}$ also (and thus also make $\boldsymbol{p}$ bounded).\,. .\,.\,Hm, and we \emph{can} raise the bounds on $\boldsymbol{p}$ (while keeping it discrete, however) already at the end of the path integral derivation when $\boldsymbol{q}$ is assumed bounded.\,. .\,.\,Oh, but then then the Hamiltonian.\,. wait.\,. .\,.\,No, we will not at all get a nice proto-Hamiltonian, then.\,. .\,.\,Hm, is there a clean GE solution when $C$ is bounded (probably not, but let's see.\,.)?\,.\,. .\,.\,Hm, but we \emph{will} then have the same bounds on $\boldsymbol{q}$ for the Dirac Hamiltonian.\,. 
.\,.\,Hm, no.\,. There is no way that it's possible to extend the solutions to a bounded $\boldsymbol{q}$.\,. \ldots Oh wait, I start with the Hamiltonian, so I \emph{will} of course get a neat expression for that. Yeah, of course, and then we only need to obtain something that approaches the right Lagrangian in the limit. So I \emph{could} assume such periodic boundary conditions.\,. .\,.\,And I can just put bounds both the potential terms and on $\hat p$ (or $\hat \Pi$, rather.\,.) on the same time, simply by factoring them all with a (very broad) step function.\,. .\,.\,Hm, that will then give nice conditions for the GE section, but it will make the Gaussian integration look ugly, most likely.\,. (.\,.\,?) %(Kl. ti i seks.)
.\,.\,Hm, or is it just equivalent of discretizing $\boldsymbol{p}$, in which case it won't look so bad.\,.\,? .\,.\,Oh right, it should be the same. Fine.\,. .\,.\,Well, then that should definitely be my approach, right.\,.\,? .\,.\,Yeah, and as mentioned, we can just put temporary bounds on $\boldsymbol{p}$ as well (and discretize $\boldsymbol{q}$) and then just lift them straightaway after the path integral derivation.\,:)\,.\,.  

\ldots Oh, wait.\,. .\,.\,No, factoring on a (broad) step function might not.\,. .\,.\,No, it \emph{is} not the same as just discretizing $\hat{p}$ (/ $\hat \Pi$).\,. .\,.\,Hm, but for wave functions confined to that bounded space of $\boldsymbol{q}$-values, it is.\,. .\,.\,Which is all we need, okay! Then the approach should work out.\,. %(Kl. kvart over syv.)
.\,.\,Oh right, this is actually quite trivial; I only got a bit off-track when I started thinking about factoring on a step function, instead of just restricting $\hat p$ like I'm used to when thinking about it.\,.


%(Kl. halv otte.)
\ldots\ Okay, let me try to do text for the heuristic derivation here, and then I can always copy-paste if something of this turns out to be reusable for the article.

I will assume that I have just written something like: 
\textit{But luckily, we can just assume $V(\boldsymbol{q})$, $\boldsymbol{C}(\boldsymbol{q})$ and $\hat H_F(\boldsymbol{q})$ to all be bounded for now and then raise these bounds again at a later time, as we will see. In appendix ?? we discuss why such bounds are sufficient restrictions for making $\hat H$ self-adjoint.}
\noindent And if I need something else than this, then I will just say so as we go along. Here goes:

I will now do a heuristic derivation of the path integral and in A.something, I will show a more careful version.

The idea follows many %other *(d'oh..)
textbooks\ldots\ For this heuristic derivation, let us allow ourselves to make use of the virtual states $\ket{\boldsymbol{q}}$ and $\ket{\boldsymbol{p}}$, where 
%$\int \ket{\boldsymbol{q}}\bra{\boldsymbol{q}} = 
%\int \ket{\boldsymbol{p}}\bra{\boldsymbol{p}} = \hat I$ is the identity operator, 
$\int d\boldsymbol{q}\, \ket{\boldsymbol{q}}\bra{\boldsymbol{q}}$ and 
$\int d\boldsymbol{p}\, \ket{\boldsymbol{p}}\bra{\boldsymbol{p}}$ both equal the identity operator, $\hat I$, 
and where $\braket{\boldsymbol{q} | \boldsymbol{p}} = (2\pi)^{-1/2} \exp(i \boldsymbol{q} \cdot \boldsymbol{p})$.\footnote{
	Another normalization of these virtual states that is common to see in literature is to choose $(2\pi)^{-1} \int d\boldsymbol{p}\, \ket{\boldsymbol{p}}\bra{\boldsymbol{p}} = \hat I$ and then have $\braket{\boldsymbol{q} | \boldsymbol{p}} = \exp(i \boldsymbol{q} \cdot \boldsymbol{p})$. Choosing between the two is a matter of preference. %Hm, couldn't I actually use the other normalization just fine. The problem was that I thought it would fit the appendix derivation better, but maybe I could just normalize those states in a similar way..? ..Hm, nah.. This is the more natural way for that derivation and for consistency I will then just use the same kind of normalization here..
}
These two sets of states then each form a virtual basis for $\textbf{H}_B$. 

\ldots Hm, but don't I want to have a very explicit assumption for $\hat p$'s restriction before I go anywhere (since I will need it later as well.\,.).\,.\,? 

%(Kl. 25 i tolv.)
(03.04.22) Okay, I feel like I did a step backwards last evening with that attempt; I had some more insights that I kinda forgot again. But last evening, after I stopped writing, I had some more insights. I for instance found out that I technically don't have to put $\exp(-i\hat H_1 \delta t)$ and $\exp(-i\hat H_2 \delta t)$ in the two different matrix elements, so I don't even have to get the two versions of $\dot q$. Except, there is a problem that I found out in bed before rising, and that is that the kinetic Dirac energy does not commute with the Dirac potential terms at all and that means we cannot actually split it up into two!\,. I have though some more this noon, and now I think that I can just make $\hat H_B$ completely bounded, and then use.\,. oh wait, no.\,. I should probably make.\,. hm, wait a minute.\,. .\,.\,Can I leave the kinetic Dirac energy unbounded, or should it be bounded too somehow?\,.\,. .\,.\,Oh, I think I \emph{can} leave it unbounded.\,. .\,.Yeah, that should work, and then I actually think i will just use the $O(\delta t^2)$ argument for the (bounded) $\hat H_B$.\,:)\,.\,. .\,.\,Hm, or I guess one could actually argument via Trotter that the relevant error will be negligible.\,. .\,.\,Yes, that should also work (and is probably easier, at least when making a rigorous version *(but the $O(\delta t^2)$ argument \emph{can} also be made rigorous, is the point)).\,. And then I also thought last evening/night, that I should just make the heuristic version straightaway, before we consider curing the non-self-adjointness and so on (and then I can just explain how to change the derivation --- and refer to an appendix).\,. 

.\,.\,Oh, and the point is still that $\hat p$ should only be bounded for the duration of the path integral derivation; it should be kept unbounded in the actual ``initial Hamiltonian.'' 

.\,.\,Hm, maybe the $O(\delta t^2)$ argument actually is the easier one.\,. 


\ldots Okay, let me actually try to do the heuristic derivation.\,. .\,.\,Oh, let me actually just try to do it in the \texttt{draft0} document directly, why not?\,. %(Kl. 25 over tolv.)

%(Kl. tyve over fem.)
\ldots\ I just found out that I can probably just use Trotter initially to separate $\hat H_B$ and $\hat H'$ and then use Trotter once again to argue that the $T_m$s must converge to the same, even if we split it in two.\,.\,!\,\texttt{:D} .\,.\,Let me just think a bit more on a few details.\,. %..Hm no, actually I just need a bit more of a break..

%(Kl. 25 over tolv.)
(04.04.22) Oh, it is customary to use $\otimes$ rather than $\times$, oops. It's just called the `tensor product' rather than `direct product.' Hall has an appendix about it. But $\otimes$ is then just an abstraction over, what one might implement with a Cartesian product in practice (and also with appropriate extensions of the standard vector operations), so using the Cartesian product is not wrong, exactly.\,. I think mathematicians would call it ``choosing a basis'' for $V\otimes W$, even though this actually, the way I see, builds on an intuitionistic interpretation of mathematics.\,. 

%(Kl. tyve i et.)
\ldots I have been thinking this noon and midday about the fact that it might be a bit of a shame to essentially only show that the path integral formulation works when putting bounds on $\hat p$ (which is what I intended to use for the $O(\delta t^2)$ argument), even though we must be able to show that it works for an unbounded $\hat p$.\,. Hm, I think I am on the track now towards an easy argument that it will hold for an unbounded $\hat p$ also, but let me just think a bit more, actually.\,. .\,.\,Hm, when putting bounds on $\boldsymbol{q}$ for the integral, the argument should be pretty easy, and yeah, we \emph{can} do that.\,. .\,.\,Okay, well then that's just it.\,.  .\,.\,And those bounds do not have to match the bounds on the potentials, that's a quite important thing to note. The bounds on $\boldsymbol{q}$ for the path integral is just chosen for the specific path integral and just the higher the bounds, the higher the precision for a certain starting point vector. .\,.\,Yeah, and I should just be able to mention this afterwards, right.\,.\,? .\,.\,Hm, what is the best structure for the derivation (and on from there), then.\,.\,? .\,.\,Hm, shouldn't I then just actually use the $O(\delta t^2)$ argument tentatively og $\hat H_B$, even though $\hat p$ is not assumed bounded, and then I will just refer to the appendix to clear up this matter (which will also clear up why we can exchange $\int d\boldsymbol{p}$ with $\lim_{A \to \infty} \int_{-A}^{A} d\boldsymbol{p}$).\,. .\,.\,Yes, good.(!)\,:)


(05.04.22) (Kl. ti over et.) I have just been thinking about some things today until now. I can get back to what else I have though of, but let me just say that I have just realized that you can add a $\sum \tilde{A}_{0\boldsymbol{k}\sigma}^2$ term to the Hamiltonian and still solve it (partially)! The reason I have thought about this, is that I have had the idea that adding $\sum \tilde{A}_{0\boldsymbol{k}\sigma}^2$ and $\sum \tilde{A}_{3\boldsymbol{k}\sigma}^2$ term could be another way to ensure self-adjointness of the initial Hamiltonian (or the ``proto-Hamiltonian'' as I have called it). So let me now think about if I can still solve it when adding the $\sum \tilde{A}_{3\boldsymbol{k}\sigma}^2$ term.\,. (.\,.\,I am looking at page 82 above, btw.)
.\,.\,Oh! In fact, the solution might only work exactly if we also include a 
$\sum \tilde{A}_{3\boldsymbol{k}\sigma}^2$ term!\,\texttt{:D} %(Kl. tyve over et.)

.\,.\,Okay, let us see.\,. If we add a factor of %...Hm no, they should have opposite sigmas..
\begin{align}
\begin{aligned}
%	\hat{\boldsymbol p\,}\! 
	\exp\Big(
		i a \sum_{\boldsymbol{k}, \sigma} %\sigma 
		\tilde A_{0\boldsymbol{k}\sigma} 
		\tilde A_{3\boldsymbol{k}-\sigma} 
%		f_{\boldsymbol{k}\sigma}(\boldsymbol{x}) / k
	\Big)
\end{aligned}
\end{align}
to the solution, then will get additional terms of
\begin{align}
\begin{aligned}
	\frac{1}{2\xi} \hat \Pi_{0\boldsymbol{k}\sigma}^2 
	\exp\Big(
		i a \sum_{\boldsymbol{k}, \sigma} %\sigma 
		\tilde A_{0\boldsymbol{k}\sigma} 
		\tilde A_{3\boldsymbol{k}-\sigma} 
	\Big) =&\,
	\frac{-a^2}{2\xi} \tilde A_{3\boldsymbol{k}-\sigma}^2 
	\exp\Big(
		i a \sum_{\boldsymbol{k}, \sigma} %\sigma 
		\tilde A_{0\boldsymbol{k}\sigma} 
		\tilde A_{3\boldsymbol{k}-\sigma} 
	\Big), \\
	\frac{1}{2\tilde m} \hat \Pi_{3\boldsymbol{k}-\sigma}^2 
	\exp\Big(
		i a \sum_{\boldsymbol{k}, \sigma} %\sigma 
		\tilde A_{0\boldsymbol{k}\sigma} 
		\tilde A_{3\boldsymbol{k}-\sigma} 
	\Big) =&\,
	\frac{-a^2}{2\tilde m} \tilde A_{0\boldsymbol{k}\sigma}^2 
	\exp\Big(
		i a \sum_{\boldsymbol{k}, \sigma} %\sigma 
		\tilde A_{0\boldsymbol{k}\sigma} 
		\tilde A_{3\boldsymbol{k}-\sigma} 
	\Big) \\
	\sigma k \hat{A}_{3 \boldsymbol k -\sigma} \hat P_{0 \boldsymbol k \sigma} 
	\exp\Big(
		i a \sum_{\boldsymbol{k}, \sigma} %\sigma 
		\tilde A_{0\boldsymbol{k}\sigma} 
		\tilde A_{3\boldsymbol{k}-\sigma} 
	\Big) =&\,
	\sigma i k a \tilde A_{3\boldsymbol{k}-\sigma}^2 
	\exp\Big(
		i a \sum_{\boldsymbol{k}, \sigma} %\sigma 
		\tilde A_{0\boldsymbol{k}\sigma} 
		\tilde A_{3\boldsymbol{k}-\sigma} 
	\Big), \\
	-\sigma k \hat{A}_{0 \boldsymbol k \sigma} \hat P_{3 \boldsymbol k -\sigma} 
	\exp\Big(
		i a \sum_{\boldsymbol{k}, \sigma} %\sigma 
		\tilde A_{0\boldsymbol{k}\sigma} 
		\tilde A_{3\boldsymbol{k}-\sigma} 
	\Big) =&\,
	-\sigma i k a \tilde A_{0\boldsymbol{k}\sigma}^2 
	\exp\Big(
		i a \sum_{\boldsymbol{k}, \sigma} %\sigma 
		\tilde A_{0\boldsymbol{k}\sigma} 
		\tilde A_{3\boldsymbol{k}-\sigma} 
	\Big). \\
\end{aligned}
\end{align}
Reference:
\begin{align}
\begin{aligned}
	\hat H_{03} = 
		\sum_{\boldsymbol k, \sigma}\Big(
			\frac{1}{2\xi} \hat P^2_{0 k \sigma} +
			\frac{1}{2m} \hat P^2_{3 \boldsymbol k \sigma} +
			\sigma k \hat{A}_{3 \boldsymbol k -\sigma} \hat P_{0 \boldsymbol k \sigma} + 
			\sigma k \hat{A}_{0 \boldsymbol k -\sigma} \hat P_{3 \boldsymbol k \sigma} 
		\Big).
\end{aligned}
\end{align}
.\,.\,Okay, and can we then find an $a$ that makes this work, or should I change the factor somewhat.\,.\,? .\,.\,Hm, $a$ needs to depend on $\boldsymbol{k}$ and $\sigma$ for one thing.\,. 
.\,.\,Hm, it seems not to work, since $\xi$ needs to be positive.\,. .\,.\,Or wait.\,. We don't need it to be zero, right? We just need at to be positive.\,. .\,.\,No, negative, rather.\,. .\,.\,Which can always be achieved with a large enough *(real) $a$.\,. (\,:)\,.\,.)
.\,.\,Oh, but we don't want $a$ to be real exactly; we want it to eat.\,. hm, well then, that might be hard.\,. .\,.\,Hm, let us choose $a=v+iu$.\,. 
%(Min mormor ringede her.)
\ldots\ So 
\begin{align}
\begin{aligned}
	\frac{-a^2}{2\tilde m} \pm 	\sigma i k a = c\,\Longrightarrow\\
	a = \tilde m (\pm \sigma i k \pm \sqrt{-k^2 + 2c/\tilde m})\,.\,.
\end{aligned}
\end{align}
Hm, and this then needs to be true for.\,. .\,.\,Hm, we need to have this equation hold for both $+$ and $-$ in $\pm$ but where we can choose two different (positive) $c$s in each case.\,. .\,.\,So
\begin{align}
\begin{aligned}
	\tilde m (  \sigma i k \pm \sqrt{-k^2 + 2c_1/\tilde m}) = 
	\tilde m (- \sigma i k \pm \sqrt{-k^2 + 2c_2/\tilde m})\, \Longleftarrow\\
	2 \sigma i \tilde m  k = 
		\mp \tilde m\sqrt{-k^2 + 2c_1/\tilde m}  
		\pm \tilde m\sqrt{-k^2 + 2c_2/\tilde m}\, \Longleftarrow\\
	2 \sigma i  k = 
		\mp \sqrt{-k^2 + 2c_1/\tilde m}  
		\pm \sqrt{-k^2 + 2c_2/\tilde m}\,.\,.
\end{aligned}
\end{align}
\ldots Hm, that seems unsolvable for positive $c$s.\,. .\,.\,No oops! I get to choose each of the signs, so I just need to choose them as.\,. hm, $\sigma$, but then the only solution is still just when $c_1 = c_2 = 0$.\,.\,:\textbackslash\,.\,. .\,.\,But let me try to not have $\xi = \tilde m$.\,. .\,.\,Then I'll get
\begin{align}
\begin{aligned}
	\tilde m (  \sigma i k \pm \sqrt{-k^2 + 2c_1/\tilde m}) = 
	\xi      (- \sigma i k \pm \sqrt{-k^2 + 2c_2/\xi})\, \Longleftarrow\\
	\sigma i (\tilde m + \xi)  k = 
		\mp \tilde m\sqrt{-k^2 + 2c_1/\tilde m}  
		\pm \xi     \sqrt{-k^2 + 2c_2/\xi}\,.\,.
\end{aligned}
\end{align}
which again only has no solutions when $c_1, c_2 > 0$.\,.

Oh, well.\,. %Nå, lad mig lige gå en lille tur og summe over mine muligheder, og så kan jeg vende tilbage med, hvad jeg også ellers har tænkt på siden sidst i går aftes.. %(Kl. kvart over tre.)

%(Kl. ti i fire.) Jeg var lige ude på en lille gåtur og handle, og på vej til fakta kom jeg på en ret snedig tanke til muligvis at lappe noget, jeg tænkte på tidligere omkring at putte et cap på \tilde A-koordinaterne (i \hat H og i GE-løsningen), nemlig omkring at man så måske bare selv kunne tilføje en Coulomb-interaktion for alle \tilde A_3-koordinater, der overstiger grænsen. På vej hjem kom jeg dog i tanke om, at jeg så skal vise, at Dirac-ligningen stadig er selv-adjungeret efter denne tilføjelse, og det er måske lidt svært. Men så kom jeg også på, at jeg jo selvfølgelig også lige skal prøve at tilføje exp(-\tilde A_0^2)- og exp(-\tilde A_3^2)-led til løsningsgættet ovenfor, da man jo helt klart må forvente dette. Så det prøver jeg lige først..

\ldots\ I've realized that I should of course also add factors of 
\begin{align}
\begin{aligned}
%	\hat{\boldsymbol p\,}\! 
	\exp\Big(
		- a \sum_{\boldsymbol{k}, \sigma} %\sigma 
		(\tilde A_{0\boldsymbol{k}\sigma}^2 + 
		\tilde A_{3\boldsymbol{k}-\sigma}^2 )
	\Big)
\end{aligned}
\end{align}
to my guess at a solution here. Let me then rename the $a$ from before to $b$.\,. .\,.\,I should then get additional terms from:
\begin{align}
\begin{aligned}
	\frac{1}{2\xi} \hat \Pi_{0\boldsymbol{k}\sigma}^2 
	\psi =&\,
	\frac{-b^2}{2\xi} \tilde A_{3\boldsymbol{k}-\sigma}^2 
	\psi
	+
	\,.\,.
\end{aligned}
\end{align}
Oh, wait! Shouldn't the $c$s from before actually be negative.\,.\,?\,? .\,.\,Right.\,.\,! .\,\,Oh, and adding the Gaussian factors basically just let's me have them positive as well, the way I see it.\,. %(Kl. ti over fire.)
.\,.\,But but maybe it would actually be nice to add the Gaussian factors so that the solutions are finally also normalizable.\,.\,:) .\,.\,Nice.\,.(:)) 

.\,.\,Okay, so I'll add a factor of
\begin{align}
\begin{aligned}
%	\hat{\boldsymbol p\,}\! 
	\exp\Big(
		\sum_{\boldsymbol{k}, \sigma}(
			- a\tilde A_{0\boldsymbol{k}\sigma}^2  
			- a\tilde A_{3\boldsymbol{k}-\sigma}^2
			+ b \tilde A_{0\boldsymbol{k}\sigma} 
				\tilde A_{3\boldsymbol{k}-\sigma} 
		)
	\Big).
\end{aligned}
\end{align}
And that then gives me additional terms of
\begin{align}
\begin{aligned}
	\frac{1}{2\xi} \hat \Pi_{0\boldsymbol{k}\sigma}^2 
	\chi =&\,
%	\frac{2 a^2}{\xi} \tilde A_{0\boldsymbol{k}\sigma}^2 -
%	\frac{a}{\xi} \psi +
%	\frac{b^2}{2\xi} \tilde A_{3\boldsymbol{k}-\sigma}^2 
%	\psi +
%	..\psi, \\
%	\sigma k \hat{A}_{3 \boldsymbol k -\sigma} \hat P_{0 \boldsymbol k \sigma} 
%	\psi =&\,
%	\sigma k a \tilde A_{0\boldsymbol{k}\sigma} A_{3\boldsymbol{k}-\sigma} +
%	\sigma k b \tilde A_{3\boldsymbol{k}-\sigma}^2 
	\frac{1}{2\xi} \hat \Pi_{0\boldsymbol{k}\sigma}(
		2 i a A_{0\boldsymbol{k}\sigma} -
		i b A_{3\boldsymbol{k}-\sigma}
	) \chi \\=&\,
	\frac{1}{2\xi}
	\Big(
%		\frac{i a}{\xi} -
%		\frac{2 a^2}{\xi} \tilde A_{0\boldsymbol{k}\sigma}^2 -
%		\frac{b^2}{2\xi} \tilde A_{3\boldsymbol{k}-\sigma}^2 +
%		2
		2i a -
		4 a^2 \tilde A_{0\boldsymbol{k}\sigma}^2 -
		b^2 \tilde A_{3\boldsymbol{k}-\sigma}^2 +
		4 a b A_{0\boldsymbol{k}\sigma}A_{3\boldsymbol{k}-\sigma}
	\Big) \chi \\=&\,
	\Big(
		\frac{i a}{\xi} -
		\frac{2 a^2}{\xi} \tilde A_{0\boldsymbol{k}\sigma}^2 -
		\frac{b^2}{2\xi} \tilde A_{3\boldsymbol{k}-\sigma}^2 +
		\frac{2 a b}{\xi} A_{0\boldsymbol{k}\sigma}A_{3\boldsymbol{k}-\sigma}
	\Big) \chi \\
	\frac{1}{2\tilde m} \hat \Pi_{3\boldsymbol{k}-\sigma}^2 
	\chi =&\,
	\Big(
		\frac{i a}{\tilde m} -
		\frac{2 a^2}{\tilde m} \tilde A_{3\boldsymbol{k}-\sigma}^2 -
		\frac{b^2}{2\tilde m} \tilde A_{0\boldsymbol{k}\sigma}^2 +
		\frac{2 a b}{\tilde m} A_{0\boldsymbol{k}\sigma}A_{3\boldsymbol{k}-\sigma}
	\Big) \chi \\
\end{aligned}
\end{align}
\begin{align}
\begin{aligned}
	\sigma k \hat{A}_{3 \boldsymbol k -\sigma} \hat \Pi_{0 \boldsymbol k \sigma} 
	\chi =&\,
	\sigma k \tilde A_{3\boldsymbol{k}-\sigma} (
		2 i a A_{0\boldsymbol{k}\sigma} -
		i b A_{3\boldsymbol{k}-\sigma}
	) \chi \\=&\,
	(
		-\sigma i k b \tilde A_{3\boldsymbol{k}-\sigma}^2 +
		\sigma 2 i k a A_{0\boldsymbol{k}\sigma} A_{3\boldsymbol{k}-\sigma}
	) \chi \\
	- \sigma k \hat{A}_{0 \boldsymbol k \sigma} \hat \Pi_{3 \boldsymbol k -\sigma} 
	\chi =&\,
	-\sigma k \tilde A_{0\boldsymbol{k}\sigma} (
		2 i a A_{3\boldsymbol{k}-\sigma} -
		i b A_{0\boldsymbol{k}\sigma}
	) \chi \\=&\,
	(
		\sigma i k b \tilde A_{0\boldsymbol{k}\sigma}^2 -
		\sigma 2 i k a A_{3\boldsymbol{k}-\sigma} A_{0\boldsymbol{k}\sigma}
	) \chi.
\end{aligned}
\end{align}
Okay, that took a little time.\,. .\,.\,So we can collect the terms to get
\begin{align}
\begin{aligned}
	\frac{2 a b}{\xi} + \frac{2 a b}{\tilde m} + \sigma 2 i k a - \sigma 2 i k a = -\beta\,.\,.
\end{aligned}
\end{align}
Okay, so before I move on, this already shows that we would like $b$ to be.\,. we would like to either have $b$ be negative or to have $a> b$.\,. .\,.\,Since $\beta$ is here the factor in from of an added $\hat{A}_{0 \boldsymbol k \sigma} \hat \Pi_{3 \boldsymbol k -\sigma}$ term to the Hamiltonian. .\,.\,We should also add a constant energy term proportional to $-a$.\,. And then we should just have $\tilde A^2$ terms left. When we collect these, we get
\begin{align}
\begin{aligned}
	\frac{-4 a^2}{2\xi} + \frac{-b^2}{2 \tilde m} + \sigma  i k b = -\alpha_0\\
	\frac{-4 a^2}{2\tilde m} + \frac{-b^2}{2 \xi} - \sigma  i k b = -\alpha_3.
\end{aligned}
\end{align}
If we then choose $\xi = \tilde m$, we get
\begin{align}
\begin{aligned}
	\frac{4 a b}{\tilde m} = -\beta\\
\end{aligned}
\end{align}
and
\begin{align}
\begin{aligned}
	\frac{4 a^2 + b^2}{\tilde m} =&\, \alpha_3 + \alpha_0,\\
	\sigma  2 i k b =&\, \alpha_3 - \alpha_0.
\end{aligned}
\end{align}
.\,.\,Hm, this looks pretty promising.\,. .\,.\,Yeah, it looks like we can pretty much just take two positive (different) numbers $\alpha_0$ and $\alpha_3$ such that $\sigma(\alpha_3-\alpha_0)>1$, and then just determine $b$ from the last of the three equations. Then you can determine $a$.\,. wait, will $a$ always be positive then?\,.\,. Hm, yeah if the $\alpha$s are just chosen large enough (compared to their difference).\,. .\,.\,Oh wait. I forgot about the $i$ in the last equation.\,. .\,.\,Oh, but since we have $b^2$ in the second equation, we can probably make it work, let's see.\,. .\,.\,Oh no, except for what the first equation tells us.\,.\,:\textbackslash\ \,.\,.\,Hm, can't we have $b=0$, then?\,.\,. .\,.\,Hm, it seems so.\,. 

.\,.\,Okay, it might actually be pretty big if this works, but let me just take it slowly.\,. I also have some other news from last night / noon / midday, but I will get to that in time.\,. %(Kl. seks.)

.\,.\,Hm, is there a chance that the 
$\exp(
	i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma} 
	f_{\boldsymbol{k}\sigma}(\boldsymbol{x}) / k
)$ 
term might interfere somewhat.\,.\,? .\,.\,Hm yeah, I guess.\,. .\,.\,Ah, but maybe we can cure this by adding (or subtracting) a little strength to one of the two $qV$ energy terms.\,.\,!\,.\,.\,? %(Kl. ti over seks.)
.\,.\,Right, that must be doable.\,.\,!\,.\,. 

.\,.\,Okay, it's not \emph{that} big, actually; I had an idea in my head that this might lead to a more simple proof of self-adjointness of the gauge-eliminated $\hat H$, but no.\,. .\,.\,Yeah no, cause by then we have gone to the continuum limit and then the self-adjointness might fall off, for all we know (except that I have my proof (strategy) that I think will work). .\,.\,But nevertheless, it \emph{certainly} makes thing a lot nicer.\,!\,:) %(Kl. kvart over seks.)

.\,.\,Oh, we also have to consider the fact the the $\sigma k \hat{A}_{3 \boldsymbol k -\sigma} \hat \Pi_{0 \boldsymbol k \sigma}$ term is no longer 0 everywhere, but I guess we can just cure this contribution with a $\beta$ term, which would then only be there to cancel this.\,. %(Kl. tyve over seks.)
(.\,.\,And here I'm talking about an added $\hat{A}_{0 \boldsymbol k \sigma} \hat{A}_{3 \boldsymbol k -\sigma}$ term to the Hamiltonian, not any further changes to the solution (so $b$ is still 0).)

.\,.\,Hm, it's wrong, however, to say that this is \emph{not} big; it definitely \emph{is}.\,.\,!\,\textasciicircum\textasciicircum\ %(Kl. 25 over seks.)

%(Kl. kvart i syv.)
\ldots Hm no, we cannot just add a $\hat{A}_{0 \boldsymbol k \sigma} \hat{A}_{3 \boldsymbol k -\sigma}$ term; it is more complicated than that.\,. .\,.\,Yeah, we should get a weird-looking, but constant (I think), energy term that depends on $\barbsx$ and on $\tilde A_3$.\,. .\,.\,It should be sort of like
\begin{align}
\begin{aligned}
	\sum_{\boldsymbol k, \sigma} 
		\sigma k \hat{A}_{0 \boldsymbol k -\sigma} 
		\hat P_{3 \boldsymbol k \sigma} 
		\psi(\tilde A_\mu, \boldsymbol{x}) 
	= 
	-q\sum_{\boldsymbol k, \sigma}
		\tilde A_{0 \boldsymbol k -\sigma} 
		f_{\boldsymbol{k} -\sigma}(\boldsymbol{x}) 
		\psi(\tilde A_\mu, \boldsymbol{x})
	= 
	-q A_0(\boldsymbol{x}) \psi(\tilde A_\mu, \boldsymbol{x})
\end{aligned}
\end{align}
from above, except that the $1/k$ is no longer canceled (and with $\tilde A_3$ instead.\,.).\,. .\,.\,Hm, but yeah, I think we can just add this term (which will be proportional to $\pm a$) as well, since it will be dominated by the quadratic potentials at infinity (and it also vanishes for $a\to 0$, as is required).\,. 

.\,.\,Hm, but are we sure that.\,. well, I just said that it depends on $\barbsx$, but we in fact need it not to, so how are we sure that it does not depend on $\barbsx$.\,.\,? .\,.\,Oh, never mind!\,.\,. The dependency will of course vanish since we have specifically added a new term to cancel this energy.\,. .\,.\,Yeah, so never mind.\,. 

%(Kl. otte.)
\ldots\ Oh no, won't I get an imaginary contribution from the cross terms of $\hat \Pi_3^2$?\,.\,. (Then I can't just add a term to cancel it (without breaking the symmetry of $\hat H$).\,.) 

.\,.\,Hm, is there actually a way to have $a$ be complex by having $b\neq 0$ be complex as well.\,.\,? .\,.\,No.\,. 

.\,.\,Hm, maybe one could fix it by also adding a
$\exp(
	i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{3\boldsymbol{k}-\sigma}^2 
	f_{\boldsymbol{k}\sigma}(\boldsymbol{x}) / k
)$-like factor.\,. %(Kl. kvart over otte.)
.\,.\,Hm, or how about a 
$\exp(
	i q \sum_{\boldsymbol{k}, \sigma} \sigma \tilde A_{0\boldsymbol{k}\sigma} 
	f_{\boldsymbol{k}\sigma}(\boldsymbol{x}) / k
)$-like factor.\,.\,? 

.\,.\,Hm, if we add a factor of.\,. Wait, let's first see what we have too much. That should be a contribution of
\begin{align}
\begin{aligned}
	2\frac{1}{2\tilde m}  
	2ia \tilde A_{3\boldsymbol{k}-\sigma}
	q \sigma f_{\boldsymbol{k}\sigma}(\boldsymbol{x}) / k
	\chi = 
	\sigma
	\frac{2i q a}{\tilde m k}  
	f_{\boldsymbol{k}\sigma}(\boldsymbol{x})
	\tilde A_{3\boldsymbol{k}-\sigma}
	\chi.
\end{aligned}
\end{align}
.\,.\,So if I add a factor to the solution of 
\begin{align}
\begin{aligned}
	\exp\Big(
		i\sum_{\boldsymbol{k}, \sigma} 
		\frac{-\sigma}{k}
		\frac{2i q a}{\tilde m k}  
		f_{\boldsymbol{k}\sigma}(\boldsymbol{x})
		\tilde A_{0\boldsymbol{k}\sigma} 
	\Big),
	\label{3.23}
\end{aligned}
\end{align}
that should.\,. .\,.\,Hm, that should cancel the offending term, but now I also get a new contribution from the fermion $\hatbsp$s.\,. .\,.\,And what will that be.\,.\,? .\,.\,Hm, that just gives me yet another imaginary energy term that I can't just immediately cancel (by adding a term to the Hamiltonian).\,. %(Kl. kvart i ni.)

.\,.\,I also just realized (maybe) that it might not actually solve all problems (of getting from the gauge-eliminated $\hat H$ to the desired path integral) if we can find this solution.\,. But let me take a break now %(Er ved at blive ret ristet..)
and maybe just return tomorrow, if not later.\,. 


%(06.04.22) (Kl. fem over et.) Stod sent op igen i dag, og så har jeg tænkt lidt indtil nu. Der er flere forskellige ting, jeg skal forklare, men lad mig lige nævne her, at jeg faktisk tror min løsning ovenfor, nemlig med bare at indsætte en Coulomb interaktion efter \tilde A-koordinat-cappet, virker (som jeg kom frem til lidt tidligere i dag), og nu tror jeg faktisk også, jeg vil få gjort brug af den. Lad mig fortsætte i den renderede tekst..
(06.04.22) I will not need a solution that adds quadratic potentials to $\hat H$, so never mind all these calculations from yesterday. But I think I might actually make use of a different solution that achieves the same thing, which I have so far only mentioned very briefly in the %out-commented text.\,. 
comments of the source text (to this text).\,. I can see that I should go back to arguing from bounded potentials and about the continuity of the solutions near the GE (partial) solution (GEPS\.\,.\,?). But this continuity might be best argued for by knowing that the Hamiltonian in that neighborhood is approximated arbitrarily well by a family of self-adjoint Hamiltonians.\,. .\,.\,Hm, and I still need the self-adjointness for the gauge-eliminated $\hat H$, right.\,.\,? .\,.\,Hm, but that is where it might get a bit complicated, cause how do we know that it's self-adjoint in the neighborhood (and not just on the GEPS exactly).\,.\,? .\,.\,Hm well, since we at this point have already discretized the system, and since.\,. (.\,.\,hm, bounded potentials, something-something.\,.(?).\,.) .\,.\,Hm yeah, if I have all coordinates of $\tilde A_\mu$ bounded, then it should be self-adjoint, right? (.\,.\,and I should be able to have that.\,.\,?) 
\ldots Yeah, as simple as that.\,. .\,.\,Hm, and I shouldn't need the solution from the source comments, by the way, right.\,.\,? .\,.\,Hm.\,. .\,.\,No.\,. .\,.\,No, I just need to know that on the exact point of the GEPS, the.\,. .\,.\,Hm.\,. .\,.\,Oh, right. No, I just need to know that wave functions supported on the neighborhood of the GEPS will, for large enough bound on the potentials, behave approximately according the the propagator of the gauge-eliminated $\hat H$, which can be argued by looking at how the eigenvectors of $\hat H$ is ``approximate eigenvectors'' for the wave functions supported by the neighborhood of the GEPS. Hm, and that's really it, isn't it? (Is there anything more to that.\,.\,?) .\,.\,No, that's it (and I then don't need any nice solutions such as the ones I tried to find yesterday (and had an idea for today also); they don't serve any purpose in this argument). .\,.\,Right, okay. Let me make sure to return and read this paragraph if I ever forget how the argument goes again. 

*(You could actually also use the fact that the contribution of eq.\ (\ref{3.23}) above vanishes for $a\to 0$, which means that the solution is an ``approximate eigenvector'' .\,.\ oh wait, no.\,. .\,.\,Hm no, it is a problem, that the contribution not normalizable, since it grows as $\tilde A_{3\boldsymbol{k}-\sigma}$.\,. Oh well, if such a solution like this ever gets relevant, I can just go back here and try to find I solution like I did, but where I will allow for the solution to end up having (normalizable) extra terms (that makes them slightly un-parallel to the incoming $\psi$) as long as those terms vanish in the limit.\,.)


I also had some other tings to write. I think it will actually only make things easier, if I do the double-Trotter expansion (when it comes to arguing the Lorentz invariance --- though one could perhaps also do it almost as easily with the path integral one would get from a Suzuki expansion). And today I have then also realized that if I just do the version, where I get two parameters $M_1$ and $M_2$ that will give the Suzuki version of the path integral when they approach infinity at the same exact rate. I can then remark that I don't have a good reference that they can do so, and that we should have $M_2$ approach infinity lastly (such that it might grow much bigger than $M_1$), but luckily this will not make the later arguments any harder. .\,.\,I now have a very good idea for how I want to structure the first sections, and I have pretty good ideas for how the GE section and (a bit less) the continuum/Lorentsz invariance section(s) (I might change sections before getting to the Lorentz invariance of the GEPS) will go. In the GE section (following the path integral section), I will by the way solve it with no bounds assumed for the potentials, and then I will just clear all that up in the continuum / Lorentz invariance section. Okay, let me get to work. (I think I might jump to the GE section before I clear the earlier sections up completely (and just continue from there).) %(I btw haven't written yet on draft0.tex since the day before yesterday.)

\ldots\ Oh, and I forgot to mention: The reason why it works with the double-Trotter (and with $M_2$ and $M_1$, $M_2>M_1$), is that in the space-time grid that I've found, where the midpoints of the steps in one inertial system matches the midpoint of steps in the other, we can then just keep that larger steps for the fermion propagator, while the discretization that goes into calculating the action for each of the path integrals in the two systems can approach a finer and finer grain, while the fermion propagators don't see this at all; they keep seeing the $M_1$ grain, while $M_2$ grows larger and larger. %(Kl. tyve i tre.)

%(Kl. kvart over tre.)
\ldots Okay, let me actually, before I start working on \texttt{draft0} again, make sure that I have completely check on the Dirac equation. Let me start a new section for this.

\section{The Dirac equation}
Okay, let me see. Shankar has
\begin{align}
	\hat H_D \psi = \big(
		\boldsymbol{\alpha} \cdot (\hatbsp - q \boldsymbol{A}) +
		\beta m +
		q V
	\big)\psi,
\end{align}
with
\begin{align}
\begin{aligned}
	\boldsymbol{\alpha} &=
		\begin{pmatrix}
		0 & 					\boldsymbol{\sigma} \\
		\boldsymbol{\sigma} & 	0
		\end{pmatrix},
		\quad
	\beta &=
		\begin{pmatrix}
		I & 					0 \\
		0 & 					-I
		\end{pmatrix}.
\end{aligned}
\end{align}
Abers has
\begin{align}
	\hat H_{D} \psi = \big(
		\gamma^0 \boldsymbol \gamma \cdot (\hatbsp - q \boldsymbol A) -
		\gamma^0 m + 
		q V
	\big)\psi,
\end{align}
with
\begin{align}
\begin{aligned}
	\boldsymbol{\gamma} &=
		\begin{pmatrix}
		0 & 					\boldsymbol{\sigma} \\
		-\boldsymbol{\sigma} & 	0
		\end{pmatrix},
		\quad
	\gamma^0 &=
		\begin{pmatrix}
		I & 					0 \\
		0 & 					-I
		\end{pmatrix}.
\end{aligned}
\end{align}
So they seem to disagree only on the sign of $m$.\,. 
\ldots Hm, the \texttt{B10\_DiracEquation} document agrees with Shankar on the sign of $m$.\,. .\,.\,Yeah, that document has $+m$ instead, for sure.\,. .\,.Okay, and what about Lancaster and Blundell?\,.\,. 

\ldots Ah, I see that if you transform the basis by $\gamma^0 \hat H \gamma^0$ (since $(\gamma^0)^{-1}=\gamma^0$), where $\gamma^0$ is as in Lancaster and Blundell, namely
\begin{align}
\begin{aligned}
	\gamma^0 &=
		\begin{pmatrix}
		0 & 					I \\
		I & 					0
		\end{pmatrix},
\end{aligned}
\end{align}
then that has the effect of changing the signs of all $\gamma$s of Abers (e.g.), and that can give the minus sign on $m$, then. And changing the basis thus just means changing the left-handed and the right-handed part of the Dirac spinors. So either should be right.\,. 

.\,.\,And what does Lancaster and Blundell have.\,. .\,.\,With their $\gamma^0$, they have
\begin{align}
	\hat H_{D} \psi = \big(
		\gamma^0 \boldsymbol \gamma \cdot (\hatbsp - q \boldsymbol A) +
		\gamma^0 m + 
		q V
	\big)\psi\,.\,.
\end{align}
.\,.\,I'm actually a bit stuck with comparing this with the others, so let me just try to move on.\,. 

\ldots Ah, Shankar also shows that $\psi \to \exp(-i q \Lambda) \psi$.\,. wait, let me see about the sign.\,. .\,.\,Ah, yes he has $\psi \to \exp(-i q \Lambda) \psi$, nice.\,. .\,.\,Oh, but that was for $\boldsymbol{A}\to \boldsymbol{A} - \nabla \Lambda$, so I think it agrees with Abers.\,. By the way, since Abers and Shankar both use $\Lambda$, I will do the same.\,. (.\,.\,And I will get my sign right eventually, so it's still really nice that I can refer to Shankar.\,.) .\,.\,If only he solves it for the free Dirac equation.\,. .\,.\,Ah, he do indeed.\,. .\,.\,Oh yeah, just put on the opposite factors for $\chi$ and $\Phi$ to solve (20.2.7) or (20.2.8).\,:)\,.\,. (.\,.\,After starting from the same two-spinor, that is.\,.\,:)) *(Oh, which is exactly what he does in (20.2.9), he.\,x)) .\,.\,It does'nt seem to immediately agree exactly with the \texttt{B10\_DiracEquation} document, but who cares!\,.\,. 

\ldots Hm, let's see, equation (20.2.7-9) are then fulfilled if (inserting (9) in (6))
\begin{align}
	(E^2 - m^2 )\chi = (\boldsymbol{\sigma} \cdot \boldsymbol{p})^2\chi
		= \sum_{i, j = 1}^3 p_i p_j \sigma_i\sigma_j \chi
		= \sum_{i = 1}^3 p_i^2 \sigma_i\sigma_i \chi
		= \boldsymbol{p}^3 \chi,
\end{align}
where we have used $\sigma_i \sigma_j = - \sigma_j \sigma_i$ for $i\neq j$, and $\sigma_i^2 = I$ for all $i$. Cool, so that checks out.\,:)\textasciicircum\textasciicircum\ %(Kl. kvart over fem.) 

I can therefore trust in Shankar, and I should be able to just refer solely to him/it when refering to the Dirac equation.\,:) 

.\,.\,Hm, but let me check that these solutions are orthogonal.\,. The should of course be for different $E$ (taking values of $\pm\sqrt{\boldsymbol{p}^2 + m^2}$), but what about for similar $E$?\,.\,. .\,.\,Oh, that's trivial since they are proportional to.\,. .\,.\,Yeah, they are proportional to 
\begin{align}
\begin{aligned}
		\begin{pmatrix}
		(\pm |E| + m) \chi \\
		(\boldsymbol{\sigma} \cdot \boldsymbol{p}) \chi
		\end{pmatrix}\,.\,.
\end{aligned}
\end{align}
.\,.\,And 
$\braket{(\boldsymbol{\sigma} \cdot \boldsymbol{p}) \chi_1 |
(\boldsymbol{\sigma} \cdot \boldsymbol{p}) \chi_2} = 
\braket{\chi_1 | (\boldsymbol{\sigma} \cdot \boldsymbol{p}) 
(\boldsymbol{\sigma} \cdot \boldsymbol{p}) | \chi_2} =
\boldsymbol{p}^3 \braket{\chi_1 | \chi_2}$, so for similar $E$, they are orthogonal. And we can also just quickly check for different $E$: The inner product will here be 
$(m^2 - |E|^2)\braket{\chi_1 | \chi_2} + \boldsymbol{p}^3 \braket{\chi_1 | \chi_2}$, which is indeed 0 for all $\chi_1$ and $\chi_2$ (each being either a spin-up or a spin-down state). Okay.\,:) 

I should then also think about, why we know that we can extend it for multiple particles by summing the operators.\,. .\,.\,Oh, hopefully this will will not be too hard to check.\,. (.\,.\,But it might require some knowledge of the $\gamma$ matrices and so on.\,.) %(Kl. kvart i seks.) %(..Holder lige lidt pause..)

%(Kl. 25 i syv.)
\ldots\ Hm no, I can probably just use commutation.\,. Let's see.\,. 
\begin{align}
	\hat H_D \psi(\boldsymbol{x}) = \big(
		\boldsymbol{\alpha} \cdot (\hatbsp - q \boldsymbol{A}(\boldsymbol{x})) +
		\beta m +
		q V(\boldsymbol{x})
	\big)\psi(\boldsymbol{x}),
\end{align}
\begin{align}
\begin{aligned}
	\boldsymbol{\alpha} &=
		\begin{pmatrix}
		0 & 					\boldsymbol{\sigma} \\
		\boldsymbol{\sigma} & 	0
		\end{pmatrix},
		\quad
	\beta &=
		\begin{pmatrix}
		I & 					0 \\
		0 & 					-I
		\end{pmatrix}
\end{aligned}
\end{align}
for one particle, and
\begin{align}
	\hat H_D \psi(\barbsx) = \sum_{i=1}^{n}\big(
		\boldsymbol{\alpha_i} \cdot (\hatbsp_i - q \boldsymbol{A}(\boldsymbol{x}_i)) +
		\beta_i m +
		q V(\boldsymbol{x}_i)
	\big)\psi(\barbsx)
\end{align}
for multiple (i.e.\ $n$).\,. 

.\,.\,Maybe the Cartisian product basis that I have intended to use doesn't work.\,. This is quite unrelated but let me just think about that now (and write about it here).\,. .\,.\,Hm, or maybe it does.\,.\,? .\,.\,Oh yeah, it does, doesn't it.\,.\,? .\,.\,Yes, and we can use it for $\psi(\barbsx)$ as well, which is why I thought of it now.\,. .\,.\,Hm yeah, we have a sum of operators that all commute, so can't we just argue about the propagator $\exp(-i \hat H_D t)$ from this.\,.\,? .\,.\,Which has the form of my $K$ --- or it matrix elements has, rather --- from my draft document (since the potentials are time-dependent).\,. .\,.\,Sure.\,. .\,.\,Yeah, so that was quite easy.\,. %(Kl. fem i syv.) 

.\,.\,Okay, so let me just look a bit on me GE section above (under the ``argument and formulas'' section), and then start to work on my draft document again. %(which I last worked on the day before yesterday.)


%(07.04.22) (Kl. ti i to.) Nå, jeg håbede, jeg kunne slappe lidt af i går aftes med ro i sindet, men jeg kunne ikke lade være med så at tænke over mine Lorentz-invarians-argumenter igen, og der fandt jeg altså bare noget knas. Så det endte med en tænke-aften, primært, og jeg tænkte også en del i sengen (både om natten og inden jeg stod op). Vågnede tidligt og stod op et par timer efter. Og så har jeg også tænkt hele formiddagen, indtil jeg endelig fik en indsigt kl. fem i elleve, hvor jeg begyndte at tro, der var en ny løsning på vej. Så holdte jeg lidt pause til middag, hvor jeg begyndte at tænke nærmere over min nogenlunde-idé til en løsning, og nu er jeg så lige kommet på en ny vigtig indsigt: Jeg kan jo sikkert udføre de Gaussiske integraler og vise direkte (med visse antagelser om at være dekoblet tilstrækkeligt fra fermionernes propagation), at et vist (\omega, k)-koordinat (i det samlede integrale over sådanne) vil have et lille bidrag, npr der integreres over det, for tilstrækkelig store \omega og k. ..Og hvis jeg så lige går tilbage og forklarer mere om idéen, så handler det altså om, at stiintegralet rigtigt nok må blive dekoblet på en rigtig rar både, når man transformerer t til \omega. Og grunden til at min gamle idé nok ikke holdte alligevel, er nok, at det der palaver om at sammelinge to felt-stier i (\omega, k)-rum, hvor den ene transformerer til den anden ved først at gå til x-rum, så Lo.-transformere, og så til (\omega, k)-rum derfra igen, det holder altså nok ikke, fordi disse diskrete felter simpelthen vil være for ujævne. Man kan således dårligt argumentere for (tror jeg nu), at virkningen bliver mere og mere den samme for sådanne felt-sti-par, når stierne samtidigt også bliver mere og mere ujævne i denne grænse. Det var altså dette, jeg lidt indså i går aftes, og så har jeg sidenhen spekuleret over, om ikke man kunne sammenligne par direkte fra en Lorentz-transformation fra (\omega, k)-rum til (\omega, k)-rum (og uden x-rums-mellemtrinnene). Jeg stod så op med en idé (he, som jeg faktisk fik starten på inden jeg var helt vågnet; ikke imens jeg sov, men hvor jeg slumrede og altså faldt i søvn igen efter), om at stiintegralet nok må dekoble på en ret pæn måde, når man går fra t til \omega --- noget jeg har været klar over tidligere, men som jeg lidt har haft glemt igen inden --- og at jeg jeg måtte prøve at se på, om ikke jeg kunne bruge dette. Så har jeg ellers mest bare stirret den, der pt. er ligning (7) i mit draft0 (og startede også lige med at slå op i Lancaster og Blundell for at se, at det rigtigt nok bliver et fint, dekoblet resultat, når man fourier-transformer en funktion med diskrete differentialer). Og ja, der lidt i elleve kom jeg lidt frem til, at jo man må kunne fokusere et argument på, at indragelsen og integrationen over ethvert nyt koordinat med store nok k og/eller (måske "eller"..) \omega ikke vil ændre resultatet (efter en vis grænse, som sagt). Og nu her kom jeg så som sagt altså på, at jeg jo sikkert simpelthen kan udføre integrationerne for at vise dette --- dog med en antagelse om fermionerne "dekoblethed" fra koordinaterne (for små nok amplituder, nemlig hvor det gaussiske integrale har support ("støtte," hedder det måske på dansk..)).. ..Åh, og det vil bare være sådan en lettelse, hvis dette fortsætter med at se ud som en holdbar mulighed. Nå ja, jeg kiggede forrsten også lidt i den der Glimm og Jaffe bog, som jeg har lånt, og åh.. Jeg kan bare mærke, hvor meget jeg bare ikke orker, at skulle ud i alt muligt ekstra arbejde omkring det her.. ..Det vil bare være så vanvittigt rart, hvis dette bare rigtignok kommer til at vise sig at være et fornuftigt Lorentz-inv.-argument..!(..!!..) %(Kl. tyve over to.) %..Ha! så ramte trætheden mig.x)xD

%(Kl. 25 i syv.) Jeg har gjort mig nogle flere tanker, og nu fik jeg lige en særlig (og spændende) idé: Med en dobbelt Trotter-ekspansion kan man muligvis opnå et stiintegrale, hvor de forskellige k'er har forskellige \delta t'er..!!.. ..Fuck, det var da en god idé!..! (Fik den her 25 over, og så skulle jeg lige summe lidt over den, inden jeg tog til tasterne her..:)) ...Ej, det var en skide god idé, altså..!.. Det virker helt klart til, at den idé vil kunne klare mange af ærterne, hvis alt går vel. Så er det lige det med fermion-propagationen, hvor jeg ikke længere er helt så.. ..vent, kunne man mon også bruge idéen her..? ..Det må jeg lige tænke over, for som jeg var ved at sige, så er jeg ikke længere så sikker på, at mine tidligere argumenter for, at man kan få nøjagtigt samme fermion-prapagation.. ..he, sikke et hurtigt vejrskift: hagl.. ..Nå men: få nøjagtigt samme fermion-propagation i begge systemer, jeg er ikke længere sikker på, at det argument holder helt (ikke medmindre jeg gennemgår og får lappet det..).. 
%...Hm, jo måske kan det egentligt godt holde.. Lad mig lige tænke lidt mere.. %(Kl. syv.)
%..Hm, eller behøver man mon egentligt overhovedet sådan et indviklet argument..?.. ..Hm, det er da lige før, jeg tror, man ikke gør det.. ..Det kunne være fedt:), men lad os nu se.. For vi må jo nemt kunne argumentere for (især nu), at det må konvergere således, at vi kan skære høje \omega fra.. ..(Og høje k også.) ..Og nu snakker vi altså ift., bølge-koordinaternes indvirkning på fermion-propagatoren (den jeg for tiden kalder K).. ..Hm, og vil dette ikke blive nok til argumentet, eller hvad..? ..Hm, måske; hvis det opfører sig pænt når \delta k går mod 0 --- og hvis man kan få \delta \omega (som går proportionelt med t) til også at gå mod nul, hvis nu man også har brug for dette.. ..Hm, eller det kan måske godt være, at man får brug for mere indviklede argumenter, nu hvor vi i hvert fald taler om den dobbelte Trotter-ekspansion.. ..Hm, men som sagt kan man måske godt lappe mit tidligere argument / føre det igennem.. ..Hm, eller er der et mere simpelt argument..?.. %(Kl. 25 over syv.)
%..Hm, man kan vel ikke bare bruge, at når \delta k og \delta t går mod nul, så stiger finheden af propagationen, men at vi samtidigt også ved, at vi så ikke behøver at bekymre os om de ekstra overgange, som så bliver mulige når man.. ja, i hvert fald når man lader \delta k gå mod 0..? ..Hm, eller det er rettere finheden ift., at når man Lo.-transformerer, så vil et transformeret felt ligge tæt på sin modpart.. ..Hm, får man det mon så virkeligt sådan, at det er "gratis" at gå til større og større finhed her, fordi man ved at det ikke "koster" noget at lade k_{max} (eller \Lambda, eller hvad vi skal kalde den) og \omega_{max} (el. hvad vi skal kalde den) vokse..??.. %(Kl. 25 i otte.) ..Hm, det kan da næsten ikke være så simpelt.. ..Hm, tænk, hvis det virkeligt er så simpelt..(!).. ..Hm, tænk sig..!.. 
%...Hov, kan man egentligt få Dirac-interaktionen med under min nye særlige Trotter-teknik; så at de interaktionen, der hører til en vis k bare kommer med der..?!.. (..Ikke at jeg ved at det nødvendigvis løser noget endnu..) %(Kl. ti i otte.) ..Hm, og så må man vel altså holde den frie propagator ude med de større (M_1)-mellemrum imellem sig.. ..Hm, that's maybe not such a bad option to have.. ..Hm nej, det kunne muligvis ende med at kunne forstærke argumentet..(:)..) ..Ja, det kunne så..! ..Spændende!.. Nå, nu vil jeg altså tage mig en god aftenpause..:) %(Kl. fem i otte.) %..Lidt overkill med alle de kopier/backups, jeg laver, men det er jo bare fordi, jeg er så glad for denne seneste udvikling.^^

%(08.04.22) Ah, hvor er det dejligt. Og jeg synes også, det giver rigtigt god mening, at man efter et vist punkt må kunne inkludere vilkårligt mange \omega (ved at lade \omega_{max} stige), uden at det ændrer noget, selv endda for hver enkelte k. Og at tilføjelsen ikke ændrer fermion propagationen, svarer til, at man sætter felt-bølge-amplituden for (\omega, k)-koordinatet til 0. Og hermed kan vi altså opnå, at vi medtager det samme begrænsede antal koordinater i begge inertial systemer, som også passer (og altså transformerer) til hinanden. Og efter som finheden også bliver bedre og bedre, når flere og flere \omega'er tages med (svarende til at \delta t går mod 0) --- hvorved man i øvrigt også kan lade en kunstig k-bølge diskretisering (nemlig hvis man deskretiserer \hat H' (og specifikt iteraktionsdelen, \hat H_I, i \hat H')) gå mod 0 også, hvis man altså gerne vil argumentere ud fra dette (mere rum-tids-symmetriske) billede.. 
%..Nu vil jeg lige pointere noget om, at man måske godt også kunne lave et argument med de kvadratiske potentialer oven for, skrive en note her omkring, hvad jeg er nået frem til, og så.. Tja, lad mig egentligt lige vende tilbage til, hvad så.. *...Jo, jeg tror selvfølgelig, at jeg vil gennemgå $t\to\omega$-matematikken, som også var planen..

(08.04.22) I have found out something amazing. I first found out that my previous solution to making the argument for Lorentz invariance was troublesome, but after a good deal of thinking, I have found another argument that works much better.\,. and is really just super nice.\,. .\,.\,See my comments in the source file for some details about the process of finding the solution.\,. .\,.\,Hm, I think I will try to go through it and try to check the math of the solution (a bit), so let me make another section and start that work now.\,. (And then I will also first explain the idea there.)


\section{$t\to\omega$ and my new argument for Lorentz invariance}

Okay, let us say that we are at 
\begin{align}
\begin{aligned}
	U(\boldsymbol{q}_M, \psi_{j_M}, \boldsymbol{q}_0, \psi_{j_0}, t) =
		\lim_{M\to \infty} \bigg[
			\int 
			\prod_{i=1}^{M} (d\boldsymbol{q}_i) 
			\prod_{i=0}^{M} \bigg(\hspace{-.1em}\frac{d\boldsymbol{p}_i}{(2\pi)^N}\!\bigg)\, 
			e^{i \sum_{m=1}^{M} [\hspace{.07em}%\big(
					\boldsymbol{p}_m \dotbsq_m - 
					H(\boldsymbol{p}_m, \boldsymbol{q}_m)
				]%\big) 
				\delta t
			}
			\hspace{.07em}
			K(\psi_{j_M}, \psi_{j_0}, \barbsq, t)
		\bigg].
\end{aligned}
\end{align}
We then do the Gaussian integral, using\footnote{See e.g.\ Shankar. .\,.Hm, jeg skal enten gøre lidt mere arbejde selv, eller måske finde en mere passende kilde til mit formål\ldots}
\begin{align}
\begin{aligned}
	\lim_{A \to \infty}\int_{-A}^{A} dx\, e^{-ax^2/2 + b x} = 
		\Big(\frac{2\pi}{a}\Big)^{1/2} e^{b^2/(2a)},
\end{aligned}
\end{align}
which tells us that *(hm, there's an ambiguity with $(-i)^{1/2}$.\,.)
\begin{align}
\begin{aligned}
	\lim_{A \to \infty}\int_{-A}^{A} dp\, 
		e^{i\dot q p \delta t - i p^2 /(2 \tilde m) \delta t - i C p \delta t - i V \delta t} 
	=&\, 
		\Big(\frac{2\pi \tilde m}{i\delta t}\Big)^{1/2} 
			e^{i^2 \tilde m (\dot q - C)^2 \delta t^2/(2i\delta t)}
			e^{-i V \delta t}
	\\=&\, 
		\Big(\frac{2\pi\tilde m}{i\delta t}\Big)^{1/2} 
				e^{i L_{N=1}(\dot q, q) \delta t},
\end{aligned}
\end{align}
to get to (by integrating all the $N(M+1)$ $p$-coordinates):
\begin{align}
\begin{aligned}
	U(\boldsymbol{q}_M, \psi_{j_M}, \boldsymbol{q}_0, \psi_{j_0}, t) =
		\lim_{M\to \infty} \bigg[
			\Big(\frac{\tilde m}{i\delta t}\Big)^{N(M+1)/2}  
			\int 
			\prod_{i=1}^{M} (d\boldsymbol{q}_i)\,
			e^{i \sum_{m=1}^{M} 
				L(\dotbsq, \boldsymbol{q})
				\delta t
			}
			\hspace{.07em}
			K(\psi_{j_M}, \psi_{j_0}, \barbsq, t)
		\bigg].
\end{aligned}
\end{align}
.\,.\,I will forget the ambiguity for now. 

Now we have the desired path integral of eq. (1), or whatever it will be called. 

Okay, but really, we actually want to do a double Trotter expansion instead. And one of my (really) big ideas for my new approach (which I got yesterday (it's (08.04.22) now, btw)) is to actually use the commutation of $\hat H_B$ between unrelated $(\boldsymbol{k}, \sigma)$-coordinates to actually do the inner Trotter expansion with varying $M_2$ for each $\boldsymbol{k}$. %(Kl. tyve i to.) %(Kom åbentbart lidt sent i gang ved tasterne i dag, ved ikke helt præcist hvorfor..:)..)

.\,.\,Hm, but do I want to try to look at $t\to \omega$ first in the normal case (and also at Lorentz transformations in this case).\,.\,? 

.\,.\,Hm, let me just start by looking at Lorentz transformations of $(\omega, \boldsymbol{k})$ waves (given by (or proportional to, rather) $\sin(\boldsymbol{k}\cdot \boldsymbol{x} - \omega t)$ and $\cos(\boldsymbol{k}\cdot \boldsymbol{x} - \omega t)$). I know that $\exp(i \boldsymbol{k}\cdot \boldsymbol{x} - i \omega t)$ transforms to.\,. well, if we leave the $1$- and $2$-dimensions be and write $\exp(i k_3 x_3 - i \omega t)$.\,. Hm, why do I prefer $x_3$ and not $x_1$.\,.\,? .\,.\,Ah, because it is common to want to pair $x$ and $y$ together, I guess --- and it's common to have $(x_1, x_2, x_3) \equiv (x, y, z)$, I guess.\,. .\,.\,Hm, let me actually just write $\exp(i k_1 x_1 - i \omega t)$ for now, and think of it as $\exp(i k_z z - i \omega t)$, also.\,. 

.\,.\,Anyway, so $\sin(\boldsymbol{k}\cdot \boldsymbol{x} - \omega t)$ transforms to.\,. Yeah, to $\sin( \Lambda_\mu^\nu x_\nu \Lambda_\rho^\mu k^\rho)$ as expected (being $\sin( x_\mu k^\mu)$ to begin with).\,. 

\ldots Hm, I wonder if you can translate your $\boldsymbol{k}$s (partially) into the negative $k_1$-volume for sine/cosine functions, then.\,.\,? .\,.\,Hm, let me try to figure this out.\,. .\,.\,Oh, don't I know how to handle translating the $k$s for the exponential waves?\,.\,.  .\,.Hm, looking at what is now page 44.\,. .\,.\,Hm yeah, so we can indeed translate the range of $\boldsymbol{k}$, and shouldn't this work for the sine/cosine functions also, then? .\,.\,Hm no, I guess I need the range to be symmetric around 0 to transform (at least easily.\,.) to sine/cosine waves, right?\,.\,. .\,.\,Yeah.\,. .\,.\,Ah, but if I am allow to translate any particular $k$-coordinate (with $N\delta k$) and still get the nice properties of the discretization, then there might be a pretty transformation (from the skew $\Lambda(\omega, \boldsymbol{k})$-coordinates), let's see.\,. %(Kl. 25 i tre.)
.\,.\,Yeah, we can translate any individual coordinate thus if we want to. Yeah, so we should actually be able to reinterpret.\,. wait, let's see, one moment.\,. .\,.\,We can reinterpret them when we are on a discrete lattice, but are we that here.\,.\,? .\,.\,Hm, let me think a bit about this.\,. %(Kl. kvart i tre.)

\ldots Oh wait, it's of course the opposite way around; I just need to know that I am allowed for any system to.\,. hm, wait.\,. .\,.\,Do I know that I can just choose a sine/cosine-discretization with such a range to begin with.\,.\,? .\,.\,Hm, and that would be when I go from the contiuum limit (of the real theory) to the (sine/cosine-)discretized quantum system.\,. .\,.\,Oh, wait, no!\,.\,. It does not make sense to use sine and cosine functions with negative $k_1$ (when the corresponding positive ones are already being used), except in the context of the $(\omega, k)$-waves, so what I probably wanna do is to transform (or reinterpret) to wave with positive $k_1$ but with potentially negative $\omega$! That should be the way to go. Let's see.\,. %(Kl. tre.) 
.\,.\,And what is $(\omega, -k_1, k_2, k_3)$ then similar to (for sine and cosine functions)?\,.\,. .\,.\,It is similar (only with a different sign prefactor for the case of cosine, perhaps) to $(-\omega, k_1, -k_2, -k_3)$. .\,.\,Hm, let me try to draw, how this makes us able to transform the $\Lambda(\omega, \boldsymbol{k})$-volume.\,. \ldots Hm, it doesn't look so nice as I had hoped.\,. %(Kl. ti over tre.)
.\,.\,Hm, but I can also translate with $M\delta \omega$, so.\,. .\,.\,Hm, it's some puzzle, but I think there must be a solution to it where the coordinates are transformed to match the regular square.\,. .\,.\,Hm, I wonder why this seems so hard, though; it should be an easy matter in my mind.\,. There must be something I am overlooking.\,. %..Lad mig lige tage en kort pause og summe lidt over det.. (Kl. 25 over tre.)

%(Kl. 25 i fire.)
\ldots Oh, hm.\,. By translating the $\omega$s and the $k_1$s respectively for the two flipped volumes, I get.\,. a sort of arrowhead shaped volume in the first (positive) quadrant.\,. .\,.\,Hm, shape that I can work with in terms of the (special, new) double Trotter expansion if need be.\,. .\,.\,Hm no, wait, maybe I don't get the exact shape I just had in mind.\,. .\,.\,Oh, but I get another weird-arrowhead shape (that I can also work with if need be.\,.).\,. %(Kl. kvart i fire.)


%(Kl. ti over elleve.) Ah, det er simpelthen så skønt.. Jeg kom egentligt frem til, at hvis jeg ændrede mærkelig-pilehoved-formen (i.e. lod den nederste del være og kun flippede men ikke translaterede -k_1-delen) så kunne det lade sig gøre, men i går aftes fik jeg endeligt den idé, at jeg jo slet ikke behøver at lade k_1-dimensionen være både boost-dimensionen \emph{og} \mathbb{R}_+-dimensionen!x)xD Og så har man altså slet ikke disse problemer.:) Og ja, nu er jeg bare så glad for, at det hele ser ud til at gå i hak.. Men lad mig fortsætte i det renderede..
(09.04.22) 
Last evening I realized that I do not have to choose $k_1$ as both the boost-dimension \emph{and} the $\mathbb{R}_+$-dimension!\texttt{x)xD}\,\, I could for instance choose $\boldsymbol{k}\in\mathbb{R}^2 \times \mathbb{R}_+$ and then boost in the $k_1$ dimension. I also realized later on, that I can probably actually split up $\hat H$ into two by dissecting the free fermion propagator (in $k$-space) as well, but we will get to that later.

And the best part is: my solution now just seems really neat and \emph{reasonable}.\,. I think one of the problems has also been that I (at least sometimes) have thought, %in the recent period ..Det siger man nok ikke på engelsk..
here in the recent times, that I needed $\delta k$ and $\delta \omega$ to tend towards zero to get.\,. ``closer and closer dynamics'' of two corresponding waves in the two systems. But with the recent realizations, I can now see that the beauty is: we only need.\,. well $\omega_{max}$ to grow in particular, but we can also have $k_{max}$ grow at the same time if we want. Oh, and I have forgotten to mention another important realization from last evening (.\,.well, maybe from before that (I'm not completely sure), but that was when I checked that it was possible) that makes this work so nicely, namely that with the ability to translate all $\omega$s for any specific $\boldsymbol{k}$ coordinate (and specifically for any given $k_1$-coordinate) by any amount, we can translate all $\omega$s for a given $k_1$ such that they are translated slightly more and more for growing $k_1$, which makes us able to create a discretization where all $(\omega, \boldsymbol{k})$-coordinates in a grid is Lorentz-transformed into another grid that can be obtained from the path integral. So to get back to the growing $\omega_{max}$ and all that, .\,. well, maybe I should repeat another point first.\,. Let me do that. So with my realizations from the day before yesterday, I have found out that you can (and I should check some of the math today, but I am pretty sure it will work.\,:)\,.\,. 7, 9, 13.\,.) .\,.\,that you can argue --- namely from my new Trotter expansion where there is different $M$, potentially, for all $\boldsymbol{k}$ --- that.\,. well, exactly that you can choose any $M$ for each $\omega$ (which then gives you the $\omega_{max}$, since.\,. since $\omega_{max}- \omega_{min} = M \delta \omega$) as long as $M$ is big enough.\,. Oh, and I am also pretty confident that for big enough $\boldsymbol{k}$, we can also let $M$ get arbitrarily close to zero (but I can hopefully check this today).\,. And there we are: this means that we can argue that even if we include more $(\omega, \boldsymbol{k})$-coordinates (at the boundary of the $(\omega, \boldsymbol{k})$-volume), the will not change the fermion propagator, or the propagation of the field modes. This means that if only we make sure to factor on the right normalization constant, we can actually just include more $(\omega, \boldsymbol{k})$-coordinates, but \emph{not} integrate over them and just let them remain fixed at their zero-amplitude point. And this is tremendous. So by including more and more $(\omega, \boldsymbol{k})$-coordinates, we get a finer and finer grain for the fermion propagation (assuming that the fermion propagator.\,. well, let me actually get back to that in a moment.\,.).\,. we can get waves that match more and more each other in the two inertial systems, but where all $(\omega, \boldsymbol{k})$-coordinates after a certain boundary is fixed to 0 (i.e.\ the value over that coordinate is, which represents the mode's amplitude).\,.\,! And since are $(\omega, \boldsymbol{k})$-grid within the boundary now matches another (valid) grid within another (valid) boundary of the other inertial system, we have all the dynamics described by a discretized and bounded space of $(\omega, \boldsymbol{k})$-coordinates (or rather two sets of coordinates that Lorentz-transform to one another) where the contribution for each set of $\tilde A_{\mu\omega\boldsymbol{k}\sigma}$-values on this $(\omega, \boldsymbol{k})$-grid will approach the.\,. Lorentz-transformed contribution, let us call it that, from the other inertial system.\,:) Now, once you know that you can fix $(\omega, \boldsymbol{k})$-values to 0 after a certain boundary (which is determined by the $\varepsilon$ error that is allowed for the propagation, by the way), we can then actually just choose all $M_{\boldsymbol{k}}$ to be the same for the path integral (which now just have a lot of coordinates (namely all outside the boundary) fixed to 0). This means that our fermion propagator will now be discretized with this same $M$ (since we, as mentioned, can find a way to distribute the fermion propagator to the same $M_{\boldsymbol{k}}$-grid). And yeah, as this $M$ is now free to grow, the fermion propagation will then tend to that of the completely continuous case, i.e.\ for any given $\{\tilde A_{\mu\omega\boldsymbol{k}\sigma}\}_{(\omega, \boldsymbol{k})\in \mathrm{the\ bounded\ }(\omega, \boldsymbol{k})\mathrm{-grid}}$-field, the fermion propagator will tend to that the continuous version of this field (as opposed to the case where at least time is discretized, which is what we have initially for the path integrals).\,.\,:) %(Kl. halv et.)

%(Kl. tyve i tre.)
\ldots\ Oh, and by the way, because of how I thought that I needed $\delta k$ and $\delta \omega$ to tend to 0, I also worried about the normalization constant in front of the path integral. But now I see that there is no need: it is \emph{just} a normalization constant, no more. It will always be exactly what it should be and nothing more than that. And yeah, that is also nice to have realized.\,.\,:)

Okay, so what to do now? Should I keep working on the path integral part --- which I by the way now think should come after the GE section and just before the Lorentz-invariance section.\,. .\,.\,? .\,.\,Oh, I guess I should check that thing about $M$ being allowed to go to 0 (.\,.\,or to 1, perhaps.\,.) for the $k_1$ near their maximum for the bounded $(\omega, \boldsymbol{k})$-volume.\,. 

.\,.\,Unrelated comment: Oh, $t$ should by the way play the role of $\Omega$ (i.e.\ the (spacial) volume) when we Fourier-transform the time dimension.\,. .\,.\,Hm, which is nice since $t$ is constant (now) in the limit(s) we are interested in.

.\,.\,Hm, yeah let me think about how to show the proposition of the previous paragraph (before the $t,\Omega$ comment) now.\,. %(Kl. fem over tre.) 

%(Kl. halv fire.)
\ldots Hm, I think I'm overlooking something, because it cannot.\,. Ah.\,. I don't know if it's something that I've overlooked, but.\,. Oh yeah, I have overlooked it in the sense that the fermion propagator cannot be split up and distributed such that all operator groups commute with each other.\,. .\,.\,Hm, so how \emph{should} we expand, exactly.\,.\,? .\,.\,Hm, I by the way just got an idea for how we might show that $M$ can tend to 1 for $k_1$ going to the boundary.\,:)\,.\,. %(Kl. tyve i fire.)
.\,.\,Hm, it is a somewhat hacky solution (if it works), but it is always nice to have something.\,. (.\,.\,Though the real question for now is how I \emph{can} expand in the first place.\,.(?)) .\,.\,Oh, maybe the way I had in mind \emph{is} actually the way to do it.\,.(?\,.\,.) .\,.\,Then the order of the different.\,. ``$\boldsymbol{k}$-propagators'' can not be rearranged at all times.\,. hm, which might be a problem.\,. .\,.\,And I should also mention that what I have in mind now requires and outer $M_1$, and thus an initial (more rough-grained) $\delta t_1$ (.\,.\,so I would also have to check how I can get that).\,. 

%(Kl. halv fem.)
\ldots\ Oh, I should actually also remember that.\,. right: now I actually only \emph{need} the different $\delta t$s at the edges of the boundary on the $k_1$-axis.\,.\,! Great; this simplifies it a lot!\,.\,.\,:) %(Kl. halv fem.)

.\,.\,And thus it is maybe the case that all I need now is the argument about $M$ tending to 1 at these $k_1$-boundary edges, maybe the one I thought about a little earlier, and then I'm (hopefully) good to go!\,.\,. 

.\,.\,Hm, I do also need to find out how I should do the regular part of the (Trotter) expansion, but let me get back to thinking about that later.\,. %(Kl. tyve i fem.)
(.\,.\,He, so maybe I actually won't really need my great idea from the day before yesterday (if I'm not mistaken (the one about getting many different $M_{\boldsymbol{k}}$s)) so much after all --- not in the final argument, anyway, but it will always be a valuable idea in the sense of how it led me on to this new solution.\,.\,:)) .\,.\,Hm, but I \emph{should} need the idea for my new argument, shouldn't I (since it very much relies on it.\,.)?\,.\,. .\,.\,Yeah, so it's actually still a bit complicated.\,. %(Kl. kvart i fem.)

%(Kl. fem i fem.)
\ldots Hm, maybe we can do something where we can an underlying, extremely small $\delta t$ which divides all $M_{\boldsymbol{k}}$, and then build the $M_{\boldsymbol{k}}$-determined grid on top of this somehow.\,. .\,.\,Hm, could this then simply be done with a double Trotter expansion somehow.\,.\,!\,.\,? %(Kl. fem i fem (stadig).)
.\,.\,Hm.\,. .\,.\,Hm, but is it even a problem that the fermion propagator gets a larger grain; let me think about that for a bit.\,.\,? .\,.\,Hm, it means that the boundary might depend on said grain, but is this a problem.\,.\,? .\,.\,Yeah, it is.\,. .\,.\,Okay, so let me think about the double Trotter again.\,. .\,.\,Hm, the fermion propagator alone is what couples the different $\boldsymbol{k}$-modes (for which there are eight of each, as $\mu$ and $\sigma$ varies), right.\,.\,? %(Kl. fem over fem.)
.\,.\,Right.\,. .\,.\,Hm, so it would be nice if we could leave the free-energy part of the propagation (which is what couples them more exactly, not the potential part) out of the fine-grained (inner) part of the/an expansion.\,. .\,.\,Hm, or \emph{is} there a way to get this into the finer part, also, if we just slit it up a certain way.\,.\,? (.\,.\,I'm thinking about a way to split the field parts up in two such that this is possible.\,.) .\,.\,Oh.\,.\,! Wouldn't this just be splitting it.\,. Hm, I was about to say splitting it up in equally spaced intervals where you put every other in one group an the rest in a second group but.\,. Oh, I was about to write, but that only works when $k_1$.\,. well, whatever $k$ we are looking at I guess, but let me get back to that and for now just think of it in one dimension. Then I was about to say that it only works for $k$ larger than those interval, but then I of course had the thought: why not just make these as small as $\delta k$?\,.\,. .\,.\,Hm, yeah that might work, at least in one dimension.\,. .\,.\,Hm, and also in all three dimensions, right?\,:)\,.\,. %(Kl. tyve over fem.)
.\,.\,Yes, okay: I might definitely be on to something with that.\,. .\,.\,Hm, but unfortunately that doesn't really solve anything, when the free-energy propagator is then still split up throughout each of the outer (larger) $\delta t$-intervals.\,. .\,.\,Okay, let me just take some time to think about the problem (away from the keys).\,. %(Kl. 25 over fem.)

%(Kl. halv otte.) Jeg var kun lige på vej ud af døren (en lille tur), der omkring halv seks tidligere, da jeg fik indskydelsen, at jeg jo rigtignok sikkert netop ikke behøver de forskellige M_k alligevel, for argumentet virker jo sådan set også, selvom man bare snakker om en hel række af ekstra (\omega, k)-koordniater, der bliver tilføjet eller fjernet på en gang til/fra \omega_{max}-/\omega_{min}-grænsen. Siden da er der faktisk ikke sket så meget, men nu er jeg lige kommet frem til også, at jeg nok godt bare kan argumentere via tidsafhængig perturbationsteori, hvis jeg ikke lige finder på noget bedre, for at slå fast at man også må kunne fjerne og tilføje (\omega, k)-koordinater omkring k_{max}/k_{min}-grænserne, når blot disse er meget større (numerisk) end \omega_{max}.. og.. Hm, men \omega_{max} og \omega_{min} må jo også skulle vokse/falde, hvis man lader k_1 vokse (nemlig proportinelt med \gamma k_1, eller noget i den retning).. ..Hm, jeg burde skrive dette i det renderede.. ..Tja, eller ikke: Nu tænker jeg bare lige lidt over det.. ..Hm, men måske man bare kan bruge, at |k_{max}| - |\omega_{max}| bliver større og større for koordinaterne..(?) ..Hm jo, og så har man jo også, at amplituderne, som supporter det gaussiske integrale, også går mod 0, eller rettere support-intervallet går.. bliver mere og mere snævert omkring 0.. ..Ja, så det virker faktisk som en udmærket mulighed, og så kan jeg altid bare sige: "Der skal nok kunne finde et mere elegant bevis, men indtil videre så kan vi overbevise os selv med dette." Det synes jeg ikke, jeg vil tabe ansigt på overhovedet.. Men ja, jeg bør nu alligevel lige holde det i mente og tænke lidt mere over, om jeg mon kan finde en lidt mere elegant løsning på dette (lille) delproblem.. %(Kl. ti i otte.)
\ldots\ I have now realized that I actually don't need the different-$M_{\boldsymbol{k}}$s expansion, since one \emph{can} just make the same argument for a whole row of $(\omega, \boldsymbol{k})$-coordinates at once.\,:) I have then also though about how to argue that we can remove/add $(\omega, \boldsymbol{k})$-coordinates at the end of the $k_1$-min/max boundaries, and though I haven't found an elegant solution yet (and the idea I mentioned before doesn't seem to make a lot of sense.\,. but maybe I should think some more about it.\,.), I have at least sort of concluded that an argument that talks about time-dependent perturbation theory actually might be okay to use in this instance (since I think there actually is a very good chance that it \emph{can} be rigorized, even though that might take some work compared to whatever elegant solution has escaped me yet).\,. %(Kl. fem i otte.)

%.\,.\,Hm, let me by the way mention that I sort of have doubts that the %..Nej, det er ikke så interessant, så lad mig lige udkommentere.. (Det er bare, at jeg lidt forudsiger, at t\to\omega-transformationen ikke bliver totalt pæn med det samme, men jeg tror så dog sikkert, det skal vise sig, at det bliver mere og mere pænt i grænsen når \omega_{max}\to\infty.. ..Det ville i hvert fald give god mening, hvis det kommer til at gå sådan..)

\ldots Hm, the thing is also: even if there is a more ``elegant'' argument, it might very well be way to complicated to include rather than the much simpler t.d.p. argument.\,. .\,.\,Which is indeed a \emph{fine} argument.\,.\,:) Hm.\,. %(Kl. ti over otte.)
.\,.\,You know what.\,. .\,.\,It's a pretty \emph{decent} argument, actually.\,.\,:)\,.\,. .\,.\,Yeah.\,. .\,.\,Oh, maybe one could even add arguments to it.\,. %(Kl. kvart over otte.)
.\,.\,If $k_1$ becomes far greater than the.\,. sort of ``$p_{max}$'' (or $p_{1 max}$) for the fermions, meaning the max $\ket{p_1}$ you would ever measure inside or at the boundaries of the path integral given some $\varepsilon$ (of what ``ever'' means in this formulation), then.\,.(?) %.\,.\,Hm oh, unfortunately %..Det gider jeg ikke lige at skrive, men hvis man fjerner en gruppe koordinater ved k_{1 max} grænsen, så kan man nå ind i p_{1 max}-intervallet kun med to overgange med k'er fra denne gruppe.. 
.\,.\,Hm, my initial idea does not work, but let me just think a bit more.\,. .\,.\,No, I can't find a good argument with that.\,. %(cause it's hard to argue that whatever the actual state does isn't just because the effect of some of the removed coordinates is canceled by removing the others with it (like you're supposed to if the proposition doesn't hold)..) 
But still: the t.d.p. argument is still a good argument --- and I'm sure (not really, but almost) there is some rigorous theory about t.d.p. out there, that one can use. It would be very surprising to me, if the argument cannot be rigorized, so let me just go with it!\,.\,.\,:) %(Kl. halv ni.)

%(Kl. fem i ni.)
\ldots Ah, and if the td.p.t. work ``for small enough times,'' then is must also work large enough energies, since we can always transform the energies to smaller ones, transform the time $t$ to a smaller one and transform the $\omega$s of the (time-dependent) field/potential smaller ones as well.\,. .\,.\,Yeah.\,. .\,.\,Hm no, shouldn't $t$ then grow bigger in this transformation.\,.\,? .\,.\,Hm, so smaller $t$, bigger energies and.\,. bigger $\omega$s.\,.\,? .\,.\,Yeah. So therefore we cannot immediately worry that $t$ is ``not small.'' Hm, but I guess one should actually just look up the actual propositions (which must have been shown somewhere.\,.) that tells us what error we can expect, and if the error is small as long as.\,. Hm, wait.\,. .\,.\,Hm, maybe we would expect that ``the errors are small when $(|E_2 - E_1|-|\omega|)^{-1}$ is small compared to $t$.''.\,.\,? .\,.\,Yeah, it will probably be something like that (for a constant amplitude, that is), which would be good in our case.\,. %(Kl. ti over ni.)
(.\,.\,So let us just say that that's the case, shall we not?\,.\,;)) (.\,.\,I would genuinely be absolutely surprised if this (td.p.t.) argument does not hold, so I do plan to use it.\,.\,:))

(10.04.22) Okay, let me do the $t\to\omega$ Fourier transform.\,. 

We want to investigate
\begin{align}
\begin{aligned}
	\sum_{i=1}^{M} L(\dotbsq_i, \boldsymbol{q}_i) \delta t = 
		\sum_{i=1}^{M} \Big(
%			\frac{1}{2}\tilde m (\dotbsq_i - C(\boldsymbol{q}_i))^2 - V(\boldsymbol{q}_i)
			\frac{1}{2}\tilde m \big( \boldsymbol{\dot q}_i - C(\boldsymbol{q}_i)\big)^2 -
			V(\boldsymbol{q}_i
		\Big)\delta t.
\end{aligned}
\end{align}
And we want to Fourier transform the $\boldsymbol{q}_i$s.\,. .\,.\,Hm, let me write out $C$ and $V$.\,. 
.\,.\,Hm no, I know that $V$ will decouple so let me remove that. But let me use that $C(\boldsymbol{q})$ is just a permutation of $\boldsymbol{q}$ plus.\,. Oh, I just realize now $\xi$ should be replaced by.\,. no, wait.\,. .\,.\,Hm no, instead we need to have $\xi=\tilde m$ if we want to get to, what is now eq.\ (8) and (9) in \texttt{draft0}.\,. .\,.\,I think I will just do that from the get go; there is no need to carry around $\xi$ if it complicates things. Ok. .\,.\,And then $\hat C$ only add a factor of $\sigma k$ --- or of 0 --- and then permutes $\boldsymbol{q}$.\,. .\,.\,So if we look at only one coupled pair of $(\boldsymbol{k}, \sigma)$ and $(\boldsymbol{k}, -\sigma)$, we want to Fourier-transform a general term on the form
\begin{align}
\begin{aligned}
	\sum_{i=1}^{M} 
		\frac{1}{2}\tilde m \big( 
			\frac{\partial}{\partial t} q_{i\boldsymbol{k}\sigma} - 
			a q_{i\boldsymbol{k} -\sigma} 
		\big)^2 
		\delta t,
\end{aligned}
\end{align}
with $a = \sigma k$ or $a = 0$. .\,.\,Well, for $a=0$ is trivial *(or maybe not, but we'll see.\,.), so it's the $a = \sigma k$ case we are really interested in.\,. .\,.\,Oh, actually we want to look at
\begin{align}
\begin{aligned}
	\sum_{i=1}^{M} 
		\frac{1}{2}\tilde m \big( 
			(q_{i\boldsymbol{k}\sigma} - q_{(i-1)\boldsymbol{k}\sigma}) / \delta t - 
			a q_{i\boldsymbol{k} -\sigma} 
		\big)^2 
		\delta t.
\end{aligned}
\end{align}
.\,.\,Hm, so now we should expand with cosine and sine functions.\,. .\,.\,Hm, and for that I should use some identities for this expansion.\,. .\,.\,Hm, let me just expand it for now.\,. We get.\,. .\,.\,Hm, I need to change variables away from $\boldsymbol{k},\sigma$ first.\,. Let us write *(oh, and changing $m\to i$ was also a bad decision.\,.) *(let me also just remove the factor of $\tilde m / 2$ for now.\,.)
%\begin{align}
%\begin{aligned}
%	\sum_{i=1}^{M} \sum_{\omega'}
%		\frac{1}{2}\tilde m \big( 
%			(
%				\sum_{\omega} \tilde q_{\omega\boldsymbol{k}\sigma} - 
%				q_{(i-1)\boldsymbol{k}\sigma}
%			) / \delta t - 
%			a q_{i\boldsymbol{k} -\sigma} 
%		\big)^2 
%		\delta t.
%\end{aligned}
%\end{align}
\begin{align}
\begin{aligned}
	\sum_{m=1}^{M} 
%		\frac{1}{2}\tilde m 
		\big( 
			(q_{m \alpha} - q_{(m-1) \alpha}) / \delta t - 
			a q_{m \beta} 
		\big)^2 
		\delta t.
\end{aligned}
\end{align}
Then can write
\begin{align}
\begin{aligned}
	\sum_{m=1}^{M}
%		\frac{1}{2}\tilde m 
		\bigg( 
			\sum_{\omega, \sigma} 
				\tilde q_{\omega\sigma\alpha}
				f_{\omega \sigma}(m\delta t) 
				/ \delta t 
			- 
			\sum_{\omega', \sigma'} 
				\tilde q_{\omega'\sigma'\alpha}
				f_{\omega' \sigma'}((m-1) \delta t) 
			 	/ \delta t 
			- 
			a \sum_{\omega'', \sigma''} 
				\tilde q_{\omega''\sigma''\beta}
				f_{\omega'' \sigma''}(m \delta t) 
		\bigg)^2 
		\delta t.
	\label{3.44}
\end{aligned}
\end{align}
.\,.\,Okay, and now we need to use some orthogonality identities.\,. 
%.\,.\,Yeah, we should have
%\begin{align}
%\begin{aligned}
%	\sum_{m=1}^{M} f_{\omega \sigma}(\delta t) f_{\omega' \sigma'}(\delta t) 
%\end{aligned}
%\end{align}
.\,.\,Oh wait, first we need to rewrite the middle term.\,. .\,.\,Addition formulas.\,.\,? .\,.\,Or rewriting in terms of complex exponentials, though that should give the same.\,. .\,.\,Ah, the trick with exponentials must be to just factor out $\exp(-i \omega \delta t)$, but we can't exactly do that here, I guess.\,. But the addition formulas gives us.\,. .\,.\,No, let me actually calculate it by using the expression for $f$.\,. .\,.\,or what.\,.\,? .\,.\,No: addition formulas tells us that
\begin{align}
\begin{aligned}
	f_{\omega 1}((m-1)\delta t) =&\, 
		f_{\omega 1}(m \delta t) f_{\omega 1}(\delta t) +
		f_{\omega -1}(m \delta t) f_{\omega -1}(\delta t) \\
	f_{\omega -1}((m-1)\delta t) =&\, 
		f_{\omega -1}(m \delta t) f_{\omega 1}(\delta t) -
		f_{\omega 1}(m \delta t) f_{\omega -1}(\delta t).
\end{aligned}
\end{align}
So we can rewrite eq.\ (\ref{3.44}) as
\begin{align}
\begin{aligned}
	&\sum_{m=1}^{M} \sum_{\omega}
%		\frac{1}{2}\tilde m 
		\Big( 
			\big(
				\tilde q_{\omega 1\alpha} / \delta t -
				\cos(\delta t) \tilde q_{\omega 1\alpha} / \delta t +
				\sin(\delta t) \tilde q_{\omega-1\alpha} / \delta t -
				a \tilde q_{\omega 1\beta}
			\big)
			\cos(\omega m \delta t) 
		\Big)^2 
		\delta t\\
	+&\sum_{m=1}^{M} \sum_{\omega}
%		\frac{1}{2}\tilde m 
		\Big( 
			\big(
				\tilde q_{\omega-1\alpha} / \delta t -
				\cos(\delta t) \tilde q_{\omega-1\alpha} / \delta t -
				\sin(\delta t) \tilde q_{\omega 1\alpha} / \delta t -
				a \tilde q_{\omega-1\beta}
			\big)
			\sin(\omega m \delta t) 
		\Big)^2 
		\delta t.
\end{aligned}
\end{align}
.\,.\,So if we now change variables such that the $\tilde q$s are coefficients of \emph{normalized} sine and cosine functions, we get when we sum over $\omega$:
\begin{align}
\begin{aligned}
	&\sum_{m=1}^{M} 
		\Big(
			\big(1 - \cos(\delta t)\big) \tilde q_{\omega 1\alpha}  / \delta t +
			\sin(\delta t) \tilde q_{\omega-1\alpha} / \delta t -
			a \tilde q_{\omega 1\beta}
		\Big)^2 
		\delta t\\
	+&\sum_{m=1}^{M} 
		\Big(
			\big(1 - \cos(\delta t)\big) \tilde q_{\omega-1\alpha}  / \delta t -
			\sin(\delta t) \tilde q_{\omega 1\alpha} / \delta t -
			a \tilde q_{\omega-1\beta}
		\Big)^2 
		\delta t.
\end{aligned}
\end{align}
.\,.\,Hm, and now, $\sum_{m=1}^{M} \delta t$ just becomes $t$ *(wrong, because we also have $\omega$ appearing in the subscripts), so we get
\begin{align}
\begin{aligned}
	&\,\Big(
		\big(1 - \cos(\delta t)\big) \tilde q_{\omega 1\alpha}  / \delta t +
		\sin(\delta t) \tilde q_{\omega-1\alpha} / \delta t -
		a \tilde q_{\omega 1\beta}
	\Big)^2 
	t \\
	+&\,\Big(
		\big(1 - \cos(\delta t)\big) \tilde q_{\omega-1\alpha}  / \delta t -
		\sin(\delta t) \tilde q_{\omega 1\alpha} / \delta t -
		a \tilde q_{\omega-1\beta}
	\Big)^2 
	t.
\end{aligned}
\end{align}
\ldots Okay, let me collect the terms.\,. .\,.\,Oh, I have forgotten some $\omega$s. Let me put those on.\,. Oh, wait. I wanted to put them on such that $\cos(\delta t)\to \cos(\omega \delta t)$, but this means that we can no longer sum like that over all $\omega$s. So we are back to
\begin{align}
\begin{aligned}
	&\sum_{m=1}^{M} \sum_{\omega}
%		\frac{1}{2}\tilde m 
		\Big( 
			\big(
				\tilde q_{\omega 1\alpha} / \delta t -
				\cos(\omega\delta t) \tilde q_{\omega 1\alpha} / \delta t +
				\sin(\omega\delta t) \tilde q_{\omega-1\alpha} / \delta t -
				a \tilde q_{\omega 1\beta}
			\big)
			\cos(\omega m \delta t) 
		\Big)^2 
		\delta t\\
	+&\sum_{m=1}^{M} \sum_{\omega}
%		\frac{1}{2}\tilde m 
		\Big( 
			\big(
				\tilde q_{\omega-1\alpha} / \delta t -
				\cos(\omega\delta t) \tilde q_{\omega-1\alpha} / \delta t -
				\sin(\omega\delta t) \tilde q_{\omega 1\alpha} / \delta t -
				a \tilde q_{\omega-1\beta}
			\big)
			\sin(\omega m \delta t) 
		\Big)^2 
		\delta t.
\end{aligned}
\end{align}
\ldots Or back to
\begin{align}
\begin{aligned}
	&\sum_{m=1}^{M} \sum_{\omega}
		\Big(
			\big(1 - \cos(\omega\delta t)\big) \tilde q_{\omega 1\alpha}  / \delta t +
			\sin(\omega\delta t) \tilde q_{\omega-1\alpha} / \delta t -
			a \tilde q_{\omega 1\beta}
		\Big)^2 
		\cos^2(\omega m \delta t)
		\delta t\\
	+&\sum_{m=1}^{M} \sum_{\omega}
		\Big(
			\big(1 - \cos(\omega\delta t)\big) \tilde q_{\omega-1\alpha}  / \delta t -
			\sin(\omega\delta t) \tilde q_{\omega 1\alpha} / \delta t -
			a \tilde q_{\omega-1\beta}
		\Big)^2 
		\sin^2(\omega m \delta t)
		\delta t.
\end{aligned}
\end{align}
.\,.\,Ah, but can't we sum over $m$ directly here?\,.\,. .\,.\,Sure.\,. .\,.\,I'm pretty sure we would want $\sum_{m=1}^{M} c^2 \sin^2(\omega m \\\delta t) \delta t = \sum_{m=1}^{M} c^2 \sin^2(\omega m \delta t) \delta t = \,.\,.$ hm, I wanted to say ``$=t$'' but I should check this to be more careful.\,. .\,.\,No, I guess we want $\sum_{m=1}^{M} c^2 \sin^2(\omega m \delta t) = \sum_{m=1}^{M} c^2 \sin^2(\omega m \delta t) = 1$.\,. (.\,.\,where $c$ is the normalization constant.\,.) .\,.\,Yeah, that must be so.\,. .\,.\,And then we get (rewriting the above expression further) *(and with $\tilde q \to c \tilde q$ *(namely since this is what we should have had from the start))
\begin{align}
\begin{aligned}
	&\sum_{\omega}
		\Big(
			\big(1 - \cos(\omega\delta t)\big) \tilde q_{\omega 1\alpha}  / \delta t +
			\sin(\omega\delta t) \tilde q_{\omega-1\alpha} / \delta t -
			a \tilde q_{\omega 1\beta}
		\Big)^2 
		\delta t\\
	+&\sum_{\omega}
		\Big(
			\big(1 - \cos(\omega\delta t)\big) \tilde q_{\omega-1\alpha}  / \delta t -
			\sin(\omega\delta t) \tilde q_{\omega 1\alpha} / \delta t -
			a \tilde q_{\omega-1\beta}
		\Big)^2 
		\delta t.
	\label{eq_3.51}
\end{aligned}
\end{align}
And if this holds, we can then see that the cross terms with $\cos(\omega \delta t)$ or $\sin(\omega \delta t)$ will vanish under the summation, which should yield us %(.\,.\,using that $\sum_\omega \delta t = t$)
\begin{align}
\begin{aligned}
	&\sum_{\omega}
		\Big(
			\tilde q_{\omega 1\alpha}  / \delta t -
			a \tilde q_{\omega 1\beta}
		\Big)^2 
		\delta t
	+
	\sum_{\omega}
		\big(
			\cos(\omega\delta t) \tilde q_{\omega 1\alpha}  / \delta t
		\big)^2 
		\delta t
	+
	\sum_{\omega}
		\big(
			\sin(\omega\delta t) \tilde q_{\omega-1\alpha} / \delta t 
		\big)^2 
		\delta t\\
	+&\sum_{\omega}
		\Big(
			\tilde q_{\omega-1\alpha}  / \delta t -
			a \tilde q_{\omega-1\beta}
		\Big)^2 
		\delta t
	+
	\sum_{\omega}
		\big(
			\cos(\omega\delta t) \tilde q_{\omega-1\alpha}  / \delta t
		\big)^2 
		\delta t
	+
	\sum_{\omega}
		\big(
			\sin(\omega\delta t) \tilde q_{\omega 1\alpha} / \delta t 
		\big)^2 
		\delta t,
\end{aligned}
\end{align}
and using the idiot formula %, as well as $\sum_\omega \delta t = t$, 
then gives us (rewriting the expression further)
\begin{align}
\begin{aligned}
	&\,\sum_{\omega} \delta t \bigg(
		\big(
			\tilde q_{\omega 1\alpha}  / \delta t -
			a \tilde q_{\omega 1\beta}
		\big)^2 
		+
		\big(
			\tilde q_{\omega-1\alpha}  / \delta t -
			a \tilde q_{\omega-1\beta}
		\big)^2 
		+
		\big(
			\tilde q_{\omega 1\alpha}  / \delta t
		\big)^2 
		+
		\big(
			\tilde q_{\omega-1\alpha}  / \delta t 
		\big)^2 
	\bigg) \\
%	=&\,\bigg(
%		2\big(
%			\tilde q_{\omega 1\alpha}  / \delta t
%		\big)^2 
%		+
%		2\big(
%			\tilde q_{\omega-1\alpha}  / \delta t 
%		\big)^2 
%		+
%		2\big(
%			a \tilde q_{\omega 1\beta} 
%		\big)^2 
%		+
%		2\big(
%			a \tilde q_{\omega-1\beta} 
%		\big)^2 
%		-
%		2\big(
%			a \tilde q_{\omega 1\alpha} \tilde q_{\omega 1\beta} / \delta t 
%		\big)^2 
%		-
%		2\big(
%			a \tilde q_{\omega-1\alpha} \tilde q_{\omega-1\beta} / \delta t
%		\big)^2 
%	\bigg) t
	=&\,\sum_{\omega} \delta t \bigg(
		2\sum_\sigma \big(
			\tilde q_{\omega\sigma\alpha}  / \delta t
		\big)^2 
		+
		2\sum_\sigma \big(
			a \tilde q_{\omega\sigma\beta} 
		\big)^2 
		-
		2\sum_\sigma \big(
			a \tilde q_{\omega\sigma\alpha} \tilde q_{\omega\sigma\beta} / \delta t 
		\big)^2 
	\bigg) \\
	=&\,2 \sum_{\omega,\sigma} \delta t \bigg(
		\big(
			\tilde q_{\omega\sigma\alpha}  / \delta t
		\big)^2 
		+
		\big(
			a \tilde q_{\omega\sigma\beta} 
		\big)^2 
		-
		\big(
			a \tilde q_{\omega\sigma\alpha} \tilde q_{\omega\sigma\beta} / \delta t 
		\big)^2 
	\bigg).
	\label{eq_3.53}
\end{aligned}
\end{align}
.\,.\,Hm, it would make more sense, if I have forgotten a factor of 2 or $1/2$ somewhere.\,. %..Let me take a tiny break.. ..No never mind.
.\,\,Ah, I guess I have forgotten about the $\cos(\omega \delta t)\sin(\omega \delta t)$ terms.\,. .\,.\,Hm, we can probably gather all those into an addition formula expression.\,. .\,.\,Yeah so I have left out a contribution (looking at eq.\ (\ref{eq_3.51})) of
\begin{align}
\begin{aligned}
	\sum_{\omega}
		\Big(
			\big(
				\sin(\omega\delta t) \cos(\omega\delta t) - 
				\cos(\omega\delta t) \sin(\omega\delta t)
			\big) \tilde q_{\omega 1\alpha} \tilde q_{\omega-1\alpha}  / \delta t^2 
		\Big)^2 
		\delta t =
	\sum_{\omega}
		\Big(
			0 \tilde q_{\omega 1\alpha} \tilde q_{\omega-1\alpha}  / \delta t^2 
		\Big)^2 
		\delta t = 0.
\end{aligned}
\end{align}
Oh, it turned out to be a very trivial addition formula. The terms simply cancel, is another way of looking at it. Okay, so I'm back to eq.\ (\ref{eq_3.53}) for the time being.\,. %..Now let me take a little break..
\ldots $\!$Well, I have made a mistake in eq.\ (\ref{eq_3.53}), first of all.\,. .\,.\,(I'm not completely sure about the $c$ normalization as well, but that's another story.\,.)
\ldots Hm, let me maybe take a break from this problem. But so far I have arrived at (correcting eq.\ (\ref{eq_3.53})) 
\begin{align}
\begin{aligned}
\sum_{\omega,\sigma} \delta t \bigg(
		2\big(
			\tilde q_{\omega\sigma\alpha}  / \delta t
		\big)^2 
		+
		\big(
			a \tilde q_{\omega\sigma\beta} 
		\big)^2 
		-
		2\big(
			a \tilde q_{\omega\sigma\alpha} \tilde q_{\omega\sigma\beta} / \delta t 
		\big)^2 
	\bigg).
\end{aligned}
\end{align}
And when I get back to this problem, I should also investigate more what I actually want as the result.\,. 

\ldots\ Ha. Ah, now I know what's wrong. I cannot sum over $\omega$ (again because of the $\tilde q_\omega$s). .\,.\,So I'm back to
\begin{align}
\begin{aligned}
	&\sum_{\omega}
		\Big(
			\big(1 - \cos(\omega\delta t)\big) \tilde q_{\omega 1\alpha}  / \delta t +
			\sin(\omega\delta t) \tilde q_{\omega-1\alpha} / \delta t -
			a \tilde q_{\omega 1\beta}
		\Big)^2 
		\delta t\\
	+&\sum_{\omega}
		\Big(
			\big(1 - \cos(\omega\delta t)\big) \tilde q_{\omega-1\alpha}  / \delta t -
			\sin(\omega\delta t) \tilde q_{\omega 1\alpha} / \delta t -
			a \tilde q_{\omega-1\beta}
		\Big)^2 
		\delta t.
\end{aligned}
\end{align}
.\,.\,And for small $\delta t$, this becomes approximately
\begin{align}
\begin{aligned}
	&\sum_{\omega}
		\Big(
			\omega \tilde q_{\omega 1\alpha} +
			\omega \tilde q_{\omega-1\alpha} -
			a \tilde q_{\omega 1\beta}
		\Big)^2 
		\delta t\\
	+&\sum_{\omega}
		\Big(
			\omega \tilde q_{\omega-1\alpha} -
			\omega \tilde q_{\omega 1\alpha} -
			a \tilde q_{\omega-1\beta}
		\Big)^2 
		\delta t\,.\,.
\end{aligned}
\end{align}
\ldots Hm, and this is equal to.\,. .\,.\,Hm, and let me write this as 
\begin{align}
\begin{aligned}
	&\sum_{\omega}
		\Big(
			\omega \tilde q_{\omega 1\alpha} +
			\omega \tilde q_{\omega-1\alpha} -
			a \tilde q_{\omega 1\beta}
		\Big)^2 
		\delta t\\
	+&\sum_{\omega}
		\Big(
			-\omega \tilde q_{\omega 1\alpha} +
			\omega \tilde q_{\omega-1\alpha} -
			a \tilde q_{\omega-1\beta}
		\Big)^2 
		\delta t
\end{aligned}
\end{align}
first.\,. Then we can see that it is equal to
\begin{align}
\begin{aligned}
%	&\sum_{\omega} \Big(
%		\big(
%			\omega \tilde q_{\omega 1\alpha} -
%			a \tilde q_{\omega 1\beta}
%		\big)^2
%		+
%		\big(
%			\omega \tilde q_{\omega 1\alpha} +
%			a \tilde q_{\omega 1\beta}
%		\big)^2
%		+
%		2\big(
%			\omega \tilde q_{\omega-1\alpha}  -
%			a \tilde q_{\omega 1\beta}
%		\big)^2
%	\Big)
%	\delta t\,.\,.
	&\,\sum_{\omega} \Big(
		2(\omega \tilde q_{\omega 1\alpha})^2 
		+
		2(\omega \tilde q_{\omega-1\alpha})^2
		+
		2(a \tilde q_{\omega 1\beta})^2
		-
		4 \omega a \tilde q_{\omega-1\alpha} \tilde q_{\omega 1\beta}
	\Big)
	\delta t \\
	=&\,2\sum_{\omega} \Big(
		(\omega \tilde q_{\omega 1\alpha})^2 +
		(\omega \tilde q_{\omega-1\alpha} - a \tilde q_{\omega 1\beta})^2
	\Big).
\end{aligned}
\end{align}
This, finally, looks much more like something I would expect.\,.\,! .\,.\,Ah, but there is an error (which is good, since it it isn't actually what we wood expect exactly.\,.). I overlooked the $-1$ in the last $\beta$ term. So instead we get
\begin{align}
\begin{aligned}
	&\,\sum_{\omega} \Big(
		2(\omega \tilde q_{\omega 1\alpha})^2 
		+
		2(\omega \tilde q_{\omega-1\alpha})^2
		+
		(a \tilde q_{\omega 1\beta})^2		
		+
		(a \tilde q_{\omega-1\beta})^2\\
		&\,-
		2\omega a \tilde q_{\omega 1\alpha} \tilde q_{\omega 1\beta}
		-
		2\omega a \tilde q_{\omega-1\alpha} \tilde q_{\omega 1\beta}
		+
		2\omega a \tilde q_{\omega 1\alpha} \tilde q_{\omega-1\beta}
		-
		2\omega a \tilde q_{\omega-1\alpha} \tilde q_{\omega-1\beta}
	\Big)
	\delta t \\
	=&\,\sum_{\omega} \Big(
		(\omega \tilde q_{\omega 1\alpha} - a \tilde q_{\omega 1\beta})^2 +
		(\omega \tilde q_{\omega 1\alpha} + a \tilde q_{\omega-1\beta})^2 +
		(\omega \tilde q_{\omega-1\alpha} - a \tilde q_{\omega 1\beta})^2 +
		(\omega \tilde q_{\omega-1\alpha} - a \tilde q_{\omega-1\beta})^2
	\Big).
\end{aligned}
\end{align}
Nice, and that's a result we can get behind.\,!\,.\,. .\,.\,Hm, we can shorten this a bit as
\begin{align}
\begin{aligned}
	\sum_{\omega, \sigma} \Big(
		(\omega \tilde q_{\omega 1\alpha} - \sigma a \tilde q_{\omega\sigma\beta})^2 +
		(\omega \tilde q_{\omega-1\alpha} - a \tilde q_{\omega \sigma\beta})^2 
	\Big).
\end{aligned}
\end{align}

.\,.\,Hm, it's still not exactly what I would expect.\,. 
\ldots Oh, wait! I thought about the fact that I actually have to have a constant $q_{0\alpha}$, and then I looked and saw/recalled that $q_{M\alpha}$ also has to be constant. And then I realized: maybe we should expand only in terms of sine functions, then!\,.\,. .\,.\,Yeah, that must be the pragmatic solution. And this should luckily not interfere with the Lorentz argument (since sine waves transform to sine wave).\,.\,:) (.\,.\,This seems like such a minor thing to be happy about, but it is rather important that get this done --- at least compared to the time it.\,. \emph{should} take.\,. so it's nice if (.\,.\,\emph{if}.\,.) I'm on the track to good, neat solution now.\,. Let's hope.\,.) 

Okay, so we are in a sense back to 
\begin{align}
\begin{aligned}
	\sum_{m=1}^{M}
%		\frac{1}{2}\tilde m 
		\bigg( 
			\sum_{\omega} 
				\tilde q_{\omega\alpha}
				f_{\omega}(m\delta t) 
				/ \delta t 
			- 
			\sum_{\omega'} 
				\tilde q_{\omega'\alpha}
				f_{\omega'}((m-1) \delta t) 
			 	/ \delta t 
			- 
			a \sum_{\omega''} 
				\tilde q_{\omega''\beta}
				f_{\omega''}(m \delta t) 
		\bigg)^2 
		\delta t,
\end{aligned}
\end{align}
but now.\,. oh, let me just erase the $\sigma$s then.\,. Now the $f_\omega$s are (normalized) sine functions. And then we just get
\begin{align}
\begin{aligned}
	\sum_{m=1}^{M} \sum_{\omega}
		\Big(
			\big(1 - \cos(\omega\delta t)\big) \tilde q_{\omega-1\alpha}  / \delta t -
			a \tilde q_{\omega-1\beta}
		\Big)^2 
		c^2 \sin^2(\omega m \delta t)
		\delta t,
\end{aligned}
\end{align}
since we only have the $\sin(\omega (m-1)\delta t) = \sin(\omega m \delta t)\cos(\omega \delta t) - \cos(\omega m \delta t)\sin(\omega \delta t)$ addition formula in play, and since the $\cos(\omega m \delta t)$ term vanishes under the sum. .\,.\,This looks \emph{so} much nicer.\,. And if we want to see what happens when $\delta t$ is much smaller than $\omega^{-1}$, we can see that here we will approximately get
\begin{align}
\begin{aligned}
	\sum_{\omega}
		\Big(
			\omega \tilde q_{\omega-1\alpha} -
			a \tilde q_{\omega-1\beta}
		\Big)^2 
		\delta t,
\end{aligned}
\end{align}
which.\,. hm.\,. .\,.\,Well, this is a bit hard to compare to anything.\,. Oh, maybe the cosine doesn't actually die/vanish, then.\,. Let me see.\,. .\,.\,Hm, maybe it's a bad choice to use only sine functions.\,.(?\,.\,.) \ldots Yeah, it's better to have both sine and cosine, and then simply just include $q_{0\alpha}$ and $q_{M\alpha}$ in the path integral and time the integrand with $\psi_0(q_{0\alpha})$. And since we sum over $m$ and not $\omega$, this should be absolutely fine.\,. 

\ldots\ D'oh! Oh, what a waste of time.\,. Of course $\lim_{\delta t\to 0}(1-\cos(\omega \delta t)) / \delta t$ isn't $\omega$.\,.\,! It's 0. .\,.\,Oh well, this is just how things go.\,. 
.\,.\,So what I get instead is
\begin{align}
\begin{aligned}
	&\sum_{\omega}
		\Big(
			\omega \tilde q_{\omega-1\alpha} -
			a \tilde q_{\omega 1\beta}
		\Big)^2 
		\delta t\\
	+&\sum_{\omega}
		\Big(
			-\omega \tilde q_{\omega 1\alpha} -
			a \tilde q_{\omega-1\beta}
		\Big)^2 
		\delta t,
\end{aligned}
\end{align}
which is exactly what we would hope for. Okay, nice. It took a little longer to get this confirmation than it should, but I'm just glad I'm here at last (today has really felt slow.\,.).\,. 

.\,.\,Okay, and can we then see that each $\omega$ contribution must converge in a nice way, when $\omega_{max}$ tends to infinity.\,.\,? .\,.\,This is the result before the approximation (except perhaps some approximation about $q_0$ and $q_M$):
\begin{align}
\begin{aligned}
	&\sum_{\omega}
		\Big(
			\big(1 - \cos(\omega\delta t)\big) \tilde q_{\omega 1\alpha}  / \delta t +
			\sin(\omega\delta t) \tilde q_{\omega-1\alpha} / \delta t -
			a \tilde q_{\omega 1\beta}
		\Big)^2 
		\delta t\\
	+&\sum_{\omega}
		\Big(
			\big(1 - \cos(\omega\delta t)\big) \tilde q_{\omega-1\alpha}  / \delta t -
			\sin(\omega\delta t) \tilde q_{\omega 1\alpha} / \delta t -
			a \tilde q_{\omega-1\beta}
		\Big)^2 
		\delta t.
	\label{eq_3.66}
\end{aligned}
\end{align}
.\,.\,Hm well, of course.\,. .\,.\,Hm, I can't see anything that would hinder my Lorentz argument, but I feel like I'm forgetting something.\,. %..(It's also late now (twenty minutes to ten), as I started quite late today; I started around twelve today..)
.\,.\,Hm no; the concern was just that there would be many small couplings, such that adding more $\omega$s would also introduce a greater number of errors, even though these would get smaller and smaller. But at least if $q_0$ and $q_M$ does not cause to much trouble, the only small coupling is between pairs of $\tilde q_{\omega 1\alpha}, \tilde q_{\omega 1\beta}$ and $\tilde q_{\omega-1\alpha}, \tilde q_{\omega-1\beta}$. So nothing to worry about, if just $q_0$ and $q_M$ are not too troublesome.\,. 

%(Kl. kvart i ni.) Hov, det kan være, jeg har lavet en fejl i mit stiintegrale, men jeg er for ristet nu, så jeg tager lige en pause (eller holder fri)..


%(Kl. 25 over tolv)
(11.04.22) Okay, I think I know roughly what to do now, but I need to calculate a bit first, so here we go.\,. If we make sure to integrate over $q_0$ in the path integral.\,. Hm, and I guess we \emph{could} also integrate over $q_M$ if we want to, and just leave the coordinate out of the Fourier transform.\,. .\,.\,But yeah, then we might as well see it as a constant for now, sure.\,. (.\,.\,I think I prefer having $q_0$ as the more natural part of the variable path, since we could think about wanting to do a measurement at $t$ (and thus on $q_M$).\,.) And now, when we do the sum of 
\begin{align}
\begin{aligned}
	\sum_{m=1}^{M}
%		\frac{1}{2}\tilde m 
		\bigg( 
			\sum_{\omega, \sigma} 
				\tilde q_{\omega\sigma\alpha}
				f_{\omega \sigma}(m\delta t) 
				/ \delta t 
			- 
			\sum_{\omega', \sigma'} 
				\tilde q_{\omega'\sigma'\alpha}
				f_{\omega' \sigma'}((m-1) \delta t) 
			 	/ \delta t 
			- 
			a \sum_{\omega'', \sigma''} 
				\tilde q_{\omega''\sigma''\beta}
				f_{\omega'' \sigma''}(m \delta t) 
		\bigg)^2 
		\delta t,
\end{aligned}
\end{align}
we get.\,.
\begin{align}
\begin{aligned}
	&\sum_{m=1}^{M} \sum_{\omega}
		\Big(
			\big(1 - \cos(\omega\delta t)\big) \tilde q_{\omega 1\alpha}  / \delta t +
			\sin(\omega\delta t) \tilde q_{\omega-1\alpha} / \delta t -
			a \tilde q_{\omega 1\beta}
		\Big)^2 
		c^2 \cos^2(\omega m \delta t)
		\delta t\\
	+&\sum_{m=1}^{M} \sum_{\omega}
		\Big(
			\big(1 - \cos(\omega\delta t)\big) \tilde q_{\omega-1\alpha}  / \delta t -
			\sin(\omega\delta t) \tilde q_{\omega 1\alpha} / \delta t -
			a \tilde q_{\omega-1\beta}
		\Big)^2 
		c^2 \sin^2(\omega m \delta t)
		\delta t\\
	-&\sum_{\omega}
		\bigg( 
			\sum_{\omega, \sigma} 
				\tilde q_{\omega\sigma\alpha}
				f_{\omega \sigma}(M\delta t) 
				/ \delta t 
			- 
			\sum_{\omega', \sigma'} 
				\tilde q_{\omega'\sigma'\alpha}
				f_{\omega' \sigma'}((M-1) \delta t) 
			 	/ \delta t 
			- 
			a \sum_{\omega'', \sigma''} 
				\tilde q_{\omega''\sigma''\beta}
				f_{\omega'' \sigma''}(M \delta t) 
		\bigg)^2 
		\delta t\\
	+&\sum_{\omega}
		\bigg( 
			q_{M\alpha}	/ \delta t 
			- 
			\sum_{\omega', \sigma'} 
				\tilde q_{\omega'\sigma'\alpha}
				f_{\omega' \sigma'}((M-1) \delta t) 
			 	/ \delta t 
			- 
			a q_{M\beta}
		\bigg)^2 
		\delta t.
	\label{eq_3.68}
\end{aligned}
\end{align}
.\,.\,Yeah, hopefully this is the way to go.\,. .\,.\,Okay, and then this error (of the last two lines).\,.\, which I guess we should also try to shorten a bit --- maybe by also summing over $\omega$, but let's see.\,. \ldots No, not that.\,. Well, anyway, this error is what tells us, basically, how to couple the $\{\tilde q_{\omega\sigma\alpha}\}$-field to a final state.\,. .\,.\,Okay, and the idea is of course that since the $\{\tilde q_{\omega\sigma\alpha}\}$-path has $M$ variables (from $q_0$ trough $q_{M-1}$), that is how we.\,. well, first, that is how we get the first two lines (since now all the $f$s are orthogonal under the $m\in\{1, \ldots, M\}$ sum), and it is also why these two lines can be rewritten as what we have in eq.\ (\ref{eq_3.66}). .\,.\,Okay, and this is where I now look at the error and conclude that this causes no trouble when $\omega_{max}$ grows large, let's see.\,. 
\ldots Hm, I guess the term does get a bit complicated in the $\omega_{max}\to \infty$ limit.\,. .\,.\,Yeah.\,. %(Kl. 25 i to.) (Det går lidt langsomt i dag med tænkeren, synes jeg..)

%(Kl. ti over to.)
\ldots\ Hm, it actually does seem a bit.\,. not-easy, this problem, but I just got the idea that maybe you could add and subtract a $((q_{0\alpha} - q_{M\alpha})/ \delta t - a q_{0\beta})^2$ term.\,. .\,.\,Yeah, that would at least make the expression prettier, if nothing else.\,. This would then make us able to let the sum run from $m=0$ to $m=M$, where we then just subtract the $m=0$ term again.\,. .\,.\,Hm, but the problem is still quite complicated, actually, from there.\,.\,:\textbackslash\,.\,. .\,.\,But it's still nice to have the problem reduced to a single $((q_{0\alpha} - q_{M\alpha})/ \delta t - a q_{0\beta})^2$ term, even though this still gets complicated when we look at ``what happens when $\omega_{max}$ grows and grows?''.\,. .\,.\,Hm, and that term \emph{can} now be expanded as well.\,. .\,.\,Hm, maybe we actually want to do that, cause we want to investigate how the $\tilde q_\omega$s couple in this term.\,. .\,.\,Hm well, we will just get all kinds of cross terms.\,. .\,.\,Ah, but we want to do a Gaussian integration! And here we can note that the fermion propagator is decoupled from the term.\,.\,:)\,.\,. Okay, let's see.\,. %(Kl. 25 over to.)
.\,.\,Hm, and I guess this will be a kind of Gaussian integral where we have a non-diagonal (positive definite) $A$-matrix.\,. .\,.\,Okay, this smells like a possible road to a solution.\,. 

.\,.\,Okay, so what we have exactly is
\begin{align}
\begin{aligned}
	&\,\bigg( 
		\sum_{\omega} 
			\tilde q_{\omega 1\alpha} 
			/ \delta t 
		- 
		\sum_{\omega'} \big(
			\cos(\omega' \delta t)) \tilde q_{\omega' 1\alpha} -
			\sin(\omega' \delta t)) \tilde q_{\omega'-1\alpha}
		\big) / \delta t 
		- 
		a \sum_{\omega''} 
			\tilde q_{\omega'' 1\beta}
	\bigg)^2 
	\delta t %*Lad mig lige forkorte dette yderligere:
	\\
	=&\,\bigg( 
		\sum_{\omega} 
			(1 - \cos(\omega \delta t)) \tilde q_{\omega 1\alpha} 
			/ \delta t 
		+ 
		\sum_{\omega} \big(
			\sin(\omega \delta t)) \tilde q_{\omega-1\alpha}
		\big) / \delta t 
		- 
		a \sum_{\omega} 
			\tilde q_{\omega 1\beta}
	\bigg)^2 
	\delta t
\end{aligned}
\end{align}
.\,.\,So the %diagonal elements of 
$A_{\omega 1\alpha\omega' 1\alpha}$ matrix elements are given by (let us ignore the $\delta t$ at the back and put it on again later.\,.)
\begin{align}
\begin{aligned}
	A_{\omega 1\alpha\omega' 1\alpha} = 
		(1 - \cos(\omega \delta t)) (1 - \cos(\omega' \delta t))
%		\tilde q_{\omega 1\alpha} \tilde q_{\omega' 1\alpha}.
\end{aligned}
\end{align}
And for the $A_{\omega-1\alpha\omega'-1\alpha}$ matrix elements, we have
\begin{align}
\begin{aligned}
	A_{\omega 1\alpha\omega'-1\alpha} = 
		\sin(\omega \delta t) \sin(\omega' \delta t)
%		\tilde q_{\omega-1\alpha} \tilde q_{\omega'-1\alpha}.
\end{aligned}
\end{align}
And for the $A_{\omega 1\alpha\omega'-1\alpha}$ matrix elements, we have
\begin{align}
\begin{aligned}
	A_{\omega 1\alpha\omega'-1\alpha} = 
		(1 - \cos(\omega \delta t)) \sin(\omega' \delta t)
%		\tilde q_{\omega 1\alpha} \tilde q_{\omega'-1\alpha},
\end{aligned}
\end{align}
and a similar thing for the $A_{\omega-1\alpha\omega' 1\alpha}$s.\,. .\,.\,And then we also have 
\begin{align}
\begin{aligned}
	A_{\omega 1\alpha\omega' 1\beta} =&\, 
		-a (1 - \cos(\omega \delta t))\\
	A_{\omega-1\alpha\omega' 1\beta} =&\, 
		-a \sin(\omega \delta t),
\end{aligned}
\end{align}
and similar expressions for the $A_{\omega 1\beta\omega'\sigma'\alpha}$ elements.\,. 
.\,.\,Okay, and technically, one should now check that $A$ is positive definite, and find the inverse, I guess.\,. %(Kl. tre.)
.\,.\,Hm, the positive definiteness is trivial since.\,. well, let me just check the exact defining property, just to be sure.\,. .\,.\,Right; what I thought. And since $\tilde{\boldsymbol{q}}^\dagger A \tilde{\boldsymbol{q}}$ is just.\,. .\,.\,Hm, it is just the expression from above, right.\,.\,? .\,.\,Yes, of course. And this is of course always.\,. well, at least it is non-negative.\,. .\,.\,Oh, ``for every non-zero vector'' it has to be positive.\,. .\,.\,Hm, but I guess we can't quite ensure that for all $\tilde{\boldsymbol{q}}$.\,. .\,.\,Hm.\,. .\,.\,Hm, it's zero exactly when the error term vanishes, though.\,. %(Kl. kvart over tre.)
.\,.\,Hm, now I'm thinking a bit about adding imaginary constants.\,.  

%(Kl. halv fire.)
\ldots Hm, but maybe it's just a matter of arguing that all these terms tend to 0 when at least one of the $\omega,\omega'$ pair is.\,. Well, they will all always be greater than some $\sim 1/ t$ constant (while $\delta t$ can get infinitely small).\,. .\,.\,Hm, there \emph{will} then be more and terms in $A$, but.\,.(?\,.\,.) 

.\,.\,Hm, should I try to diagonalize $A$.\,.\,? .\,.\,Hm, maybe I should try to find a CAS program.\,. .\,.\,Hm, I actually have some Maple-like one (Xcas), but maybe it's too much work to get started on.\,. .\,.\,Hm, how about finding ``approximate eigenvectors'' instead.\,.\,?\,.\,. 

.\,.\,Hm, if I perturb/Taylor-expand it to first order, we actually see that only the $A_{\omega 1\alpha\omega'-1\alpha}$s, the $A_{\omega- 1\alpha\omega' 1\alpha}$s, the $A_{\omega-1\alpha\omega' 1\beta}$s and the $A_{\omega 1\beta\omega'-1\alpha}$s do not vanish.\,. .\,.\,Unless we also wanna include the $A_{\omega 1\alpha\omega'-1\alpha}$ term (somehow).\,. .\,.\,We can also view this is looking at
\begin{align}
\begin{aligned}
	&\,\bigg( 
		\sum_{\omega} 
			(1 - \cos(\omega \delta t)) \tilde q_{\omega 1\alpha} 
			/ \delta t 
		+ 
		\sum_{\omega} \big(
			\sin(\omega \delta t)) \tilde q_{\omega-1\alpha}
		\big) / \delta t 
		- 
		a \sum_{\omega} 
			\tilde q_{\omega 1\beta}
	\bigg)^2 
	\delta t
	\\
	\to&\,\bigg(
		\sum_{\omega} \big(
			\omega \delta t \tilde q_{\omega-1\alpha}
		\big) / \delta t 
		- 
		a \sum_{\omega} 
			\tilde q_{\omega 1\beta}
	\bigg)^2 
	\delta t
\end{aligned}
\end{align}
instead, I guess.\,. .\,.\,Hm, and we could change the $\to$ for a $=$ if we then add a $O(\delta t^2)$ (formal) term, I guess.\,. .\,.\,Or.\,. Oh wait, let me actually just expand to second order to begin with and write
\begin{align}
\begin{aligned}
	\bigg(
		\sum_{\omega} 
			\frac{1}{2} \omega^2 \delta t \tilde q_{\omega 1\alpha} 
		+ 
		\sum_{\omega} \big(
			\omega  \tilde q_{\omega-1\alpha}
		\big)
		- 
		a \sum_{\omega} 
			\tilde q_{\omega 1\beta}
	\bigg)^2 
	\delta t
	+
	O(\delta t^2) \delta t.
\end{aligned}
\end{align}
And I can then also write 
\begin{align}
\begin{aligned}
	\bigg(
		\sum_{\omega} \big(
			\omega  \tilde q_{\omega-1\alpha}
		\big)
		- 
		a \sum_{\omega} 
			\tilde q_{\omega 1\beta}
	\bigg)^2 
	\delta t
	+
	O(\delta t) \delta t,
\end{aligned}
\end{align}
if we can get away with just using that.\,. %(Kl. ti over fire.)

.\,.\,Hm, can we reason about the eigenvectors in regards to whether we need the $\omega^2\delta t$ term or not.\,.\,? %..I need a break.. (Kl. tyve over fire.)

%(Kl. 25 over seks.)
\ldots\ Okay, maybe, instead of trying to get rid of the ``error'' term, I should embrace it.\,. .\,.\, Oh, and I should also mention in regards to the previous work: $\delta t$ should of course be compared to $\omega^{-1}$, not $\omega$ (like I have noted before). But never mind all that now, cause I think I'm onto something better now.\,. .\,.\,The idea I have now is that we can just see this error as a ``cost'' of jumping on and off a path, so to speak.\,. .\,.\,It might make more sense to then keep.\,. no, let's see what the options are.\,. .\,.\,Hm no, it's probably best to stick to this approach, namely where both $q_0$ and $q_M$ are part of the (Fourier-transformed) lattice, and where we then get the $((q_{0\alpha} - q_{M\alpha})/ \delta t - a q_{0\beta})^2\delta t$ boundary term.\,. .\,.\,Or $-((q_{0\alpha} - q_{M\alpha})/ \delta t - a q_{0\beta})^2\delta t$, rather.\,. .\,.\,I have been thinking that we might wnat this term to be Lorentz-invariant, but maybe I should get back to considering, if we can't simply use that this goes approximately as $\sim q_{0\alpha} / \delta t - q_{M\alpha} / \delta t$.\,.\,? .\,.\,Hm no, this will probably not make sense.\,. .\,.\,Oh, and it's $\sim (q_{0\alpha} - q_{M\alpha})^2 / \delta t$ instead.\,. .\,.\,Hm, why don't I just integrate over $q_{0\alpha}$ and.\,. Oh, because then the can't be part of the Fourier transformation.\,. \ldots Hm, maybe I should let $q_M$ be and only Fourier-transform the rest.\,. And then I get a kind of ``jumping-off-the-path error''.\,. .\,.\,Or phase shift, I guess I should say, not error.\,. .\,.\,Hm, and then we would be back to looking at eq.\ (\ref{eq_3.68}).\,.

.\,.\,Let me just copy it:
\begin{align}
\begin{aligned}
	&\sum_{m=1}^{M} \sum_{\omega}
		\Big(
			\big(1 - \cos(\omega\delta t)\big) \tilde q_{\omega 1\alpha}  / \delta t +
			\sin(\omega\delta t) \tilde q_{\omega-1\alpha} / \delta t -
			a \tilde q_{\omega 1\beta}
		\Big)^2 
		c^2 \cos^2(\omega m \delta t)
		\delta t\\
	+&\sum_{m=1}^{M} \sum_{\omega}
		\Big(
			\big(1 - \cos(\omega\delta t)\big) \tilde q_{\omega-1\alpha}  / \delta t -
			\sin(\omega\delta t) \tilde q_{\omega 1\alpha} / \delta t -
			a \tilde q_{\omega-1\beta}
		\Big)^2 
		c^2 \sin^2(\omega m \delta t)
		\delta t\\
	-&\sum_{\omega}
		\bigg( 
			\sum_{\omega, \sigma} 
				\tilde q_{\omega\sigma\alpha}
				f_{\omega \sigma}(M\delta t) 
				/ \delta t 
			- 
			\sum_{\omega', \sigma'} 
				\tilde q_{\omega'\sigma'\alpha}
				f_{\omega' \sigma'}((M-1) \delta t) 
			 	/ \delta t 
			- 
			a \sum_{\omega'', \sigma''} 
				\tilde q_{\omega''\sigma''\beta}
				f_{\omega'' \sigma''}(M \delta t) 
		\bigg)^2 
		\delta t\\
	+&\sum_{\omega}
		\bigg( 
			q_{M\alpha}	/ \delta t 
			- 
			\sum_{\omega', \sigma'} 
				\tilde q_{\omega'\sigma'\alpha}
				f_{\omega' \sigma'}((M-1) \delta t) 
			 	/ \delta t 
			- 
			a q_{M\beta}
		\bigg)^2 
		\delta t.
\end{aligned}
\end{align}
And the idea would then be (not that I have let go of my other idea.\,.) to integrate over the two $q_M$s.\,. .\,.\,Hm, and we should be able to do this integral just the way that we (or I, rather) are/am used to; we shouldn't need any theory about the $A$-matrix and so on.\,. \ldots Hm, would a double Gaussian integral like that, i.e.\ like $(x + b + y)$, wouldn't that integrate to something that does not depend on $b$, namely since you get an exponent like $(b + y)^2$ from the first integration.\,.\,? .\,.\,Hm, I guess not cause that can't really be.\,. .\,.\,I also shouldn't really need to integrate over the $q_M$s, should I.\,.\,? 

Hm, let me go back to what I thought about in the last paragraph before the previous one.\,. .\,.\,Well, like me actually just think afk for a bit; I feel like there should be some simple solution that I either haven't quite reached yet, or which is something very different from the track I'm on right now.\,. %(Kl. halv otte.)

%(Kl. 25 over otte.)
\ldots\ Oh, maybe there \emph{is} a really simple solutiom.\,..\,!\,.\,. I had a thought back on some earlier work on the path integral where I seemed to miss a $\boldsymbol{p}\cdot \boldsymbol{q}$ at one of the boundaries. And that got me thinking about putting a $\int d\boldsymbol{q}\, \ket{\boldsymbol{q}}\bra{\boldsymbol{q}}$ right after the $\bra{\boldsymbol{q}_M}$ from the left, and now I'm (therefore) thinking: Why don't we just let $q_M$ ``vary'' and have it as part of the Fourier transformed path coordinates, but then simply put in a Kronecker's delta, or something to that effect, at the end.\,.\,?\,!(.\,.\,?) .\,.\,Hm, it kinda seems like it would work when I think about it.\,. .\,.\,Hm, or am I overlooking something.\,.\,? .\,.\,Hm, perhaps not, cause if we look at a particular path, then the exponent should be exactly what I have been working with.\,. .\,.\,Hm, let me look at the above equations for a moment.\,. .\,.\,No, the sine/cosine functions and the $m$-summation does not care whether the $\tilde q$s adhere to some constraint, right?\,.\,. .\,.\,No. .\,.\,Oh, wait is this actually any different from what I was dealing with to (sort of) begin with.\,.\,? .\,.\,Hm, I do indeed have $M$.\,. .\,.\,Ah, but then $m=1$ term will be wrong, so we have to subtract and add; the same situation as before.\,. .\,.\,Hm, but if we put a Kronecker's delta in both ends and add and subtract (where the latter is what we will then be left with) the $((q_{0\alpha} - q_{M\alpha})/ \delta t - a q_{0\beta})^2\delta t$ term, aren't we just able to integrate over the non-transformed $q_0$ and $q_M$ then at the end.\,.\,? .\,.\,Yeah, that must be so.\,. .\,.\,And then this is just a simple Gaussian integral (for all $\alpha$).\,. %.\,.\,Hm, I guess I need to take a break and.\,. ``hum'' over it (in my head), as I often call it in Danish.\,. (.\,.\,To sort of let it run a bit in the back of my mind and pull it back and forth, while I also do other things *(that way, you keep resetting your mind, almost, and you also reconstitute some brain.\,. power.\,.).\,.) %(Kl. fem i ni.) %(Det her kan ligeså godt stå herude i kommentarerne, så jeg udkommenterer lige..)

(12.04.22) Okay, I think I might finally be sort of seeing the solution.\,. It only took me 29 years to get there\,;) (hopefully), but yeah, I might finally have it.\,. I think I need to let the point for $m\in\{0,\ldots,M-1\}$ vary and be part of the Fourier transform, and then put in a Kronecker's delta for the $m=0$ boundary. Oh, and I should also mention that my $((q_{0\alpha} - q_{M\alpha})/ \delta t - a q_{0\beta})^2\delta t$ result is most likely wrong, as it is not full wave lengths that divide $t$. So $f(M)$ is not close to $f(0)$ in other words.\,. Anyway, let me get back to the solution that I am now hopeful for. The $m=M$ point is kept constant. The idea is then to look at small ``path volume'' around a certain path described by finite range of $\omega$s. .\,.\,Well actually it is specifically the $q_{M-1}$-value that we want to look at volume/interval for, I guess.\,. .\,.\,.And then the idea is that only the small volume/interval of the $q_{M-1}$-value around the $q_M$ point --- which I guess can be discretized also.\,. yes.\,. --- then it's only that volume that will contribute with something non-vanishing when $\delta t\to 0$ (including more and more $\omega$s outside of the initial range). And the factor obtained after all this integration, which might have a complex norm different from 1, by the way, should, as I see it%..Hvordan siger man 'umiddelbart' på engelsk..?
, not depend on either the $\tilde q_\omega$-values for the $\omega$s within the initial range or (hopefully) on the.\,. well on $q_M$.\,. %(Kl. 25 over elleve.)

.\,.\,Hm, and I guess we must be able to prove, actually, that said factor must approach 1 when the initial range of $\omega$s grows.\,. (.\,.\,Namely if the factor is constant for all $q_M$.\,.) .\,.\,Yeah, that sounds about right.\,. .\,.\,Oh, how awesome it would be if this holds --- it seems like it will; it seems very reasonable.\,. (7, 9, 13.\,.) %(Kl. halv tolv.)

%(Kl. tyve over tolv.)
\ldots\ Hm, maybe I should then just, from there, actually use another td.p.t.\ argument, first to say that the underlying (growing) $\omega$ range can approach infinity without it disturbing the fermionic wave functions, and then use the previous td.p.t.\ argument on top of that to argue that for the fixed ``initial $\omega$ range'' (which gives a discrete lattice Fourier space (of paths), but where each discrete path value still corresponds to a continuous field when the ``underlying $\omega$ range has approached infinity), we are also allowed to remove a handful of $(\omega, \boldsymbol{k})$ points from near the $k_1$-boundaries. .\,.\,Hm, if there is a good td.p.t. argument for the former (as well), then I think this will just be the solution I will propose for the article.\,.\,:)\,.\,. .\,.\,Hm, but I guess we can't dodge the on-shell waves, then.\,. .\,.\,Let me think if there isn't a more clean argument, like I have concluded before --- and which I ought to check anyway.\,. %(Kl. halv et.)
.\,.\,Hm, there might (very well) be an error on the ``factor'' which is now (since we haven't here assumed the fermion propagator is (approximately) decoupled, like I had in the work above of the last two days) actually a fermionic propagation operator, but this error converges (right.\,.\,?) when the ``underlying $\omega$ range'' tends to infinity (starting from the initial one and growing from there).\,. .\,.\,Hm, which means that it approaches the identity operator, I guess, for the initial range going to infinity, but.\,. Ah, and if we can then argue, that this limit is converges at sort of the same rate regardless of how large $k_{1 max}$ is.\,.\,!\,.\,. %(Kl. tyve i et.)
.\,.\,Hm, and we shouldn't use perturbation theory for this, but it definitely sounds like it would be possible (some other way).\,.\,!\,.\,. 
.\,.\,Hm, I should figure out the exact reason why it converges --- hopefully by arguing about the path integral --- and then I can hopefully see why, at an appropriately large $\omega_{max}$, $k_{1 max}$ is then free to turned up arbitrarily high (becoming arbitrarily large, i.e.) from there.\,. %..Hm, I might take a break (and a walk) and gather some "brain power" to look at this matter..:)

%(Kl. ti i syv.) Gik en tur, tog en (halv-)lur, gik en tur igen, og der slog en mulig løsning mig pludselig: (..Nå, min mor ringede lige, så vi skriver (Kl. syv) i stedet.:))
\ldots\ Maybe, I have finally found an adequate argument. I had the idea a bit earlier (on a walk) that I should just look and compare with a simple (two-state, maybe just) Hamiltonian and look at the transition rate for those. Of course the transition rate (in terms of the wave-function amplitude) will be linearly proportional with the potential-wave amplitude. And if this goes as $1/(\omega k)$ like I have sort of calculated before, and.\,. Well, in simple terms, when we sum over all errors from removing $(\omega, \boldsymbol{k})$-points, namely to match the $(\omega', \boldsymbol{k}')$-volume, then I'm pretty sure that we will find (heuristically (at first, at least.\,.)) that these errors sum to something smaller and smaller for increasing $\omega_{max}$- and $k_{1 max}$-boundaries (where the on-shell points are now in the two corners (and on the diagonal line) of the two $(\omega, \boldsymbol{k})$-volumes, just to note.\,. or at least I \emph{think} this will be beneficial to have for this error-sum argument.\,.). .\,.\,This will not be the most elegant solution ever, and I don't mind mentioning that, but it is absolutely \emph{fine} for my case (as I of course can't keep going on %with 
working on 
this).\,.\,!\,:) .\,.\,Hm, but I think I will just be happy with today and start looking more into this argument tomorrow.\,.\,\textasciicircum\textasciicircum


%(Kl. halv tolv.)
(13.04.22) I actually feel pretty confident, that this argument will hold up. And I also actually feel like going back to work on the draft again today, so let me do that and then I can maybe just return to this argument when I get there in the draft.\,. 

.\,.\,Hm, there \emph{is} still the Trotter expansion to consider, though.\,.
\ldots Hm, could you do something like splitting the free propagator up and handing out parts of the three relevant free-energy propagators to each $\hat H_{\boldsymbol{k}}$.\,.\,? %(Kl. tolv.)
.\,.\,Hm, but all fermion propagators are then relevant for each $\boldsymbol{k}$.\,. .\,.\,Hm, my trouble is, that if I do just a simple double Trotter like I have thought of before, where the fermion propagator is kept out at a larger discretization grain, then the argument from yesterday doesn't immediately work in the case of points with a large $k_1$ and a small $\omega$.\,. 

%(Kl. ti i et.)
\ldots\ Hm, I actually think that I can just use the approach that I had in mind when writing the current (unfinished) version af the path integral section of my \texttt{draft0}, where I thus simply notice that there is an error when going from the phase-space path integral to the neat configuration-space one, but that this error tends very rapidly to zero if we keep reducing $\delta t$ while also then increasing $\|\hat \Pi\|$ and (if need be) $\|\hat Q\|$ (or what we want to call it). The reason why this works is then that we are allowed to increase $\|\hat \Pi\|$ and $\|\hat Q\|$ at a polynomial rate, when $\delta t^{-1}$ grows, which means that the error of the Gaussian integral from going phase space $\to$ configuration space will decrease at some exponential-like rate (i.e.\ like the so-called error function (err)). And then, when doing the Lorentz-invariance argument, we can argue that the $(\omega, \boldsymbol{k})$ modes must be decoupled down to a small error which vanishes rapidly enough when $\omega_{max}$ grows, that we can effectively say that all the modes are more and more decoupled, even though we also add more modes to the mix when $\delta t$ is reduced. %(Kl. fem over et.) 

.\,.\,This argument must be good enough; let's go.\,. 

.\,.\,I should then find a good formula that can show the ``polynomial rate'' at which we can increase $\|\hat \Pi\|$ and $\|\hat Q\|$, but let me just do that at some point while I write the sections up until the Lorentz-invariance section.


(26.04.22) I have some important new notes on how to actually show the Lorentz covariance. They can be found e.g.\ in \texttt{draft1\_73.tex}, right over the ``navi.'' section header. I will also copy them into the comments between this paragraph and the next.

%Kopieret fra draft1.tex:
	%(23.04.22, 12:45) Okay, det blev en hel tænkedag i går, og jeg har så tænkt videre denne formiddag. Og her for en time siden kom jeg så frem til noget stort: Nu kan jeg se, hvordan man argumenterer for, at de imaginære (hurtigere og hurtigere oscillerende) gaussiske integraler, i form af bidragene fra hver (\omega, k)-mode, kun bidrager med noget på et begrænset interval, og at man altså kun gør en lille fejl, hvis man sætter grænser på integralerne. Og dermed behøver jeg altså ikke \alpha! Ikke til den del i hvert fald..! Og måden man argumenterer på er ved at diskretisere slut-tilstandende, bruge linearitet, når det kommer til de forskellige bidrag.. hm, lad mig lige tænke over dette to sekunder.. ..Hm.. ..Hm, kan man se på, hvad man har, hvis man allerede har integreret over de andre modes..? ..Hm, men så bliver det måske lidt svært at argumentere for fermion-bølgefunktionens "langsomme afhængighed," nemlig hvis man skal gøre det for alle felt-koordinater samtidigt.. (12:56) ..Hm, men hvis man nu kun behøver de aftagende mode-amplitude-interval i den videre argumentation, og altså ikke skal bruge off-resonance-argumenter..?.. (13:01)
	%..Hm, jeg har et par idéer, der lige skal kastes lidt rundt i hovedet, og det kan jeg ligeså godt gøre udenfor i det (fortsat) flotte vejr..
	
	%(24.04.22, 16:01) Okay, jeg gik en god tur her lidt tidligere, og der tror jeg muligvis, jeg fandt på den idé, der kan give mig et godt (eller fint, om ikke andet) heuristisk argument..!:) Den store idé var at bemærke, at frekvensen på de gaussiske oscillationer må gå som \omega^2 \tilde A. Og så må man kunne argumentere at bidraget omkring det punkt må gå som 1/(\omega^2\tilde A), når man kun tager disse oscillationer i betragtning. Men ineteraktionen med fermion-bølgenfunktionen, \psi, vil være proportional med \tilde A, og så har vi at det går som 1/\omega^2. Og det er altså \emph{før}, vi tager højde for at (\omega, k)-bølgen i reglen er off-resonance. Nå, jeg gik så lidt videre og fik fundet frem til, at jeg også samtidigt skal bruge et argument om, at når man overstiger en vis grænse (given ens initielle \psi'er (i den samlede start-tilstand)), så må man kunne argumentere for, at man kan kvadrere den amplitude man summer over, for så vil der være tale om overgange til (\psi-)tilstande med små bølgelængder, og så skal der altså også ske en interaktion tilbage igen, før amplituden kan ændre et vist indre rum af tilstande, vi er interesserede i at måle --- eller man kan tænke det som, at "sandsynligheden" for overgangen så vil være propertionel med overgangsamplituden i anden, netop når der altså kan antages at være en forsvindende amplitude der i forvejen. Så vores 1/\omega^2 bidrag vil altså befine sig i en stråle omkring k=0 (plus/minus en hel del, men ikke i forhold til, hvor mange k vi tager med i den samlede integration), og på den anden side af de to.. |k|=k_{in,max}-grænser kan vi altså snakke om 1/\omega^4 i stedet. Så hermed har vi altså allrede rigeligt skyts (også hvis man tænker på at de fleste bidrag er off-resonance --- men det behøver man altså så måske ingen gang at bruge) til at sige, at vi kan skrue fermion-\tilde{A}-koblingen ned for alle (\omega, k)-bølger efter en vis.. \omega_{coupling, max} --- og vi kan også medtage så mange igen, vi har lyst til, til hver en tid efter den grænse. Nu har vi så kan en stråle af (\omega, k)-bølger tilbage omkring \omega = 0 (relativt set). Og for denne ståle har vi så også lov til at kvadrere. Og her kan vi så bruge off-resonance-argumentet til først at få en (nogenlunde) 1/k-afhængighed, så vi så kan kvadrere til 1/k^2. Og så kan vi altså også kvæle koblingen efter en vis grænse her --- samt også sætte så mange koblinger på igen efter denne grænse. Og alle disse argumenter er så uagtet af, hvor stort et (\omega, k)-volumen, vi startede med (og altså hvor de øvre og ydre grænser var til at starte med). Vi kan derfor nu medtage så mange (\omega, k)-punkter, vi har lyst til, uden for de grænser, vi lige har sat, og særligt kan vi medtage punkter så volumenet kommer til at matche et fra et andet inertialsystem (altså måske i en mere naturlig udgave). Og fordi de egentlige ydre grænser (for de grænser, vi lige har sat, handler jo bare om hvornår vi må kvæle fermion-foton-koblingen) kan være så langt ude, som vi har lyst til, så vil alle bidragene fra hver af de punkter fra det (\omega, k)-volumen, vi endeligt har medtaget kobling (eksklusivt) fra, bidrage med det samme, uanset hvilket inertialsystem, man ser det fra.. Eller rettere hver lattica-koordnatvektor, når man integrerer over (\omega, k)-koordinaterne i dette volumen, vil give det samme bidrag i begge systemer, der der så er tale om arbitrært glatte felter, set med fermionernes øjne --- nå ja, og virkningen vil også være det samme, når felterne.. Hm vent, vil virkningen blive det samme (allerede) ud fra dette argument..? (16:28) ...Hm ja, for pointen er vel bare, at bidragene til virkningen er de-koblede, og når fermionerne så også er dekoblet fra dem, så vil alle de ydre (\omega, k)-punkters bidrag (til virkningen, er et jo så) være dekoblet fra de alle de indres. ..Jep..:) Okay, det er altså lige før, jeg tror det holder (som fornuftigt nok argument), det her..!^^ Hvor er det bare sindsygt rart, at jeg allerede --- måske --- har fundet en løsning, så jeg kan komme tilbage på sporet igen..! ..Jeg må sige, at er lidt træt efterhånden, af at der hele tiden går kludder i det, og at jeg så skal bryde min hjerne så meget; min hjerne trænger altså sådan til en god pause snart.. ..Det er jo ofte sjovt at bryde sin hjerne med ting, og det er ofte det fedeste, når man så finder en løsning, men jeg kan nu også mærke, at nu er jeg altså lidt træt (har brug for et hvil snart; har brug for, at jeg snart bliver færdig med.. projekterne, og især dette projekt..).. Så ja, det er altså for fedt, at jeg fik den idé om at se mere på det samlede bidrag, og se at vi får (som jeg kan se det) den der 1/(\omega^2\tilde A)-faktor, istedet for kun hele tiden at tænke i, hvordan jeg har kunne sætte grænser på.. "support-intervallet"..(..:)^^) (16:54)
	%..Nå, jeg må også hellere lige nævne (som jeg vist kom frem til i går aft.. eftermiddags/aftes..(?)), at jeg i rigtig lang tid har gået og tænkt på min sinus-cosinus-ekspansion, som om at en (k_1, k_2, k_3)-bølge er paret med (k_1, k_2, -k_3)..! Det passer jo ikke! (x)) Alle cosinus/sinus-bølger kommer ved at parre to \boldsymbol{k}\mathbb{R}^3-koordniater spejlet igennem 0 (og ikke igennem k_3=0-planen..!) Så ja, dette har altså sikkert medført nogle noter, der er lidt svære at tyde. Og nu giver det pludelsigt \emph{meget} bedre mening (og det er meget mere intuitivt), hvordan sinus- og cosinus-bølgerne Lorentz-transformeres. ..Så ja, der har jeg altså lige glemt at tænke mig ordenligt om (nu efter at være startet på fysikken igen; der er jo mange ting, jeg lige har måtte brushe op på..). (Bemærk dog, at der stadig gælder, at \boldsymbol{k}\in\mathbb{R}^2\times\mathbb{R}_+ for cos/sinus-bølgerne..)
	%..Nå, hvad mangler jeg ellers at fortælle..?.. ..Nå jo, at jeg nu faktisk tror, at jeg skal lave path int--sektionen ved at sætte et "\epsilon\sum_{\mu=0}^4\tilde A^2" (eller hvad vi skal kalde koblingen) på, så \hat H_{in} bliver self-adjoint, og så kan jeg sætte en \alpha på fra start.. måske.. ..Hm, inden jeg tænker videre over det, så lad mig lige forklare, at idéen så er allerede nærmest at lade \alpha og \epsilon_{\tilde A^2} "gå mod 0" (så vidt muligt) så hurtigt som muligt (efter CS-stiintegralet er udledt), da vi jo nu ikke skal bruge \alpha (eller \epsilon_{\tilde A^2}..) i det videre argument.. Men lad mig nu lige se en gang..
	%(19:23) Yes, jeg tror bare, jeg kan lave en dobbelt Trotter; mit argument fra i dag bør stadig holde, så vidt jeg kan se..:) ..Hm, og hvad så med \alpha..? ..Hm, kan jeg mon bare sætte \alpha og \epsilon_{\tilde A^2}\sum \tilde A^2 på fra starten..?.. ..Hm, det er måske ikke super ideelt, selv hvis det ellers holder, for det kræver så også en speciel (ny) udgave af Trotter-formularen.. ..(Jeg har forresten lavet fejl i eq.\ (\ref{gauss_H_to_L}), det har jeg ikke lige fået nævnt, men den får jeg bare rettet, når jeg finder løsningen..) ..Hm, er det lige før, jeg bare må finde en god reference for at integralet også holder for Re(\alpha) = 0, udover Abers og L&B, som nemlig faktisk begge (/ alle tre) påstår det, selvom de dog alle referere til beviser, som alt andet end lige ser ud til at antage Re(\alpha) > 0..(?) Hm, godt spørgsmål.. ...Hm, intuitivt giver det faktisk god mening, at integralet også gælder for Re(\alpha) = 0, for hvis man kigger på en voksende firkant minus den indesluttede (voksende) disk, så giver det intuitivt god mening, hvis inegralet over dette grænseområde går mod nul (når dimensionerne vokser).. (19:42) ..Hm, det er lige før, jeg bare kunne referere til Abers og sige, at godt nok er beviset, som Abers benævner, ikke helt fyldestgørende (sagt på en anden måde), men der skal tilsyneladende bare en lille justering til, nemlig at man argumenterer for, at grænselandets bidrag forsvinder for voksende dimensioner.. ..Hm, men vent.. Hvad med r\exp(r^2)-integralet..? ..Hm, det bliver oscillerende (..og altså divergerende), så never mind, at det giver intuitivt god mening..
	%(21:10) Hall viser sgu, at resultatet om det gaussiske integrale holder for Re(\alpha) \geq 0..!!:D Fedt..! Jeg har ikke læst beviset endnu (men har tænkt mig det), men det er bare \emph{fedt} at vide, at det holder.. \emph{og} at jeg samtidigt har en god reference på det.:D
	
	%(25.04.22, 9:52) Abers har svaret på, hvordan man integrerer \int sin(kx)/x dx..! Jeg blev nemlig lige lidt distraheret over det spørgsmål da jeg scrollede over problemet ovenfor.xD Men ja, løsningen er at man adderer i\epsilon i divisoren, og så får funktionen en pol, man så kan lave kontur-integrering (og ved brug af Jordans lemma, må man gå ud fra) rundt om den, hvorved man.. Hm.. Tja, eller måske vil man gerne have polen på selve aksen, for der sker jo et diskret skift, når man integrere igennem en pol, og så ville man også, vist nok, få et svar, der passer bedre med det kendte resultat.. ..Hm, lad mig lige tage Abers frem igen.. ..Åh, jeg kan se at Abers også giver svaret på hele Fourier-transformationen, så jeg kan faktisk bare bruge en reference direkte, og slippe for alle mellemregningerne selv.xD ..Fedt nok.. Og ja, det \emph{er} jo et kendt resultat, så det \emph{er} jo mest fornuftigt at.. at referere til det kendte resultat i hovedteksten, ja, og så er det jo ellers altid frit for også selv at vise udregningen i et appendix, hvis man vil.:).. ..Hm, Abers' midterste resultat i A.6 er da også ret spøjst.. ..Og det giver nemlig heller ikke mening, for hvis man trak i\epsilon \emph{fra} i stedet, så ville man få 0, så ja, det rigtige svar må jo være \pi, nemlig for at integrere midt igennem en pol (så at sige), og.. hov, men er der en pol.. ja, når vi har \exp(-ikx) i stedet for sin(kx)..(?..) ..Ja ok, så det ville altså være sådan, jeg ville løse det: Først gøre sin(kx) til \exp(-ikx), og så se at vi kan lave kontur-integrale med Jordans lemma, og hvor vi så har en pol i 0, som vil give os \pi (hvilket så skal halveres, når integralet halveres, så det går fra 0 til +uendeligt). (10:14)
	%..Nå, men det jeg egentligt burde fokusere på, er om jeg nu faktisk gør, som jeg har lagt op til i dette draft som sektionen er nu, bare uden noget \alpha.. og ja, grunden til, at det her sin(kx)/x dx-spørgsmål fangede, var så netop også, at det kunne være rart med et mål på, hvor hurtigt selvsamme integrale konvergerer, for konvergensen af det imaginære gauss-integrale bør nemlig gå nogenlunde som integralet af a sin(c x)/x (hvis man finder nogle passende konstanter at indsætte..).. ..Hm, men konturintegral-regningen skulle hjælpe her, så ville man skulle dykke lidt ind i beviset for Jordans.. 
	%(11:06) Min hjerne har været lidt langsom, når jeg har kigget på path-integrale-sektionen, men jeg skal nok på det klaret. (Jeg tror muligvis, det skyldes, at jeg er så lettet over mit store resultat fra (gåturen) i går..:D^^) Nå, og nu kom jeg lige på noget andet interessant. Jeg har nemlig overvejet lidt, om jeg virkeligt skal prøve at inkludere og forklare så meget jeg kan af mit argument (og svede en hel masse over det), eller om det ikke ville være mere fornuftigt, hvis jeg delte opgaven op, ligesom, og så lagde det ud på, og referede til, min GitHub i stedet. Og nu kom jeg lige på den tanke, at jo! Det kan da netop være, at jeg bare skal gå totalt i datalog mode (og også meget passende givet visse af mine visioner for det fremtidige internet (og særligt om brede kollaborationer (og min "w...-idé"))) og så linke til en GitHub-mappe, som så nærmest kan udgøre en "kollaborativ sektion"..:D:DxD(..?) ..Med den måde at se det på, så tiltaler idéen mig altså (umiddelbart) pludeselig helt vildt meget..:DxD^^ ..Og så er tanken lidt bare, at jeg dog lige opsummerer et "snapshot" af sektionen (og altså en overordnet skitse af argumentet) i artiklen (eller hvad man kalder et 'paper' på dansk helt præcist..).. (..Og dette gælder så både for mit Lo.-inv.(/cov.)-argument og mit selvadjungeretheds-argument..)
	%...Hm, det er da lige før, at jeg \emph{skal} bruge en hurtig konvergens (af imaginær gauss / sin(x)/x -integralet), hvis jeg bruger strategien om at begrænse \hat H_B..:\.. (11:26) 
	%(11:50) Hm, man kan give et intuitivt argument for at sinus-integralet ("Si(x)") må konvergere som O(1/x).. (..Så altså at Si(x)-\pi/2 = O(1/x) for store x..)
	%(12:15) Nå, det går af en eller anden grund rigtigt langsomt i dag; jeg kan af en eller anden grund ikke rigtigt koncentrere mig så godt om stiint.-problemet.. Men det er vel også okay, at tage den lidt roligt i dag; det har jeg næsten fortjent.. selvom det jo ville være super dejligt lige at få opklaret dette problem også.. Men ja, det skal jeg nok få gjort, og det er alligevel et problem, jeg godt kan regne på i hovedet, så lad mig bare nyde vejret lidt i dag --- måske blive klippet, endelig..:).. 
	%...Hm nej, lad mig lige først tænke lidt på tasterne.. Hvis vi begrænser, så må vi alt andet end lige lade \|\hat H_B\| gå som M, når vi lader M vokse.. ..Desuden mener jeg stadig at en dobbelt Trotter er en gyldig mulighed.. ..Hm, men når M stiger, vil fejlen så gå som 1/M, hvilket samlet set vil få fejlen til at blive konstant, alt andet end lige.. ...Hm, bortset fra, at p_{max} \sim \sqrt{ \|\hat H_b\| }, så.. ..Ja, så det er endnu værre.. ..Hm, så jeg skal nok hellere lave den der dobbelte Trotter ekspansion.. ..Hm, men så kan det stadig godt være, at M bliver nødt til at stige, hvis vi ændrer i \hat H_B (og lader begrænsningerne vokse).. ..Hm, medmindre.. Hm, kunne jeg komme uden om dette, hvis jeg tilføjer et \tilde A^2-term..? ..Ja, det er da lige før, jeg tror, man kan det..!(..) ..For man må da vist kunne argumentere for, at vi kan lade diskretisationen gå imod kontinuum-grænsen, samtidigt med at (et tilstrækkeligt stort) M bare holdes konstant (hvis altså \hat H_B allerede er selvadjungeret på dette tidspunkt)..:)..(?) (12:45) 
	%..Ja, det må sgu næsten holde..!..:) ..Og er det så en dobbelt Trotter, jeg er ude i..? ..Ah, hvor sweet, at jeg endeligt ser ud til næsten at have samlet tråden godt op igen *(eller en ny tråd, rettere, for den gamle holdt jo ikke) --- syv, ni, tretten(!!).. ..Ah, jeg kan godt sagtens lave dobbelt Trotter, og så kan jeg nemlig bare lade \sum \tilde A^2-led komme med i alle dele, så alle delene er sikret at være selvadjungeret..:D (12:58) ..Nu vil jeg snart ud og nyde det lidt (vejret og de nye fremskridt^^)!.. ..Hm, og så kan jeg lige summe lidt over det fulde Lo.-cov.-argument, hvis jeg har lyst, for lige at få fremkaldt alle delene, så får god styr på, hvad planen (og tråden) er..:)
	%(17:08) Nå, jeg fik gået en god lang tur, blev klippet, og fik nydt tanken om de seneste fremskridt. Og jeg kom så på den gåtur i tanke om, at jeg jo så slet ikke behøver alt det palaver omkring "diskretiserings-skemaet"..!!xD^^ Så ja, virkeligt godt at jeg endeligt fik læst mig til og fundet ud af, hvordan det imaginære gauss-integrale konvergerer.^^ Og nu kan jeg altså se, at man jo bare kan indsætte af-cuttede identitetsoperator-integraler, hvor man så tager grænsen udvendigt. Og så kommer udregningen til at passe --- nemt.^^ (..Og ja, jeg har altså så stadig de der \epsilon\sum\tilde A^2-led med også, hvor man så bare kan lade \epsilon blive mindre og mindre (alt efter behov) bagefter.) 
	%..Ah, nu virker det faktisk næsten til, at jeg så er ret tæt på (7, 9, 13!)..^^ ..Nemlig især når jeg nu også vil tillade mig bare at skitsere mine argumenter for henholdsvis Lo.-covarians og selvadjungerethed overordnet her i forbindelse med den første udgivelse (og så bare arbejde videre på detaljerne bagefter, og måske sammen med andre..:))..:) 

The notes are in Danish, but so are a lot of my notes.\,. .\,.\,Let me just say that the big new idea is to not try to argue, that you can cut parts of the integral (over $(\omega, \boldsymbol{k})$-wave amplitudes) away, and more and more of it for increasing $\omega$ (and $k$). No, instead I should keep the whole integral range, but then just argue how we get a factor going as $1/(\omega^2 \tilde A_{\omega})$ (for all $\boldsymbol{k},\sigma$) for the contribution, since the contribution will be inversely proportional to the local ``wave vector'' of the Gaussian function (coming from differentiating it with respect to $\tilde A_{\omega}$, which will yield a factor of $2\omega^2 \tilde A_{\omega}$). And since the interaction coupling (between $\tilde A$ and the fermions) is proportional to $\tilde A_{\omega}$, we will get an overall contribution going as $1/\omega^2$. So even without off-resonance arguments, we already have plenty of decay from this factor. The next part of the argument, to carry on from this idea, is to use the fact that after a certain $k_{fermion, max}$, we expect the fermion amplitude to be almost zero, and therfore we are actually really interested in the amplitude squared, when looking at transitions with such big $k$s. (One can think of it in terms of probability, but a better argument is to use the fact that there has to be a ``transition back'' in order for the contribution to matter for a certain set of inner states that we want to measure.) So we can now put a limit on $\omega$s and a limit on $k$s to divide all the $(\omega, \boldsymbol{k})$-coordinates into four areas: one with $|\omega|\geq\omega_{coupling, max}, |k|<k_{coupling, max}$, one with $|\omega|\geq\omega_{coupling, max}, |k|\geq k_{coupling, max}$ (consisting of two separated areas), one with $|\omega|<\omega_{coupling, max}, |k|\geq k_{coupling, max}$ (also consisting of two separated areas) and the fourth one is the inner one we want to let be. For the first area, the $1/\omega^2$ factor means that the contribution to the fermion wave function will vanish if we choose a large enough $\omega_{coupling, max}$. So we might as well turn the coupling for all such coordinates to zero (if we want to; we might also leave some be). For the second area(s), we can square the $1/\omega^2$ factor and have plenty of reason to do the same thing (i.e.\ turn as many coupling constants to zero as we want). And for the last outer area(s), we can use the factor coming from being off-resonance, namely if we choose $k_{coupling, max}$ large enough (given our $\omega_{coupling, max}$), which is on the order of $1/k$ overall, and which we can square to get a factor on the order of $1/k^2$, which is plenty to also make the integral converge --- oh, and this is because we are free to choose outer limits for $k_2$ and $k_3$ (assuming we Lorentz transform in the $k_1$ direction) that are way smaller than the outer $\omega_{max}$ and $k_{1, max}$ (since we can alway just keep cranking up $\omega_{max}$ and $k_{1, max}$ if we want to). So the integral of the third area here is also over a one-dimensional ray (like for the first area), and thus the $\approx\,\sim \!1/k^2$ factor is plenty to make the integral (or sum, rather) converge. And with this heuristic argument, we now have free rein over all these outer areas in turn of turning the coupling on and off. We can then turn a combined area on which matches an area we could have gotten (maybe in a more natural way) for the Lorentz transformed system. We can even make all the coordinate points align exactly by using a certain trick of letting the offset on the $\omega$s depend on $k_1$ (and using a certain very small $\delta k_1$ compared to the $\delta \omega$). And since we now have two areas in $(\omega, \boldsymbol{k})$-coordinate space which match, but where the actual $\omega_{max}$ and $k_{max}$.\,. is much larger.\,. Hm, let me actually think about the $k_{2, max}$ and $k_{3, max}$ again.\,. .\,.\,Hm yeah, we also want to be able to let these tend to infinity as we please.\,. .\,.\,Hm, I was about to say ``Do we then really need a factor below $1/k^2$\,?'' but surely there must be another way.\,. (right.\,.\,?) .\,.\,I have just started using new timestamps, by the way: (10:37). \ldots Ah, now I know what to do about that! (10:44) We just have to use the fact from the beginning, we are allowed (which is easy to prove) to turn the couplings to zero above a certain.\,. Hm, but does that solve this problem.\,.\,? Anyway, let me just explain that we can always make a slice like this to turn the coupling to zero (or change it to something else) for all coordinates above a large enough threshold; the hard part only comes when we only want to remove.\,. wait.\,. Didn't I just say that we can change the couplings however we want.\,.\,? .\,.\,Oh yeah, but still only for any column of fixed $\boldsymbol{k}$s at once; the hard part is indeed to remove only some of the $\omega$s from the coordinates (and not just all $(\omega, \boldsymbol{k})$-coordinates for a fixed $\boldsymbol{k}$ at once).\,. .\,.\,But yeah, back to ``does this solve this problem.''.\,. \ldots Ah yes, it \emph{does}!\,.\,. We are free to turn the coupling down for \emph{all} $(\omega, \boldsymbol{k})$-waves with $k_2$ and/or $k_3$ larger than $k_{2, max}$ and/or $k_{3, max}$. So for the ``outer areas'' that I had before, the couplings for these large $k_2$ and/or $k_3$ is just already turned down to 0 (and can remain there throughout the argument). .\,.\,Good. And where were I?\,.\,. .\,.\,Yes, and then you have two matching inner areas (or ``volumes'' if one likes) for the two systems, which are the only $(\omega, \boldsymbol{k})$-coordinates the fermions ``see,'' but where the actual $\omega_{max}$ and $k_{max}$ can in fact be arbitrarily larger than that. And since all these outer coordinates are now completely decoupled from the inner ones, we can just integrate over them (to get a normalization constant (and/or phase factor) and nothing more that is interesting when measuring the fermion wave functions at the forward hypersurface). And what what we are left with is a path integral, that, when $\omega_{max}$ and $k_{max}$ goes to infinity, is completely Lorentz covariant for the two inertial systems: whether we do the calculation for one or the other, the result will be the same (when measuring the fermions on the forward (space-like) hypersurface), only differing by a classical Lorentz transformation of the Dirac spinors (and the fields, but we are tracing over all field-configurations in this argument, at least with how I have made it here.\,.).\,:) (26.04.22, 11:18)


%(11:44):
(02.05.22) Okay, I have found out that I might need an additional argument to the one described above. For $\mu\in\{0,3\}$, we have that offset in the $\exp(iS)$ Gaussian function. But that offset decreases as $1/\omega$ for the ray with limited $k$. And if we thus (an this is my new addition, then) also use the off-resonance argument for this ray, we can cut out all $\tilde q_{\omega \boldsymbol{k}\boldsymbol{\sigma}}$-amplitudes/-values that are both greater then or less than a certain limit going as $1/\omega$. For amplitudes greater than that limit, the old argument will apply, where we will get a $1/\omega^2$ dependency (due to more and more rapid oscillation, which cancels out the coupling proportional to the amplitude, but which then still has the factor of $1/\omega^2$ in front). And for amplitudes withing the limit going as $\sim 1/\omega$, we can just use the fact that the maximal coupling then also goes as $1/\omega$ within this (decreasing) interval, as well as the off-resonance argument.\,. Hm, and we cannot use the off-resonance argument (very easily) for the $|\omega|\geq\omega_{coupling, max}, |k|\geq k_{coupling, max}$ area, but.\,. .\,.\,Hm, there might be a problem here, then.\,. .\,.\,Oh, and the argument about the $\sim 1/\omega$ limit of course does not hold here either.\,. .\,.\,Hm, I could perhaps get an off-resonance argument here, such that I divide the area(s) into a ray (/rays) along the $\omega = k$ line, but let me think.\,. %(12:05) %Oh well, I might as well think on a walk outside, and go to the library, perhaps.. (and get the Cohen-Tannoudji book, as well as deliver back the Gaussian measure books, that I luckily will not.. Oh, that's actually too early to say, since I have this little problem now.. ..Oh well, I'll just deliver them back: It would be very unlucky and surprising, if I ever have to think about that (hard) route agian.. ..7, 9, 13..)

(05.05.22) Okay, I think I almost have the solution now. Yesterday I got out of bed with an idea about making sure that there are no $(\omega, k_1)$-points on the $\omega = k$-.\,. lines.\,.\,? .\,.\,Hm, yeah, I am just realizing that $k$ also depends on $k_2$ and $k_3$, so for most $k_2$ and $k_3$, it wouldn't be a line.\,. .\,.\,Oh well, it will probably be all right, still.\,. I can even make the $k_2$ and $k_3$-grids irregular if there is anywhere where the points intersect the.\,. Hm.\,. .\,.\,And/or use the fact that there can be a limited, finite number of $k_2$s/$k_3$s, maybe.\,. .\,.\,Okay, let me put a pin in that for now, and explain that I have also thought more about whether it is possible to use the Wiener measure. The idea would be to time the Hamiltonian with some complex $\alpha$, get the integral against the Wiener measure, and then use dominated convergence to show that the two integrals, coming from the two different inertial systems, converges to the same thing. But I have actually just sort of concluded that this is a dead end --- at least I see it as such now for me. Maybe someone will be able to do something with the Wiener measure, but it won't be me.\,. (.\,.\,The way I see it now, it doesn't really help the problem: one then --- at least! --- just need to show that the are dominated by a integrable function, but once we know that, it would be very easy to make the intuitive argument, then! *(i.e.\ without using the Wiener measure and dominated convergence.) So in that sense, I don't think it helps to go more abstract: you only end up having to prove the same lemmas, and perhaps more.) 

.\,.\,Okay, and now I both need to explain more about my (heuristic) solution, and also figure out whether $k\neq k_1$ causes trouble. And I also have another thing left to show apart from that, which is that the Gauss oscillations will also give a decent ``effective distribution'' for any pair of $\mu\in \{0, 3\}$-waves around the ray (.\,.\,which now might be a slightly curved ray) around the $\omega = k_1$-line.\,. .\,.\,I will do the calculations in \texttt{draft1.tex}, and then I will at some point return and give an overview of the conclusion (and the heuristic solution, i.e.) here.\,. 

.\,.\,Oh, but let me also mention, that my plan is now to actually make the section after the path integral section, i.e.\ there section where I sum up the argument for Lorentz covariance (and existence), such that it postpones (by assuming it to be true for the duration of the section) the argument for being able to turn down the coupling for any $(\omega, \boldsymbol{k})$-point beyond a certain bound, as well as the argument for self-adjointness, of course. And then I will leave these arguments out of the main body of the paper entirely, and just reference my GitHub as a potential hub for this ``future work,'' as well as give outlines of my proof ideas in some appendices (probably).\,.\,:) .\,.\,And it's not that I don't think my proof strategies will work, not with the knowledge I have now. No, I do believe in them (even though I am not completely done outlining the one for turning down the couplings.\,.).\,. But even if they do work, I don't believe that I will be able to give a very clear-cut walkthrough of them: Whatever I will be able to produce, future readers will probably do better to read some newer versions of the proof strategy walkthroughs anyway.\,. 

\ldots Oh, of course it won't matter that $k_1 \neq k$, cause it will be so approximately when $k_1$ at large enough, and we can easily make it large enough compared to $k_{23\,coupling\, max}$ that we can assume $k_2,k_3=0$ without any significant error. 


(06.05.22) I had two important (seemingly) realizations yesterday. .\,.\,Well, plus some other important ones that are a bit hard to describe (but let's see.\,.).\,. First of all, I now think that it is important to start with a $\boldsymbol{k}$-column(/row) with no couplings (removed since we can argue that a Hamiltonian with an upper bound on what $\boldsymbol{k}$-waves couple to the fermions will approximate an unbounded one more and more as the bound grows (i.e.\ it will approximate it better and better for more and more $\psi$s)) and then ``add'' couplings (for $(\omega, \boldsymbol{k})$-points) one at a time. Because when doing so, we will know that we start with normalized initial and final wave functions in both ends. And when we then add a coupling to the first point (of the ones we want to add), then we should just, well, first do the uncoupled Gaussian integral in reverse and get the inverse factor ``back''.\,. and then redo the integral, now with a coupling added. And depending on whether it is a sine or a cosine wave, we will then have the final or the initial wave function factored into the integral. From there, one can then (hopefully) find the argument --- and I need to work a bit on that today --- that adding the coupling this way (and integrating again) will only excite a state with a maximal amplitude that decreases a decent way when $\omega$ and $k$ (and specifically $k_1$) tend toward infinity. .\,.\,And the second big realization (that is easy enough to explain), is that I should go back to some shapes of the bounded $(\omega, \boldsymbol{k})$-area/volume, that I have kind of had in mind before, but which I didn't need when I thought the argument would be easier. The idea for these shapes is to start with an arbitrary ``long'' area/volume (we can think of it as an $(\omega, k_1)$ `area,' which is why I like to use that word). Let us picture such an area where $\omega$ is on the second axis, and then let's picture a ``long'' area with a high $\omega_{coupling\, max}$ compared to $k_{1\, coupling\, max}$ (which limits the absolute value of $k_1$). Now Lorentz transform this long (column-like) are to one side (i.e.\ in the plus or minus $k_1$ direction) and add the area to the former area (such that you have a union of two long areas, where one is tilted to one side). Now transform this combined shape back in the other direction, such that the fist ``column'' is now the tilted one, and the second one is the one going straight up. These two combined shapes, the one we first obtained (by the union) and the one that was ``transformed back,'' those are the ones we want to prove are (both) valid shapes for the path integral, meaning that the path integral converges to its right result when the coupling is limited to these shapes, and when the dimensions of these shapes then tend to infinity (together with the actual outer bounds on $\omega$ and $k$ (which we can simply call $\omega_{max}$ and $k_{max}$ here)). .\,.\,Oh, I guess I forgot one thing: The second long shape (obtained from the first transformation) should also be either.\,. hm, I was about to say shrunk/enlarged, but let me just think more about this for a moment.\,. .\,.\,Oh yeah, that is what I am after.\,. ``Shrunk or enlarged.''.\,. So the second (long) shape should be scaled up or down in size, with $(\omega, k_1)=(0,0)$ as the fixpoint, such that the sides of the two.\,. let me just call them `long-shapes' here, why not? .\,.\,such that the sides of the two long-shapes intersect exactly where $\omega = k_1$. .\,.\,I don't think I need to explain it further here: one can then see that proving that the two versions of the combined shape are ``valid shapes,'' will do the trick when it comes to proving Lorentz covariance (or rather proving the important lemma, from which Lorentz covariance should follow rather easily), and one can also see the point of concerning oneselves with these shapes, namely since they mean that we only need to add a limited amount of points in the vicinity of the $\omega=k_1$ line, which does not increase in number (and the ``vicinity'' thus does not change in size) when the dimensions of the shapes grow. 


(07.05.22) I had another good idea last evening, which might potentially bring me over the finish line with the heuristic argument. I noticed (with the help of Wolfram Alpha's plotting tool) that the action for a $\tilde q_0, \tilde q_3$ pair is a.\,. well, it's apparently called an `elliptic parabloid'.\,. that has $\sim(\omega - k)^2$ as the second order coefficient in the $u = \tilde q_0 + \tilde q_3$ direction, and has $\sim(\omega + k)^2$ as the second order coefficient in the $v = \tilde q_0 - \tilde q_3$ direction. That didn't look very good for me, but in the evening I got the idea to look at the gauge symmetry surrounding the $\tilde q_0, \tilde q_3$ pair. This then tells us, that we are free to add $(\omega, k)\Lambda$ to $(\tilde q_0, \tilde q_3)$ without changing the absolute values of the fermion transitions. And the idea I got from there was then that as the dimensions grow, for points with fixed $(\omega - k)$s, call them $\Delta$s.\,. or $\Delta\omega$s.\,. .\,.\,these points will then have an $\omega$ and $k$ (as these grow) that tends toward each other. And then, since we are able to add, say, $-(\omega, k)\tilde q_3$ to $(\tilde q_0, \tilde q_3)$, the.\,. how shall I put it?\,.\,. There point is that for all the points along the $\tilde q_0 = \tilde q_3$ axis, namely in the $u = \tilde q_0 + \tilde q_3$ direction, we get closer and closer to $(0, 0)$ when adding (say) $-(\omega, k)\tilde q_3$.\,. And thus, the coupled amplitude that the fermions effectively see can then be equated to an amplitude that gets smaller and smaller for increasing $\omega, k$. And since there will be a finite number of these points with ``fixed $\Delta\omega$,'' their combined effect on the fermions will be smaller and smaller. And for any fixed areas, i.e.\ that are fixed in relation to the dimensions of the growing shape and thus scales with the shape, we will have growing $\Delta\omega$s, which will mean that the (effective) amplitude (of the given $A^\mu$ wave that couples to the fermions) that the fermions see will be supported on a smaller and smaller area, essentially, due to the Gaussian oscillations (and earlier yesterday I also found perhaps a good (more formal) argument for this principle.\,. which I should also explain now, unless there are more to the things already said.\,.).\,. .\,.\,Well, I should also mention the part that I thought about in the bath this morning (.\,.\,or morning/noon.\,.), which is about the area that can be thought of as neither with fixed $\omega - k$ or with fixed $\omega / k$, between the two other areas, so to speak.\,. .\,.\,Oh well, I actually don't want to do the calculations right now, but my strategy to solve this is just that we can take whatever power that the contribution of the fixed-$\Delta\omega$ area is decreasing with and let the area grow with a power slightly less, if necessary, and we can do something similar for the fixed-$\omega/k$ area, where we allow ourselves to.\,. .\,.\,yeah, to let $\Delta\omega_{min}$ grow slightly less than $\omega$ and $k$, namely by adding more and more fixed-$\omega/k$ area closer and closer to the $\omega = k_1$ line --- if necessary. Hm, and if this then sandwiches in a third area.\,. Hm, maybe it shouldn't, but otherwise one can then maybe use the rate at which this area becomes smaller an smaller, compared to $\omega k$, and use the fact that the $\Delta\omega_{min}$ is also increasing with some rate for this (sandwiched-in) area, if necessary (and if the area exists (properly) in the first place), to also conclude that the contribution from there will be smaller and smaller. So yeah, that's the strategy, and I'm almost certain it will do the trick when one does the calculations.\,. 

.\,.\,Okay, before I touch on the argument for using the ``decreasing support of the imaginary Gaussian function'' (of $\exp(i S_B)$), let me just note that the off-resonance argument then will be pretty central for my current strategy, when it comes to removing --- or adding, rather --- couplings for $\tilde q_0, \tilde q_3$ pairs. It is especially needed for the large-$\omega$ points above the shapes, since we cannot generally square the transition amplitudes here. Note also, that my ``combined shapes'' from the day before yesterday (which I wrote about yesterday) are part of the argument, and that it might still be beneficial (.\,.\,for instance when it comes to arguing about the contribution from that ``third area'' (which might ``exist'' in terms of not being equal to $\emptyset$) I just talked about (if necessary)) that we \emph{are} able to square all contributions above a certain $k_{1\, fermions\, max}$, which becomes smaller and smaller, of course, compared to the growing dimensions of the shapes (which means that we can even square the contributions around the edges to the side of the upright ``column''/``long-shape''). 

(08.05.22) I got into trouble yesterday again when I thought about to finish the argument from there. As mentioned, I had an idea for an argument, which by the way was something about using the convolution theorem as well as Cauchy-Schwartz (+ Parceval's) to get an upper limit to how much the transition amplitude could add to the final result, but there idea just didn't really hold up (not the way I thought of it). So yesterday was yet another thinking day, and it really seemed to be a very hard problem to get it right. .\,.\,A \emph{really} hard problem potentially.\,. But then in the late afternoon (out on a walk in the sun) I finally realized that I might not need the off-resonance argument after all. And immediately the problem seemed solvable again. So let me (hopefully) just forget about the off-resonance argument! (save for having it as an extra intuitive reason why it should converge like I want it to). And the reason why I don't think we need it, is that.\,. Well, let me just think about the argument for a little bit again, and then explain it, but basically it just uses the fact, that even the small second order coefficient of the (imaginary) Gaussian function, namely in the $u = \tilde q_0 + \tilde q_3$ direction, should still go as $\Delta\omega^2$, unless I am mistaken, so intuitively we therefore wouldn't expext to need the off-resonance argument --- not if we are also still able to square the amplitude contributions on the sides (which I still plan to use for the argument). Okay, let me think for a moment.\,. \ldots Hm, I actually think that my argument, that came to me shortly after the mentioned realization yesterday, is quite good.\,. .\,.\,Yeah, so let me just stick to it. Okay, the argument is to analyze what oscillations the coupling can maximally induce as a function of $\tilde q$ (i.e.\ of wave amplitude), and (hopefully) conclude that the oscillations are bounded by some linear function. Therefore the increasing oscillations of the Gaussian will always dominate after a certain $\tilde q$ distance, after which you (given the errors you allow yourself on the calculation) can take the oscillations to add a factor of the inverse wavelength to the contribution (since we have first of all resolved the final state in discrete $\{\tilde q\}$ states (which can be done causing only a finite error that tends to zero together with the discretization grain), such that rapid oscillations will mean a reduced contribution). After that $\tilde q$ distance, one can then (hopefully (easily)) show that the contribution from this outer interval is bounded by a value, which will furthermore decrease $1/a$, where $a$ is the second order coefficient in the exponent (which should be at least $\Delta\omega^2$, hopefully, if I am not mistaken, for the $\mu\in\{0,3\}$ dimensions). And for the inner interval, before said $\tilde q$ distance, one should be able to show that this interval decreases in size as $1/a$ as well. And thus the contributions from both intervals should go as $1/a \sim 1/(\omega - k)^2$ (which goes as $\sim 1/\omega^2$ when we look at the area above the ``long-shape'' (and within the $k_{1\,coupling\,max}$ boundaries)), which will be sufficient for making our $\omega_{coupling\, max}$ cut-off. And for the other areas, i.e.\ outside the $k_{1\,coupling\,max}$ boundaries, we first note that we do not need to cut away couplings from the $\boldsymbol{k}$-columns; we can start by setting the coupling to zero for all these columns (adding only a finite error that tends to 0 when $k_{1\,coupling\,max}$ grows), and then add the couplings of the points we need (for our ``combined shapes'') afterwards. One must then also (hopefully!) be able to make the argument, that the contributions can be squared for these points (since we need at least two transitions in order to get back to any inner point that we are interested in measuring (for we \emph{can} chose to only care about (and analyze the change at) some specific inner points for the argument)). And if so, then we can look at the 2--3 areas that I wrote about yesterday, and use the same argument about the $\sim 1/a \sim 1/\Delta\omega^2$ factor on the contributions (i.e.\ for the initial, un-squared ones) to conclude that the overall contributions must also tend to 0 as the dimensions of the shapes (as well as the outer boundaries, determined by $M$ and the initial $k_{max}$ for the path integral) all grow (but where $k_{1\,coupling\,max}$ remains constant, by the way). There we are. So this is my proof strategy now.\,:) 

(09.05.22) I don't think I need to talk about propagation local hyperspace volumes, between hypersurfaces, really. I can just argue from the picture of transforming the wave function to an extended Hilbert space, where each $\tilde q$ (however many you want to include (determining the precision)) is now a coordinate of the Hilbert space (so we are extending the bosonic Hilbert space from $N$ dimensions to $M N$ dimensions, more precisely). And that's really it. It is easy to show that this actually is a Hilbert space, and that the time-evolution is unitary in this space. I \emph{should} then actually make the path integral in the way that I was working on before all these thinking days, namely where we have inner points 1 through $M$, which are the only points we let the Hamiltonians hit (not the endpoints). We can then basically use periodic boundary conditions for the Fourier transform, where the two endpoint are left out of the picture at first. This gives us the nice semi-decoupled action, then. And then the point is, that transforming to and from the extended Hilbert space (i.e.\ the one with $\tilde q$s as coordinates) then just costs some phases, basically since you are breaking the rhythm of the ($(\omega, \boldsymbol{k})$-parameterized) wave. And the neat thing is that it is the inverse phases going to the extended space as it is going from it, and more importantly, the transitions are effectively vanishing for $q_0$-/$q_t$-lattices that are significantly away from.\,. .\,.\,wait that might not be true.\,. 
%...(11:05) ...(11:14):
\ldots Ah yes, of course. Since we are only including $\omega$s that are well below $\delta t^{-1}$ (namely since we can prove that we can remove the coupling for, and thus disregard, all $\omega$s higher than a $\omega_{coupling\, max}$), $\delta t$ can be made very (arbitrarily, in fact) small compared to the largest $\omega$ of the $\tilde q$s. And then we do indeed get that the transitions becomes are effectively zero for $q_0$-/$q_t$-lattices where $q_0$ / $q_t$ is significantly different from the initial/final point of the given $\{\tilde q\}$ wave that we want to calculate the transition to/from. %(11:21)
And this is all we need --- the first property about the phases being inverse when going to and from, that is just nice to think about, but this second property is really where it's at.\,. .\,.\,The argument for Lorentz covariance from there is to then note that the transitions to and from the extended space are.\,. .\,.\,Hm, are they invertible.\,.\,? %(11:26)
\ldots Hm, that might actually where the first property mentioned will play an important role, after all.\,. .\,.\,Hm, but maybe there will be an issue of needing to show convergence of the from-extended-space transformation.\,. \ldots Hm, I should analyze the transitions some more, I guess.\,. \ldots Oh wait, will I not get a delta function for the transitions even though the $\hat C$s/$\hat W$s are in the mix?\,.\,. .\,.\,Right, I should.\,.\,! .\,.\,Well, that's nice to know: very neat, indeed.\,. %(12:04)
.\,.\,So I have definitely found the right way of doing the path integral.\,. (.\,.\,and of Fourier-transforming it afterwards.\,.) .\,.\,And this is nice since now the transitions to and from the extended space are now pretty trivial.\,. .\,.\,Wait, let me just double-check this conclusion.\,. .\,.\,We deal with a factor of $\exp[i \boldsymbol{p} \cdot (\dotbsq - \boldsymbol{W}(\boldsymbol{q}))]$ for the transitions.\,. .\,.\,Hm, which should mean the transition amplitudes are only really supported around $\dotbsq = \boldsymbol{W}(\boldsymbol{q})$, right.\,.\,? .\,.\,Sure, and this will then give a delta function, that is slightly translated w.r.t.\ $\boldsymbol{q}$, but which still approaches the $\boldsymbol{q}$s of the endpoints of the particular $\{\tilde q\}$ wave (which has periodic boundaries).\,. .\,.\,Oh, wait.\,.\,! Can we really have periodic boundaries like that when dealing with sine and cosine waves --- no, probably not.\,. .\,.\,Damn, the picture just seemed so nice.\,. Oh well, I hope I can find an even prettier picture.\,. .\,.\,Hm well, do I really have to change anything.\,.\,? Isn't the picture already just slightly prettier than it was.\,.\,? .\,.\,Yeah, it actually seems to be.\,.\,! We don't need the waves to be periodic over an interval of $t$, in fact it would be a problem, if we were limited to such waves. .\,.\,Hm, and my latest way of doing the path integral is still the right way. .\,.\,Okay, great.\,:) %(12:28)

\ldots I just had the thought, a few moments ago, that the invertibility of the $q\leftrightarrow\tilde q$-transforms, when looking at two inertial systems simultaneously, might be ensured by that fact that all sine waves Lorentz-transform to sine waves, and similarly with the cosine waves.\,. %(13:05)
.\,.\,Hm no, that is probably not enough (in terms of an argument).\,. 
%(13:38)
\ldots Oh, we might be safe if the transformations somehow don't need to be one to one (i.e.\ if there can (somehow) be many states on the extended Hilbert space describing the same (physical) state on the regular space).\,. .\,.\,Hm, except that we would then still need to prove convergence when going from the Lorentz-transformed extended space to the regular (Lorentz-transformed) space.\,. .\,.\,He, who would have thought that this would turn into yet another thinking day; they just keep on coming.\,. Oh well, but at least I have a really good feeling about this problem (7, 9, 13); it doesn't seem like such a big problem, somehow.\,. %(..well, yesterday was not really a thinking day, so much as a cheat day that turned kinda productive in the evening with the thoughts I had, but still..)

(10.05.22) I had some thoughts yesterday that I need to write about, namely about the fact that we should be able to let $\delta\omega$ tend toward zero, even though we keep $t$ constant (since, the way I see it, one should be able to handle the redundant degrees of freedom for the integral.\,.), but let me get back to this topic.\,. Oh, but a neat thing, if it works, is that we then don't need to.\,. hm.\,. Well, we \emph{might} not need to do the trick where we are careful with how we choose different offsets for the $\omega$s for every $\boldsymbol{k}$ column. .\,.\,But returning to the problem, more specifically, about showing that the Lorentz-transformed state in the extended $\{\tilde q\}$ space does indeed correspond to a regular state in the Lorentz-transformed regular space as well: I had an idea late in the afternoon yesterday --- something about turning the coupling down for (way) earlier times and do the transformation where the coupling was 0 --- but it doesn't really seem to work now. So I have used this morning %(10:29) now, and I actually got up before 7 this morning.
thinking about another way to solve the problem. And I have just sort of landed on an idea, that I will try to describe now (also to help me check if it holds up or not).\,. 

The idea is about showing that our predicted way of making the Lorentz transformation is indeed a unitary operation. We start by selecting the pivot point of the transformation far away from where all the fermion wave functions effectively go to zero. We then want to propagate the wave functions over a triangular space bounded by the outer bounds on the $\Omega$ volume (in the $x_1$ direction). But instead we propagate it over the rectangular, double volume to begin with. We note that the bosonic action is then the standard action of $\hat H_{in}$ (a self-adjoint version of it, by the way). We then want to change $\hat H_F$ to a time dependent function (so it takes a tuple of $(t, \boldsymbol{q})$ instead of just $(\boldsymbol{q})$) such that it only propagates the fermion regularly over the mentioned triangular volume, does a transformation right at the interface between the two triangles such that the fermion wave function are kept neatly normalized at every time slice (where one part will be in the first, lower (if we imagine the propagation going up when going forward) triangle, and where the other part is in the second, upper triangle), and then vanishes for the second triangle such that the fermion time-evolution halts after the interface. Such a (time-dependent) $\hat H_F$ should exist, and at every time slice, the Hamiltonian will be $\hat H_B + \hat H_{IF}$, so the evolution should indeed be unitary so far. At the end of this path integral, we should do a sum (going from the extended space to the regular space) in order to get our final state, but we can postpone actually reducing this sum. We would then like to do a another path integral ``backwards,'' where $\hat H_{IF}$ is just 0, where $\hat H_B$ is the same, but where we use half the $\Omega t$ for the action. Again, this should of course be a unitary operation, and furthermore (when having not reduced the mentioned sum yet), this should return us to exactly the final state of the Lorentz transformation that we want, apart from a rotation of the fermion spinors and of the $A^\mu$ entries. %(11:00) 
Now, since we have a sum of two unitary operations (well, three, actually, if we also include said rotations), the combined operation will also be unitary, which then means that there does indeed exist a regular state that matches what we get if we do the Lorentz-transformation in the extended space and then reduce the sum, going to the regular space, on the hyperplane of the transformed system.\,. .\,.\,Hm, but couldn't you simply argue just from doing the transformation in the extended space and then postponing reducing the sum.\,. somehow.\,.\,? %(11:06)
.\,.\,No, of course not; that's why I have had to think this much more about the problem.\,. %(11:14)
.\,.\,Okay, but my solution here seems to hold, doesn't it?\,.\,.\,:)

.\,.\,Hm, I should double-check that the second unitary operation is indeed what reverses the propagation over the second triangle.\,. %(11:19)
\ldots Hm, and we couldn't have just started with half the $\Omega t$ factor for the action of the first triangle.\,.\,? %(11:31)
.\,.\,Hm, I don't exactly see why not.\,. 

\ldots Sweet. And let me then just reassure myself that unitarity is sufficient quality to prove.\,. 
.\,.\,Oh, but if the Lorentz transformation is unitary, then we can also transform unitarily to an end-state of the transformed system. So at all time slices in the transformed system, the (Lorentz-)transformed wave functions, when looking at it in the picture of the extended space, will sum to a normalizable wave function. .\,.\,Yes, and if we transform to an initial state (at an early time) we can also see that we can do the sum, but postpone reducing it, and then when we do the path integral (as seen in the extended space), we can.\,. do it for each term of the sum individually.\,. hm.\,. .\,.\,Well, yes, exactly!\,.\,. .\,.\,Yes, and this will indeed give a set of path integrals for each of these terms, but where each path integral then has a specific (delta function-like) initial field state --- which of course is also what we would have had anyway, namely if we never did the summation and remained in the extended space (and so, we have come back to that exact same space again). So yeah, it all seems to check out.\,:) %(12:22)

%(15:05)
\ldots\ It didn't all check out; the last thing I wrote is wrong. But I then went on a walk to think about it, and luckily, I think I might have it now. One should instead use the fact that for the Lorentz transformation path integral, that I just described earlier, one can do the sum of the path endpoints at the end (as you are normally supposed to), and then do the same path integral in reverse to get back.\,. .\,.\,This then shows that there is a representation of the physical wave function in the extended space, which is valid for the un-(Lorentz-)transformed system, and which has the quality for a certain hyperplane in the transformed system that all fermion wave functions of all paths are same within all gruops of paths where the field is the same at that space-like slice. And thus we get that the transformed system is on an exactly equal footing as the un-transformed system. (And one can also note that we thus find such representations that has said quality for any time slice (i.e.\ the space-like hyperplanes) of any of the two systems.) %(15:18) %Great! Skulle vi så ikke sige, at det var det, og at jeg ikke render ind i flere problemer fra nu af?;):) 

.\,.\,Oh, but I guess I still need to get back to the topic about letting $\delta\omega$ tend toward zero.\,. .\,.\,Hm, it might certainly be easier to just do the $\omega$-offset trick, but yeah, I'm still pretty convinces that on can handle those redundant degrees of freedom (which are equivalent of integrating over paths that extend beyond $t$ (for instance of the length $2^n t$ for some $n\in\mathbb N$)), but I probably won't really need this for my arguments.\,. .\,.\,Let me just let the topic be, at least for now. It is nice to know that it is probably doable, but oh well: if I don't need it, I don't need it.\,. %(15:34)

%(17:10)
\ldots\ I got worried again cause I thought about the fact that the wave don't decouple properly when the (hyper-)volume is small compared to the number of $(\omega, \boldsymbol{k})$s. But now I have maybe figured out some things that means that it is all OK after all.\,. And now I just realized also, that if we just take exactly the same (hyper-)volume on the other side of the mentioned pivot point in the Lorentz transformation, then we won't even need to reduce $\Omega t$, and we are also fine in terms of all the wave decoupling (not that we \emph{necessarily} need this, actually, but it is nice to know, either way).\,. .\,.\,Let me also just try to write a bit about my other thought already.\,. I think we might ought to change the picture such that we actually include as fine an $\delta\omega$ grain as we want for the extended space, and then maybe just select a rougher grain whenever we want to do a bounded path integral (bounded in time, i.e.) and make, perhaps, a measurement at the end.\,. 
%(17:24):
\ldots Hm, it seems to be a solid picture indeed, but let me see if I can find a good way of expressing why.\,. .\,.\,(And you then just choose an appropriate grain, similarly, when you do a specific Lorentz transformation (around a certain pivot point and with a chosen length, which should then be the same on both sides for a more neat calculation (even though all the fermions only (always) are located on one side of the pivot point)).\,.)
%(17:54):
\ldots Hm, maybe one could even make sure to just use the same $\Omega t$ volume for the Lorentz transformation as for the.\,. .\,.\,Hm, first of all, it's more about choosing the same $\delta \omega$.\,. .\,.\,Ah, so maybe one could choose a hypervolume for the Lorentz transformation such that it fits $\delta\omega'$.\,. %(18:03)
.\,.\,Hm, well of course one should make sure that $\delta\omega'$ matches the.\,. transformed grid.\,. hm.\,. .\,.\,Ah, so one should maybe just make sure that the $t'$ in the circuit of transformations and propagations matches $\delta\omega^{-1}$.\,.\,! Nice, that does indeed sound like the right way around.\,.\,:)\,.\,. %(18:09) 
.\,.\,Right.\,:) Now things seem to make good sense. So never mind the thing about wanting $\delta\omega$ (and $\delta\omega'$) to be able to tend to zero.\,:)

%(7:53)
(11.05.22) Let me just underline the fact, quickly, that I am now back to an argument that looks at a ``circuit'' of Lorentz transformations and propagations (a bit similar to what I described in my bachelor project, back at that time). This sort of just came out of my brainstorm yesterday evening, as written in the paragraph before this one. But note that there actually is a bit of a quirky detail now: For one of the circuit ``legs'' (parts), one ideally now has to first transform directly to the starting point of the second leg (circuit part), via a path integral of course. And then one has to ``reduce the sum'' here, as I have expressed it above (which means reducing the expression to get the new state, as you would normally). Then you actually have to do the same transformation in reverse, back to where you came from, but \emph{without} reducing the sum. Now you have the same state, but with a different representation in the ``extended ($\{\tilde q\}$) space than what you would otherwise start with. Hm, and can you then just continue with the same representation in this ``extended space'' picture, let's see.\,.(?) %(8:06) 
%(8:29):
\ldots Ah, this is actually quite interesting. I have just thought a bit more about this picture: What happens at the end of each transformation is essentially that all $\tilde q$-fields (i.e.\ space-time fields) with the same configuration at the end (hyperplane) time slice will have their fermion wave functions (including the phase coming from the action, if we thus implicitly factor this on when talking about the fermion wave functions here) added together. But when you then start a new path integral from that point, those sums of wave function will then be distributed evenly to all paths of each of these groups. And note that we get the normalization constant in front every time we start a new path integral, so it makes since that all the wave functions can be added together at each end, or at each ``point''/``vertex'' in the circuit, if we want to look at it that way. And now, the natural idea to prove Lorentz covariance would then be to make sure that both the two ``legs'' of the circuit actually takes enough detours that they both get these, let call them `contractions' here, for all the hyperplanes of the four vertices used in the circuit. %(8:42) 
.\,.\,Hm, and let me just think about the concluding part of the argument, then.\,. .\,.\,Oh, but you just continue with the plan I had for the ``first leg of the circuit,'' but then simply also make sure to do some detours for the second leg now. So for the first leg we.\,. well we essentially start with a state in the starting hyperplane of the ``second leg.'' This is then transformed to the first, let's call it.\,. well, let me actually just keep calling them legs here (that is easier to type than `inertial systems' or `transformed systems,' and what have you).\,. This state is transformed to the starting point of the first leg. .\,.\,Hm, now you actually already have two of the contractions, which thus basically comes for free from the definition of what ``first state'' we are interested in.\,. Okay, and then you of course propagate to a later time and do a final transformation. Hm, and for the second leg, you then make an \emph{actual} detour and transform to the starting point of the first leg and back. You than propagate the state along the time of the second %(8:55).. ..(8:58):
inertial system. .\,.\,And then you make a detour to the third point of the first circuit ``leg'' and back again. And this should then give the same result for both systems, right?\,.\,. Hm, can we even transform back and forth between the two final states at will, actually.\,.\,? %(9:01)
.\,.\,Yeah, it seems like once a contraction is made, it doesn't change the structure of the expression of the final result (when I think about it now% (I am not sitting and doing actual calculation on paper or anything --- never really am, btw.\,. (for all these latest months, I have only drawn a few Lo. trans.-related drawings *(the last one I did a week into April), and used Wolfram Alpha just a couple of times))
).\,. .\,.\,Oh wait, except that when a contraction is made, you also have to.\,. or.\,.(?\,.\,.) .\,.\,Hm, when a contraction is made, the distributed groups of wave functions will now sit on top (as a sum) of all the paths in the relevant path group (of which the group of wave functions, now distributed to all the paths of the group, belong, just to be completely unclear.\,.). .\,.\,Hm, and if you then propagate/transform to another hyperplane (or several) and go back from there.\,.\,? %(9:20)
.\,.\,Well, you get more and more (fermion) wave functions mixed for each contraction, but if we have the same contraction twice with other in between.\,.\,? .\,.\,Oh yeah, that does make a difference.\,. .\,\.\,Hm, we can think about it in terms of just gathering some points into different group configurations (four of such configurations for this circuit), and redistributing the wave functions evenly in each group for such gatherings.\,. .\,.\,And it easy to see that there are sets of configurations where this will continuously result in change (of the wave functions on each path) for each configuration change (in a series).\,. .\,.\,Yeah, so the picture is not as simple as I just thought, here a few moments ago.\,. %(9:40) 
%(10:58):
\ldots\ Hm, maybe I should try to show that you can always leave out the contraction at a certain inner vertex between two other vertices.\,. 

%(11:11)
\ldots Hov, er der ikke en meget nemmere overordnet måde at vise Lorentz-covarians på; gør jeg ikke problemet meget sværere, end det er, med de her tanker om at skulle vise en kreds.\,.\,? 
Overall translation: Do I really need to look at a circuit; isn't there an easier way?
.\,.\,Hm, I am thinking about instead trying to show that every state has a counterpart in another inertial system, such that this counterpart looks like the original state in the other system. This is as opposed to showing that each state has a counterpart in the other system that has the same measurement prediction, only on with transformed (space-time) coordinates in relation to the predictions of the initial state.\,. Hm, the second proposition definitely is equivalent of having Lorentz covariance, but isn't the first proposition also that.\,.\,? %(11:18)
.\,.\,Hm yeah, the first proposition must be equivalent, right.\,.\,? .\,.\,Hm, I can almost feel yet another thinking day coming on.\,. 
%(12:16)
\ldots\ Hm, I think you can show that for two Lorentz-transformation back and forth, but around a different pivot point such that you end up in a different time in the first system, you can leave out the two ``contractions'' at the two ``vertices'' and still get the same result --- namely since what you then get is just exactly the same result as a propagat%..
ion.\,. well, but are you sure that you ought to expect that result?\,.\,. .\,.\,Hm, I guess whenever you have a full circuit, you can leave out all the contractions (and get the same result, i.e.\ the one you started with).\,. .\,.\,Hm, let me see, and since all path integral operations are unitary.\,. whether or not you do a contraction at a vertex or not.\,. hm, I am almost feeling like I am nearing a conclusion.\,. .\,.\,Hm, if you leave out a certain contraction for a two-part propagation, you get the same result as if you had propagated/transformed to the third hyperplane immediately (and skipped the second hyperplane, i.e.\ the one with the (perhaps optional) contraction on it).\,. %...Hm, in a way, I \emph{should} probably have just worked some more on writing the paper and postponed this thinking, but it just feels so iportant, and it would be so nice, if I could finally claer my mind and just trust that I have.. well, have a \emph{good enough} proof strategy, at least.. ..Ah vent, nu tror jeg næsten, jeg har den (eller er lige ved at have den):
\ldots Ah, now I think I am just about to have it. Let me see, if you do two transformations/propagations to a third vertex and leave out both contractions, both at the second and the third vertex, then you get an extended state, i.e.\ a state in the extended space, that will transform back to the initial state with another, third, path integral back to that hyperplane.\,. hm, and.\,.\,? .\,.\,Well, if I know that the circuit is supposed to give the initial state back, then you can then continue this argument to show that we can indeed leave the contraction at the second vertex out, but how do I know that the circuit of these three operations should give the same, initial state back?\,. .\,.\,?   

%(17:22)
\ldots\ I went for a walk earlier ((17:22) now), and I think I might have realized how to make the argument on that walk. Let's see.\,. The idea is to start at an early hyperplane and then only make forward propagations (but maybe transformations with pivot points on the side of the hyper-volume), at least for the most part.\,. The two ``legs'' of the ``circuit'' each then start by propagating from the early plane to one of the two starting points (a different one for each leg of course) of the two inertial systems. We can think of these planes as ``starting points'' in the way that the ``experiment'' is seen as the dynamics happening after those planes, in a sense.\,. We then of course propagate each leg from there along their own time axis.\,. .\,.\,Hm, and us pause there for a moment and think about what we have so far.\,. .\,.\,Hm, I by the way think that my idea about ``contractions'' might be a bad way to view it all.\,. oh, I can feel that I'm actually a bit to tired for this.\,. But I'll keep on going, so just excuse the quality (whoever reads this (including myself of course (so an excuse to you, future me, if you read this.\,. yeah, I must be a bit tired, for sure.\,.))).\,. .\,.\,It might be sort of a bad way to view it, at least when we only have these forward propagation --- essentially since, in a way, there is always a ``contraction'' for each time slice in any path integral.\,. Hm, I should definitely get back to this tomorrow when my brain has condensed again.\,. .\,.\,Hm, or maybe I just need a break, so I think I'll take one, and then just see if I return.\,. %(17:40)

(13.05.22) Ah, I finally think I have the idea to solve this problem (namely of showing Lorentz covariance after having shown (the ``big lemma'') that the calculation is the same in $(\omega, \boldsymbol{k})$ space). I got it last evening at eight o'clock. I believe the trick is to actually divide the path integral (over a very large hyper-volume) up into smaller (and very oblong) volumes that are sandwiched between two pairs of hyperplanes where respectively $t$ and $t'$ are constant. While each such volume might be small compared to the whole volume, they are still free to be arbitrarily big themselves, and $\delta t$ and $\delta x$ ($\sim k_{max}^{-1}$) are of course free to get arbitrarily small within them. (So the ``small'' volumes do by no means need to tend smaller and smaller --- in fact, the only reason we need them to be.\,. small.\,. Oh, never mind, by the way: We could actually have them be the same width as the whole volume.\,. well, the width of the whole volume times two, in fact. As long as the fermion can never (due to the Lorentz covariance of the Dirac equation) propagate to the sides of the whole volume, we should be fine.) We will need to have periodic boundary conditions on the sides of the volume.\,. well, I should actually look a bit into that part of the solution. Hopefully this will cause no trouble (I think it won't, but then again: things tend to do.\,.). .\,.\,Well, it might turn out that there is a reason there to have the smaller volumes be relatively small compared to the larger volume, but I will look into this later.\,. .\,.\,Okay, the benefits of using these oblong, narrow volumes is that first of all, it means that the fermion wave functions propagate independently on the two neighboring volumes that are (strictly!) forward in time, which means that we can add the volumes on ``brick'' at a time in the path integral. And the second, more important, thing is that now it makes perfect sense again to ask about measurement along either of the faces of this grid (which has the appearance like a crystal). This was a big problem before: Once we have gone to $(\omega, \boldsymbol{k})$ space, we cannot just break up the volume again, and ask for measurement somewhere within it (not without developing a whole new method of doing this). So this is why I am so excited about this way of doing the path integral: now it \emph{makes sense} again to do measurements along either of the faces. And this seems to be a very integral part, for how else would you define Lorentz covariance of a quantum system, if not by what measurements you expect of (any) two corresponding states at some (any) points in space-time?\,. 

Note that while any of the smaller (oblong) volumes are free to have almost any $\{\tilde q\}$-values (and not that the whole path integral thus now consist of many $\{\tilde q\}$-integrals (an important point to note)), there will be the restriction that the fields should match at the interfaces.\,. hm, why will this be exactly, come to think of it.\,.\,? .\,.\,Hm, well you \emph{should} get delta functions (.\,.\,Which are called `Dirac delta functions' more precisely.\,.), just like you do at $\boldsymbol{q}_0$ and $\boldsymbol{q}_t$, but let me see how these come about.\,. .\,.\,Ah, they come about in exactly the same way: you can just make all the ``faces''/interfaces/boundaries first for the path integral, and then evaluate and Fourier transform each individual (smaller) volume to get the desired result (i.e.\ with a $\{\tilde q\}$ integral for each). So yeah, these integrals will then be restricted (only) by these delta functions on the interfaces. .\,.\,Okay, and what else should I note?\,.\,. oh, that we can then do the ``big lemma'' argument for each of the small volumes, of course, to.\,. well, to essentially make all the high-frequency waves ``invisible'' to the fermions.\,. .\,.\,Oh, but there is a thing to think about: What does this mean for the delta functions on the interfaces, since the actual field values on the interfaces is given by the full $\{\tilde q\}$ and not the reduced version of it.\,.(?)  

(14.05.22) Ah. \emph{Now} I think I might finally have it! (7, 9, 13.) I worked on the problem I discovered yesterday at the end of the previous paragraph. More specifically, I thought about how to also ``cut off'' integration over $\tilde q$s outside some $\omega, \boldsymbol{k}$ boundary, this time not in terms of setting a coupling to zero, but in terms of letting the $\tilde q$s be constant, equal to zero, and thus getting rid of the integrals. If we look at points way outside the volume for which we have the couplings intact (so out where the couplings are set to zero), we deal with simple Gaussian functions. But it took me some time to figure out how to make the $\omega$ cut-off needed. But at some point, probably in the early afternoon yesterday, or around that time, I thought of the convolution theorem, which I have considered recently (when my problem was still the fermion-boson coupling cut-off), and that seems to solve the problem immediately. Note that we only need to show that we can make a cut-off for one $\boldsymbol{k}$ column at a time, so we only need an $\omega$ dependency decreasing faster than $\omega^{-1}$. And if you use the convolution theorem, we see that we, in Fourier space of the $q$-amplitude, get a product of Gaussian functions with the inverse variances. And since the variances then roughly goes as $\omega^{-2}$, any point of the Fourier-transformed $q$-amplitude will be an exponential function with sum in the exponent going as $\sim \sum_{\omega=\omega_{integration\, max}}^{\infty} 1 / \omega^2$. And this of course tends to zero as $\omega_{integration\, max}$ tends to $\infty$, so.\,. well the product of the exponential functions (giving the mentioned sum in the exponent) is actually not for the whole Fourier transformed $q$ function, but only all the ones coming from all the convolutions. And this product then point-wisely tends to a constant function, namely since the exponent tends point-wisely to 0, which means that we get the same function back after all the convolutions, when $\omega_{integration\, max}$ tends to $\infty$. So for large enough $\omega_{integration\, max}$, we might as well just remove these convolution integrals and just set the $\tilde q$s with $\omega$ larger than $\omega_{integration\, max}$ to 0. So far, so good, but what about making a cut-off for $\boldsymbol{k}$?\,. Well, I'm actually a bit proud of how quickly I found a solution to this problem, even though I didn't feel particularly sharp yesterday. But I was still able to pretty quickly *(after a few dead ends and pauses) see (``pretty quickly'' in the sense that I found the solution somewhere around four o'clock) that we can actually make a cut-off for both inertial systems with $q$-waves ($\boldsymbol{k}$-waves, i.e.) we simply don't care about, namely such that if any $\tilde q$ wave has a $\boldsymbol{k}$ that is outside the $\boldsymbol{k}$ bounds of \emph{both} inertial systems, we can choose to not care about this contribution whatsoever. This is simply due to that fact, that we can always choose to put a bound on what photons we are interested in measuring. And since the the coupling is already turned to zero for the relevant photons, there behavior is then completely decoupled from the states that are within the bounds of interest. At the same time, we see that at the interfaces, when going from one.\,. of the smaller, oblong volumes to another, if the a $\tilde q$ wave is out of (interest-)bounds for both inertial systems, then it will only couple to other $q$-waves that are outside our bounds of interest.\,. Hm well, maybe this part of the argument then requires a sort of measurement at each interface, to be rid of.\,. hm.\,. Let me think for just a moment.\,. %..(10:39) btw..
%(11:42):
\ldots\ Ah, I think I'm back on track! This last hour, I've been thinking a bit about whether to make a kind of measurement on the interfaces and/or use something about.\,. well, that doesn't matter now! (And I also found it a bit hard just to collect my thoughts, but once I finally got them collected, just now, I can see why my solution from yesterday actually holds as it is.) No, let me get back to explaining the idea from yesterday then, and hopefully it will hold up all the way through. The idea is that if you cut off any $\tilde q$ that has a $\boldsymbol{k}$ and a $\boldsymbol{k}'$ that are both outside of the bounds of interest, and you do this for all the (smaller) oblong volumes, then for both inertial systems, the error you get will be.\,. well, zero, in fact, since you only get errors on $q$ waves (in either of the two inertial systems) that you don't care about. The reason I just got confused is that I got the thought that you need to change back and forth between the inertial systems for the argument (and then I thought that there might be a string of $q$s that couple to each other in these transformations, such that you can go from a $\tilde q$ outside of the bounds and eventually to a $\tilde q$ inside of the bounds (but I will not explain this thought further, as it isn't the right way of looking at things after all)). But you just need to make \emph{one} cut (for both inertial systems simultaneously, namely such that all the $\tilde q$s inside the bounds maps to $\tilde q$s inside the bounds of the other inertial system), and then argue that this cut will cause no error inside the bounds of interest for both systems. %(11:54)
.\,.\,Okay, and then I still need to explain how to make these cuts. First of all, we note that the argument for the $\omega$ cut-off allows to choose a certain $\Delta\omega$ and then cut off any $\tilde q$s we want (and leave any one we want to be) above the $\Delta\omega$-margin line, which is at a distance of $\Delta\omega$ above the $\omega=k$ line. It is then not hard to see, that if we choose a $k_{1\, integration\, max}$ large enough compared to $k_{1\, interest\, max}$ *(and to $\Delta\omega$), as well as an appropriate $\omega_{integration\, max}$-curve above the $\Delta\omega$-margin line, then we get an $(\omega, k_1)$ volume, that when transformed only differs from the un-transformed volume on points that are outside of the compound interest bounds (i.e.\ both above the $\Delta\omega$-margin line and outside of $k_{1\, interest\, max}$). And these are all $\tilde q$-points we are free to remove/add anyway, so both the transformed and the un-transformed volume will be ``valid volumes'' for our integration-max boundaries in the two inertial systems. And now we have a very desirable picture! We have a path integral which can be separated into the ``oblong volumes'' that I got the idea to use the day before yesterday, and where for each of these volumes, we can integrate over a specific $\tilde q$-parameter volume (and getting only an arbitrary small error (as compared to the original path integral with no cut-offs)), which when transformed to the other inertial system also gives a ``valid'' $\tilde q$-volume for the path integral. So from that point on we only ever need to consider these exact $\tilde q$-parameters (or their (Lorentz-)transformed counterparts) --- as well as the somewhat smaller volume which gives us the coupling-max boundary (which also transforms to another ``valid'' boundary) --- when propagating the wave function(s) over an ``oblong-volume,'' let me just call them that here, for now.\,. (.\,.\,In my head, I also like to think of the volumes as ``crystals,'' but I prefer to call them `oblong-volumes' over that.\,.) Since the actual path integral has much larger $\omega$s and $\boldsymbol{k}$s in the Fourier space, the contribution for each $\{\tilde q\}$ wave will be approximately the same (arbitrarily so, i.e.), and another thing this fact (of being a smaller volume inside a larger Fourier volume) gives us is that we will get arbitrarily precise (Dirac) delta functions on the interfaces between all the (``crystals'') / ``oblong-volumes''.\,. such that the $\{\tilde q \}$-fields have to meet the same boundary values as their neighbors' as the only restriction on these fields.\,. %(12:22)
.\,.\,(And these restrictions will of course also transform to the same restrictions, since the are just delta functions for the field values to be the same on the boundaries.\,.) .\,.\,Is there anything else I need to talk about.\,.\,? .\,.\,I am so happy, that it seems that I can finally be getting back and begin finishing the paper.\,.(!) .\,.\,It seems like there is nothing more that I need for this argument. But let me just take a walk (a victory lap, almost) and just ``hum'' a bit over, whether I've really reached the goal, finally.\,. %(13:37)

%(14:28):
\ldots\ Before I left, I thought about the fact that it will probably be good to make sure that $\boldsymbol{k}$-waves match the.\,. oh, I was about to say the $\boldsymbol{k}$-waves on the other side of the interface, but this should be pretty trivial.\,. Yeah, and I haven't found anything else to add so far.\,. I was a bit distracted, so let me just think a bit more about the whole problem, and then (hopefully) move on and resume working on my paper.\,.\,:) .\,.\,Hm, I think we are good.\,.\,:)\,.\,. \ldots I just thought about about the outer boundary conditions, which I mentioned something about, I think it was the day before (but I don't care to search above to find out). I thought back then that we might need to have periodic boundary conditions.\,. So I just thought a bit about this, and I've realized that all you need to do, is to have no outer boundary conditions and then just make sure that the interface (``crystal face'') boundary conditions are met between each ``crystal''/``oblong-volume,'' starting from the face(s) where the initial state is defined and going out from there (in space and in time, both forwards and potentially backwards in time, say if you first want to propagate back to an earlier face with constant $t'$ and use that as the initial state in the transformed system, whose dynamics you then want to compare to the dynamics of the state in the first system). .\,.\,And that's it. We will then have shown that you can do all these propagations/transformations from there by doing the partial path integrals over the ``oblong-volumes,'' one at a time, and that the resulting dynamics of each such integral will be Lorentz-covariant. .\,.\,:)\,! 

(15.05.22) Ha, why didn't I just an ``oblong-volume'' a rhombus instead?\,.\,x) Let me call them that from now on.\,.\,\textasciicircum\textasciicircum\ 

(17.05.22) I have found out more about how to construct the $(\omega, k_1)$ grid. I want all points to transform onto the new $k_1'=\mathrm{const.}$, such that they are equally spaced on those lines (with what will be $\delta\omega'$), and I would like for all $k_1=\mathrm{const.}$ / $k_1'=\mathrm{const.}$ lines (in both systems) to have a point exactly on the $\omega=k_1$ line. The way to get this is then to start at $(0,0)$ and plot a series of equally spaced points on the $\omega=k_1$ line. I like to think of this line as being a 45\textdegree\ line, by the way, but I guess one can think of it as one likes. Oh wait, no, the spacing between these points are not arbitrary, but is determined by the following. Draw a $k_1'=\mathrm{const.}$ line from $(0,0)$, and mark a point where the line intersects the line that is parallel to the $\omega = k_1$ line, but a vertical distance of $\delta\omega$ above it. Then draw a vertical line through this point, such that the point becomes the opposite point to $(0,0)$ in a parallelogram, namely with two vertical sides of length $\delta\omega$ and two sides that are parallel to the $\omega=k_1$ line. The bottom (right, when we take the $k_1$ axis to go to the right) corner that is not $(0,0)$ will then be the second point on the $\omega=k_1$ line, and the points horizontal spacing is thus equal to the width of the parallelogram. Now you simply build the rest of the grid as a lattice of these parallelograms and the goal is met. This construction does, however, require a certain $\delta k$ that is fixed relative to $\delta\omega$, which is not desirable since this would limit the precision of the path integral (and note that a fixed $\delta\omega$ does not, as the latter only depends on $t$). But luckily we can add to the construction by adding points between the original points on all the $\omega=k_1$-parallel lines, with equal spacing between them, of course. This still gives us a grid of the same parallelograms, but now the are just overlapping. This way we can see that we can get $\delta k_1$ and $\delta k_1'$ to be arbitrarily small. 

I also realized something else this morning. I think I am going to move the path integral section up to just after the deriving $\hat H_{in}$ section, and then I think I might just add to the end of the partial solution section, such that I already include the added ($\propto\epsilon$) potentials and maybe even make the argument of Lorentz covariance right then and there.\,. Hm, well maybe not; maybe.\,. Ah yeah, maybe I should divide it into two sect.\,. hm.\,. .\,.Hm no, I think I will indeed include it at the end of that section.\,. .\,.\,Yes, okay. And then I can just see if I want to start the argument for Lorentz covariance there, or if I want to save even that part for later. Okay. Then let me actually begin a new document, namely \texttt{draft2.tex}, and then also make sure to cut away a lot of out-commented line, including comment brainstorms and such. %(11:10)

(18.05.22) The approach that I have written about in my draft somewhere, where I intend to argue for how Lorentz covariance of $\hat H_{in}$ leads to Lorentz covariance of the partial solution (if the restrictions of the partial solution also transforms Lo.-covariantly) by defining some solutions that depend on $\epsilon$, that does not work. I need to be able to let $\epsilon$ tend to 0 while the approximate partial solution space remains constant, and then I should probably argue, that by narrowing the initial solution space more and more around the clean (non-normalizable) partial solution (before letting $\epsilon$ tend to 0), then the dynamics should approach that of $\hat H$.\,. .\,.\,I know I have previously concluded on this problem and then written something like: ``future me should just return here, if I ever forget how to do this again'' (which I apparently do all the time for god-knows-what reason.\,.), but now I can't find it.\,x)\, So let me just brainstorm a bit here.\,. .\,.\,Let me actually change section for good measure.


\section{Lorentz covariance}
This section is not actually about a whole treatment of how to show Lorentz covariance, since my last section basically turned into that at the end. So this is just to draw attention to the fact that my current ((18.05.22)) solution to showing Lorentz covariance is written about (in the form brainstormy notes where I figure it out as I write) in the previous (``$t\to\omega$'') section. And this section is then actually just a continuation of that section --- and hopefully, it won't be a long one, since I feel like I finally have a pretty good grip on the solution.

But I need to brainstorm a bit about.\,. well, about what I just wrote about in the last paragraph of the previous section, since the solution for that part has slipped my mind again (or so it seems; I don't know if I actually had it right the last time (as I can't quite remember the solution)).\,. 

\ldots I found the ``if I ever forget again'' paragraph (by searching on forget), but it just says what my overall remembrance is of that solution, which is: ``use the fact that the ``approximate eigenvectors'' approximate those of $\hat H$ better and better''.\,. well, but isn't that exactly what I need to do.\,.\,? .\,.\,Hm, I somehow foresee that I will actually need to think a bit more about this, so I might as well go out in the lovely weather and do that.\,.\,;)\,.\,.  

\ldots It took a little bit of thinking, but I've reached a solution that should make it pretty easy. If we make the partial solution normalizable by factoring on 
$\exp(-\epsilon' \sum | \tilde A_0 | - \epsilon' \sum | \tilde A_3 |)$, or better yet:\\ $\exp(-\epsilon' \sum \sqrt{\delta + \tilde A_0^2 } - \epsilon' \sum \sqrt{\delta + \tilde A_3^2 })$ (to make it nicer to differentiate), then we can (if I'm not mistaken) see that we get only bounded errors (which tends to zero together with $\epsilon'$) in terms of the effective operator on $\Psi$. The problem with adding a factor of $\exp(-\epsilon' \sum \tilde A_0^2 - \epsilon' \sum \tilde A_3^2)$ was that then the error would increase with the $\tilde A_{03}$-coordinates, and you would have to argue about the ``effective support'' of the wave function, or that we can somehow choose to only be interested at what happens to $\Psi$ around the smaller $\tilde A_{03}$-coordinates.\,. But with this solution, it should all be pretty simple.\,. %(13:59) (I got up late today (for whatever reason), even though I went to bed relatively early..)
.\,.\,The argument from there will then be, that for all $\epsilon'$, we can let $\epsilon$ go to zero and get a more and more Lorentz covariant evolution (of whatever state we are looking at), and by choosing a small enough $\epsilon'$, the effective operator on $\Psi$ will be closer and closer to $\hat H$ (for the given $\Psi$). (.\,.\,And one can %nemlig
argue that when $(\Phi\Psi)^\dagger \hat H_{in} \Phi\Psi$ approximates $\Psi^\dagger \hat H \Psi$ better and better, then the dynamics of the propagator on the local part of $\mathbf{H}_{in}$ must get closer and closer to the $\hat H$ propagator on the collapsed/reduced $\mathbf{H}$. (.\,.\,When $\hat H$ is self-adjoint.))

\ldots Ah, and first you discretize $\hat H$.\,. .\,.\,And then you make the argument where you approximate this discretized system with the self-adjoint version of $\hat H_{in}$ on $\mathbf{H}_{in}$. And you then see that when the solution space is narrowed around the ``partial solution'' (meaning that $\epsilon'$ is taken to be smaller and smaller) and when $\epsilon$ also tends to 0, then the dynamics of the solution space will approximate that of the discretized $\hat H$, and they will be more and more Lorentz-covariant as well. This then shows that $\hat H$ is Lorentz-covariant. .\,.\,Yeah, it seems like a good detail to make sure to discretize $\hat H$ first thing. And that's where the self-adjointness of $\hat H$ enters the argument (apart from being a requirement overall, I guess.\,.). 



\section{Showing self-adjointness of $\hat H$ in more detail}
%(17:43)
(23.05.22) I actually think that it might be a good idea for me now to begin working a bit on this part in the evenings (which it's about to be now (or \emph{is}, one \emph{could} say.\,.)).\,. %(i.e. with my overall prefered definitions..)

Anyway, let me therefore try to get going with that problem now.\,. 

(24.05.22, 12:52) Okay, I think I have gotten I good idea of the basic approach for proving self-adjointness again. Well, actually I have gotten a slightly different idea now (which I got very late this night; for some reason I decided to think about the problem at about one to half past one last night, three glasses of wine in, and I actually managed to think some pretty good thoughts (my brain can sometimes work decently enough when tired, depending on the type of problem.\,.)). I think I will use the actual definition 9.1 in Hall, instead of the equivalent one underneath. But let me get back to this matter, because I actually think it is better for me to get some more writing done today, and then I can sort of ``hum'' (in my head, i.e.) over the problem in the breaks I take. Then when I get back to the problem, I will hopefully have a better idea for exactly where to start in terms of the calculations to check my solution idea. %(13:01)

(15:17) Okay, let me try to write some things up now.

Let $V$ (for now; all of these names can change.\,.) be a set of virtual $\{\{\mathbf{k}\}, \{\mathbf{p}\}\}$-(delta-)states that contains all the ($\{\{\mathbf{k}\}, \{\mathbf{p}\}\}$-)areas that are the standard areas to cancel ``productions'' with. So if a state with $n$ photons $\psi_n$ has its productions, given by $A^+ \psi_n$, canceled the standard way, then $\psi_{n+2}$ is a state exclusively over areas in $V$, at least unless we happen to have some other states in $\psi_{n+2}$.\,. well, I know what I mean.\,. 

We could also divide $V$ up into even and odd levels, but I will only do that if need be. 

When following $V$, each area has a part of $V$ designated to cancel its productions, but how much of the production is canceled, and/or how big the norm of the minimal state over the designated area need to be in order to cancel said productions, that might vary.\,. .\,.\,We of course wanna be good to areas that are themselves part of $V$, and we of course want the un-canceled areas and/or the minimal norm of the canceler states to generally be smaller and smaller, at least at a point where a overall state starts to follow the prescription of $V$.\,. .\,.\,And one of the most important qualities of $V$ is that for any state over areas in $V$.\,. Oh wait, so some of what I just said is actually wrong.\,. *(No: ``good to areas'' in terms of canceling their productions. So what I wrote should make sense.\,.)

But let me just continue: For any state $\psi$ exclusively over (/ supported only by) areas in $V$, we should have that $A^- \psi$ is supported by no areas in $V$.\,. 

.\,.\,Hm, let me actually take a little break, and then think about, how I want to try to continue on, if I don't just write some more on the paper, that is.\,. %(15:54)

\ldots\ Hm, and let us say that areas in $V$ can get all their productions canceled by areas in $V$ (two levels above).\,. 

Now we want to somehow construct our Dom($A$) so that all $\psi\in\mathrm{Dom}(A)$ have.\,. ``canceler tails'' almost exclusively in $V$, or rather in what we could call $W$ (for now) of states that are integrals only over the (delta-like) virtual states in $V$.\,. 

.\,.\,Hm, let me just copy these formulas down for a moment.\,.\,:
\begin{align}
\begin{aligned}
	\braket{\phi'| A \psi} =&\, 
		\braket{\phi'_{n}   | A^- \psi_{n+1}} + \big[
		\braket{\phi'_{n+2} | A^+ \psi_{n+1}} + 
		\braket{\phi'_{n+2} | A^- \psi_{n+3}} \big] + \big[
		\braket{\phi'_{n+4} | A^+ \psi_{n+3}} + 
		\ldots\\
	\braket{A \phi'| \psi} =&\, 
		\big[
		\braket{A^+ \phi'_{n}   | \psi_{n+1}} + 
		\braket{A^- \phi'_{n+2} | \psi_{n+1}} \big] + \big[ 
		\braket{A^+ \phi'_{n+2} | \psi_{n+3}} + 
		\braket{A^- \phi'_{n+4} | \psi_{n+3}} \big] + 
		\ldots
	\label{symmetry_considerations_ldots}
\end{aligned}
\end{align}

\ldots We also, by the way, want to make it costly for states over $\mathbf{H} \setminus W$ to ``join'' $V$ such that states can't oscillate back and forth, away from $V$ and then back again, forever without racking up an infinite norm of their image.\,. (.\,.\,But we probably don't want to make it \emph{more and more} costly, like I first thought; we probably want to make it just costly enough, roughly.\,.) 

.\,.\,Okay, it is not hard to see intuitively, why we can probably get Dom($A$) with such a definition to be symmetric under $A$, looking at Eq.\ (\ref{symmetry_considerations_ldots}).\,. .\,.\,Once both $\phi$ and $\psi$ has ``joined $V$,'' we nemlig %*(I wish there were a good adverb just like 'nemlig' in English..)
see that all these terms (since they can all be written in terms of a ``matrix element'' of $A^-$) should start to vanish.\,. 

(19:01) Wow, %(wauw)
now it almost seem like showing that $\mathrm{Dom}(A^*)\subset\mathrm{Dom}(A)$ is going to be quite easy (though I'm not completely sure yet, of course), and if it is still easy enough to make Dom$(A)$ symmetric under $A$, then.\,.\,:)\,.\,. .\,.\,Let's hope (7, 9, 13).\,. 

.\,.\,Basically, it seems like if $\phi'$ is a ``cancellation tail'' of an overall state $\phi$ where $\phi'$ never joins $V$, then we can make an arbitrarily big $\braket{\phi'_{n}   | A^- \psi_{n+1}}$ (with $\psi$s taken from $\mathrm{Dom}(A)$), and we can also continue this by choosing $\psi$s that always cancel every area of $\phi_{n+2j}$ completely, such that $\braket{\phi'_{n+2j}   | A^- \psi_{n+1+2j}}$ keeps getting the same high value as $\braket{\phi'_{n}   | A^- \psi_{n+1}}$.\,. %(19:13)

.\,.\,Hm, and I guess we should be able to show that $\braket{\phi'_{n+2j}   | A^+ \psi_{n-1+2j}}$ and/or $\braket{A^- \phi'_{n+2j} |  \psi_{n-1+2j}}$ (hopefully both.\,.) will keep having the opposite value of $\braket{\phi'_{n-2+2j}   | A^- \psi_{n-1+2j}}$.\,. .\,.\,But I should think about that.\,. .\,.\,Oh, we do have $\braket{\phi'_{n+2j}   | A^+ \psi_{n-1+2j}} = \braket{A^- \phi'_{n+2j} |  \psi_{n-1+2j}}$.\,.\,:)\,.\,. .\,.\,(And note that we may not need the second line of the above equation, expect for the fact that substituting $\braket{\phi'_{n+2j}   | A^+ \psi_{n-1+2j}} = \braket{A^- \phi'_{n+2j} |  \psi_{n-1+2j}}$ can make it a bit easier to understand sometimes --- or it's nice to see both things sometimes, at least.\,.\,:)) .\,.\,Ah, and \emph{if} $\phi'$ is a --- or is very close to --- a ``cancellation tail,'' then we should indeed have 
$\braket{A^+ \phi'_{n+2j}   | \psi_{n+1+2j}} = - \braket{A^- \phi'_{n+2+2j} | \psi_{n+1+2j}}$.\,:)\,.\,. .\,.\,Okay, so maybe this part \emph{will} actually be a lot easier than anticipated with my solution.\,. (namely with my new approach added, where we use the actual Definition 9.1, instead of the equivalent one.) .\,.\,(7, 9, 13.\,.)

.\,.\,Ah, but I \emph{am} actually using that.\,. well, let me put it this way: For this argument, I still then need to show that all $\phi$s not in Dom$(A)$ will have such a ``cancellation tail'' that never ``joins $V$'' (almost completely never), and that then requires the part about making it costly to join, such that we can't have.\,. well, can't have oscillations without getting an infinite image, and then we need the argument on top of that saying that infinite-image $\phi$s can't.\,. .\,.\,can't be part of Dom$(A^*)$. So yeah, we still need all these parts of the argument, after all.\,. %(19:47)
.\,.\,Oh, but we don't then need the part about the formula being the same on Dom$(A^*)$; we only need to show $\mathrm{Dom}(A^*)\subset\mathrm{Dom}(B)$ (i.e.\ no infinite images), which is probably an improvement.\,. %(19:49)

\ldots Oh, and the reason why we shouldn't make it \emph{more and more} costly, is that we need to be able to find $\psi$s with larger and larger (arbitrarily so) 
$\braket{\phi'_{n+2j} | A^- \psi_{n+1+2j}}$, without ever having to.\,. .\,.\,Hm.\,. .\,.\,Ah yes, without the $\psi$s in the series ever getting an infinite image, cause that will mean that they cannot be in Dom($A$).\,. 

%...Okay, og i morgen må jeg så kunne finde frem til, hvordan jeg (lidt) mere præcist skal definere Dom(A), og så tage den derfra.. 

(25.05.22, 11:46) Uh, now I just got the idea: Can't it be costly for the norm of the wave function \emph{itself} to oscillate, instead of just the norm of its image?\,.\,.\,! 
.\,.\,Ah, and that is actually in a way an idea from yesterday, cause there I had the thought to add: ``and/or how big the norm of the minimal state over the designated area need to be in order to cancel said productions'' (without thinking much more about this when writing it).\,:)\,\textasciicircum\textasciicircum\ 
.\,.\,And then we shouldn't even need to show that $\mathrm{Dom}(A^*)\subset\mathrm{Dom}(B)$ *(i.e.\ as a lemma; it still needs to be true at the end, of course), or what.\,.\,?\,:) %(11:52)

%(12:39)
\ldots Hm no *(/ yes, we might.\,.), I actually don't think it's gonna be quite that simple.\,. .\,.\,Hm, no I think we do need to make it costly for the image, and to show $\mathrm{Dom}(A^*)\subset\mathrm{Dom}(B)$ (i.e.\ that the formula of $A$ sends any $\phi\in\mathrm{Dom}(A^*)$ into a normalizable wave function).\,. 

%(12:54)
\ldots Hm, the way I see it, there is a reasonable way to define this costliness: When we define $V$, it is quite natural to define it with a built-in specification for how quickly the norm of the ``cancellation tails'' should converge. So $V$ will probably have a formula for how big the norms should be at every step, of course given how big the norm of the original state was, whose productions we want to cancel. This formula is of course \emph{when} the tails follow $V$. But should they then break off from $V$, then $V$ will ``know'' how big the original norm was compared to the one of the wave function part supported on the area that just violated $V$ prescription.\,. .\,.\,Yeah, and then we (or ``$V$'') should know how much to punish this break-off tail, i.e.\ by having it as part of the prescription that this area need to produce a large image compared to its own norm, and exactly how large is then derived from the mentioned formula ``inside $V$.'' And this way, we should, I think(.\,.), be able to make the problematic oscillations impossible without getting an infinite image under $A$('s formula). And the reason why oscillations are ``problematic,'' by the way, is that they individually do not break the symmetry (and will thus be part of Dom$(A^*)$ unless we do something to prevent this), but when all oscillating states are added to Dom($A$), it does break the symmetry of this (``under $A$,'' that is).\,.  .\,.\,(Namely since the oscillating states can be ``asymmetric under $A$ with each other''.\,.) 

(15:29) Okay, I have thought about various things and had various ideas and insights, and now I just realized, that we might actually be able to exclude all $\phi$ for Dom($A^*$) that even just have a ``finite part of the cancellation tail that is not in $V$ (or $W$.\,.), but let me just think some more on that.\,. .\,.\,Well, ``finite part'' is probably not a good way of qualifying it, but we could maybe say ``an actual sub-tail that is not in $W$'' instead. In other words, I am talking about a part of the tail that is not in $W$ where the norm of each level of the sub-tail decreases such that the norm converges, but where it never becomes 0 completely and stays there (for all subsequent levels).\,. 

.\,.\,Hm, does that then really mean that we can take all states that at some point (i.e.\ at some level) ``joins $V$'' completely to be the set we want to use for Dom($A$).\,.\,?\,.\,. %(15:45)

%(18:27)
\ldots\ I took a walk and found out that it is probably important to actually choose infinite areas as valid areas for canceling the productions of each point in $V$ (two levels down). We should thus, in other words, make sure that each point in $V$ can have its productions canceled by an arbitrarily small (in terms of its norm) cancellation tail. I see no reason why allowing this should cause any trouble.\,. And then our Dom($A$) can maybe indeed (7, 9, 13) just include all states that is (almost-)completely (except in subsets with vanishing Lesbeque measure volume, or whatever one would call it) in $W$ after a certain level (which can vary from state to state, of course).\,.  

\ldots Wow, %(wauw)
imagine if it really is this simple.\,.(!\,.\,.)  

\ldots Oh, and I should mention why I think that all other states are excluded from Dom($A$) (which by the way also have the restriction, of course, that $\mathrm{Dom}(A^*)\subset\mathrm{Dom}(B)$. The reason is that when a $\phi$ has any tail not in $W$ that does not vanish after a certain level, then we can construct a state that is in Dom($A$) where we for each level of this non-vanishing tail, call its wave function at that level $\phi'_n$, take very small (and smaller and smaller) $\psi_{n+1}$ to give a certain $\braket{\phi_n | A^- \psi_{n+1}}$ that we want; any value we want. And we can get that same value for all levels, even though the tail might decrease rapidly, for we can then just construct each $\psi_{n+1}$ to be similarly more and more aggressive against $\bra{\phi'_n}$. This makes $\braket{\phi | A \psi}$ converge to that value, and since we can do this for any value we want, the functional $\psi \mapsto \braket{\phi | A \psi}$ is unbounded. Therefore $\phi$ is not in Dom($A^*$), which then (7, 9, 13) means that $\mathrm{Dom}(A^*) \subset \mathrm{Dom}(A)$, giving us $\mathrm{Dom}(A^*) = \mathrm{Dom}(A)$.\,. 

.\,.\,Oh, but we still need, then, to show that $\mathrm{Dom}(A^*)\subset\mathrm{Dom}(B)$; namely that we can't choose $\phi$s either that fulfills the new $\mathrm{Dom}(A^*)$ restriction, but which happen to have an infinite image under $A$.\,. %(19:17)

\ldots Yeah, and we probably need a quite different argument for this, let's see.\,. .\,.\,Hm, can we construct $\psi$s where each $\ket{\psi_{n+1}}$ squeezes more and more out of $\bra{A^+ \phi_{n} + A^- \phi_{n+2}}$, and/or exploits $\phi$ for more and more levels in the series *(of overall $\psi$s).\,.\,?\,.\,. %(19:43)
.\,.\,Hm, I probably do need to increase $N$ for the series for this argument, where $N$ in this context is the maximal level before all $\psi_{N+j}$s are completely contained in $W$.\,. %(19:47)
.\,.\,But when doing so, shouldn't we then be able to exploit such a $\bra{\phi}$ more and more, exactly like we want to be the case.\,.\,? .\,.\,Hm, I guess I need to obtain, then, that we can match the non-converging series of $\bra{A^+ \phi_{n} + A^- \phi_{n+2}}$ more and more with $\psi_{n+1}$s, but where the overall $\psi$s that does this still doesn't increase in norm for the series (of overall $\psi$s).\,. .\,.\,And I guess that this then just (since we should indeed just (unless I'm mistaken, 7, 9, 13) be able to increase $N$ more and more, ad libitum) amounts to showing, that for an infinite (norm-wise) wave function $\chi$, one can get an arbitrarily big $\braket{\chi | \psi}$ with a series of normalized $\psi$s.\,. .\,.\,Hm, and to show this, let us look at a cut-out of $\chi$, call it $\chi'$, that has finite norm. By choosing a $\psi$ that is parallel to $\chi'$, we then get $\braket{\chi' | \psi} = \|\chi'\|$. And by choosing a larger and larger cut-out $\chi'$, and a matching $\psi$, more importantly.\,. oh, and by also using the fact that for such $\psi$s, $\braket{\chi' | \psi}=\braket{\chi | \psi}$, then we see that we can indeed get an arbitrarily big $\braket{\chi | \psi}$ this way. :) .\,.\,! %(20:04)

%(26.05.22, 10:36) Nå, humøret har lige sænket sig adskillige grader.. ..Jeg vågnede lidt tidligt ift., hvornår jeg gik i seng, og lå så og slumrede lidt. Og der fik jeg så tænkt lidt videre på, hvordan formlen for V måske skulle se ud. Det slog mig så, at det måske ikke fungerer alligevel, og at jeg altså måske har lavet en fejl ret tidligt i forløb.. tja, eller vent, for det er jo nok nærmere lige præcis tanken om, at V sagtens kan lade sine egne cancellation tails være; nu er jeg altså bange for, at jeg må have lavet en fejl, da jeg sagde god for dette dengang.. (10:41) ..(Eller rettere, lade sine (designerede) cancellation tail-områder være..)
%... Hm, så det er faktisk lige før, min "forkerte udregning" fra dengang i efteråret eller start vinteren '17 faktisk \emph{var} rigtig nok.. sådan overordnet set.. (11:38)  

%(16:45) Okay, jeg er kommet på en idé omkring at sørge for, at trin/niveauer med jævne mellemrum faktisk bruger lav-k \psi_{n+2} tilstande til at kvæle alle productioner fra \psi_n, som så selv (altså \psi_n) skal nås at gøres virkeligt lille, sådan at den overordede tilstand kan holde til disse trin, uden at det ødelægger dens konvergens --- eller dens billedes konvergens i øvrigt. Nå, og nu er jeg så lige kommet på, at vis jeg.. Nå nej, jeg skal også først sige, at jeg så også er kommet frem til, at min løsning fra i går ikke helt holdt ellers, fordi den heller ikke tager nok højde for "oscillerende tilstande." Nå, men nu er jeg så lidt kommet frem til, at det \emph{måske} godt kunne se ud til, at der er en sandsynlighed for, at min tidligere løsning, før i går, måske kunne få denne løsning med de sære trin (med jævne mellemrum) til at gå op.. Så det er altså der, jeg er nu. Tankerne kræves selvfølgelig mere forklaring, men lad mig hellere tænke noget mere over det hele, inden jeg prøver at forklare disse (ret løse) tanker bedre.. (16:53)
%..Nå jo, men jeg bør lige tilføje, at det altså så er meningen, at disse lav-ks cancellations-områder netop skal være dem, som V foreskriver, skal lades være; hvorimod vi så tillader V at snyde for de andre trin-typer, hvad vi bliver tilsyneladende nødt til (altså hvis det da overhovedet virker..), hvis tilstandende skal kunne konvergere (norm-vist).. (17:00)

(27.05.22) Okay, as I have written out in the comments, I have realized that it's not at all that simple to make $V$ ``leave its own cancellation tails be.'' And with my previous solution, I probably also didn't consider ``oscillating states'' (in and out of $V$) enough, by the way. 

Yesterday I then found out that we actually might be able to construct $V$s that let their own cancellation tails be, at least for some levels. And if these special levels happens at periodic intervals, then the set of states following $V$ should be ``symmetric under'' $A$. 

I thought some more about all this, and today then ought to be a calculation day, where I try to construct and test concrete $V$s to see if I can derive one that fulfills all (or as many as possible) of the requirements. 

So let me start a new subsection where I do this, and hopefully this will an illuminating task.

\subsection{Trying to find a concrete Dom($A$)}

Let me use a simplified $\hat A$, namely
\begin{align}
	\hat A = \int d\mathbf{k}\, 
		\big(
			k \hat a_\mathbf{k}^\dagger \hat a_\mathbf{k} +
			\frac{1}{\sqrt{k}} ( \hat a_\mathbf{k}^\dagger +  \hat a_\mathbf{k})
		\big).
\end{align}

I plan of using $\mathbf{k}$s with increasing angles for the cancellation tails, slicing the.\,. let's say the $k_1, k_2$ plane up into areas with decreasing width for increasing angle $\varphi$, such that there is an infinite number of slices.\,. 
.\,.\,Let's see, we could do this: if $0\leq\varphi < 2\pi$, then we could make a slice every time $4/(1-\varphi/(2\pi))$ is an integer (the 4 is so that the first semicircle is divided into several slices, which for me is nicer to visualize, somehow.\,.).

The first task I want to tackle is just to get a $V$ prescription that results in finite $\hat A\psi$s (most of the time), and also in finite $\psi$s themselves, of course. %(11:02)

.\,.\,Let's also start by looking only at states ``based on'' states with no photons, i.e.\ where the wave function at all other levels are just exactly the one prescribed by $V$. 

What we need for $\psi_{2}$ does then not necessarily need to depend on the initial $\mathbf{k}$, and yeah, let me by the way also just assume that there are only one fermion (with one $\mathbf{k}$ (or $\mathbf{p}$, rather.\,.)) in the system. And getting back to what I was saying: It does not need to depend on this $\mathbf{p}$, but it does need to depend on the first $\mathbf{k}$, call it $\mathbf{k}_1$ (and note that it is the $\mathbf{k}$ that is produced in the $\psi_1$ level (though here, our $\psi_1$ is actually 0; hope this is not more confusing.\,.'xD) (coming from the $\psi_0$ level)). 

.\,.\,Okay, now comes a big first step.\,. .\,.\,Let us by the way forget about the vaguely defined $V$ for now, and just focus on the $\psi_{2j}$s ($j\in\{1, 2, \ldots\}$), that we need in order to ``cure'' our initial $\psi_0$ state.

Hm, can we not also forget a bit about $\varphi$ somehow.\,.\,? .\,.\,Hm, for now let us just denote the width of slice 2 by $w_2$, and then find a $\psi_2(k)$ that is thus symmetric for the $w_2$ slice in the way that is only depends on $k$ within it.\,. (But the $\mathbf{k}_2$s are still confined to the second slice, call it $s_2$, by the way.\,.) 

So let us thus try to find a solution for $\psi_2$ where it can be written on the form (if you can say ``on the form'' in English, which I am not sure about):
\begin{align}
	\psi_2(\mathbf{k}_0, \mathbf{k}_1, \mathbf{k}_2) = 
%		\int d\mathbf{k}_0 d\mathbf{k}_1 d\mathbf{k}_2\, 
		\psi_0(\mathbf{k}_0)
%		\frac{\sqrt{k_2}}{\sqrt{k_1}}
		\sqrt{\frac{k_2}{k_1}}
		\Psi_2(k_1, k_2)
%		\hat a_{\mathbf{k}_0}^\dagger
%		\hat a_{\mathbf{k}_1}^\dagger
%		\hat a_{\mathbf{k}_2}^\dagger
%		\ket{0}
		,
\end{align}
where $\Psi_2$ is the function that is bound to the our desired ``cancellation tail area''.\,. I have let $\Psi_2$ be locally symmetric with respect to $\mathbf{k}_1$ also, namely by letting it depend only on $k_1$.\,. 

When working with $A$, for all levels below 3, we then get
\begin{align}
	\hat A\psi = 
		\hat A_0\psi_0 + 
		\hat A_0 \psi_2 +
		\int d\mathbf{k}\, 
			\frac{1}{\sqrt{k}} ( \hat a_\mathbf{k}^\dagger \psi_0 +  \hat a_\mathbf{k} \psi_2)
		+ \ldots,
\end{align}
where $A_0 = \int d\mathbf{k}\, k \hat a_\mathbf{k}^\dagger \hat a_\mathbf{k}$.
Hm, let us call.\,. No, wait.\,. Let us define ``$\cdot\, |_n$'' as an operation, that binds less tightly than a $\hat A \psi$ operation, and which takes a Fock space state $\psi$ and returns the wave function of that state at level $n$. Then I should almost have written $\psi_2 |_ 2 (\mathbf{k}_0, \mathbf{k}_1, \mathbf{k}_2)$ in the equation above, instead of $\psi_2(\mathbf{k}_0, \mathbf{k}_1, \mathbf{k}_2)$, but let us just assume that $\psi_n$ is overloaded and can mean both things, depending on the context. 

We then have
\begin{align}
	\int d\mathbf{k}\, 
		\frac{1}{\sqrt{k}} \hat a_\mathbf{k}^\dagger \psi_0 \big|_1
			(\mathbf{k}_0, \mathbf{k}_1) 
	=
		\frac{1}{\sqrt{k_1}}
			\psi_0\big|(\mathbf{k}_0),
\end{align}
where I have also chosen to shorten $\psi_n |_n$ notationally to just $\psi_n |$ (namely for $\psi_0 |_0$ on the right-hand side). And for the more complicated 
$\int d\mathbf{k}\, 
\frac{1}{\sqrt{k}} \hat a_\mathbf{k} \psi_2$, 
we have.\,.
\begin{align}
\begin{aligned}
	\int d\mathbf{k}\, 
		\frac{1}{\sqrt{k}} \hat a_\mathbf{k} \psi_2 \big|_1
			(\mathbf{k}_0, \mathbf{k}_1) 
	=
		&\,\int d\mathbf{k}_0\, \frac{1}{\sqrt{k_0}}
			\psi_0(\mathbf{k}_0)
			\sqrt{\frac{k_2}{k_1}}
			\Psi_2(k_1, k_2)
		\,+\\
		&\,\int d\mathbf{k}_1\, \frac{1}{\sqrt{k_1}}
			\psi_0(\mathbf{k}_0)
			\sqrt{\frac{k_2}{k_1}}
			\Psi_2(k_1, k_2)
		\,+\\
		&\,\int d\mathbf{k}_2\, \frac{1}{\sqrt{k_2}}
			\psi_0(\mathbf{k}_0)
			\sqrt{\frac{k_2}{k_1}}
			\Psi_2(k_1, k_2).\,.
\end{aligned}
\end{align}
.\,.\,Hm, and/but then I need to remember this these wave functions specifically are antisymmetric.\,. 
.\,.\,Hm, so let's see, what we really have is then %(.\,.\,symbolically written.\,.)
\begin{align}
\begin{aligned}
	\int d\mathbf{k}\, 
		\frac{1}{\sqrt{k}} \hat a_\mathbf{k} \psi_2 \big|_1
			(\mathbf{k}_0, \mathbf{k}_1) 
	=
		&\,
			\int d\mathbf{k}_2\, \frac{1}{\sqrt{k_2}} \big(
				\psi_2(\mathbf{k}_0, \mathbf{k}_1, \mathbf{k}_2) -
				\psi_2(\mathbf{k}_1, \mathbf{k}_0, \mathbf{k}_2) 
			\big)\, +
		\\&\,
			\int d\mathbf{k}_2\, \frac{1}{\sqrt{k_2}} \big(
				\psi_2(\mathbf{k}_1, \mathbf{k}_2, \mathbf{k}_0) -
				\psi_2(\mathbf{k}_0, \mathbf{k}_2, \mathbf{k}_1)
			\big)\, +
		\\&\,
			\int d\mathbf{k}_2\, \frac{1}{\sqrt{k_2}} \big(
				\psi_2(\mathbf{k}_2, \mathbf{k}_0, \mathbf{k}_1) -
				\psi_2(\mathbf{k}_2, \mathbf{k}_1, \mathbf{k}_0) 
			\big).
\end{aligned}
\end{align}
.\,.\,Hm, and that is just the anti-symmetrized version of what we get, when we do the integrations of the previous equation, only I probably need a minus sign somewhere.\,. .\,.\,Well or maybe the anti-symmetrization process just needs to make sure to give the minus sign to the reverse cyclic order (in this case when we have only three $\mathbf{k}$s).\,. .\,.\,Hm, no I should still rewrite the expression: We have
\begin{align}
\begin{aligned}
	\int d\mathbf{k}\, 
		\frac{1}{\sqrt{k}} \hat a_\mathbf{k} \psi_2 \big|_1
			(\mathbf{k}_0, \mathbf{k}_1) 
	=
		&\,\int d\mathbf{k}\, \frac{1}{\sqrt{k}}
			\psi_0(\mathbf{k}_0)
			\sqrt{\frac{k}{k_1}}
			\Psi_2(k_1, k)
		\,+\\
		&\,\int d\mathbf{k}\, \frac{1}{\sqrt{k}}
			\psi_0(\mathbf{k}_1)
			\sqrt{\frac{k_0}{k}}
			\Psi_2(k, k_0)
		\,+\\
		&\,\int d\mathbf{k}\, \frac{1}{\sqrt{k}}
			\psi_0(\mathbf{k})
			\sqrt{\frac{k_1}{k_0}}
			\Psi_2(k_0, k_1),
\end{aligned}
\end{align}
or at least this is the expression before it is then anti-symmetrized in $\mathbf{k}_1$ and $\mathbf{k}_1$ again. So we thus have an implicit anti-symmetrization (square) bracket around the right-hand side. %(13:02)

.\,.\,Now, the overall idea is then to design $\Psi(k_1, k_2)$, such that the first term here eats that from\\  
$\int d\mathbf{k}\, \frac{1}{\sqrt{k}} \hat a_\mathbf{k}^\dagger \psi_0$.\,. 
.\,.\,This is ensured if $\int d\mathbf{k}_2\, \Psi_2(k_1, k_2) = 1$ for all $k_1$ (since both the first term here and the RHS of the $\int d\mathbf{k}\, \frac{1}{\sqrt{k}} \hat a_\mathbf{k}^\dagger \psi_0$ equation are both to be anti-symmetrized).\,. 
.\,.\,And I have had an idea for a long time, that if the support area on the $k_2$ axis grows very rapidly as a function of $k_1$, then the $\int d\mathbf{k}\, \Psi(k, k_2)$ contraction can be made arbitrarily small (or let us hope that something to that effect is true).\,. %(13:19)

.\,.\,Oh, and we'll of course assume that $\psi_0$ *(or rather $\mathbf{k}\mapsto \psi_0(\mathbf{k})/\sqrt{k}$) is in $L^1(\mathbb{R})$, i.e.\ that $\int d\mathbf{k}\, \psi_0(k)$ *($/\sqrt{k}$) integrates to a finite value. 

.\,.\,Okay, it is important for me to try and solve, this step. Oh, and let me mention that if it doesn't quite work, then maybe I can try drop the $\mathbf{k}_2 \to k_2$ symmetry and let the support area grow as a function of $\varphi$ (within the slice) as well, but this is just in case.\,. Anyway, let me take a little break, and think about my overall solution idea for a bit; see if it still seems to have hope for being a solution.\,. %(13:32)

\ldots Okay, first of all, I think I \emph{can} find a solution (don't know exactly what, but it must be possible) with the $\mathbf{k}_2 \to k_2$ symmetry intact. And I also still think that my overall solution might work in the end --- though it will probably get way to complicated for the main paper, still. And by the way, just to underline this, it is now part of the solution again to make it increasingly more ``costly'' in terms of the size of the image (i.e.\ $\|\hat A \psi\|$) to ``join $V$'' at a late time (in terms of levels). This will mean that we cannot have infinitely ``oscillating'' states. Oh, and I don't think I've mentioned yet that I then still actually intend to use the actual (or first variant of) Definition 9.1 in Hall to show that states that have cancellation tails that keep out of $V$ cannot be in Dom($A^*$), namely since we can then find a state in Dom($A$) that keeps canceling the area of the other state's (i.e.\ the $\phi$ we want to conclude is not in Dom($A^*$)) cancellation tail, which will mean that there's a part of $\braket{\phi_{2j} | A^- \psi_{2j+1}}$ that remains constant for all levels. And since we can also find $\psi$s that will make this constant as large as we want (namely by getting the initial $\braket{\phi_{n} | A^- \psi_{n+1}}$ as large as we want, and then watch as that value is maintained for all $\braket{\phi_{n+2j} | A^- \psi_{n+2j+1}}$), then we get that $\phi$ cannot be in Dom($A^*$). %(14:05)

%(16:03)
\ldots\ And my idea for periodically (at certain levels) letting the productions to areas designated (by $V$, so to speak) to the cancellation tail be still seems to make sense. Out in the comments, I talked about using low-$k$ areas as the ones that shouldn't be canceled. That seems to indeed work, but then it is also important to remember that we only need to let the productions be from a certain $\psi_n$ that are themselves in areas of $V$. So to try to summarize the idea, we should let part of $\hat A^+ \psi_n$ be, and thus construct $\psi_{n+2}$ as to not cancel said part, and the part we want to let be is exactly the part in the area that $V$ uses for canceling productions from $\phi_{n-1}$ to the $n$th level, i.e.\ the $\hat A^+ \psi_{n-1} |_n$ production. Now, since this area of $\phi_{n+1}$ (/ $\hat A^+ \psi_{n}|_{n+1}$) is a finite area, we can allow it to be have low $k_{n+1}$-values, as long as we then just make sure that.\,. hm, no.\,. well, yeah: as long as we just make sure the overall norm converges, but the point is that these details shouldn't really make this harder.\,. Okay, so we can in other words allow the part of $\phi_{n+1}$.\,. oh, where I here use $\phi$ to denote odd-number-of-photon states, I forgot to mention.\,. But to continue: In other words, we choose $\phi_{n+1}$ to be supported only for low $k_{n+1}$-values, whenever $(k_{n}, k_{n-1}, \ldots)$ is contained in (/ ``has already at some point joined'') $V$. And for all other $(k_{n}, k_{n-1}, \ldots)$ --- and remember that $\phi_{n-1}$ will have productions (i.e.\ $\hat A^+ \psi_{n-1}|_n$) to a lot of those, namely at least whenever $k_n$ is not part of $V$ (given the previous $k$s) --- $\phi_{n+1}$ is still allowed to have as high a $k_{n+1}$ as it likes (which is needed in order to make its norm converge). Now we can then ask ourselves: will the low-$k_{n+1}$ part of $\phi_{n+1}$ converge (and will $\phi_{n+1}$ be able to converge overall --- and by smaller and smaller for every period at increasing levels, such that $\phi$ converges overall) --- yes, I believe so --- and we can ask: will the images of the $\psi$s converge, i.e.\ will $\hat A \psi$ converge, even when we need to let all these specific productions be, periodically (as we do for instance for $\hat A^+ \psi_n$ here in this example)? And to the last question: yes, I believe so, since we make sure to let only a limited area of productions be with low $k_{n+1}$-values.\,:) So yeah, it actually for now seems that my solution will work --- 7, 9, 13! I certainly hope so.\,:) And now I feel like I can almost relax a bit again with respect to this problem. I will still continue this subsection, maybe today, or at least in the coming days, but I think I will also go back writing the paper again (and assume that I will be able, not to include a self-adjointness section in the main body of the paper, but include a decent appendix with an explanation of this solution idea).\,:) %(16:45)

%(19:33) Jeg bruger aftenen nu på at tænke. Jeg fandt nemlig frem til her for små timer siden (mener jeg), at mit gamle problem omkring at man bliver låst til, hvad jeg her kalder \Psi_2 ovenfor, det kan jeg ikke længere se, at jeg skulle have en løsning på. Jeg kom dengang (hvornår det nu var; føles som om det er rigtigt lang tid siden) frem til, at man kunne komme uden om dette fænomen ved brug af en stærkt voksende forskrift for, hvor supportet for.. ja, hvad der svarer til k_2 her, er, lidt ligesom jeg lige har nævnt i teksten ovenfor, lidt tidligere i dag.. Men ja, nu kan jeg altså ikke få det til at give mening. Som jeg ser der nu, så bliver man lidt låst til sit første valg af, hvad der her er \Psi_2.. Hm, i hvert fald når det ligesom kommer til hovedparten/halen af \Psi_2, og nu overvejer jeg så lidt, om man mon kan bruge denne frihed til at lade, hvad der i eksemplet ovenfor var $\phi_{n+1}$-områderne, være... (19:41)
%..Hm, men måske man kunne bruge noget med, at man sørger for, at \Psi_4 også er en funktion af k_1... (19:50) 
%..Hm, det var måske faktisk ikke helt dumt..!... (19:58)
%(21:20) I do think that works; I think one can make sure that the contribution to \hat A^- \psi_{n}|_{n-1} always predominantly comes from contracting k_n, and none of the others. And I'm sure the solution I think about now is similar to what I thought before (at some point quite some time ago). But I wouldn't describe it it exactly the same now.. Oh well, maybe.. But yeah, it is probably better to say: the point is to really stretch out the \Psi_n wave function with respect to k_n; and make it supported by a much broader area (in general) compared to the other k_j-dimensions. And the broadness can then also increase as rapidly as one wants with respect to the other k_j-coodinates. And this way one can make sure that nothing happens woth writing home about when contracting along the other k_j-axes, but when contracting k_n, one can then get a real contribution to \hat A^- \psi_{n}|_{n-1}. 
%But this isn't just what I wanted to write. I just got a new idea a few moments ago, which is the real reason why I wanted to write these notes now. The idea is that maybe one can simply construct the, say, even part of $V$ first, call it $V_0$ or $V_2$, and then construct $V$ afterwards (or the other way around), where one then just makes a careful construction that allows for the productions from the $\phi_{1+2j}$s to actually leave all areas of V_0 (or "V_2") be from the beginning to the end, namely be simply just making sure that all the $\phi_{1+2j}$s are just very, very small in comparison to the \psi_{2+2j}s; sufficiently small such that even on the quite large areas of V_0, their productions still have a small norm (when cut out and restriced to those areas).. Hm, let me just think for a short moment, cause something about this sound potentially.. dangerous.. (21:39) ..Hm, well maybe.. I'm not quite sure, but it actually seems that there is a chance this could work.. But I'm to tired.. well my brain is.. ..my brain is to slow now, so let me just come back to this tomorrow. ..And let me also make tomorrow about this problem as well, and thus also go on to try and find a concrete solution if my ideas now still seem to work tomorrow morning. 

%(28.05.22, 11:17) Jeg er ikke sikker på, at det holder, det jeg sluttede med i går. I nat omkring kl. ti over et kom jeg så på en ny idé, nemlig omkring måske at prøve at sørge for, at alle vektorer i Dom(A) bare sørger for at reparere deres egen brud på symmetrien ved at tilføje flere bølgefunktioner til sig selv til at udligne symmetribrudet. Her lidt tidligere har jeg så tænkt på, at en sådan løsning måske ville indebære ligesom at farve alle områder i forskellige (to, eller måske tre, hvis der også er "neutral") farver (bare en vag idé indtil nu). Og nu kom jeg så lige på (hvorefter jeg gik til tasterne nu her), at tilstandende i Dom(A) måske bare sørger.. at asymmetrierne altid bliver udlignet, men at man måske stadig har en frihed til at "udnytte" idividuelle asymmetrier arbitrært meget, men hvor der så bare altid skal være en modsatrettet asymmetri, der bidrager modsatrettet ligeså meget, så det hele tiden udlignes --- bare en vag tanke indtil nu, men følte lige, jeg ville fælde den ned. Og pointen med det, eller håbet med det, rettere, er at man så herved vil kunne bruge (første variant af) Def. 9.1 i Hall til at udelukke alle andre vektorer fra Dom(A^*).. men nu må vi se, hvad af det overhovedet giver mening.. (11:27)
%(12:20) ..Ja, jeg tror nok, det bliver svært at få min løsning fra i går aftes til at gå op; det ser ikke rigtigt ud til, at man kan komme til at bruge de lav-k-områder, jeg har haft tænkt mig, uden at det vil skabe uendeligt store billeder osv.. Men ja, jeg bør selvfølgelig prøve at regne bedre efter, men nu har jeg jo også min nye idé at tænke over.. Jeg tager snart til Gilleleje en smut, og så regner jeg med at tænke over den nye idé på vejen frem og tilbage.. 

%(16:05)
(29.05.22) I have some thoughts to write down. I just had a realization a little time ago, that has given me hope of being able to use the low-$k$ tail parts (at periodic levels), like I wanted to be the case.\,. Well, and I have some notes out in the comments that I also need to follow up on. But I just realized that I ought to try to Fourier transform the Coulomb interaction (``back to $k$-space'' in a way.\,.), so let me just do that now, and then I'll get back to all that other stuff at a later time.

Okay, we want to look at:
\begin{align}
\begin{aligned}
	&\,\int d\mathbf{x}_1 d\mathbf{x}_2\, 
		e^{-i \mathbf{p}_1' \cdot \mathbf{x}_1 - i \mathbf{p}_2' \cdot \mathbf{x}_2 }
		\frac{1}{\| \mathbf{x}_2 - \mathbf{x}_1 \|}
		e^{+i \mathbf{p}_1 \cdot \mathbf{x}_1 + i \mathbf{p}_2 \cdot \mathbf{x}_2 }
	\,\,=\\
	&\,\int d\mathbf{x}_1 d\mathbf{x}_2\, 
		e^{-i \mathbf{p}_1' \cdot (\mathbf{x}_2 - \mathbf{r}) - i \mathbf{p}_2' \cdot \mathbf{x}_2 }
		\frac{1}{\| \mathbf{r} \|}
		e^{+i \mathbf{p}_1 \cdot (\mathbf{x}_2 - \mathbf{r}) + i \mathbf{p}_2 \cdot \mathbf{x}_2 }
	\,\,=\\
	&\,\int - d\mathbf{r}\, 
		e^{i (\mathbf{p}_1' - \mathbf{p}_1) \cdot \mathbf{r}}
		\frac{1}{\| \mathbf{r} \|}
		\delta(\mathbf{p}_1' + \mathbf{p}_2' - \mathbf{p}_1 - \mathbf{p}_2).
\end{aligned}
\end{align}
So from here, we just need to evaluate: %(16:30)
\begin{align}
\begin{aligned}
	&\,\int_0^{\infty} dr \int_{0}^{\pi} d\theta \int_{0}^{2\pi} d\phi\,
		\sin(\theta) \cos(\Delta p_1 r \cos \theta )
		\frac{-r^2}{r}.\,. %(16:38)
\end{aligned}
\end{align}
.\,.Yeah, so this will not converge (but oscillate as a $\sin(\Delta p_1 r)$ *($/\Delta p_1$, btw) function), as I anticipated might be the case.\,. .\,.\,Oh, well.\,. It kinda makes sense that it wouldn't transform to some polynomial formula, in a way.\,. Anyway, I don't think this will be troublesome for me; as long as the Dirac sea reinterpretation can happen without needing this transform to turn into a nice formula, then.\,. (.\,.\,then I should be fine, I guess.\,.) %(16:45)
.\,.\,Oh, but it might add some extra difficulty to the self-adjointness problem in the end.\,. 


(31.05.22, 18:07) Good news on the way.\,. And also one not-so-good point.\,. But mainly good news, and overall really good.\,.\,:) I don't want to write about it too much now, as I want to think a bit more on the not-so-good issue.\,. .\,.\,But just so I don't forget it --- and this is not part of any of the good (or bad) news --- I have to correct an error above: The $\psi$s in the above equations (before the little part about Fourier transforming $V_{Coulomb}$) should be symmetric, not antisymmetric, since there is only one fermion, and the rest, of course, are photons.\,. So yeah, just a tiny correction there.\,. 

.\,.\,Okay, but let me just quickly note what the news are about: I think I actually might have had it with an earlier solution. At about two o'clock today I had the thought that maybe the solution we ought to look for should just have states in Dom($A$) where the wave functions ``leave their own cancellation tails be'' exactly once, namely when they ``join $V$,'' and not continuously. And a little time ago, I realized that we probably then actually want it to be ``more and more costly to join $V$,'' which should by the way then be achieved in this instance by using larger and larger areas as the designated cancellation areas (``in $V$'') --- when a state has to ``leave'' those areas ``be,'' it thus has to.\,. .\,.\,no, that's not the explanation.\,. This is: A state that does not join $V$ will then have larger and larger areas ``in $V$'' that it fails to leave be, so to speak, and these larger and larger areas can then be exploited by a series of $\psi$s in Dom($A$) to give a larger and larger $\braket{\phi | A \psi}$. So yeah, \emph{that} is the idea.\,:)\,.\,. %(18:27)

.\,.\,But let me get back to explaining further why I believe this solution might work. Let me just also note now that the not-so-good news are that I have realized (yesterday) that the ``conjugated theory'' (i.e.\ with the Dirac sea reinterpretation.\,.) might need renormalization when $\Omega\to\infty$, since this might very well cause the fermion number to go to infinity.\,. .\,.\,And this might ruin the mathematical rigor, that we could perhaps otherwise achieve.\,. Anyway.\,. I have some more things to mention, but let me just go back to thinking about this matter now, and then continue with these notes tomorrow (if not sooner, if I get the urge.\,.). 

(01.06.22) Last evening at around half past nine, I realized that my previous argument/solution where the negative-energy solutions are reinterpreted via a Dyson expansion actually still kinda holds. .\,.\,Hm, I still feel somewhat dizzy; I woke very early this morning (/night, almost (I think.\,.)).\,. So I'm just gonna take it very slowly today. Hopefully I will manage to write down all my notes of the new realizations, and hopefully also get to look a bit more on my new (even though it's really more an new (\emph{perhaps}) configuration of old ideas) solution for showing self-adjointness, at least for my toy $A$. .\,.\,So yeah, let me take another break (if we count the delay of getting started this morning as a break), and hopefully get a more clear head (I really am a bit dizzy right now, no kidding.\,.).\,. (9:02) 

(10:53) Okay, I think I can get some more work done now.\,. .\,.\,Let's see.\,. .\,.\,The point about the Dyson argument still working in practice.\,. .\,.\,Hm, maybe I actually need to think a bit more about it, but the basic point is that while knowledge of how exactly to do.\,. well, or knowledge that it can be done.\,. .\,.\,well, let me get back to this, but just to continue: the knowledge is needed in order to then be able to renormalize.\,. or to know that one can do so.\,. such that the quantum system can fit a Hilbert space, even in the $\Omega\to\infty$ limit. .\,.\,But while this might be the case, the path integral / Feynman diagrams should still be well-defined.\,. Well, let me just think some more, and then get back. Though I might also think (and write) about other stuff beforehand, such as the matter of the self-adjointness of $A$.\,. %(11:02)

(11:32) Well, I think I'm gonna take another walk, and think about those two things some more. But let me just note more precisely what I have in mind for the initial (at least) Dom($A$) now: I'm thinking about a subset wherein all vectors can be divided into two parts: an vector without cancellation tail, however we want to define that (but I might start by investigating what happens if we simple chose this class of states to be all states that is a finite sum of almost-/close-to momentum eigenstates), and the cancellation tail itself, which is strictly defined by $V$. Note, however, that a part of a vector is only considered part of the ``cancellation tail'' if it (when integrated over (and worked on with $A^-$)) cancels the production of another part completely, or at least the part of the production that should be canceled according to $V$.\,. Well, so if we have a part that doesn't quite cancel the production as it ought to, or if it over-cancels it, well then the part can either be interpreted as simply not part of the cancellation tail (but part of the other (more fundamental) division of the state), or it could be divided into a sum of a valid cancellation tail, plus (and with an arbitrary phase in front) some other sub-state, that is then not part of the cancellation tail. I think that defining a Dom($A$) this way, will make $A$ symmetric on Dom($A$). The question --- apart from the question of confirming this --- is then what it takes for this kind of Dom($A$) to be adjusted so that it is also ensured to be self-adjoint. Oh, and I've already mentioned that I think making $V$ leave more and more of the productions be for higher photon-number levels is a good idea investigate. But let me maybe take a walk and think some more on this (and perhaps on the Dyson/vacuum-normalization matter.\,.).\,. %(11:48)

%(11:51):
.\,.\,Oh, and another very important point is that it should be required (``by $V$'' (whatever $V$ will be exactly.\,.)) that states leave the area designated (by $V$) to cancel itself be, in terms of not canceling their productions one level up from there, exactly in the transition between the normal and the cancellation tail part.\,. Yeah, and I should think some more on this idea as well.\,. %(11:54)

(19:44) I actually almost think that the perturbed vacuum state approaches the bare vacuum when $\Omega\to\infty$.\,. Heuristically, one might see it as being because the 0-momentum states are all smeared over the whole volume, so when this volume increases, then any excitation will be more and more thinly spread. But in more concrete terms, and I haven't made the calculations yet, but I think that because we only ever integrate over either three of the four $\mathbf{k}$s or two of the three $\mathbf{k}$s for the Coulomb (double-)pair production or the Dirac interaction pair production respectively, then we always get an extra factor of $1/\sqrt{\Omega}$ (I think) to much, such that in the $\Omega\to\infty$ limit, the pair-producing interaction becomes less and less significant.\,. %(19:51) (I have finally regained some brain power, as one can probably tell..)
.\,.\,So yeah, this is obviously pretty exciting. I need to do the actual calculation before I know if I'm right, but if so, then all of a sudden, there is no cow on the ice with respect to the perturbed vacuum.\,:) %(19:53)

I have also, in the recent hours, thought about the fact that the $V_{03} \sim 1/r$ conclusion might be a bit harder to make, since we don't immediately know that we are allowed to do the integral as the limit of an expanding sphere (or ball, rather).\,. Oh, and I should also mention that I have realized that a good approach to Fourier transform $\widetilde V \sim 1 / k^2$ is probably to first do the $V \sim 1/r$ calculation backwards, at least if some good way of curing the mentioned (ball-versus-box (integral)) ambiguity.\,. And then, one solution I have thought of, is to add a $\xi(k)=\exp(-\epsilon k)$, or whatever one usually does to make the Fourier transform go smoothly, in front of the $\hat \Pi_3$-terms.\,. %(20:01)
.\,.\,And I guess I have also thought about some more things, but the big point is, that it is most likely not a problem, that will be hard to solve at all: that would certainly surprise me (7, 9, 13, of course.\,.).\,. Oh, let me also mention, by the way, that perhaps the solution is simply just to.\,. Well, to cure it in some way (which might be by adding $\xi(k)=\exp(-\epsilon k)$), and then find a way to argue about the Lorentz covariance in the limit.\,. Anyway, let me move away again from this topic for now.\,. %(20:04)

But yeah, if my new realization holds water, then the only big thing left seems to be checking that me self-adjointness solution, not necessarily is 100 \% correct, but simply that is makes sense, and that is seems it will lead to an actual solution with some more work put into it. 

I have.\,. nemlig.\,. convinced myself that I actually don't need the.\,. Well, I don't.\,. hm.\,. .\,.\,Hm, let me just put it this way, simply: I don't need to try to strive for the Clay Millennium prize anymore; it is tempting, but I shouldn't waste any extra time, really, to try to make sure that \emph{I} will be noted as the sole.\,. inventor / problem solver for this discovery.\,. Sure, if there could be talks quickly about whether I really have solved the ``puzzle,'' then that would boost interest immensely, but I have realized that so would the prospect that there might be an opportunity to be part of the group of puzzle solvers oneself.\,. So yeah, either way my discovery should spark extra interest because of the potential for solving the prize puzzle.\,. .\,.\,I had this realization yesterday morning, if by the way, I remember correctly.\,.\,:) .\,.\,And this is really nice to know, cause then I don't have to think much about how secret I should be with it around release, or.\,. well, or much more importantly: It now certainly doesn't have to be nearly as perfect, my first version of the publication, that is. And honestly, if I can just find a good overall solution strategy that point in the right direction, i.e.\ that will lead to self-adjointness pretty quickly.\,. and with no big creative ideas needed.\,. well.\,. Maybe with other creative ideas needed, but hopefully not some, that I will then think that I could/should have gotten myself, and thus not some that I will be kincking myself for not taking the extra time to think of myself.\,. If this will be the case, then I am \emph{more} than happy with what I have achieved, and with what my part in the discovery will be. It is kinda tempting to waste extra time to figure more things out for myself, partly because of the money potentially involved, but no: If I can just get this last to-do (plus maybe repairing the new (little) $V_{03} \sim 1/r$ hole.\,.), then I am more than satisfied, indeed. %(20:23)

(02.06.22) This noon I have primarily just been thinking a bit about whether showing self-adjointness really does the trick, and yes: If it is self-adjoint on a reasonable domain, then the Hamiltonian can be approximated arbitrarily well for any state by having a momentum cutoff and let that tend to infinity. So all good in the hood there.\,. 

Now I am going to try to investigate my solution idea for self-adjointness some more, and see if I can maybe even find a domain on which $A$ is self-adjoint (which would with all likelyhood mean that my $\hat H_{QED}$ is also self-adjoint on a similarly constructed domain). I thought about it a bit more last evening, and the domain I have in mind now is where all states have a ``normal part'' in terms of a normalizable wave function.\,. well, or more specifically a normalizable series (summed together) of wave functions, and then the ``cancellation tail part'' is precisely the tails, constructed according to $V$, of each of these ``normal wave function'' in the series, added together. %(12:03)
.\,.\,And this morning (.\,.\,or was it last evening.\,?\,.\,. I actually can't recall just at the moment.\,.\,x)), I had the idea that the ``designated areas'' of $V$ could just be larger and larger areas (balls) around $\mathbf{k}=0$. This makes it both simpler an nicer to think about.\,:)\,.\,. 

.\,.\,I should clarify that the cancellation tails then.\,. hm.\,. .\,.\,Hm, they.\,. well, in the transition from ``normal part'' to the ``cancellation tail part,'' states in Dom($A$) should always leave the areas be, that are designated to canceling themselves, i.e.\ if the transition had happened earlier (and for a state with opposite parity, if we still allow ourselves to divide the states into even and odd photon number parities).\,. .\,.\,Hm, yeah, and this would be the larger and larger ball with our new assumption/specification, and then for all other areas, the state is then \emph{allowed} to cancel the productions (but we can always choose not to, i.e.\ for states in Dom($A$)).\,. .\,.\,(As long as the image is kept normalizable in the end, of course.\,.)

.\,.\,Time, then, to look at the compliment set to this trial Dom($A$).\,. %(12:25)
.\,.\,Hm, and wouldn't that then be pretty much: states that does not leave their own cancellation area (ball) be in their transition (and where one cannot redraw the lines between the ``normal'' and the ``tail'' part such that this is the case, of course), and states where the cancellation tail (even when the lines can be (re)drawn anyway possible, of course) does not stay inside its allowed zones (i.e.\ the balls in our case).\,.\,? %(12:31)

%(13:38)
\ldots\ Hm, wouldn't it be the opposite way with the mentioned balls: wouldn't the designated part be outside the ball.\,.\,?\,.\,. .\,.\,Yeah, let me look at that instead.\,. .\,.\,Yeah, that seems to make more sense.\,. .\,.\,Oh, or maybe I just confused what I was saying previously a bit.\,. .\,.\,Oh, or maybe I was just wrong just now: the designated area has to be the bounded one.\,. %(13:43)

.\,.\,Let me just copy this one down again:
\begin{align}
\begin{aligned}
	\braket{\phi'| A \psi} =&\, 
		\braket{\phi'_{n}   | A^- \psi_{n+1}} + \big[
		\braket{\phi'_{n+2} | A^+ \psi_{n+1}} + 
		\braket{\phi'_{n+2} | A^- \psi_{n+3}} \big] + \big[
		\braket{\phi'_{n+4} | A^+ \psi_{n+3}} + 
		\ldots\\
	\braket{A \phi'| \psi} =&\, 
		\big[
		\braket{A^+ \phi'_{n}   | \psi_{n+1}} + 
		\braket{A^- \phi'_{n+2} | \psi_{n+1}} \big] + \big[ 
		\braket{A^+ \phi'_{n+2} | \psi_{n+3}} + 
		\braket{A^- \phi'_{n+4} | \psi_{n+3}} \big] + 
		\ldots
%	\label{symmetry_considerations_ldots}
\end{aligned}
\end{align}
.\,.\,And then let see, if $\phi'_{n+2}$ here does not stay inside its own ball, then we might be able to construct a $\psi_{n+1}$ (as the ``normal part'' of a $\psi$) where $\braket{\phi'_{n}   | A^- \psi_{n+1}}$ first of all can become arbitrarily large, and more specifically where $\braket{\phi'_{n+2} | A^- \psi_{n+3}}$ can maintain this large value (on so on for the higher levels), namely since we might then be able find a $\psi_{n+3}$ that.\,. cancels the ``forbidden'' part of $\phi_{n+2}$.\,. and if that part is a significant part, then we might be able to show that the same ratio of the initial (large) $\braket{\phi'_{n}   | A^- \psi_{n+1}}$ value is maintained.\,. .\,.\,Hm, and let us assume that $\phi'_{2+n}$ has a ``small'' part, whatever that means, that breaks out of its ball (for enough $\mathbf{k}_{n+1}$ coordinates.\,.).\,. .\,.\,If we then cannot ``redraw the lines'' (between ``normal'' and ``tail'' part.\,. or maybe I could call it the ``head'' and ``tail'' part..) such that $\phi'_{2+n}$ becomes part of the ``normal part,'' or the ``head,'' then let's see what.\,.(?\,.\,.) %(14:05) 
.\,.\,Oh, if $\phi_{n+2j}$ keeps breaking out.\,. no.\,. We can't then just necessarily keep contructing a $\psi_{n+1+2j}$ that creates the right value, as I was about to say, since this might cause the image of $\psi$ to diverge.\,. %(14:11)
.\,.\,Hm, but if the $\phi_{n+4+2j}$s, $j\geq 0$, stays significantly inside the balls defined by $V$, then the initial large value can be maintained, and if it breaks significantly out of $V$.\,.(?\,.\,.) %(14:15)

\ldots Hm, I'm thinking about the other case when $\phi'_{n+2}$ doesn't (perhaps at the same time) leave the $\psi_{n+1}$ balls.\,. s.\,.(?\,.\,.) .\,.\,No, $\phi_n$ can be pretty localized, and then there is really just \emph{a} ball.\,. .\,.\,And it wouldn't be possible otherwise, either.\,. (.\,.\,to leave the balls be, i.e.\,.) .\,.\,But maybe we should try to rule out that $\phi'_{n+2+2j}$ can \emph{keep} violating the ``leave the designated ball be'' rule.\,.(?\,.\,.)  

% -1/2 - x < (1 - x)^2  <==  -3/2 + x - x^2 < 0  <== (x>0  ==>  ..aldrig..) %(15:23).. *(Wrong use of ==> at the end, by the way..)
%Ah, jeg skulle se på -1/2 - x < (1 - x) * 2 i stedet: --"--  <== - 5/2 + x < 0  <==  x<5/2..
%..Ja, det er jo som forventet.. 
%..Hm, lad mig gå en tur og tænke mere over self-adjointness-problemet.. (15:28)

%(16:29)
\ldots\ Hm, maybe if we require areas who seem to have just violated the ``leave the designated ball be'' rule to then leave much more than just their own designated area ball be.\,. The idea is that then one can maybe make so that one can always construct a series of $\psi_{n+3+2j}$s whose image converges dispite having to leave larger and larger balls be for growing $j$, but whose inner product with the $\phi$ that keeps violating said rule can become arbitrarily large.\,. %(16:33)

.\,.\,Or maybe their cancellation tail balls two levels up has to be smaller and smaller, such that $\phi$ itself has to become larger and larger (and diverge) if it wants to both keep violating the mentioned rule but at the same time not break the other rule (and break out of the designated balls for its tail).\,. %(16:41) %..I'm very happy about these ideas, but let me take a small break now..

%(17:50)
Hm, and should we perhaps also just do the same thing for areas that seem to have just broken out of the relevant ball, designated by $V$.\,.\,? That is, should we also make their balls two levels up be very small, and more and more so, such that a continuous violation of these type will require.\,. wait, that doesn't make sense.\,. (unless the states have to join $V$ again for some reason.\,.) But note that the thought behind this idea was just that it might make it easier: I haven't yet found any specific problem with the current trial solution, i.e.\ with this latest addition of requiring the balls of areas that does not let the ball below them be.\,. to be smaller and smaller.\,. Hm, I guess I should explain this in more detial. First of all, note that there are now two $V$s, essentially: one for the cancellation tail through all its levels, and one that only counts in the transition between the ``normal part'' or ``head'' of the state and the ``(cancellation) tail (part).'' So the idea is that if a part of the ``head'' is of an area that could be used to cancel a production one level down on an area that is part of $V$, then the transition $V$, call it $V_t$, should require this part of the head to have small cancellation balls two levels up, which means that.\,. hm, ``that the state will be large'' but doesn't this goes against the fact/requirement that the domain should be dense.\,.\,:/ .\,.\,Okay, so let's get back to requiring that a lot if said areas' productions should just be left be, such that these states will just have a large image instead %(newline to get spell checking back..)
(and thus a diverging image when the violation keeps happening (.\,.\,to a significant degree.\,.)).\,. 

.\,.\,This might be easy to forget, so remember: Some states might (in my current trial solution) be required to leave a \emph{larger} area be than just exactly the designated ball one level below.\,. 

.\,.\,Wait, isn't the ball restriction itself threatening to ruin the denseness of the domain.\,.\,? %(18:21)

%(18:24)
.\,.\,Oh, luckily no, since we are not required to cancel any particular part of the productions, which means that we can just wait until the balls are large enough (i.e.\ wait for a large enough $\mathbf{k}_{n+1}$) for us to be able to afford canceling them (given a required $\varepsilon$).\,.\,:)\,.\,. .\,.\,Oh, and the image by the way has to diverge whenever we approximate a state not in Dom($A$), since the graph of $A$ ought to end up being closed. %(18:32)

(03.05.22) Last evening/night I had another idea: If we keep making it more and more costly to ``break out of $V$,'' namely by requiring the areas to then leave larger and larger balls be (even larger than the ones used as the ``designated areas for cancellation''), then we might not need a series of $\psi$s, where the normal part of each $\psi$ is non-vanishing for all levels: Instead we might be able to get a greater and greater $\braket{\phi'_{n}   | A^- \psi_{n+1}}$ simply by using a greater and greater $n+1$ for the ``head'' of $\psi$ (located on level $n+1$). %(9:52)
And then we are not in danger of the $\psi$s not fitting in Dom($A$) (since their image are no longer in danger of diverging). 

So this is the trial solution that I will investigate now. I just want to mention, though, that it is remarkable how close I was at first with this idea (i.e.\ the idea about having a $V$ and to make it costly to break out of it.\,.) --- in fact I might kinda have been spot on initially; I don't quite remember, because I don't recall when/if I started to think that $V$ ought to leave the designated areas be at every level (instead of just initially, in the ``transition''), or if I simply didn't think about this difference at all at the time.\,. But yeah, maybe I could read though my own notes to find out, but I don't really care to. If I really have walked in circles, pretty much, well, then I'm just happy to be home safe again.\,:)\,\textasciicircum\textasciicircum\ .\,.\,7, 9, 13, of course; I'm not completely out of the woods yet. I need to investigate this maybe-solution as said, which I will try to do this noon. %(10:03) (I kind of take 10 o'clock to be where I start saying noon. And the other kind-of boundaries are at 12, 13, 17:30--18 and 23--00, roughly, I think.. ..oh, and 5--6, I guess, for when I start calling it morning.. *(Oh, and I by the way think I slept for about 3--4 hours, that other day, but I was apparently just \emph{so}.. baldret.. still..))

Okay, let me see.\,. 

.\,.\,Oh, let me by the way also mention, that I do indeed think that I'm right about that factor of $1/\sqrt{\Omega}$ to much for the vacuum excitations (in the ``conjugated'' theory).\,. Hm, and that does mean that we can start fresh for any path integral / Feynman diagram?\,.\,. .\,.\,Hm, or no.\,.\,? .\,.\,Hm, I kinda still think that this should mean that the vacuum state converges to the bare/unperturbed vacuum, but I guess I need to think a bit more about it.\,. .\,.\,If we look at the reduced Hilbert space of only 0-momentum states.\,. .\,.\,(And with no initial fermions, so to speak, such that we only look at vacuum excitations.\,.) .\,.\,Well, then the ground state should approach the bare ground state, indeed, when $\Omega\to\infty$.\,. .\,.\,But how much does the vacuum excitations perturb the Feynman diagrams / the path integral at each step of the growing $\Omega$, is the question then.\,. %(10:33)
%(10:57):
\ldots Ah, but maybe it's actually alright if the vacuum excitations keeps being relevant. I just realized that in the $\Omega\to\infty$ limit, the first-order perturbation theory should become correct, in which case it will most likely be very easy to renormalize the vacuum.\,:) .\,.\,Yeah, and there we are!\,:) So even if there actually keeps being a (significant) difference on the result of just assuming the bare/unperturbed vacuum and then of (obtaining and) using the perturbed vacuum (even when $\Omega$ grows toward infinity), then we will probably still be okay, namely because we can just assume the first-order perturbation solution to be correct, which it will be in the limit of $\Omega\to\infty$ (if I'm not mistaken). .\,.\,Great.\,.\,!\,:) 

%(11:07)
Okay, so let me move back to the self-adjointness problem.\,. 

%(12:15) (Nå, det gik lige en smule langsomt, men nu kommer jeg sikkert i gang igen.:))
\ldots\ Hm, maybe there could be a danger in the fact that the $\psi_{n+3}$-balls also have to grow as a function of $\mathbf{k}_{n+1}$.\,.(?\,.\,.) (.\,.\,In order for $\psi_{n+3}(\mathbf{k}_{n}, \mathbf{k}_{n+1}, \mathbf{k}_{n+2}, \mathbf{k}_{n+3})$ to converge.\,.) .\,.\,Oh, but then we of course just (maybe ``just'') have to use the fact again that we are not required to cancel any specific part of the ($\mathbf{k}_{n+2}$-)productions.\,:)\,.\,. %(12:22)
.\,.\,Yes, so we can get arbitrarily close to whatever $\psi$ we desire to make the $\phi$-$A \psi$ braket as large as possible.\,.\,:) 
.\,.\,Well, that is perhaps a bit dangerously worded, but in this context, we \emph{can} say it.\,.\,:) 

%(12:35)
\ldots Okay I can feel that today is not the day where I try to check the solution in greater %(false comparative)
detail, but I'm am really positive about its potential for being (at least very close to) an actual solution. The realization that we don't need for $V$ to \emph{keep} leaving ``itself'' be was really important. Now I have a solution (and of course it still takes some care to make it work when the $\hat a$s doesn't just work on the last $\mathbf{k}$ in the row, but works on them all, symmetrically and/or anti-symmetrically, but I don't think ths will require much creativity to do *[No, it shouldn't. Not now that $V$ just needs to declare ball radii, and where we only have to make sure that the wave function and the image converges in that one place of the transition.\,. (.\,.\,7, 9, 13.)]) where it very much seems that Dom($A$) will be symmetric and dense, where it seems that Dom($A^*$) is at first restricted only to states with finite image under the $A$ formula, and which at the same time can be written as a Dom($A$) state plus a state that ``never joins $V$'' (since it seems that all parts of a state in Dom($A^*$) either have to pay the ``owed cost to $V$'' off after a finite time, keep completely out of $V$ or have only a very small part of it that takes forever to completely join $V$, but with a \emph{very} rapidly decreasing tail of areas that are ``going to join $V$''). And since we can further argue that any state that has a part that ``keeps completely out of $V$ for all time'' will have an unbounded $\psi \mapsto \braket{\phi | A \psi}/\|\psi\|$, %(I should by the way go back to using | \cdot | for coordinate vectors, and only use \| \cdot \| only for (other kinds of) Hilbert space vectors (and perhaps operators if need be)..)
that thus gives us in the end that Dom$(A^*) = \mathrm{Dom}(A)$. Oh, and the fact that the states have to either ``join'' or ``keep out'' of $V$ (except for only very rapidly decreasing tails (and here I'm not talking about ``cancellation tail'' tails.\,.)), and the fact that we ought to be able to find a series of $\psi$s (whose ``head'' according to my latest idea only is located at one level, call it $n+1$ (but where $n$ then just tends to infinity for the series)) that makes $\braket{\phi | A \psi}$ larger and larger when $\phi$ has a part that ``completely keeps out of $V$,'' those two fact (if I'm right) are due to how I intend to construct $V$. (Namely where we make it more and more costly for states that seemingly has just violated the rules of $V$, specifically by requiring them to leave an even larger ball be in the transition (according to what we could call $V_t$) than the one ``designated by $V$ for cancellation.'') %(13:00)

\ldots Okay, and I should by the way also mention that I have found some good math articles that looks at the self-adjointness of this, accordning to them, ``non-relativistic'' type of Hamiltonian, except that the always add an ultraviolet cutoff to ``make the Hamiltonian well-defined.'' The last fact is quite interesting, actually, cause this suggest that I probably will be the first to find a solution (hopefully, or at least close to one) where a Hamiltonian of that type can be shown to be self-adjoint without the cutoff. And in any case, the articles also seems that they will be handy to reference, so I will definitely do that.

Otherwise I think the only thing left is to investigate my solution a bit further, which I might just do on the side while I finish my paper. I also have some ideas that I have not noted here, but which seems to lead to dead ends anyway, so I'm probably just gonna more or less forget about them now.\,. .\,.\,Yeah, I think that's it for now, though I will continue the notes here quite soon; perhaps even before the week is over. But yeah, it seems that I'm almost out of the woods --- 7, 9, 13! --- and that I have the solution now --- and this also almost includes all other parts that I'm not 100 \% certain on: There are no particular issue now that don't think I have a good grip on (and my various solutions should be notes here, at least such that someone with enough time should be able to decipher these notes and understand what my solutions are). Of course there will always be something --- the project has so many parts, so even if there are no particular area that I fear, something is always bound to pop up once I/one goes more levels down in the details (as has continuously happened (.\,.\,again and again and again and\ldots)). But yeah, I'm really positive about the current level/version of my solution.\,:) Fingers crossed that things will be pretty much smooth sailing from now on (though one can never know that that will be the case 'xD) (03.05.22, 13:29) 

%(15:55)
\ldots\ I should also note that it is not due to that fact that state parts that ``keep out of $V$'' have to leave bigger and bigger areas be according to $V_t$ that we ought to be able to make $\braket{\phi' | A \psi}$ larger and larger. That is only to secure the fact that all state part has to either join quite rapidly or ``keep out.'' And more importantly, I just realized, here in my break (it is (15:58), btw), that maybe it is important to also be ``kinder and kinder'' towards areas that can cancel (or contribute to $\braket{\phi | A \psi}$ with) an areas one level below when the lower area is one that ``continuously has violated the $V$ prescription.'' So basically we want to be kind to the types of $\psi$-areas that can be used for the large $\braket{\phi_{n}' | A^- \psi_{n+1}}$s that we want (when $\phi'$ is a state part that ``keeps violating the rules of $V$'' / ``keeps out of $V$''), as in: we want to to give those areas plenty of space for their cancellation areas (balls) two levels up, and perhaps we even want to be more and more ``kind''/``generous'' this way (if this is helps solve the problem). The reason for this is that we do not only need the $\psi$s in the series (which ought to make $\braket{\phi' | A \psi}$ larger and larger) to each be normalizable (and potentially all with norm equal to 1), but we also need them to all have a converging image under $A$, namely to be part Dom($A$) (though we do not need series of these images be bounded; the just have to each converge individually). %(16:09)

And with this, I'm pretty convinced that my idea will work --- 7, 9, 13, and excuse my boldness (I know I can't be certain, of course, but I'm pretty optimistic\,:)). Now I'm going to add a small note to my 2021--22 notes, and then, as I mentioned, I will probably go back to writing on my paper again, and then come back and continue investigating my self-adjointness solution here in my ``spare time,'' so to speak. (16:03)


(06.06.22) I thought a bit more about the self-adjointness problem yesterday, and I actually don't even think we need anything about ``being generous to certain areas,'' namely since it doesn't matter if the sequence.\,. Oh wait, I have talked a lot about a ``series of $\psi$s'' above, when I actually meant a sequence of $\psi$s. Oops.\,. Oh well, but we don't need the sequence of images for the sequence of $\psi$s to converge (we only need them to converge individually, as mentioned). And with this, I really think that it will actually not be a very complicated matter to define Dom($A$), perhaps not even for the actual $\hat H$ (and not just the toy version, $\hat A$). So I actually kinda plan of including the self-adjointness problem (with solution) in the paper now, and thus only leave the details Lorentz covariance problem for future work.\,.\,:)\,.\,. (7, 9, 13 to the statement that it does not seem complicated now.\,.)

%(13:48)
(18.06.22) I've realized that my solution might need a bit more details to make it work, and now I have given it a little more thought. My thought is now that since we are free to choose a sequence of $\psi$s with a diverging sequence of (individual finite) images under $\hat A$, then perhaps Dom($\hat A$) just needs to include exactly all states, that ``joins $V$'' quickly enough that they get a finite image under $\hat A$. And then I should \emph{not} try to create the $\psi$ sequence such that each $\psi$ is designed to exploit the large image of $\hat A \phi$ at just \emph{one} level at a time. This is not enough, since we don't require $\phi$ to have a diverging $\hat A \phi|_1, \hat A \phi|_2, \hat A \phi|_3, \ldots$ sequence for it not to be in Dom($\hat A$): we only require it to have an infinite $\hat A \phi|_1 + \hat A \phi|_2 + \hat A \phi|_3 + \ldots = \hat A \phi$ to not be in Dom($\hat A$). But luckily, there is no need to be afraid to make a sequence of $\psi$s that exploit the image at several (and infinite in particular) levels; we can make such a $\psi$ sequence while still having $\|\hat A \psi\|< \infty$ for each $\psi$ in the sequence. 
.\,.\,Yeah, and then the point of having a ``tough $V$'' is then to make sure that all $\phi$s that does not ``keep completely out of $V$'' for some part of it, and also ``joins $V$ fast enough'' to get a finite image $\hat A \phi$, that these $\phi$s are then ensured (by the ``toughness'' of $V$) to be ``symmetric under $\hat A$'' with all other.\,. hm, states in Dom($\hat A$).\,. .\,.\,Yeah, which they will indeed, if $V$ is ``tough'' enough, unless I'm mistaken. I of course need to do the calculations to be sure, but it sound very reasonable.\,.\,:) (7, 9, 13.) 


(27.06.22) I have new, important notes in the \texttt{draft3} document. Read the section called ``Another stab at \ldots'' Read also a bit of the section before that to understand e.g.\ what I mean by a ``broad $g$ function'' for a state. Let me also give a quick update here:

I think I have figured out how to show self-adjointness (in part by having found some (well, one in particular.\,.) good theorems in the literature) of $\hat H_{init}$ and all its part. I have also realized how to show that their domains meet the conditions for the Trotter product formula (which I haven't given much thought before). I have actually also concluded that this is all not really necessary in principle, since I think one if I just do my old discretization scheme of $\hat A_{\mu\ldots}$ and $\hat \Pi_{\mu\ldots}$ (just for $\hat H_{B}$, I think, and not for $\hat H_{IF}$) instead of trying to add those quadratic $\propto \epsilon$ potentials, then I think one \emph{can} indeed argue from the (Fourier transformed) path integral that the continuum limit exists (and is Lorentz-covariant) *(and that approximate $\Phi$ solutions evolve/transform into approximate $\Phi$ solutions). But I'm actually very confident now that my discrete operators are self-adjoint (and on the right domains), so I'm definitely just going to assume that (and then argue for it in a later section). %(10:35)


(03.07.22, 14:37) I am thinking about the self-adjointness problem again (with the aim of finally preparing a full argument). And now I just got the idea (don't know if I've had it before, but it feels like a new idea now) to make sure that states with ``wrong'' parts of their tail that then ``joins $V$'' again later, the image should be so large for these parts (minimally, when joining $V$), that it would always be better, image-size-wise, to simply remove that part of the tail instead (and let the production it helps kill (perhaps partly) be instead). This seems like a good idea, anyway. Cause then one can always just (the way I see it now.\,.) reinterpret these ``wrong tails'' to instead be the ``head'' of a separate state (in a superposition with the rest). %(14:45)
.\,.\,Yeah, cause if it causes a larger increase in image size anyway, then one will be free to remove at from the original state without danger of causing an infinite image. And if this can be done, then the removed part can thus be added again, but now interpreted as another $V$-joining state in superposition with the rest. And with this, if it works.\,.\,, we should then be able to define the domain as just any superposition with converging image under $\hat A$ of states that joins $V$ completely at some level.\,. .\,.\,Yes, indeed; if we allow the superpositions to be an infinity sum, of course.\,. %(14:52)

.\,.\,Hm, I think this idea is pretty important.\,. And I haven't completed the argument completely in my head, but I think it should then be easy to show the symmetry under $\hat A$ (since all finite superpositions of $V$-joining(-at/after-a-certain-level) states should be symmetric with each other and have their inner product with other such states bounded by their own image size.\,.).\,. %(15:04)
.\,.\,Hm, I guess it does take a little more thought.\,. %(15:07)
.\,.\,Hm, it seems to be maybe-problematic that the states in a tail of a superposition series can potentially (the way I see it now) reduce (and eat away at) the image produced by the previous states in the series.\,. %(15:15)
.\,.\,And it seems dangerous to try to simply assume that the individual images of the states in the series has to converge when absolute-square-integrated and then summed over.\,. 
.\,.\,Hm, but maybe we can just.\,. Hm.\,. .\,.\,Oh, but don't we already have, now with my latest (\emph{potentially} new, but I'm not 100 \% sure, though) idea, since the head of states.\,. Well, maybe not solely with my new idea, but couldn't we make sure that all head-states (for $V$-joining states) will cause a lot larger image in the higher (photon-number) levels than what they can create at.\,. the level just below.\,. Hm, but is the level just below the only concern.\,.\,? %(15:25)
.\,.\,Hm, could the answer be: ``yes, since otherwise we can just reinterpret the state as part of the previous state in the series''.\,.\,? %(15:27)
.\,.\,Hm, that sounds right.\,. .\,.\,Yeah, we can reinterpret all superposition series (of my $V$-joining states as described) such that the next state only begins.\,. No, that's not quite right.\,. .\,.\,Hm, so the problem requires more thought indeed (i.e.\ this part of the overall problem).\,. %(15:32)

(04.07.22) %... Nå, det går af en eller anden grund ret langsomt her til formiddags.. ..Jeg kan åbenbart ikke lige få min hjerne til at komme i tanke om, hvad der var det første argument fra i går i den række argumenter, jeg skal til at notere.. ..Måske hvis jeg så taster lidt, mens jeg tænker.. Vi snakker argumentet lige inden, jeg når frem til, at V-joining tilstande kan skrives som en superposition af ét-niveaus-hoveder (heads), hvor hele "halen" så er i V... ..Hm ja, mit hoved kører lidt langsomt rundt.. Er vel også vågnet lidt tidligt (selvom den er sent på formiddagen nu (11:21)) i forhold til, hvor sent jeg gik i seng.. ..Tja, og dog.. Det burde ikke gøre den store forskel.. ..Lad mig lige prøve at gå lidt rundt om mig selv for at prøve at få tankerne/hjernen i gang.. ...(11:41) Min hjerne er stadig ret sløv, men det er meget simpelt, så jeg tror jeg har den nu..:
I think I'm very close to have figured out a good strategy (for showing self-adjointness). I think I figured out yesterday (getting the final realizations at half past one or so, at night). The first point is that, continuing from the realizations of the last two paragraphs, any $V$-joining state can be reinterpreted as a superposition of states with their head at one level only, and who then ``joins $V$'' (completely) immediately after that. Cause if the head consist of parts on multiple levels, you can split them up. And if a head (part) has a tail that joins $V$ over a finite number of levels greater than one (or two, if one will, since the tail is either at all odd or all even levels above the head (which is on a level of the same parity)), then one can also just split the state up and reinterpret it as a superposition, right?\,.\,. .\,.\,Yeah, cause again: if you have part of a tail that is not in $V$, then it will cause an increase in the image, at least as big as the part it cancels at the level below, and if the image has to be finite, then so does the total production it cancels. Okay, so it wasn't actually a totally trivial argument, and it was okay that I took some time to find it again.\,:) (11:55) (.\,.\,See the source code comments for context for this last sentence).\,. .\,.\,And if the production it cancels is finite, you could have chosen to not cancel it, by which the state would join $V$ immediately, and therefore you can then split it up and into such a state, plus another state that now joins $V$ over the same finite number of levels minus one. You can repeat this process and thus reinterpret the state as a superposition of one-level head who join $V$ immediately. 

So far, so good. And what I found out a little later on my (second) walk yesterday is that any states with overlapping (one-level) heads can be reinterpreted such that no heads are overlapping, which is also nice. Okay. Later on (also at the end of a (third) little walk) I then got the idea, which will sorta return to in a moment, that states that are not in Dom($A$), and who avoids the immediate danger that will cause an unbounded functional (i.e.\ that functional, you know which, from Hall), will then have to only have a finite part of its production that is not canceled by areas conforming to $V$ (at the next level of the tail at least). I thought one could then reinterpret these finite parts as new states somehow, and thought I had solved it, but I realized a little later that it took some more thought. So I thought a little more last night, sorta put a puase on it until next morning (today), but then I actually had some good ideas after that anyway. I was also unsure last evening/night that we could always cross out the infinite-image states of Dom($A^*$), and thought I would be able to see that quickly in the morning today, and indeed I do: The infinite-image states cannot be part of Dom($A^*$). I actually had the idea for arguing this last night, but I still felt I needed to think about it again this morning. The argument is simple: you just approximate the bare wave function that has an infinite inner product with the image more and more, and make sure that the tails of each part of it leaves more and more of the approximate bare state's image be. Then the series that approximate this bare state (and with bare, I guess I just mean one without any (production-canceling) ``tail'' (i.e.\ specifically constructed for that purpose) on it). So we can cross out all states with infinite image under $A$ from Dom($A^*$). We can also show that for all states in Dom($A$), the functional (from Hall) is bounded by the norm of the image under $A$ for that state. So now we only need to show that all states that does not join $V$, and who has finite image under $A$, are not in Dom($A^*$). 

First we can then reinterpret each such state as a superposition of a $V$-joining state plus the rest. The rest will thus have a part whose tail does not conform to $V$. But if an infinite part of the production (one level up from the part of the head we are looking at) is canceled by wrong tails, then we get immediately that that state cannot be in Dom($A^*$). So otherwise we must be able to divide the productions into two parts, which might be overlapping, by the way: one that is infinite and cancels by a tail who at least on the first level of it (two levels up) conforms to $V$, and one part that is finite who is canceled exclusively by wrong tail areas on that first level of the tail from there (two levels up, i.e.). I realized last night, not long before I went to bed, that the argument from there should then be to consider the fact that the smaller the finite (``wrong''/``illegal'') part is, the larger image will be caused by the part that conforms to $V$ on the first level of its tail. But unless the finite part at some point becomes smaller and smaller, if you look at each finite part of each level (since the finite part of each level will itself be a non-$V$-joining state, which means that it can then again only have a finite part of its production that does not conform to $V$ at first, and this will thus go on and on, unless the state joins $V$ completely), then the state cannot be in Dom($A^*$) either, since we can exploit each part of it in the functional. So the point of ``making $V$ tough'' on ``wrong states'' is actually to have these two exploitation opportunities battle in a losing battle for all non-$V$-joining states. 

In a more clear argument, one should then first argue that all parts of a state's image under $A$ can be exploited for increasing the functional from Hall, and all productions that are canceled in the image but by the wrong tails can also be exploited to increase the functional. If we construct a ``tough'' $V$, then one should then be able to find a lower bound for how fast the aforementioned ``finite part'' (i.e.\ the one with the ``wrong tail'') has to approach 0, unless the image will diverge for all the $V$-conforming productions, when (squared and) summed over all levels (summing an infinite number of finite values). And with a tough enough $V$, this ``wrong'' part thus has to go to 0 at some minimal rate at least. And will we then be able to show, that if this is the case, then that state will actually be able to be reinterpreted as a superposition of $V$-joining states?\,.\,. Hm, it probably takes a little more care, since there are many options for how an ``illegal'' state can break the rules at each level, which gives a lot of combinations.\,. .\,.\,Yeah, so let me think more about this today.\,. %And I might actually take a walk (or perhaps bike ride) to the center soon (maybe..).. (12:44)

(04.07.22, 16:22) On a walk earlier I had the idea that maybe it would be a good idea to be so ``tough'' on states that follow $V$ for a while (maybe just for one level) and then breaks off again, making sure that their minimal cost of joining $V$ is at least the size of the production which the tail canceled originally. Now that I write this, I realize that I need a bit more to this argument, but the point with doing is that states that kill part of their production with such conforming-to-$V$-only-for-a-while states will not be able to achieve any decrease in their image by this, and so they have to kill all but a finite part of their productions with $V$-joining (and staying there) states. At least that was the idea, but why should those states that breaks off join $V$ again after that (if we are talking about an overall ``illegal'' state anyway)?\,.\,. 

.\,.\,I should think about this, but I want to mention something else that I just had the idea for (before returning here to write): By making sure that the cost of joining $V$ incr.\,. wait, is this even necessary.\,.\,?\,.\,. %(16:32)
.\,.\,Hm no, maybe not.\,. It regards the upper bound on the functional (in Hall) for states that are themselves in Dom($A$). There is a bound equal to the image of the state, at least if the series that tries to maximize the functional does not ``try to''.\,. .\,.\,Hm, try to create a contribution at each (photon-number) level that is ``caught'' and canceled by the next level each time, but where the states in the series try to keep renewing that contribution at each level. But this then need to be kept up for all the infinite number of levels, otherwise said contribution will be canceled at some point, and we are back to the same upper bound. I just had an idea about being tougher and tougher for each level, but this is not necessary after all, since any state that tries to keep this game up for an infinite number of levels will get an infinite norm (I think this will be very easy to see). So never mind. %(16:41)

And back to the question of the previous paragraph (before the one I just concluded).\,. 

(05.07.22, 13:18) Very good news: I realized some days ago that the spooky action at a distance actually leads to a paradox, which would be a very large critique point (or how to say it in English) for my theory (at least until one can confirm the Lorentz covariance). But yesterday evening (a couple of minutes after having a wrong realization that made me think that I had solved the self-adjointness proof (which I think I have solved now, or more precisely yesterday evening/night)) I had the idea that maybe the paradox can be lifted by the fact that the fermion--photon (Dirac) interaction isn't local in position space. I thought more about it and read a bit in Lancaster and Blundell (without much gained from that reading, though.\,.), and I concluded that, yes, the paradox might be lifted (seemingly) by this. Then I have just done some calculations this midday, where I have looked at calculating $\braket{0 | \exp(i\hat \phi(0) \tau) \exp(i\hat H_0 t) 
	\hat \phi(\mathbf{x}) 
\exp(-i\hat H_0 t)} \exp(-i\hat \phi(0) \tau) | 0
$
to first order in $\tau$. For $t>0$, I can't quite carry it through, but for $t=0$, I get the first-order term to be $\sim \tau (4\pi)/x^2$. And yeah, this actually gives a very good counter-argument against (otherwise-)paradox, since the change in energy that the fermion far away sees for the Coulomb potential, but shouldn't react to according to the Lorentz covariance, goes as $\sim v dt/x^2$.\,.\,!\,! %(13:35)

So there is no longer any immediate (and quite disturbing (otherwise, i.e.)) paradox!

Great news! But let me then go back to the self-adjointness problem. Last evening/night I think I figured it out. 

I am right about the idea that any production that is canceled by a wrong tail (that only needs to be wrong on the next level (namely since $V$-joined states should always have the freedom of canceling productions completely, once they've joined; they just have to do it while keeping to the designated ball for that area (but that ball can be very large))) can be exploited just as if it was left as part of the image. I can also use the idea from yesterday which ensures that.\,. Hm, maybe I should think more about that again, but let's see; let me continue with something else now.\,. Hm, if we disregard the $V$-breaking tails for a while, then.\,. Hm, and just assume that they are not there, or that they always only cancel a finite part of any production (if the state should have any hope of being in Dom($A^*$)), then an infinite part of the production will be canceled by $V$-joining tails, and a finte part will be canceled by a wrong tail. We can then choose $V$ to ``be tough'' on certain head states, meaning that is wrong to cancel any part of a certain radius of the head state's production. This means that one can exploit at least this ball of productions from the head in the functional (from that definition in Hall); either that production is left be in the image or canceled by a wrong tail, and in both cases the bound on the functional will increase by that much. And if you then punish wrong tails, you can thus make sure that the ``wrong tails'' have to be less and less of a part of the overall state as we go through the levels (\emph{if} the state is assumed to be a member of Dom($A^*$)). Okay, and what about the $V$-breaking tails.\,.\,? .\,.\,Well we can indeed do something similar for those, meaning that they are all ``punished by $V$'' such that, if the overall state is assumed to be a member of Dom($A^*$), then the $V$(-joining-and-)-breaking(-away-from) states can be ensured to only be able to cancel a finite part of any given production, and less and less so for increasing (photon-number) levels (after a certain point). Therefore, all states in Dom($A^*$) can then be reintepreted at every level as a $V$-joining (and staying there) state plus something else that is finite (and is also decreasing in size for increasing levels after some point), which can then again be reinterpreted in the same way at the next level, and so on. This means that that state will actually be in Dom($A$), and thus $\mathrm{Dom}(A^*)\subset\mathrm{Dom}(A)$, meaning $\mathrm{Dom}(A^*)=\mathrm{Dom}(A)$.\,:) (14:05)

\section{Regarding the paradox that seemed to be \ldots}

Regarding that paradox that seemed to be, I made a mistake in my calculations, it seems, since I forgot a factor of $-i$ on the $\sim 1/x^2$ result, that makes the term cancel when you add the complex conjugate. But there are other ways to get an instant action over a long distance. I thought about last evening and it seems that perturbation of the photonic states going roughly as $\ket{0} + c\int d\mathbf{k}\, k^{-2} \ket{\mathbf{k}}$ for some constant $c$ would not be a bad guess (or at least a completely unfounded one), when some limiting function is also included (to make it converge), I guess. But this gives a calculation that I can't easily be done, if at all. So let us just say that the vacuum is perturbed as $\sim \ket{0} + c\int d\mathbf{k}\, k^{-1} \ket{\mathbf{k}}$ with some limits (UV and IR.\,. no, only UV is needed in this case.\,.) on the integral, namely by a fermion fixed at $\mathbf{x}=0$. When then perturbing this (``perturbed'') state (further) with $\exp[-i\hat\phi(\mathbf{r})\tau]$ and calculating the first-order (in $\tau$) contribution to the expectation value of $\hat \phi(0)$ at the same time $t=0$ (just after the $\hat\phi(\mathbf{r})$ perturbation) (cause then I can do the calculation, I think), then I think one will get a contribution going as $\sim 1/x$. I could try to do these calculations, but I think.\,. Oh well, no.\,. I probably should do that calculation. I'll do that when I get the time (unless I find another confirmation that you can indeed get such action over a distance (seemingly)).\,. (06.07.22, 11:33)


\section{Additional notes}

(16.07.22) See \texttt{draft4.tex} at the end of the section that is now called ``Brainstormy: Lorentz covariance of the reduced Hilbert space'' for some notes on how to prove unitarity of the Lorentz transformation, as well as uniqueness of the continuum limit of that transformation. 


(18.07.22) The shapes in $(\omega, \mathbf{k})$ space I have now called $\widetilde X$ and $\widetilde X'$ in a section in \texttt{draft4.tex}. I have realized that (if these volumes denotes where the coupling ($q_F$) is not turned down) these shapes should both be broadest at the $\omega = k$ line (in order for the $\mu\in\{0,3\}$ part of the argument to work). And the largest $k$ in those shapes should of course be where the $q_F$ cutoff (that I use for analyzing $V(\mathbf{\bar x})$) is made (if this becomes important.\,.). %(10:31)

%(12:39):
(19.07.22) I've realized that it is actually wrong, the whole thing about being able to choose an offset for all the $\omega$ ranges (for each $\mathbf{k}$, as i have thought until now). The only viable offset is actually where $\omega_{min} = \delta\omega/2$. But this only affects my Lorentz-covariance-of-reduced-Hamiltonian argument, and for this, one can just make sure that $\delta\omega$ divides.\,. hm, wait.\,. No, that idea would only work if $\omega_{min} = 0$.\,. .\,.\,Yeah, and that's really no good.\,. Hm, but as I just wrote in some comments in the draft(5) document, it shouldn't even be necessary since you can always just do a more complicated definition of $a_{\mathbf{k}}$ and $b_{\mathbf{k}}$ (see \texttt{draft5.tex}) so that you get the same.\,. in fact \emph{exactly} the same result, since the previous argument also only works exactly when one takes the $\omega_{max}\to\infty$ limit. 



(25.07.22, 15:17)
I have some additional notes in Danish in draft5 from today (just now). I actually seem to need another assumption for the Lorentz transformation in order to be able to pick a unique, call it $\hat S_{red}$ (where $\hat S$ then denotes the Lorentz transformation (with implicit $\mathbf{v}$)): We need to assume that $\hat S$ is a continuous map around states that are close to the $\hat\Pi_{0} = \hat\Pi_{3} = 0$-wave in Fourier space. If we do that, Proposition 7.16 in Hall will let us pick $\hat S_{red}$ out from a spectral subspaces in the neighborhood of the $\hat\Pi_{0} = \hat\Pi_{3} = 0$ (``generalized'') state (i.e.\ as a limit where the spectral subspaces are chosen closer and closer to $\hat\Pi_{0} = \hat\Pi_{3} = 0$). As I just wrote in the out-commented comments in Danish, the reason why I think that this can be proven to be true --- and that it should not add too much extra work if one has already completed my proof strategy for the.\,. well completed the ``big lemmas'' in the strategy, where one shows that the Lorentz transformation can be approximated with integrals over a finite amount of $(\omega, \mathbf{k})$-parameters/components (and that the shapes of these areas can match for two inertial systems) --- is the following. I believe that it will be fairly easy to then show (well, if one has not already done so.\,. which one might.\,.) that any localized initial state in the $\widetilde A_0$--$\widetilde A_3$ that is also pretty localized in Fourier space (such as i nice old (real) Gaussian or a step function) will have a final state that decreases exponentially (in space) after some point. And since a close-to-$\hat\Pi_{0} = \hat\Pi_{3} = 0$ function can be constructed as a sum/integral over such, then one can see from this fact that for any point in the $\widetilde A_0$--$\widetilde A_3$ plane, the final state of an initial close-to-$\hat\Pi_{0} = \hat\Pi_{3} = 0$ state will only have significant contributions in that point from initial localized states (i.e.\ those that resolve the full initial close-to-$\hat\Pi_{0} = \hat\Pi_{3} = 0$ state) that are localized relatively close to that final point. In other words, localized initial states will not propagate far, and significant contributions to the final states will thus ``not have come from far away.'' And from this, one must be able to show that for any final point, their will be no non-continuous jump if we approach the $\hat\Pi_{0} = \hat\Pi_{3} = 0$ state from one side compared to another; all point of the final state will be approximately the same for all (full) initial states that are close to the $\hat\Pi_{0} = \hat\Pi_{3} = 0$ point. And there we go: that was what we want to show. Once we have shown that, then we can pick out $\hat S_{red}$ from the neighborhood of $\hat\Pi_{0} = \hat\Pi_{3} = 0$, namely since the $\hat S_{red}$s we can ``pick out'' will converge when we approach $\hat\Pi_{0} = \hat\Pi_{3} = 0$ (from any side). %(15:44)


(02.08.22, 8:26) I have some new important notes in draft5.tex. I will not repeat them here, but let me just copy the rendered paragrph I just wrote. The mentions of comments refers to the comments above the original paragraph in \texttt{draft5.tex}:

``\ \ Oh, I have some really good news that I have written about in the comments above this paragraph in the source file *[in \texttt{draft5.tex}]. I believe I might have ``solved the vacuum,'' as one might boldly say. I actually don't want to repeat myself too much. Let me just summarize that the ``big idea'' actually just is to time the ``vacuum Hamiltonian'' with $\sqrt{\delta k^3}$ and see that this gives it a continuum limit. That must mean that the dynamics of the discretized version is the same as the continuum limit, at least when we are close enough to that limit, i.e., only with potentially a constant energy difference, as well as a different factor on the energy of $\sqrt{\delta k^3}$. And then one just need to put the vacuum and the ``real'' Hamiltonian together, first without interaction or interference (due to the particles being fermions), and then you add the interactions and terms that.\,. makes them interfere.\,. Hm, I should think a little about that.\,. .\,.\,Well, let me just write first that the interactions (between the vacuum (ground) state (i.e.\ the perturbed ground state) and the ``real'' states (or the ``real world states'')) can be seen to vanish when $\delta k \to 0$. .\,.\,Oh, and let me just note (also since I left it as an open question yesterday afternoon/evening in the comments above) that you put the vacuum Hamiltonian without the $\sqrt{\delta k^3}$ factor together with the ``real part'' (hm, that sound confusing, but it'll do for here and now), i.e.\ the rest of it. The point about multiplying with that factor is only to see that there is a well-defined limit of the dynamics (if we look past the higher and higher energy --- although if we just add a constant to make sure that the ground state is renormalized to 0 energi, and since we don't expect any transitions to occur near the continuum limit, then the limit will just be an actual, normal limit: the ground state will converge to a certain state and its energy will converge to 0 (by construction)). This gives us the very important ability to look at the vacuum state as something rather constant, and where one can separate it as a sum of $n$-particle states (i.e.\ the vacuum state lives neatly inside a Fock space). %(8:11)
Okay, but let me just think about how to argue (with my process of analyzing the continuum limit of an operator (where one checks that almost eigenvectors turn into almost eigenvectors)).\,. .\,.\,Ah, yeah, you can indeed just ``add the interference'' by removing certain transitions from the full Hamiltonian, sure. And thus you can compare the two Hamiltonians, with or without the interference between the ``vacuum'' and the ``real world'' fermions, and see that the removed/added transitions in the full Hamiltonian will only cause/remove transitions with vanishing amplitude (and probability) in the continuum limit.\,. Let me just check to make sure that that is true (for the interference terms; I'm pretty sure about the interaction terms).\,. %(8:22)
.\,.\,Sure. It must be true for the interference also.\,.\,:)\ \ ''

%(8:32):
\ldots I think I might leave the proof of this vacuum solution out of the article, namely because then the article is just limited to the main part, which introduces and shows my overall idea, and also talk about how to potentially continue from there, but the actual continuation can then be seen as a separate part. And I think it is a good idea to separate it thus (plus I want to finish the first publication soon, but in and of itself, I also think it is a good idea to separate it: then if I make some big errors in the rest, then the paper want loose its value (where I would have to rewrite it as a reduced version afterwards)). But since I now once again believe that I have actually ``solved the whole thing,'' so to speak, I intend to sell the paper the same way: I have a new theory that I believe can be proven to be Lorentz-covariant, and which (importantly) is mathematically well-defined (i.e.\ once that is proven). I then leave some parts of the overall prove for future papers, but where it is also something that i truly (and I have been very honest in my analysis; I have not closed my eyes for anything (on the contrary: I think I'm quite good at being self-critical.\,. (and I see that as a very important skill, especially given how I work (i.e.\ by my self (which hopefully will chance soon, though.\,.))))). So yeah, I think that is the best course of action.\,:)


(18.08.22) I don't think my argument that I've written (a little) about here in the above paragraphs works after all. But now I have figured out what to do instead. One can read about my solution (in Danish source file comments, though) in the (backup) file called \texttt{draft6\_05.tex}. There might also be some new ideas/corrections in the \texttt{draft5\_97.tex} backup (final version of that file), which I maybe have not mentioned in this document. (I general there are of course a lot of things that I haven't mentioned here in those draft-files, but most of it goes without saying: Of course one should read my article drafts to understand the current progress of the project.) %(13:20)

(26.08.22) I think I have figured out what to do now.:) One can read about it in the source comments in \texttt{draft6.tex}, but let me also just copy those comments (the most relevant ones) below this paragraph (also as source-file comments). They're mostly in English but the last ones about Lorentz covariance are in Danish. 

%Copied from draft6.tex:
	%I have a new exciting idea for how one potentially might be able to solve this problem of making the Dirac sea reinterpretation. In short, the idea is to first break the momentum preservation slightly for the interactions (Dirac and Coulomb), such that they get the same amount of DoF as there are particles and such that the factor in front of the discretized interaction becomes (\delta k^3)^{n/2} instead of (\delta k^3)^{n/2 - 1}, where n is the DoF (degrees of freedom (or number of ladder operators in the terms of the interaction Hamiltonian)). To "break the momentum preservation" more specifically means to replace the implicit delta functions with localized (small-width/deviation/variance) functions. Now, it seams that if you then keep the "width"(/deviation/variance) constant on these functions but let \delta k \to 0, then the continuum limit will likely "fit" in/on a Fock space. So when we let \delta k approach 0 a lot faster then we let said "width" tend to 0, then it seems that the interference between the real-world and the vacuum particles will effectively vanish.(!!) (This would be SO great; it is a big part of what has troubled me in the past day or two..!!) Now, at the same time, if the mentioned "width" becomes smaller and smaller, it seems that the theory will be "more and more Lorentz-covariant," though we of course have not yet concluded that this sequence of "more and more Lorentz-covariant" theories will converge (to some unique theory). But!: It seems reasonable, as far as I can see, to expect that we would get the same result in terms of the vanishing interaction between the vacuum particles and the "physical" ones, namely the thing that I have written about above. In other words, it seems reasonable to expect that when the "width" tends to zero (with \delta k tending to zero way faster (or tending to 0 at each step of the limit where the "width" goes to zero, if one wants to look at it like that)), you would get energy gaps that tend to infinity, and that you would be able to conclude that the transition amplitudes therefore vanishes, despite the coupling strength of the transitions converging (i.e. similarly to what I have argued a couple of days ago for the case with exact momentum preservation). So yeah, big news..!! Now I have to think about how to potentially correct the proof of the vanishing interaction, i.e. for this new case where there is a break of the momentum preservation which tends to zero, with \delta k tending to zero much faster. And if the proof turns out to be simple enough, I might then consider including it in the paper, but to be honest, I think I will probably leave all this to future work (and simply conclude the article with \hat H_{CL}, and not write \hat H_{QED} up expl.. well maybe I will write it up as a suggestion for what could be, and then talk about how I intend to prove it in the "Future work" section..).. The \hat H_{QED} that I expect to come out of these new ideas, is.. the same one right (with the vacuum-perturbing terms removed)..? (16:05) ..Yes indeed, and I can by the way see how the proof of Lorentz covariance would work from there --- potentially pretty smoothly..:) ..Great..:) (16:08, 25.08.22) *(Oh, and let me just clarify: The reason I believe all this works is that I believe the Hamiltonian with the finite "width" to have a self-adjoint continuum limit, which means that the number of vacuum particels can be capped, causing only an error to the dynamics that vanishes as that cap (/bound) tends toward infinity. (And with a cap on the vacuum particle number, one would e.g. expect that there interference with the RW particles vanishes when \delta k \to 0.))
	%
	%[...]
	%
	%Maybe one doesn't even need to send the "width" to zero before the interaction vanishies: Maybe it vanishes as \delta k goes to zero.. at least if you do an experiment with an offset from the \mathbf{x}=0 center of the system that is always, let's say 1 \%, from the center (meaning a growing distance from center as \delta k \to 0). And the way to show this can then be simply to use that all wave functions will be more an more "boosted" in k-space for such experiments (when \delta k tends toward zero and the offset grows in distance). And one will then be able to show, for the constant "width," that all transition amplitudes of such experiments will go to zero, namely simply because the coupling stregths must go to zero (since the finite "width" (i.e. of the almost-delta function that replaces the delta function to break momentum preservation slightly) will mean that the momentum states are "mixed" in the transition, and since the phase oscillates more and more rapidly (in k-space) as \delta k \to 0, this "mixing" must then make the transition amplitudes vanish more and more). ..So I think this will simply be my argument.:) And I \emph{can} then include (just a brief version, similar to the brief overall explaination that I have just given in these comments, of) this argument in this section.:) (..!) All I then have to think about now, it seems, is to figure out how exactly my Lo. cov. argument then goes (to wrap the argument up). So let me think about that now.. :) (9:25) *((10:24) Oh, and I perhaps forgot to mention that the intuition for why you would expect less and less interaction when \delta k \to 0, is that this should make \mathcal{V} grow while the number of vacuum particles should remain constant (probabilitywise), which intuitively should make it less and less likely that the.. vacuum and the RW particles "meet," so to speak.)
	%
	%[..] 
	%
	%(9:43) Ah, men Lorentz-transformations-processen kan jo så bare indebære, at man også vælger en "width" og så i øvrigt også indsætter den vakuum-grundtilstand der hører til det width. Og når man transformerer, så må man vel uanset hvad (?..) få en tilstand, som består af.. hm, af "vakuum-grundtilstanden" plus en RW-tilstand eller bare af "en eller anden vakuumtilstand" plus en RW-tilstand?.. ..Hm, pointen er vel lidt, at alle "vakuumtilstande" nu i princippet kan tolkes som RW-tilstande, så hvad siger jeg lige..?.. (9:50) ..Hm, man må vel trace'e over alle "ikke-eksperiment-partikler" (eller hvad man skal sige; 'man skal vel "måle på" alle disse partikler,' kunne man også sige..)..(?) ..Ja, og det svarer jo bare til at trace over alle partikler, der ligger uden for eksperimentet; det vil alle "vakuum-partikler" så gøre med større og større sandsynlighed. ..Ja, det lugter jo virkeligt af noget godt, det her.. Og så må man nemlig kunne bruge at, jamen, der er jo ingen der siger, at den Lorentz-transformerede tilstand skal være unik (selvom al fysisk intuition siger, at den må være det (man det behøver ikke at være et krav, alligevel)), så længe den bare opfylder det, den skal opfylde (i.e. giver de samme målingssandsynligheder i diverse lokaliserede rumtidsvolumener i begge systemer). Og ja, er der så overhovedet næsten mere at sige om det..?:) (10:10) ..Hm, jeg bør måske lige overveje og gennemgå (overfladisk), hvad mine generelle Lo.-cov.-argumenter indeholder.. ..(og at/om det ikke forstyrrer disse, at eksperimenter skal gøres off-center..) ...(10:31) Hm, men kan det egentligt ikke være, at jeg kun skal bruge de argumenter for \hat H_{CL} (hvor eksperimenterne ikke behøver være off-center for at beviset vil holde), og at man jo bare måske kan nøjes med at se på \hat U og \hat S (og deres mærkede udgaver) for at vise, at Lo.-covariansen overføres?.. ..(10:36) Ah. Man formår jo hermed at vise, at \hat H_{QED} vil være mere og mere Lorentz-covariant, jo længere man kommer fra \mathbf{x}-origoet, men fordi \hat H_{QED} samtidigt nemt kan ses at være translations-covariant, så må det jo følge at \hat H_{QED} er Lorentz-covariant over det hele.!:D (10:39)

%Copied from draft6.tex:
(28.08.22) I have new important notes in \texttt{draft6.tex}. My recent solution did not hold: I do not know how to solve the vacuum. But that's fine (though it would of course have been \emph{great} if I could do that) cause at least I can now see how the apparent singularity of the ``vacuum(-perturbing) terms'' can be handled. And thus, though I probably cannot solve the vacuum myself (and it seems that it \emph{does} need to be solve: it seems that one cannot remove/ignore the ``vacuum terms'' after all), I can see that it is a problem that might not be infeasible. We may very well be able to solve it (somebody might) in the future, and if we are lucky, ``we'' (as a (global) civilization) will also be able to show that the vacuum ground state (when perhaps limited to a bounded space such that it can ``fit inside'' a Fock space) Lorentz-transforms to itself. And in that case, the Lorentz covariance of the resulting theory (where one includes the obtained vacuum ground state) will be quite easy to show. Let me now just include the relevant notes from \texttt{draft6.tex}, including the source file comments, which should explain any additional detail (overall) that I have not mentioned in this paragraph. I'll insert that here below:

%Copied from draft6.tex:
{\itshape 
	%(28.08.22, 10:04) Okay, det holder ikke, men lad mig lige tage det lidt i kronologisk. I går aftes kom jeg i tanke om, at man jo kan omskrive operatorerne til baser, der består af rumligt lokale bølgefunktioner. Og ja, pga. Lo.-covariansen af \hat S ved man så at matrixelementerne imellem rumligt meget adskildte (fermion-)bølgefunktioner vil dø ud.. Så det virkede jo meget lovende. Jeg kom også i tanke om, at man jo ligefrem kan omkrive hæve-sænke-operatorerne til andre baser, og jeg fik bekræftet at dette er ligetil at gøre både for bosoniske og fermioniske HS-operatorer. *(Nå ja, og lad mig i øvrigt også lige nævne, at hvis man bare stadig adskiller alle positiv- og negative-energi-løsninger, så kan man sagtens "konjugere" teorien i en sådan ny base, hvor man altså bare flipper de nye.. ja, hvad der svarer til de gamle \hat d-operatorer (men i den nye basis).) Nå, men senere ud på natten (gik nemlig først i seng sent; ved to-tiden) kom jeg jo så til at tænke på, at man fra dette jo lidt kommer frem til, at vakuumpartiklerne \emph{må} få en indflydelse (for det ser de ud til at gøre, når man kigger på Hamilton-operatoren i sådanne rum-lokale baser). Og efter lidt tænkeri, og der blev klokken vist tyve i et, kom jeg så frem til, hvad der er galt:
	%Når man bryder impulsbevarelsen på den måde (med en endelig "width"), så svarer det jo til at viske alle interaktioner mere og mere ud, jo længere man går "off-center," i.e. jo længere man går væk fra \mathbf{x}-origo. Og det er jo så derfor, jeg får, at der pludseligt bliver endeligt mange vakuumpartikler; det gør der netop fordi man visker matrix-elementer ud i \hat H, så den bliver mere og mere lokal. Og helt specifikt holder mit argument så ikke, fordi man jo netop ikke bare kan lave sine eksperimenter længere og længere væk fra center/x-origo, når \delta k \to 0, nemlig da der jo som sagt ikke længere er translationssymmetri. Så ja, så simpelt er det; mit trick om at bryde impulsbevarelsen svarer bare til at dæmpe Hamilton-operatoren, jo længere man kommer væk fra x-origo, og så er det jo klart, at man derved kan opnå, at der bliver et endeligt antal vakuumpartikler (som der nemlig gør). 
	%
	%Og nu ser det så faktisk i høj grad ud til, at man faktisk skal løse vakuumet i teorien, hvis man skal opnå den eksakte teori for \hat H_{QED}. (10:22) 
	%
	%Hertil kan jeg så nævne, at det jo måske kunne betale sig netop at se på sådanne rum-lokale baser, hvor matrix-elementerne aftager kraftigt på tværs af bølgefunktionsgrupper, der ligger langt fra hinanden. Jeg tænker i øvrigt lidt på en base, hvor man først deler hele k-rummet op i små intervaller, og så bagefter opløser hvert interval i cos/sin/\exp(i \cdot)-funktioner (af \mathbf{k} over det pågældende interval). Men ja, det er slet ikke sikkert, at det er den smarteste base at regne på. Men ja, håbet er jo så, at man kan finde frem til en translatorisk symmetrisk --- eller måske rettere periodisk, hvis man bruger en base, der er, ja, periodisk --- grundtilstand.. Hm, i virkeligheden kan det jo også være, at det er smartest at regne i en slags x-base (altså med delta-agtige (generelisrede) basis-vektorer). ..Men ja, håber er så at finde en grundtilstand, der bare følger et fast møster i x-rummet, således at man nemt kan udvide den til, hvor stort et rum det end skal være, og hvor man så modsat (hvad der er mere vigtigt på en måde) også altid ved, hvordan man skal approksimere denne vakuumtilstand på et lokalt udsnit af rummet (hvilket så netop (forhåbentligt) vil kunne gøres arbitrært præcist..). Men ja, alt dette bliver så selvsagt "fremtidigt arbejde" (som jeg så i dette tilfælde \emph{ikke} ved så meget om, hvordan man gennemfører).. 
	%Jeg kan dog også lige nævne, at det til gengæld så er fornuftigt nok at formode, at vakuumet lokalt set vil være meget tæt på det bare vakuum, og dermed at den gængse procedure fra gængs QFT (sålænge man bare laver alle nødvendige cutoffs og ikke genererer unødvendige divergenser, man sagtens kunne have undgået --- nå ja, og så længe man så også tager højde for, at der kan blive en ekstra konstant energi, der afhænger af det rumlige cutoff (i.e. det infrarøde "cutoff" (i.e. af \delta k)), fordi man jo skal kende vakuumets energi pr. rum, før man kan trække den fra / (mere realistisk:) lægge den til). Så i praksis kommer det nok ikke til at spille en stor rolle, hvis vi er lang tid om at løse vakuummet.. (10:43) 
	
	(28.08.22) Okay, I have some new important notes in the comments above this paragraph (in Danish). Let me summarize: It seems that the vacuum actually needs to be solved to obtain the exact theory for $\hat H_{QED}$. The good news, however, is that we might be able to do so, in the future --- not that I can promise it, not at all, but it just doesn't necessarily seem like it's gonna be an infeasible problem. And some more good ``news'' (which are not really news, but they kinda are for me.\,. *(No, but I know what I mean.\,.)) are that it probably won't matter too much if it will take us a long time to solve the problem, since coming in with the bare vacuum (like one does conventionally in QFT) probably does not give much of an error overall (and not more than other errors, such at coming in with the bare energy eigenstates instead of the actual ones).\,. .\,.\,Yeah, and that's really all there is to say about it, I guess.\,. %(10:53) 
	*(See also the comments (especially the ones in English) just below this paragraph (in the source file).) %(13:22)
	
	%(12:38) Okay, jeg forestiller mig jo så nu, at det bliver en ret kortfattet sektion, hvor jeg ligesom "antager," at vakuummet kan løses, og at løsningen transformerer til sig selv.. (og så gør det til "fremtidigt arbejde," som jeg så i dette tilfælde ikke selv ved, hvordan man skal løse (ud over mine grundlæggende viden om at prøve at løse sådanne ting, selvfølgelig (hvilket i øvrigt også inkluderer at prøve at bruge computere til hjælp)).) Nu skal jeg så lige have overvejet færdigt, om man så rigtignok får en Lo.-covariant teori, når man har vist dette (i fremtiden), men jeg regner nu ikke med at ville prøve at uddybe de overvejelser i sektionen her.. 
	%
	%...Yeah, well, the Lorentz covariance will be easy to show then: If we can indeed show in the future that there is a nice ground state that can be approximated arbitrarily well with a localized version (in x-space) if the local volume is large enough, and also show that that ground state Loretnz-transforms to itself, well then the proof of Lorentz covariance from there is simply just to define \hat S' (the continuous one) from the (continuous) \hat S, and show that the "conjugated" theory then also have that "\hat S_{-v} \hat U(t') \hat S_v = \hat U(t) [\hat T]" symmetry --- simple as that.. ..Yeah.. ..Well, almost as simple as that: One has to remember, however, that these "continuous" operators (the \hat S's and \hat U's) does need that spatial cutoff(/dampening) to be well-defined for the "conjugated theory" (i.e. where the \hat d-operators are flipped). But assuming that we in the future can indeed show that the theory converges for any localized experiment when said cutoff is sent to infinity (which we can probably show once somebody has/have solved the (pattern of the) vacuum), then all is fine: One can just choose a large enough spatial cutoff (and thus a small enough \delta k --- and/or a small enough "width" (see above or below for what I mean by that)) for any given experiment, and one can then show that this experiment will have the same results (approximately, but with arbitrarily high precision) in a Lorentz-transformed inertial system. There. That's probably all I can and will say about that.. (13:20)
}


%(01.09.22, 7:54) Her er der lige nogle flere noter, kopieret fra draft6.tex (jeg gider ikke lige introducere dem i det renderede, så jeg indsætter dem bare her):
	%(31.08.22, 10:29) It's worth to note that there might be a solution even if the vacuum ground state doesn't converge in the way I have described. Let's say we define the theory by breaking the momentum preservation, taking the $\to \delta$ limit, and using the (well-defined) vacuum ground state (underneath any experiment) at each step towards the limit. We would then like the experiments to have converging predictions, but actually we only need the predictions to have a limit point (one that we can get arbitrarily close to and with arbitrarily small ``width'' of the $\delta$ function). Furthermore, about showing Lorentz covariance, I think one might be able to make an argument that the ground state transforms into itself by using that if it does not, then due to the probability preservation (which one can likely also show), we get a contradiction, namely because of this: If the ground state does not turn into an eigenstate, then the resulting state must.\,. hm, let's see.\,. .\,.\,Hm, maybe I will just get back to this later.\,. %(10:41)
	%%(18:49):
	%\ldots\ Hm, I think it makes sense: If the transformed state is not an eigenstate then it (likely) must have a varying probability distribution (in spacetime). But if you can then show that the transformed state should have the same probability distribution, this will give a contradiction. Hm, and if one makes sure that the ground state has zero energy, it doesn't change phase throughout spacetime, and I think that it's quite likely that one can show that the same must apply for transformed state.\,. I'm not completely sure how (and I don't plan to think much more about it) but it seems reasonable to think that that is the case.\,. .\,.\,And then this way, one might be able to show that the ground state turns into a similar ground state.\,. .\,.\,Hm, and I guess the point is, that one might likely also be able to show that this can be shown to be ``more and more true'' when the ``width'' is sent to 0, but again this is mostly speculation (and I don't intend to think much more about it.\,.). But yeah, if all this is true, then one might only have to (from there) show that the predictions of the sequence of theories (with smaller and smaller ``width'' *(and where the ground state is always chosen as the background (after having subtracted its energy from the Hamiltonian))) have limit points (not necessarily that they converge) in order to show that the theory exists and is Lorentz-covariant. But yeah, this is just a couple of loose thought so far (and as mentioned, and don't plan to think more about them for now), but I thought they were worth mentioning. %(19:04)
	%\ldots\ 
	%(01.09.22, 7:41) And let me just clarify that of course the point is then that it is probably a lot easier to show that the theory, i.e.\ the set of predictions (of which there is a sequence given a sequence of ``widths'' (and/)or $\delta k$s), has limit point rather than showing that it converges, since then you kinda only have to show that it does not diverge to infinity.\,. So yeah, with these thoughts, maybe we don't even need to solve the vacuum to show that a Lorentz-covariant theory exists.\,. .\,.\,Hm, but then again, one would probably want to solve it anyway to have a useful theory. .\,.\,Of course if the sequence of theories does converge, which they ought to in my humble but admittedly biased opinion, then we don't necessarily need to solve the vacuum to have a working theory; one then just need to choose small enough ``widths'' (or $\delta k$s) to get the right predictions.\,. Anyway, but it all still seems like it's not a completely infeasible problem, not at all. But it \emph{is} (seemingly) a way harder problem than what I want (and should) try to throw myself into at this point. So again, I'll leave it here.\,.


\ 

(03.09.22, 14:54) I have just worked out, that we actually need for $k_1$ (which has a range that is a subset of $\mathbb{R}$, not $\mathbb{R}_+$ (that is $k_3$)) to include $k_1 = 0$ in its range, which is fine since we just make sure that $k_3 = 0$ is never included (and therefore we will still never get $k=0$). And for the $\omega$ ranges (which can depend on $k_1$) we need to alternate between including $\omega = 0$ and having the offset at $\delta \omega / 2$ (in the case of $\omega$, not $\omega'$). The grid we then want to draw is thus just a grid of rhombuses where all the edges follow the $k_1'=0$ and $\omega'=0$ lines in the $(k_1, \omega)$ coordinate system. This will do the trick. We won't get the points to align on the $\omega = k_1$ line anymore, but that is also fine; that would make the gauge transformation argument easier, but it will still be able to do an argument anyway, the way I see/predict it. 


(06.09.22, 11:57) There are new changes to my ``$\square^2\lambda = 0$ argument,'' which can be read about in \texttt{draft6}. There was some errors in my old argument, that I think I have fixed now. But I've actually also discovered that maybe I don't need the whole $\square^2\lambda = 0$ argument and all that. I think now that there actually is a much shorter argument where one simply used the fact that the $A_0$--$A_3$-dimensions are separated from the physical part of the state, and that's pretty much all you need to know. Read my notes (rendered this time) in \texttt{draft6.tex} for how this new, much simpler argument goes. I then actually intend to cut out that whole section and just explain the simple argument at the end of the ``reducing $\hat H_{init}$'' section. .\,.\,Hm, I might also just copy in the notes here as well.\,. .\,.\,Hm, actually no: Go to \texttt{draft6.tex} to read the recent development. Okay.:) I'll then change to \texttt{draft7}, now, and start working on this new, perhaps final, structure (/``disposition,'' if you can say that.\,.).\,. :) %(12:07)


(20.09.22) New, important notes in the source file comments below this sentence:


%Kommentarer fra sektion 4 i draft7.tex:
	%(19.09.22, 15:23) Okay, det var lidt kritisk i går. Jeg fandt simpelthen ud af (og det mener jeg stadigvæk.!), at mit continuum-limit-argument, slet ikke holder; ikke bare den version, jeg har skrevet i sektionen, som den er nu, men i det hele taget.! Og dette er virkeligt virkeligt kritisk, for det får endda også mit Lo.-cov.-argument (altså brute force-argumentet, som hører sig til "future work") til at bryde sammen.! Jeg brugte så hele dagen i går på at tænke, men kom ikke rigtigt frem til noget, der holdt. I går aftes kom jeg på, at man måske kunne lave cutoffs på \hat H_D, ift. hvilke k-bølger, de interagerer med, som kunne afhænge af fermionernes \mathbf{p}. Men jeg kom ikke frem til noget. I morges i sengen, nærmest lige efter jeg vågnede (bare et minut efter, eller deromkring) (og uden at drømme om problemet lige inden jeg vågnede), kom jeg så på den idé, at man måske.. Hov, nej: Det jeg lige skrev, det var hvad jeg kom på i morges i sengen, og i går aftes kom jeg bare på at prøve "lave cutoff'et på fermionerne," i stedet for at "lave det på (A^\mu-)k-bølgerne, hvis det giver mening.. Nå, men det har så faktisk vist sig senere (da jeg gik en tænke-tur her i formiddags-middags (vågnede ti-tyve i otte, btw)), at der måske faktisk er en mulighed (heldigvis..!), for at man kan bruge dette i et bevis/argument. Lad mig prøve at forklare:
	%(15:34) Problemet kan sådan set siges at skyldes, at man ikke kan vide, at de almost-egenvektorer, man tilnærmer \mathbf{H}_CL i \mathbf{init}, vil have et konvergerende \hat H_{init} \psi. Og det bryder så mit tidligere argument, for så vil almost-egenvektorer ikke nødvendigvis have en sekvens af vektorer hver især i et element af (\mathbf{H}_{init}(j))-sekvensen, der selv bliver mere og mere almost-egenvektorer i \mathbf{H}_{init}(j) med samme egenværdi. Så argumentet går alstå ikke.
	%Men ved først at nærme sig et cut-off \mathbf{H}_{CL}, hvor fermioner kun interagerer med en delmængde af \mathbf{k}'erne, som dog faktisk vokser (delmængden gør), for voksende p, således at høj-energi-fermioner kan interagere og blive til langt højere-energi-fermioner, langt højere en hvad lav-energi-fermioner kan interagere og blive til.. Jeg tror faktisk, der er en lille mulighed for, at man så herved kan få de approksimerede almost-egenvektorer (der approksimerer vektorer i \mathbf{H}_{CL}) til at konvergere til "mere og mere almost"-egenvektorer (i \mathbf{H}_{init}(j)). Og hvis dette passer, jamen så går det hele måske nok, for så kan man herved opløfte dette specielle cutoff mere og mere, og herved ankomme til \hat H_{CL} i \mathbf{H}_{CL} ud fra almost-egenvektor-til-almost-egenvektor-argumentet. Og det vil så sige, at man må kunne løfte dette cutoff for stiintegralet, men hvor man stadig så får, at man kan sætte et cutoff på \mathbf{k} (hvilket er nødvendigt for mit brute-force-argument), nemlig fordi man ved at teorien så konvergerer i grænsen, når man opløfter cutoff'et. Og når et højt nok \mathbf{k}-cutoff sammen med et højt nok fermion--foton-interaktions-cutoff (det specielle fra nu her (hvis dette kan virke)) så er valgt, jamen så er man herfter fri til at diskretisere \mathbf{k}, og så får man sit ønskede stiintegrale herved (sammen med friheden til at sætte et stort \mathbf{k}-cutoff (og stort fermion--foton-(specielt-)cutoff)), og så kan man så, brute-force style, udlede Lorentz-covariansen herfra. 
	%(15:52) Jeg har dog et lille problem, når jeg tænker over det, med halerne når deres egne produktioner til områder med relativt lave \mathbf{k}-værdier skal kvæles, for det kan nemlig godt være, at min løsning (på \hat H_{CL}'s domæne) også vil foreskrive, at man bruger meget høje k værdier til dette (altså til halen et (eller to, om man vil) niveuer længere oppe), og så duer det jo ikke, for den interaktion har man jo fjernet (altså med overgange fra tilstrækkeligt lave til tilstrækkeligt høje p-tilstande). Så jeg kan altså langt fra sige, at jeg har løst problemet, men jeg har dog i det mindste altså nogle tanker nu, som virker ok lovende --- OK nok for mig på nuværende tidspunkt.
	%(15:57) Og jeg har så tænkt over det, og ja, det er egentligt fint nok: Jeg har jo stadig muligvis løst det at finde et domæne til en selvadjungeret \hat H_{CL}, hvilket er en stor nok bedrigt i sig selv. Så er der så lige en ekstra hurdle, jeg ikke har løst (ikke endnu i hvert fald), men sådan må det jo bare være (der er jo alligvel også en anden hurdle i form af at finde \hat H_{CL}'\equiv \hat H_{QED} i sidste ende). Så jeg må bare sige, at selv hvis min løsning holder, så ligger der altså et yderligere problem omkring at vise, at der hele går glat, når man nærmer sig kontinuumsgrænsen (og specifikt at man kan få det sådan, at almost-egenvektorer kan approksimeres med almost-egenvektorer (med lavere og lavere \varepsilon' \når \varepsilon \to 0 og  j \to \infty)). Dette problem skal løses, hvis mit brute-force-argument skal kunne holde, men hvis det kan løses, så har jeg altså en strategi til et brute-force-argument, jeg tror kan vise Lo.-covariansen matematisk. Bum, så det bliver altså planen..:)..
	%(16:03) Og til sidst skal jeg så også lige sige, at mit argument stadigvæk holder her til slutningen af denne sektion, for her har man nemlig ikke det problem med, at de approksimerede almost-egenvektorers "billede" --- altså \hat H_{init} \psi, rettere (i.e. den vektor, de sendes til) --- ikke også konvergerer. Det vil det gøre. :) (16:05) 
	%..(16:06) Nå ja, og så er min plan også bare at omskrive sektion \ref{section_continuum_limit} så den første del ikke bliver om en "fyldestgørende betingelse," men i stedet bare bliver om en "betingelse, som er fornuftig at kræve/forvente." Og så vil jeg altså bare færdiggøre artiklen på denne måde..:) (16:08)

(26.09.22, 14:12) Apart from the point I have noted in the source file comments just above this paragraph, I should also mention that fact that making the (ball-shaped) $k \leq A$ cutoff also need a little consideration now, but it seems that my idea, which includes a $k$ cutoff, but a different one depending on the fermion's $\mathbf{p}$, and which by the way is unfinished, does not have any trouble with getting this $k \leq A, A \to \infty$ result for the Coulomb interaction.\,. %(14:17)






\chapter{Self-adjointness revisited}


%(12.10.22, 9:20) Okay, I got my paper out yesterday on viXra and on ResearchGate. It was sadly rejected from arXiv due to "not sufficient original and substantive academic research," but oh well.. This suggests that I should probably expect that I have to prove \hat H_{CL}'s self-adjointness in order to better get people's attention. I should also go talk to people I know from NBI about it, but let me just focus on this task for a bit. I have thought a bit about the task yesterday and the day before, but I haven't been able to focus very much. But now I feel focused enough again, and having thought some more about the problem this morning, it seems that there is an issue with my previous argument when it comes to the assumption/conclusion that states that does not "join V" is then forced to keep canceling their productions (completely) in a way such that other \phi-states can exploit the "non-vanishing" (by my assumption/conclusion) sequence of terms in Eq. (3.88) above. In fact, I have just reached the potential conclusion some moments ago, that it might be possible for states to ensure that all such sequences (as Eq. (3.88) is about) will tend to zero, even while the state still almost-cancels its productions enough that the image converges. And a fewer moments ago, just before I startet writing here, I then had the thought, well, cause if one could construct a "symmetric domain" by all such states that makes sure to only "almost-cancel" its productions this way, then it seems that Dom(A^*) will also include states that cancel their productions completely, first of all. And then I naturally asked myself: what about those; which ones of those to then try to include? And immediately I thought that maybe that would then be exactly such a set of states like I have thought about in my previous would-be solution.. So that's where I am now. :) Now I have to think about whether this all makes sense, and if this modified solutionen could potentially work.:).. (9:44) 

(12.10.22, 9:45) I have I few notes in the comments above this initial paragraph, namely about how my previous solution might not work, and what I now plan to think about in order to perhaps fix the solution. Let me return here when I have done that. I think I might start a new document soon and continue working in that, but let's see. 

%(10:33) Hm, I need to also keep in mind that states can also "over-cancel" their productions, but hopefully we will be able to exclude all such states in my solution idea, if it works.. 

(13.10.22, 14:00) Okay, I have thought a bit more about the problem today (it has been hard for me to keep my focus on it), and now it seems that the set of states the ``almost cancels'' their own production does not actually change the picture. It's nice to be aware of that set, but I might actually be back now, where I started this time around, namely where my previous solution might work for all I know, but where I need to investigate it again to find out. Oh, I should mention, however, that I'm not completely sure that my argument for why states with ``an infinite image under the operator'' can be excluded from Dom($A^*$). I may need some additional arguments for that part, but I will see.\,. Right now I should continue by making sure to ``think on the keys'' a lot, as I call it, in order to better keep my focus (which is exactly what that technique is brilliant for).\,. (I'll start doing this in the comments below now.\,.) %(14:08)

%(14:08) Brain: ..Okay, the big thing I need to investigate is how I can get that states that violate "V," which I guess I will just continue to call it for now, will either do so more and more (and such that the terms in Eq. (3.88) can be made bigger and bigger by choosing different \phi's), or "their image" will not converge.. ..Hm, jeg frygter jo lidt, at jeg alligevel har en cirkelslutning her (selvom jeg kan huske, at jeg var opmærksom på denne fare i hvert fald på et eller andet tidspunkt..): "This means that one can exploit at least this ball of productions from the head in the functional (from that definition in Hall); either that production is left be in the image or canceled by a wrong tail, and in both cases the bound on the functional will increase by that much" (kopieret ovenfra). (14:18) ..(14:24) Oh wait, my new "almost-production-canceling states" \emph{does} seem to matter since they seem to disprove my previous "solution," don't they?.. ..Hm, perhaps, but I'm not completely sure.. (14:28) ..Hm, maybe I do need a bit of a break before I can continue with this.. 

\ldots (15:20) Woah, okay, now I just had another idea: Say that we can indeed find a set of ``almost-production-canceling states,'' which more precisely is a set of states that makes sure all states.\,. well, makes sure that even states that just kill their own productions very.\,. brutally, such as e.g.\ states that are constructed to be an eigenvector in a very.\,. false way.\,. even such states that just kill their productions completely for the most part, they will get (perhaps, but we are making that assumption now) a convergent sequence of terms in Eq.\ (3.88). Let me try to rephrase that.\,. .\,.\,A set of states that always leave a little bit of their productions behind, such that even $\phi$'s that cancel their productions pretty much completely will get a Eq.\ (3.88) sequence that tends to zero (not just that the series converges, since it might do that even if the terms converge to a non-zero number (since the sign is alternating in the series)). Now, if we then consider this as a domain for $A$ (or ``$\hat H_{CL}$'' if one will) and look at Theorem 9.21 in Hall, wouldn't we then be able to get arbitrarily close to any momentum almost-eigenstate (after operating with $A \pm i I$) if we start with a $\psi$ of this domain that first of all has a part of it one level above the desired momentum almost-eigenstate that turns into said state via photon absorption?\,.\,. And couldn't we choose a sequence of such $\psi$'s such that the combined productions of each $\psi$ (including those of its ``cancellation tail'') tends to norm zero for the sequence.\,.\,? (15:35) .\,.\,Hm, I kinda don't see why not.\,. \emph{if} this set of ``almost-production-canceling states'' exists and works like I have in mind.\,. %(15:40)


%(I øvrigt: backup-løsener: ord fra barndommen.)
(14.10.22, 9:32) Damn.\,. I thought I had it with this new idea: It still seems to work in my head, except that it also leads to a paradox if it works. If not for that paradox, I would think that it would be possible to construct a domain of such ``almost-production-canceling states'' (and here you then don't have to include every possible one, since the actual domain would be the closure of this domain) such that the operator becomes symmetric and so that one could always get close to any $\phi \in \mathbf{H}$ by choosing a sequence of $(A \pm i I)\psi$'s according to what I wrote yesterday, at the end of the previous paragraph. But when you think about it, it would lead to a paradox that you would then be able to find two $\psi$'s that are almost orthogonal but where the two $(A \pm i I)\psi$'s would be almost parallel. .\,.\,Hm, yeah, it seems fishy.\,. Now, I know that I then need to figure out exactly what goes wrong here in order to better be able to continue my search from there. And I should then also at some point get back to my previous maybe-solution and investigate that more thoroughly, but I can really feel that I need a break now from this project. I have also not received any feedback/comments/questions/answers from anyone yet, so I don't feel like I need to hurry myself particularly. Of course, when I get in tough with someone, especially in terms of mathematicians, I should of course also get back to the problem again, but until then, I think I will try to continue with some of my other projects in the meantime (and hopefully get some energy back in that break when it comes to this project). (9:46)

.\,.\,Oh, I forgot to also mention that yesterday evening I then also ``realized'' that (if not for the fact that I must be wrong about something) it would seem that this new solution would solve ``Task 2'' quite easily, namely since it no longer requires.\,. or at least so it seemed.\,. no longer requires productions to be canceled by absorption of a greater and greater $\mathbf{k}$ (photon) wave vector. .\,.\,And even though there seems to be a paradox with this solution, it's still a nice realization that if one were to find a solution that does not require $\mathbf{k}$ to grow rapidly for each level of the ``cancellation tail,'' one might then be able to solve ``Task 2'' pretty easily.\,. (9:57)


\newpage
\section*{navi.}































\newpage
\ 
\end{document}

